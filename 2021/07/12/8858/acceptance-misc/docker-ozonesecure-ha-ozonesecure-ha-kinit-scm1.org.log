Attaching to ozonesecure-ha_kms_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_om2_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_om3_1, ozonesecure-ha_recon_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_s3g_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_kdc_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_om1_1, ozonesecure-ha_scm1.org_1
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2021-07-12 10:39:04,505 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = ccdb996b39f4/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
datanode2_1  | STARTUP_MSG:   java = 11.0.10
datanode2_1  | ************************************************************/
datanode2_1  | 2021-07-12 10:39:04,597 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2021-07-12 10:39:06,738 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2021-07-12 10:39:07,653 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2021-07-12 10:39:08,543 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2021-07-12 10:39:08,543 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2021-07-12 10:39:09,610 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:ccdb996b39f4 ip:172.25.0.103
datanode2_1  | 2021-07-12 10:39:12,996 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-07-12 10:39:13,951 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2021-07-12 10:39:13,952 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2021-07-12 10:39:15,749 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2021-07-12 10:39:15,790 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2021-07-12 10:39:15,791 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2021-07-12 10:39:15,795 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2021-07-12 10:39:22,757 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2021-07-12 10:39:22,851 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:ccdb996b39f4
datanode2_1  | 2021-07-12 10:39:22,855 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2021-07-12 10:39:22,963 [main] ERROR client.DNCertificateClient: Invalid domain ccdb996b39f4
datanode2_1  | 2021-07-12 10:39:22,964 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@ccdb996b39f4
datanode2_1  | 2021-07-12 10:39:27,087 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2021-07-12 10:39:27,172 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2021-07-12 10:39:27,192 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2615449502355.crt.
datanode2_1  | 2021-07-12 10:39:27,224 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2530584589045.crt.
datanode2_1  | 2021-07-12 10:39:27,224 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2021-07-12 10:39:27,306 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode2_1  | 2021-07-12 10:39:28,112 [main] INFO reflections.Reflections: Reflections took 627 ms to scan 2 urls, producing 84 keys and 166 values 
datanode2_1  | 2021-07-12 10:39:29,550 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2021-07-12 10:39:29,621 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2021-07-12 10:39:29,625 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2021-07-12 10:39:29,679 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2021-07-12 10:39:30,063 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2021-07-12 10:39:30,190 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-07-12 10:39:30,204 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2021-07-12 10:39:30,228 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2021-07-12 10:39:30,229 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2021-07-12 10:39:30,230 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2021-07-12 10:39:30,358 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode2_1  | 2021-07-12 10:39:30,372 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode2_1  | 2021-07-12 10:39:30,377 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2021-07-12 10:39:30,377 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2021-07-12 10:39:36,054 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-07-12 10:39:36,617 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2021-07-12 10:39:37,099 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2021-07-12 10:39:37,099 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2021-07-12 10:39:37,115 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2021-07-12 10:39:37,159 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2021-07-12 10:39:37,161 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-07-12 10:39:37,171 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2021-07-12 10:39:37,175 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-07-12 10:39:43,687 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2021-07-12 10:39:43,691 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-07-12 10:39:43,693 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-07-12 10:39:43,759 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-07-12 10:39:45,729 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2021-07-12 10:39:45,729 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2021-07-12 10:39:45,729 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2021-07-12 10:39:45,862 [main] INFO util.log: Logging initialized @48770ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2021-07-12 10:39:46,296 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2021-07-12 10:39:46,306 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2021-07-12 10:39:46,314 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2021-07-12 10:39:46,319 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2021-07-12 10:39:46,319 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2021-07-12 10:39:46,330 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2021-07-12 10:39:46,600 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2021-07-12 10:39:46,610 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode2_1  | 2021-07-12 10:39:46,813 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2021-07-12 10:39:46,813 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2021-07-12 10:39:46,837 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2021-07-12 10:39:47,019 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-07-12 10:39:47,059 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2e895acb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2021-07-12 10:39:47,059 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@546ca9da{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2021-07-12 10:39:47,764 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-07-12 10:39:47,853 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@9742012{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-10587815766142534743/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2021-07-12 10:39:47,939 [main] INFO server.AbstractConnector: Started ServerConnector@433d5536{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2021-07-12 10:39:47,939 [main] INFO server.Server: Started @50847ms
datanode2_1  | 2021-07-12 10:39:47,942 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2021-07-12 10:39:47,955 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2021-07-12 10:39:47,965 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2021-07-12 10:39:48,228 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a2f0f0a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2021-07-12 10:39:48,670 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2021-07-12 10:39:50,774 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2021-07-12 10:39:50,776 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2021-07-12 10:39:51,099 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode2_1  | 2021-07-12 10:39:51,229 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start RPC server
datanode2_1  | 2021-07-12 10:39:51,249 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: GrpcService started, listening on 9856
datanode2_1  | 2021-07-12 10:39:51,259 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: GrpcService started, listening on 9857
datanode2_1  | 2021-07-12 10:39:51,271 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: GrpcService started, listening on 9858
datanode2_1  | 2021-07-12 10:39:51,323 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6 is started using port 9858 for RATIS
datanode2_1  | 2021-07-12 10:39:51,328 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2021-07-12 10:39:51,328 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2021-07-12 10:39:51,326 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$327/0x00000008405b2040@71cc59ce] INFO util.JvmPauseMonitor: JvmPauseMonitor-dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: Started
datanode2_1  | 2021-07-12 10:39:51,384 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-07-12 10:39:51,384 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-07-12 10:39:54,348 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode2_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:269)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:454)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	... 1 more
datanode2_1  | 2021-07-12 10:39:54,420 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:39:55,400 [Command processor thread] INFO server.RaftServer: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: addNew group-05A9F269F8E5:[dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-05A9F269F8E5:java.util.concurrent.CompletableFuture@6bed47dd[Not completed]
datanode2_1  | 2021-07-12 10:39:55,500 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: new RaftServerImpl for group-05A9F269F8E5:[dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-07-12 10:39:55,504 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-07-12 10:39:55,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-07-12 10:39:55,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-07-12 10:39:55,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-07-12 10:39:55,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-07-12 10:39:55,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-07-12 10:39:55,519 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-07-12 10:39:55,533 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5: ConfigurationManager, init=-1: [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-07-12 10:39:55,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-07-12 10:39:55,536 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-07-12 10:39:55,570 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c72a7bef-074b-455f-a2d4-05a9f269f8e5 does not exist. Creating ...
datanode2_1  | 2021-07-12 10:39:55,603 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c72a7bef-074b-455f-a2d4-05a9f269f8e5/in_use.lock acquired by nodename 7@ccdb996b39f4
datanode2_1  | 2021-07-12 10:39:55,630 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c72a7bef-074b-455f-a2d4-05a9f269f8e5 has been successfully formatted.
datanode2_1  | 2021-07-12 10:39:55,644 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-05A9F269F8E5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-07-12 10:39:55,669 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-07-12 10:39:55,672 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-07-12 10:39:55,774 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-07-12 10:39:55,774 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-07-12 10:39:55,813 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5
datanode2_1  | 2021-07-12 10:39:55,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-07-12 10:39:55,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-07-12 10:39:55,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-07-12 10:39:55,998 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c72a7bef-074b-455f-a2d4-05a9f269f8e5
datanode2_1  | 2021-07-12 10:39:55,998 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-07-12 10:39:56,003 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-07-12 10:39:56,007 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-07-12 10:39:56,012 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-07-12 10:39:56,017 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-07-12 10:39:56,038 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-07-12 10:39:56,038 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-07-12 10:39:56,038 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-07-12 10:39:56,128 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-07-12 10:39:56,141 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-07-12 10:39:56,201 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-07-12 10:39:56,211 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-07-12 10:39:56,261 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2021-07-12 10:39:04,945 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 071a21c71cec/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | 2021-07-12 10:39:56,267 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-07-12 10:39:56,275 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-07-12 10:39:56,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-07-12 10:39:56,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2021-07-12 10:39:04,764 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = f311c7ebb23c/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
datanode3_1  | STARTUP_MSG:   java = 11.0.10
datanode3_1  | ************************************************************/
datanode3_1  | 2021-07-12 10:39:04,854 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2021-07-12 10:39:06,924 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2021-07-12 10:39:07,918 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2021-07-12 10:39:08,766 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2021-07-12 10:39:08,771 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2021-07-12 10:39:09,654 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f311c7ebb23c ip:172.25.0.104
datanode3_1  | 2021-07-12 10:39:12,891 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-07-12 10:39:13,621 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2021-07-12 10:39:13,621 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2021-07-12 10:39:15,445 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2021-07-12 10:39:15,463 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2021-07-12 10:39:15,463 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2021-07-12 10:39:15,464 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2021-07-12 10:39:20,324 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2021-07-12 10:39:20,407 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:f311c7ebb23c
datanode3_1  | 2021-07-12 10:39:20,420 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2021-07-12 10:39:20,422 [main] ERROR client.DNCertificateClient: Invalid domain f311c7ebb23c
datanode3_1  | 2021-07-12 10:39:20,437 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@f311c7ebb23c
datanode3_1  | 2021-07-12 10:39:24,372 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2021-07-12 10:39:24,448 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2021-07-12 10:39:24,463 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2530584589045.crt.
datanode3_1  | 2021-07-12 10:39:24,486 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2612531528108.crt.
datanode3_1  | 2021-07-12 10:39:24,487 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2021-07-12 10:39:24,561 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode3_1  | 2021-07-12 10:39:25,311 [main] INFO reflections.Reflections: Reflections took 565 ms to scan 2 urls, producing 84 keys and 166 values 
datanode3_1  | 2021-07-12 10:39:26,564 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2021-07-12 10:39:26,599 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2021-07-12 10:39:26,612 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2021-07-12 10:39:26,615 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2021-07-12 10:39:26,781 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2021-07-12 10:39:27,008 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-07-12 10:39:27,012 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2021-07-12 10:39:27,023 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2021-07-12 10:39:27,025 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2021-07-12 10:39:27,034 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2021-07-12 10:39:27,222 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode3_1  | 2021-07-12 10:39:27,241 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode3_1  | 2021-07-12 10:39:27,242 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2021-07-12 10:39:27,243 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2021-07-12 10:39:32,845 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-07-12 10:39:33,258 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2021-07-12 10:39:34,346 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2021-07-12 10:39:34,356 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2021-07-12 10:39:34,367 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2021-07-12 10:39:34,397 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2021-07-12 10:39:34,421 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-07-12 10:39:34,436 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2021-07-12 10:39:34,440 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-07-12 10:39:40,107 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2021-07-12 10:39:40,109 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-07-12 10:39:40,109 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-07-12 10:39:40,175 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
datanode1_1  | STARTUP_MSG:   java = 11.0.10
datanode1_1  | ************************************************************/
datanode1_1  | 2021-07-12 10:39:05,062 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2021-07-12 10:39:07,214 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2021-07-12 10:39:07,952 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2021-07-12 10:39:08,706 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2021-07-12 10:39:08,711 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2021-07-12 10:39:09,814 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:071a21c71cec ip:172.25.0.102
datanode1_1  | 2021-07-12 10:39:12,901 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-07-12 10:39:13,842 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2021-07-12 10:39:13,842 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2021-07-12 10:39:15,502 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2021-07-12 10:39:15,504 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2021-07-12 10:39:15,504 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2021-07-12 10:39:15,509 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2021-07-12 10:39:22,365 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2021-07-12 10:39:22,445 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:071a21c71cec
datanode1_1  | 2021-07-12 10:39:22,465 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2021-07-12 10:39:22,494 [main] ERROR client.DNCertificateClient: Invalid domain 071a21c71cec
datanode1_1  | 2021-07-12 10:39:22,497 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@071a21c71cec
datanode1_1  | 2021-07-12 10:39:26,700 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2021-07-12 10:39:26,774 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2021-07-12 10:39:26,810 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2530584589045.crt.
datanode1_1  | 2021-07-12 10:39:26,828 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2614971215607.crt.
datanode1_1  | 2021-07-12 10:39:26,837 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2021-07-12 10:39:26,930 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode1_1  | 2021-07-12 10:39:27,817 [main] INFO reflections.Reflections: Reflections took 727 ms to scan 2 urls, producing 84 keys and 166 values 
datanode1_1  | 2021-07-12 10:39:29,144 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2021-07-12 10:39:29,191 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2021-07-12 10:39:29,194 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2021-07-12 10:39:29,225 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2021-07-12 10:39:29,485 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2021-07-12 10:39:29,698 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-07-12 10:39:29,711 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2021-07-12 10:39:29,724 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2021-07-12 10:39:29,727 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2021-07-12 10:39:29,746 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2021-07-12 10:39:29,870 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode1_1  | 2021-07-12 10:39:29,896 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode1_1  | 2021-07-12 10:39:29,906 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2021-07-12 10:39:29,911 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2021-07-12 10:39:35,815 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-07-12 10:39:36,249 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2021-07-12 10:39:36,989 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2021-07-12 10:39:37,008 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2021-07-12 10:39:56,299 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-07-12 10:39:56,441 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5
datanode2_1  | 2021-07-12 10:39:56,489 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5
datanode2_1  | 2021-07-12 10:39:56,552 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5: start as a follower, conf=-1: [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-07-12 10:39:56,584 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-07-12 10:39:56,585 [pool-23-thread-1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-FollowerState
datanode2_1  | 2021-07-12 10:39:56,616 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-05A9F269F8E5,id=dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode2_1  | 2021-07-12 10:39:56,634 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5
datanode2_1  | 2021-07-12 10:39:56,767 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=c72a7bef-074b-455f-a2d4-05a9f269f8e5
datanode2_1  | 2021-07-12 10:39:56,768 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=c72a7bef-074b-455f-a2d4-05a9f269f8e5.
datanode2_1  | 2021-07-12 10:39:56,769 [Command processor thread] INFO server.RaftServer: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: addNew group-8025B34C7403:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-8025B34C7403:java.util.concurrent.CompletableFuture@6914eaa5[Not completed]
datanode2_1  | 2021-07-12 10:39:56,786 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: new RaftServerImpl for group-8025B34C7403:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-07-12 10:39:56,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-07-12 10:39:56,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-07-12 10:39:56,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-07-12 10:39:56,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-07-12 10:39:56,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-07-12 10:39:56,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-07-12 10:39:56,789 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-07-12 10:39:56,790 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: ConfigurationManager, init=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-07-12 10:39:56,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-07-12 10:39:56,791 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-07-12 10:39:56,791 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403 does not exist. Creating ...
datanode2_1  | 2021-07-12 10:39:56,797 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403/in_use.lock acquired by nodename 7@ccdb996b39f4
datanode2_1  | 2021-07-12 10:39:56,801 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403 has been successfully formatted.
datanode2_1  | 2021-07-12 10:39:56,806 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-8025B34C7403: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-07-12 10:39:56,806 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-07-12 10:39:56,807 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-07-12 10:39:56,810 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-07-12 10:39:56,823 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-07-12 10:39:56,825 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403
datanode2_1  | 2021-07-12 10:39:56,825 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-07-12 10:39:56,827 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-07-12 10:39:56,827 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-07-12 10:39:56,828 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403
datanode2_1  | 2021-07-12 10:39:56,828 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-07-12 10:39:56,828 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-07-12 10:39:56,831 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-07-12 10:39:56,832 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-07-12 10:39:56,832 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-07-12 10:39:56,832 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-07-12 10:39:56,832 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-07-12 10:39:56,832 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-07-12 10:39:56,833 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-07-12 10:39:56,837 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-07-12 10:39:56,854 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-07-12 10:39:56,854 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-07-12 10:39:56,856 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-07-12 10:39:56,856 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-07-12 10:39:56,859 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-07-12 10:39:56,859 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-07-12 10:39:56,859 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-07-12 10:39:56,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-07-12 10:39:56,862 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403
datanode2_1  | 2021-07-12 10:39:56,867 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403
datanode2_1  | 2021-07-12 10:39:56,870 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: start as a follower, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2021-07-12 10:39:56,871 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-07-12 10:39:37,011 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2021-07-12 10:39:37,057 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2021-07-12 10:39:37,063 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-07-12 10:39:37,091 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2021-07-12 10:39:37,099 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-07-12 10:39:43,692 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2021-07-12 10:39:43,699 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-07-12 10:39:43,705 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-07-12 10:39:43,788 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-07-12 10:39:42,035 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2021-07-12 10:39:42,038 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2021-07-12 10:39:42,038 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2021-07-12 10:39:42,189 [main] INFO util.log: Logging initialized @44943ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2021-07-12 10:39:42,786 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2021-07-12 10:39:42,822 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2021-07-12 10:39:42,825 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2021-07-12 10:39:42,837 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2021-07-12 10:39:42,838 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2021-07-12 10:39:42,844 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2021-07-12 10:39:43,076 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2021-07-12 10:39:43,082 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode3_1  | 2021-07-12 10:39:43,264 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2021-07-12 10:39:43,270 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2021-07-12 10:39:43,276 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2021-07-12 10:39:43,368 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-07-12 10:39:43,394 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@183e64a8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2021-07-12 10:39:43,395 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1aa64998{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2021-07-12 10:39:43,943 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-07-12 10:39:44,032 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@42ceb67f{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-12016440167833965169/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2021-07-12 10:39:44,072 [main] INFO server.AbstractConnector: Started ServerConnector@6ca9ec77{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2021-07-12 10:39:44,096 [main] INFO server.Server: Started @46849ms
datanode3_1  | 2021-07-12 10:39:44,101 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2021-07-12 10:39:44,101 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2021-07-12 10:39:44,111 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2021-07-12 10:39:44,214 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1cf435a6] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2021-07-12 10:39:44,574 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2021-07-12 10:39:48,272 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2021-07-12 10:39:48,283 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2021-07-12 10:39:48,694 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode3_1  | 2021-07-12 10:39:48,835 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: start RPC server
datanode3_1  | 2021-07-12 10:39:48,860 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: GrpcService started, listening on 9856
datanode3_1  | 2021-07-12 10:39:48,867 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: GrpcService started, listening on 9857
datanode3_1  | 2021-07-12 10:39:48,868 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: GrpcService started, listening on 9858
datanode3_1  | 2021-07-12 10:39:48,894 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1ab7aeaf-7670-4a86-9686-feb8bb11c16a is started using port 9858 for RATIS
datanode3_1  | 2021-07-12 10:39:48,894 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1ab7aeaf-7670-4a86-9686-feb8bb11c16a is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2021-07-12 10:39:48,894 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1ab7aeaf-7670-4a86-9686-feb8bb11c16a is started using port 9856 for RATIS_SERVER
datanode3_1  | 2021-07-12 10:39:48,907 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$327/0x00000008405b2040@37bf281f] INFO util.JvmPauseMonitor: JvmPauseMonitor-1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Started
datanode3_1  | 2021-07-12 10:39:48,942 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-07-12 10:39:48,944 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-07-12 10:39:50,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:39:50,540 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$327/0x00000008405b2040@37bf281f] WARN util.JvmPauseMonitor: JvmPauseMonitor-1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Detected pause in JVM or host machine (eg GC): pause of approximately 107856779ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=157ms
datanode3_1  | 2021-07-12 10:39:53,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:39:56,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:39:59,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:02,767 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:04,938 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode3_1  | 2021-07-12 10:40:05,340 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Failed requestVote dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6->1ab7aeaf-7670-4a86-9686-feb8bb11c16a#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-07-12 10:40:05,781 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:06,054 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Failed requestVote 5244f159-1b5c-4bd3-a569-521c9d7b4032->1ab7aeaf-7670-4a86-9686-feb8bb11c16a#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 2021-07-12 10:39:46,555 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2021-07-12 10:39:46,555 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2021-07-12 10:39:46,555 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2021-07-12 10:39:46,881 [main] INFO util.log: Logging initialized @49664ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2021-07-12 10:39:48,038 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2021-07-12 10:39:48,154 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2021-07-12 10:39:48,183 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2021-07-12 10:39:48,184 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2021-07-12 10:39:48,184 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2021-07-12 10:39:48,222 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2021-07-12 10:39:48,604 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2021-07-12 10:39:48,624 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode1_1  | 2021-07-12 10:39:48,944 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2021-07-12 10:39:48,954 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2021-07-12 10:39:48,960 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2021-07-12 10:39:49,092 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-07-12 10:39:49,097 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18bab95b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2021-07-12 10:39:49,101 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2f1b8770{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2021-07-12 10:39:49,508 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-07-12 10:39:49,551 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@221961f2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-16745172637421461983/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2021-07-12 10:39:49,581 [main] INFO server.AbstractConnector: Started ServerConnector@eb23b9c{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2021-07-12 10:39:49,583 [main] INFO server.Server: Started @52366ms
datanode1_1  | 2021-07-12 10:39:49,592 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2021-07-12 10:39:49,606 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2021-07-12 10:39:49,607 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2021-07-12 10:39:49,790 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7110bee5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2021-07-12 10:39:50,067 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2021-07-12 10:39:52,347 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2021-07-12 10:39:52,349 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2021-07-12 10:39:52,930 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode1_1  | 2021-07-12 10:39:53,066 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start RPC server
datanode1_1  | 2021-07-12 10:39:53,090 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 5244f159-1b5c-4bd3-a569-521c9d7b4032: GrpcService started, listening on 9856
datanode1_1  | 2021-07-12 10:39:53,092 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 5244f159-1b5c-4bd3-a569-521c9d7b4032: GrpcService started, listening on 9857
datanode1_1  | 2021-07-12 10:39:53,099 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 5244f159-1b5c-4bd3-a569-521c9d7b4032: GrpcService started, listening on 9858
datanode1_1  | 2021-07-12 10:39:53,121 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 5244f159-1b5c-4bd3-a569-521c9d7b4032 is started using port 9858 for RATIS
datanode1_1  | 2021-07-12 10:39:53,123 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 5244f159-1b5c-4bd3-a569-521c9d7b4032 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2021-07-12 10:39:53,123 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 5244f159-1b5c-4bd3-a569-521c9d7b4032 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2021-07-12 10:39:53,121 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$326/0x00000008405b2c40@490dedbc] INFO util.JvmPauseMonitor: JvmPauseMonitor-5244f159-1b5c-4bd3-a569-521c9d7b4032: Started
datanode1_1  | 2021-07-12 10:39:53,161 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-07-12 10:39:53,161 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-07-12 10:39:55,988 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:39:56,924 [Command processor thread] INFO server.RaftServer: 5244f159-1b5c-4bd3-a569-521c9d7b4032: addNew group-DFB2E619C9E2:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-DFB2E619C9E2:java.util.concurrent.CompletableFuture@3c2b6806[Not completed]
datanode1_1  | 2021-07-12 10:39:57,064 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032: new RaftServerImpl for group-DFB2E619C9E2:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-07-12 10:39:57,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-07-12 10:39:57,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
kdc_1        | Jul 12 10:37:40 kdc krb5kdc[7](info): Loaded
kdc_1        | Jul 12 10:37:40 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Jul 12 10:37:40 kdc krb5kdc[7](info): setting up network...
kdc_1        | Jul 12 10:37:40 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Jul 12 10:37:40 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Jul 12 10:37:40 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Jul 12 10:37:40 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Jul 12 10:37:44 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:37:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086275, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:08 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1626086288, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1626086293, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086275, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:38:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1626086288, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:38:29 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086309, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:34 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1626086314, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086309, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:38:38 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086318, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1626086314, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:38:41 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1626086321, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1626086321, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:38:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086318, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:38:50 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:50 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1626086330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:38:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:38:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1626086330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:00 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086340, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1626086353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1626086353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1626086353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:15 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1626086355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:15 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1626086355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:16 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1626086356, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1626086355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1626086356, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1626086355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1626086353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1626086353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1626086353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086340, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086374, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:45 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1626086385, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:47 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1626086387, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:48 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1626086388, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:39:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1626086385, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode2_1  | 2021-07-12 10:39:56,872 [pool-23-thread-1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState
datanode2_1  | 2021-07-12 10:39:56,897 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8025B34C7403,id=dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode2_1  | 2021-07-12 10:39:56,898 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403
datanode2_1  | 2021-07-12 10:39:56,912 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403
datanode2_1  | 2021-07-12 10:39:57,065 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-95B3891D32B3->5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode2_1  | 2021-07-12 10:39:57,479 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$327/0x00000008405b2040@71cc59ce] WARN util.JvmPauseMonitor: JvmPauseMonitor-dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: Detected pause in JVM or host machine (eg GC): pause of approximately 108840693ns.
datanode2_1  | GC pool 'ParNew' had collection(s): count=1 time=110ms
datanode2_1  | 2021-07-12 10:39:57,503 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:00,510 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 2021-07-12 10:39:57,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-07-12 10:39:57,093 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-07-12 10:39:57,094 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-07-12 10:39:57,097 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-07-12 10:39:57,097 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-07-12 10:39:57,117 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2: ConfigurationManager, init=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-07-12 10:39:57,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-07-12 10:39:57,145 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-07-12 10:39:57,146 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/269136cc-c909-477b-8eee-dfb2e619c9e2 does not exist. Creating ...
datanode1_1  | 2021-07-12 10:39:57,174 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/269136cc-c909-477b-8eee-dfb2e619c9e2/in_use.lock acquired by nodename 7@071a21c71cec
datanode1_1  | 2021-07-12 10:39:57,225 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/269136cc-c909-477b-8eee-dfb2e619c9e2 has been successfully formatted.
datanode1_1  | 2021-07-12 10:39:57,283 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-DFB2E619C9E2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-07-12 10:39:57,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-07-12 10:39:57,381 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-07-12 10:39:57,453 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-07-12 10:39:57,485 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-07-12 10:39:57,579 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2
datanode1_1  | 2021-07-12 10:39:57,661 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-07-12 10:39:57,716 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-07-12 10:39:57,727 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-07-12 10:39:57,783 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/269136cc-c909-477b-8eee-dfb2e619c9e2
datanode1_1  | 2021-07-12 10:39:57,790 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-07-12 10:39:57,791 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-07-12 10:39:57,806 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-07-12 10:39:57,810 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-07-12 10:39:57,814 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-07-12 10:39:57,815 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-07-12 10:39:57,820 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-07-12 10:39:57,821 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-07-12 10:39:57,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-07-12 10:39:57,927 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-07-12 10:39:57,964 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-07-12 10:39:57,964 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-07-12 10:39:57,990 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-07-12 10:39:57,992 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-07-12 10:39:57,998 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-07-12 10:39:57,998 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-07-12 10:39:58,003 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-07-12 10:39:58,005 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-07-12 10:39:58,142 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2
datanode1_1  | 2021-07-12 10:39:58,190 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2
datanode1_1  | 2021-07-12 10:39:58,247 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2: start as a follower, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-07-12 10:39:58,255 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-07-12 10:39:58,260 [pool-23-thread-1] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-FollowerState
datanode1_1  | 2021-07-12 10:39:58,294 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFB2E619C9E2,id=5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode1_1  | 2021-07-12 10:39:58,299 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2
datanode1_1  | 2021-07-12 10:39:58,395 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=269136cc-c909-477b-8eee-dfb2e619c9e2
datanode1_1  | 2021-07-12 10:39:58,400 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=269136cc-c909-477b-8eee-dfb2e619c9e2.
datanode1_1  | 2021-07-12 10:39:58,403 [Command processor thread] INFO server.RaftServer: 5244f159-1b5c-4bd3-a569-521c9d7b4032: addNew group-8025B34C7403:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-8025B34C7403:java.util.concurrent.CompletableFuture@62aeaa0d[Not completed]
datanode1_1  | 2021-07-12 10:39:58,413 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032: new RaftServerImpl for group-8025B34C7403:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-07-12 10:39:58,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-07-12 10:39:58,419 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-07-12 10:39:58,419 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-07-12 10:39:58,419 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-07-12 10:39:58,419 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-07-12 10:39:58,419 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-07-12 10:39:58,420 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-07-12 10:39:58,422 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: ConfigurationManager, init=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-07-12 10:39:58,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-07-12 10:39:58,423 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-07-12 10:39:58,428 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403 does not exist. Creating ...
datanode1_1  | 2021-07-12 10:39:58,435 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403/in_use.lock acquired by nodename 7@071a21c71cec
datanode1_1  | 2021-07-12 10:39:58,439 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403 has been successfully formatted.
datanode1_1  | 2021-07-12 10:39:58,439 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-8025B34C7403: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-07-12 10:39:58,446 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-07-12 10:39:58,446 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-07-12 10:39:58,446 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-07-12 10:39:58,446 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-07-12 10:39:58,446 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403
datanode1_1  | 2021-07-12 10:39:58,447 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-07-12 10:40:07,123 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Failed requestVote 5244f159-1b5c-4bd3-a569-521c9d7b4032->1ab7aeaf-7670-4a86-9686-feb8bb11c16a#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-BF278ABA4990 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 2021-07-12 10:39:58,447 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-07-12 10:39:58,447 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-07-12 10:39:58,469 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403
datanode1_1  | 2021-07-12 10:39:58,470 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-07-12 10:39:58,470 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-07-12 10:39:58,470 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-07-12 10:39:58,470 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-07-12 10:39:58,470 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-07-12 10:39:58,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-07-12 10:39:58,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-07-12 10:39:58,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-07-12 10:39:58,479 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-07-12 10:39:58,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-07-12 10:39:58,489 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-07-12 10:39:58,489 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-07-12 10:39:58,490 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-07-12 10:39:58,490 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-07-12 10:39:58,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-07-12 10:39:58,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-07-12 10:39:58,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-07-12 10:39:58,496 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-07-12 10:40:00,519 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-982375608D8A->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode2_1  | 2021-07-12 10:40:00,599 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:01,779 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-FollowerState] INFO impl.FollowerState: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5194257574ns, electionTimeout:5164ms
datanode2_1  | 2021-07-12 10:40:01,780 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-FollowerState] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: shutdown dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-FollowerState
datanode2_1  | 2021-07-12 10:40:01,780 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-FollowerState] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-07-12 10:40:01,783 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-07-12 10:40:01,784 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-FollowerState] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1
datanode2_1  | 2021-07-12 10:40:01,813 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-07-12 10:40:01,813 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2021-07-12 10:40:01,814 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: shutdown dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1
datanode2_1  | 2021-07-12 10:40:01,819 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2021-07-12 10:40:01,828 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-05A9F269F8E5 with new leaderId: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode2_1  | 2021-07-12 10:40:01,829 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5: change Leader from null to dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6 at term 1 for becomeLeader, leader elected after 6166ms
datanode2_1  | 2021-07-12 10:40:01,861 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-07-12 10:40:01,870 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403.
datanode2_1  | 2021-07-12 10:40:01,888 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: new RaftServerImpl for group-BF278ABA4990:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-07-12 10:40:01,894 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-07-12 10:40:01,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-07-12 10:40:01,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-07-12 10:40:01,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-07-12 10:40:01,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-07-12 10:40:01,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-07-12 10:40:01,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-07-12 10:40:01,902 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: ConfigurationManager, init=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-07-12 10:40:01,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-07-12 10:40:01,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-07-12 10:40:01,906 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990 does not exist. Creating ...
datanode2_1  | 2021-07-12 10:40:01,906 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO impl.FollowerState: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5033764775ns, electionTimeout:5005ms
datanode2_1  | 2021-07-12 10:40:01,928 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: shutdown dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState
datanode2_1  | 2021-07-12 10:40:01,928 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-07-12 10:40:01,928 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-07-12 10:40:01,928 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2
datanode2_1  | 2021-07-12 10:40:01,955 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/in_use.lock acquired by nodename 7@ccdb996b39f4
datanode2_1  | 2021-07-12 10:40:01,960 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990 has been successfully formatted.
datanode2_1  | 2021-07-12 10:40:01,963 [Command processor thread] INFO server.RaftServer: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: addNew group-BF278ABA4990:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-BF278ABA4990:java.util.concurrent.CompletableFuture@771d7f66[Not completed]
datanode2_1  | 2021-07-12 10:40:01,964 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BF278ABA4990: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-07-12 10:40:01,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-07-12 10:40:01,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-07-12 10:40:01,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-07-12 10:40:01,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-07-12 10:40:08,855 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:10,720 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Failed requestVote dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6->1ab7aeaf-7670-4a86-9686-feb8bb11c16a#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-07-12 10:40:11,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:12,598 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Failed startLeaderElection 5244f159-1b5c-4bd3-a569-521c9d7b4032->1ab7aeaf-7670-4a86-9686-feb8bb11c16a#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-BF278ABA4990 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.startLeaderElection(RaftServerProxy.java:553)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.startLeaderElection(GrpcServerProtocolService.java:185)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:398)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
kdc_1        | Jul 12 10:39:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1626086387, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1626086388, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:39:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086374, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:40:05 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086405, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:40:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086405, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:40:17 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086417, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:40:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086417, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:40:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086424, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:40:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086424, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jul 12 10:40:29 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086429, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:40:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086429, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:40:36 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:40:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:40:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:41:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086548, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:42:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086548, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086548, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode1_1  | 2021-07-12 10:39:58,497 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403
datanode1_1  | 2021-07-12 10:39:58,503 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403
datanode1_1  | 2021-07-12 10:39:58,507 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: start as a follower, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode1_1  | 2021-07-12 10:39:58,507 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-07-12 10:39:58,507 [pool-23-thread-1] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState
datanode1_1  | 2021-07-12 10:39:58,516 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8025B34C7403,id=5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode1_1  | 2021-07-12 10:39:58,519 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403
datanode1_1  | 2021-07-12 10:39:58,527 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403
datanode1_1  | 2021-07-12 10:39:58,717 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1AE0898C55BA->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode1_1  | 2021-07-12 10:39:59,073 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:01,042 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-07-12 10:40:01,068 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E2709B3C955F->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode1_1  | 2021-07-12 10:40:01,831 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-07-12 10:40:01,832 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403.
datanode1_1  | 2021-07-12 10:40:01,832 [Command processor thread] INFO server.RaftServer: 5244f159-1b5c-4bd3-a569-521c9d7b4032: addNew group-BF278ABA4990:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-BF278ABA4990:java.util.concurrent.CompletableFuture@52a1e60[Not completed]
datanode1_1  | 2021-07-12 10:40:01,834 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032: new RaftServerImpl for group-BF278ABA4990:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-07-12 10:40:01,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-07-12 10:40:01,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-07-12 10:40:01,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-07-12 10:40:01,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-07-12 10:40:01,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-07-12 10:40:01,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-07-12 10:40:01,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-07-12 10:40:01,836 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: ConfigurationManager, init=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-07-12 10:40:01,836 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-07-12 10:40:01,839 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-07-12 10:40:01,841 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990 does not exist. Creating ...
datanode1_1  | 2021-07-12 10:40:01,847 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/in_use.lock acquired by nodename 7@071a21c71cec
datanode1_1  | 2021-07-12 10:40:01,856 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990 has been successfully formatted.
datanode1_1  | 2021-07-12 10:40:01,857 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BF278ABA4990: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-07-12 10:40:01,871 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-07-12 10:40:01,895 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-07-12 10:40:01,895 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-07-12 10:40:01,895 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-07-12 10:40:01,895 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:01,896 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-07-12 10:40:01,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-07-12 10:40:14,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:17,798 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Failed startLeaderElection 5244f159-1b5c-4bd3-a569-521c9d7b4032->1ab7aeaf-7670-4a86-9686-feb8bb11c16a#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-BF278ABA4990 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.startLeaderElection(RaftServerProxy.java:553)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.startLeaderElection(GrpcServerProtocolService.java:185)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:398)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | 2021-07-12 10:40:01,964 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990
datanode2_1  | 2021-07-12 10:40:01,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-07-12 10:40:01,969 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-07-12 10:40:01,970 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-07-12 10:40:01,970 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990
datanode2_1  | 2021-07-12 10:40:01,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-07-12 10:40:01,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-07-12 10:40:01,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-07-12 10:40:01,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-07-12 10:40:01,975 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-07-12 10:40:01,976 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-07-12 10:40:01,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-07-12 10:40:01,989 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-07-12 10:40:02,011 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-07-12 10:40:01,988 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2021-07-12 10:40:02,017 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5
datanode2_1  | 2021-07-12 10:40:02,040 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-07-12 10:40:02,050 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1        | Jul 12 10:42:35 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086555, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:42:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086555, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086555, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086555, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086555, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:42:54 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086574, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:42:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086574, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086574, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:06 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086586, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:43:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086586, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086586, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:14 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086594, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:43:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086594, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086594, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:21 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086601, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:43:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086601, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:25 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086605, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode1_1  | 2021-07-12 10:40:01,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-07-12 10:40:01,902 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990
datanode1_1  | 2021-07-12 10:40:01,902 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-07-12 10:40:01,902 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-07-12 10:40:01,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-07-12 10:40:01,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-07-12 10:40:01,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-07-12 10:40:18,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:21,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:22,997 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Failed startLeaderElection 5244f159-1b5c-4bd3-a569-521c9d7b4032->1ab7aeaf-7670-4a86-9686-feb8bb11c16a#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-BF278ABA4990 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.startLeaderElection(RaftServerProxy.java:553)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.startLeaderElection(GrpcServerProtocolService.java:185)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:398)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | 2021-07-12 10:40:23,344 [Command processor thread] INFO server.RaftServer: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: addNew group-1AB14A6AB8A5:[1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-1AB14A6AB8A5:java.util.concurrent.CompletableFuture@45a2ee9f[Not completed]
datanode3_1  | 2021-07-12 10:40:23,370 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: new RaftServerImpl for group-1AB14A6AB8A5:[1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-07-12 10:40:23,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-07-12 10:40:23,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-07-12 10:40:23,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-07-12 10:40:23,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-07-12 10:40:23,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-07-12 10:40:23,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-07-12 10:40:23,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-07-12 10:40:23,381 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5: ConfigurationManager, init=-1: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-07-12 10:40:23,382 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-07-12 10:40:23,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-07-12 10:40:23,387 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5 does not exist. Creating ...
datanode3_1  | 2021-07-12 10:40:23,399 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5/in_use.lock acquired by nodename 7@f311c7ebb23c
datanode3_1  | 2021-07-12 10:40:23,413 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5 has been successfully formatted.
datanode3_1  | 2021-07-12 10:40:23,419 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-1AB14A6AB8A5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-07-12 10:40:23,453 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-07-12 10:40:23,457 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-07-12 10:40:23,519 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-07-12 10:40:23,519 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-07-12 10:40:23,527 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5
datanode3_1  | 2021-07-12 10:40:23,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:23,565 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-07-12 10:40:23,571 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-07-12 10:40:23,585 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5
datanode3_1  | 2021-07-12 10:40:23,588 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-07-12 10:40:23,589 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-07-12 10:40:23,590 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:23,594 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-07-12 10:40:02,050 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-07-12 10:40:02,050 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-07-12 10:40:02,050 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-07-12 10:40:02,050 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-07-12 10:40:02,051 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-07-12 10:40:02,053 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-07-12 10:40:02,063 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-07-12 10:40:02,064 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990
datanode2_1  | 2021-07-12 10:40:02,053 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2021-07-12 10:40:02,065 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode2_1  | 2021-07-12 10:40:02,070 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990
datanode2_1  | 2021-07-12 10:40:02,087 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: start as a follower, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-07-12 10:40:02,088 [pool-23-thread-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-07-12 10:40:02,091 [pool-23-thread-1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState
datanode2_1  | 2021-07-12 10:40:02,092 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF278ABA4990,id=dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode2_1  | 2021-07-12 10:40:02,092 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990
datanode2_1  | 2021-07-12 10:40:02,094 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990
datanode2_1  | 2021-07-12 10:40:02,111 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5E9B565C485B->5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode2_1  | 2021-07-12 10:40:02,138 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2021-07-12 10:40:02,160 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2021-07-12 10:40:02,161 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2021-07-12 10:40:02,218 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderStateImpl
datanode2_1  | 2021-07-12 10:40:02,228 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2021-07-12 10:40:02,415 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-07-12 10:40:02,951 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-LeaderElection1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5: set configuration 0: [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-07-12 10:40:03,327 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-05A9F269F8E5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c72a7bef-074b-455f-a2d4-05a9f269f8e5/current/log_inprogress_0
datanode2_1  | 2021-07-12 10:40:03,636 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:04,165 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
kdc_1        | Jul 12 10:43:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086605, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:43:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:50 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086630, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:43:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086630, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:43:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086630, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086630, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086630, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:04 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086644, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:44:04 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086644, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:44:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086644, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086648, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:44:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086648, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode1_1  | 2021-07-12 10:40:01,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-07-12 10:40:01,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-07-12 10:40:01,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-07-12 10:40:01,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-07-12 10:40:01,919 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-07-12 10:40:01,921 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-07-12 10:40:01,933 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-07-12 10:40:01,934 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-07-12 10:40:01,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-07-12 10:40:01,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-07-12 10:40:01,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-07-12 10:40:01,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-07-12 10:40:01,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-07-12 10:40:01,939 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:01,942 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:01,944 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: start as a follower, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-07-12 10:40:01,951 [pool-23-thread-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-07-12 10:40:01,952 [pool-23-thread-1] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState
datanode1_1  | 2021-07-12 10:40:01,963 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF278ABA4990,id=5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode1_1  | 2021-07-12 10:40:01,965 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:01,969 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990
datanode1_1  | 2021-07-12 10:40:01,994 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E18372B0F9D6->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode1_1  | 2021-07-12 10:40:02,143 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:02,541 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-07-12 10:40:04,167 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F9E63B7B7AF2->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode2_1  | 2021-07-12 10:40:05,284 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-07-12 10:40:05,286 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990.
datanode2_1  | 2021-07-12 10:40:05,505 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode2_1  | 2021-07-12 10:40:05,660 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2: ELECTION REJECTED received 1 response(s) and 1 exception(s):
datanode2_1  | 2021-07-12 10:40:05,661 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection:   Response 0: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6<-5244f159-1b5c-4bd3-a569-521c9d7b4032#0:FAIL-t1
datanode2_1  | 2021-07-12 10:40:05,661 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode2_1  | 2021-07-12 10:40:05,661 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2 ELECTION round 0: result REJECTED
datanode2_1  | 2021-07-12 10:40:05,671 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode2_1  | 2021-07-12 10:40:05,672 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: shutdown dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2
datanode2_1  | 2021-07-12 10:40:05,672 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection2] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState
datanode2_1  | 2021-07-12 10:40:06,149 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode2_1  | 2021-07-12 10:40:06,164 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: receive requestVote(ELECTION, 5244f159-1b5c-4bd3-a569-521c9d7b4032, group-8025B34C7403, 1, (t:0, i:0))
datanode2_1  | 2021-07-12 10:40:06,168 [grpc-default-executor-1] INFO impl.VoteContext: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FOLLOWER: reject ELECTION from 5244f159-1b5c-4bd3-a569-521c9d7b4032: already has voted for dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6 at current term 1
datanode2_1  | 2021-07-12 10:40:06,188 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403 replies to ELECTION vote request: 5244f159-1b5c-4bd3-a569-521c9d7b4032<-dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6#0:FAIL-t1. Peer's state: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403:t1, leader=null, voted=dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, raftlog=dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2021-07-12 10:40:06,709 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:07,138 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: receive requestVote(ELECTION, 5244f159-1b5c-4bd3-a569-521c9d7b4032, group-BF278ABA4990, 1, (t:0, i:0))
datanode2_1  | 2021-07-12 10:40:07,141 [grpc-default-executor-1] INFO impl.VoteContext: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FOLLOWER: accept ELECTION from 5244f159-1b5c-4bd3-a569-521c9d7b4032: our priority 0 <= candidate's priority 0
datanode2_1  | 2021-07-12 10:40:07,141 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode2_1  | 2021-07-12 10:40:07,141 [grpc-default-executor-1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: shutdown dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState
datanode2_1  | 2021-07-12 10:40:07,141 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState] INFO impl.FollowerState: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 2021-07-12 10:40:23,596 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-07-12 10:40:23,597 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-07-12 10:40:23,597 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-07-12 10:40:23,597 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-07-12 10:40:23,625 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:23,626 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-07-12 10:40:23,647 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-07-12 10:40:23,652 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-07-12 10:40:23,665 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-07-12 10:40:23,670 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-07-12 10:40:23,670 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-07-12 10:40:23,671 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-07-12 10:40:23,674 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-07-12 10:40:23,676 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-07-12 10:40:23,779 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5
datanode3_1  | 2021-07-12 10:40:23,785 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5
datanode3_1  | 2021-07-12 10:40:23,796 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5: start as a follower, conf=-1: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-07-12 10:40:23,800 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-07-12 10:40:23,804 [pool-23-thread-1] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: start 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-FollowerState
datanode3_1  | 2021-07-12 10:40:23,816 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1AB14A6AB8A5,id=1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode3_1  | 2021-07-12 10:40:23,817 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5
datanode3_1  | 2021-07-12 10:40:23,834 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5
datanode3_1  | 2021-07-12 10:40:23,835 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5.
datanode3_1  | 2021-07-12 10:40:23,837 [Command processor thread] INFO server.RaftServer: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: addNew group-8025B34C7403:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-8025B34C7403:java.util.concurrent.CompletableFuture@3a80dea7[Not completed]
datanode3_1  | 2021-07-12 10:40:23,846 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: new RaftServerImpl for group-8025B34C7403:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-07-12 10:40:23,847 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-07-12 10:40:23,847 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-07-12 10:40:23,847 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-07-12 10:40:23,847 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-07-12 10:40:23,850 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-07-12 10:40:23,850 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-07-12 10:40:23,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-07-12 10:40:23,851 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403: ConfigurationManager, init=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-07-12 10:40:23,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-07-12 10:40:23,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-07-12 10:40:23,851 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403 does not exist. Creating ...
datanode3_1  | 2021-07-12 10:40:23,854 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403/in_use.lock acquired by nodename 7@f311c7ebb23c
datanode3_1  | 2021-07-12 10:40:23,857 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403 has been successfully formatted.
datanode3_1  | 2021-07-12 10:40:23,868 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-8025B34C7403: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-07-12 10:40:23,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-07-12 10:40:23,870 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-07-12 10:40:23,870 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-07-12 10:40:02,571 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BBD2D89E2DB4->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode1_1  | 2021-07-12 10:40:03,141 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-07-12 10:40:03,149 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990.
datanode1_1  | 2021-07-12 10:40:03,401 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-FollowerState] INFO impl.FollowerState: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5141341363ns, electionTimeout:5107ms
datanode1_1  | 2021-07-12 10:40:03,401 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-FollowerState] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: shutdown 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-FollowerState
datanode1_1  | 2021-07-12 10:40:03,401 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-FollowerState] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-07-12 10:40:03,413 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-07-12 10:40:03,413 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-FollowerState] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1
datanode1_1  | 2021-07-12 10:40:03,433 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-07-12 10:40:03,436 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2021-07-12 10:40:03,437 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: shutdown 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1
datanode1_1  | 2021-07-12 10:40:03,442 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2021-07-12 10:40:03,442 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DFB2E619C9E2 with new leaderId: 5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode1_1  | 2021-07-12 10:40:03,443 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2: change Leader from null to 5244f159-1b5c-4bd3-a569-521c9d7b4032 at term 1 for becomeLeader, leader elected after 6063ms
datanode1_1  | 2021-07-12 10:40:03,458 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-07-12 10:40:03,462 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2
datanode1_1  | 2021-07-12 10:40:03,477 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-07-12 10:40:03,493 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode1_1  | 2021-07-12 10:40:03,513 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-07-12 10:40:23,870 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-07-12 10:40:23,870 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403
datanode3_1  | 2021-07-12 10:40:23,870 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:23,871 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-07-12 10:40:23,873 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-07-12 10:40:23,873 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403
datanode3_1  | 2021-07-12 10:40:23,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-07-12 10:40:23,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-07-12 10:40:23,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:23,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-07-12 10:40:23,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-07-12 10:40:23,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-07-12 10:40:23,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-07-12 10:40:23,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-07-12 10:40:23,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:23,878 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-07-12 10:40:23,879 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-07-12 10:40:23,879 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-07-12 10:40:23,885 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-07-12 10:40:23,885 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-07-12 10:40:23,885 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-07-12 10:40:23,885 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-07-12 10:40:23,885 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-07-12 10:40:23,886 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-07-12 10:40:23,886 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403
datanode3_1  | 2021-07-12 10:40:23,886 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403
datanode3_1  | 2021-07-12 10:40:23,887 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403: start as a follower, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2021-07-12 10:40:23,888 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-07-12 10:40:23,888 [pool-23-thread-1] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: start 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403-FollowerState
datanode3_1  | 2021-07-12 10:40:23,890 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8025B34C7403,id=1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode3_1  | 2021-07-12 10:40:23,891 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403
datanode3_1  | 2021-07-12 10:40:23,894 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403
datanode3_1  | 2021-07-12 10:40:23,951 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-2A3F71F54B5C->5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode3_1  | 2021-07-12 10:40:24,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:24,309 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-07-12 10:40:24,316 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-735AD20EA4B0->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode3_1  | 2021-07-12 10:40:24,491 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-07-12 10:39:06,072 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-07-12 10:40:24,492 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403.
datanode3_1  | 2021-07-12 10:40:24,494 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: new RaftServerImpl for group-BF278ABA4990:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-07-12 10:40:24,494 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-07-12 10:40:24,494 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-07-12 10:40:24,494 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-07-12 10:40:24,494 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-07-12 10:40:24,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-07-12 10:40:24,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-07-12 10:40:24,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-07-12 10:40:24,495 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: ConfigurationManager, init=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-07-12 10:39:06,122 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-07-12 10:39:15,043 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-07-12 10:39:15,377 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-07-12 10:39:15,383 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-07-12 10:39:15,387 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-07-12 10:39:16,327 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2021-07-12 10:39:16,335 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-07-12 10:39:16,529 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-07-12 10:39:20,167 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2021-07-12 10:39:23,121 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2021-07-12 10:39:23,147 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2021-07-12 10:39:23,154 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2021-07-12 10:39:27,710 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2021-07-12 10:39:27,959 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2021-07-12 10:39:27,962 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2021-07-12 10:39:27,984 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2021-07-12 10:39:27,986 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-07-12 10:39:28,008 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-07-12 10:39:28,011 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-07-12 10:39:28,011 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-07-12 10:39:28,014 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:834b4eb7-146a-4c2a-bac6-4409b0eef822,clusterId:CID-ea67d158-f30d-4de4-8e61-b39e69e4a611,subject:om1
om1_1        | 2021-07-12 10:39:28,671 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2021-07-12 10:39:30,068 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-ea67d158-f30d-4de4-8e61-b39e69e4a611;layoutVersion=0
om1_1        | 2021-07-12 10:39:30,247 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-07-12 10:39:38,299 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2021-07-12 10:40:07,142 [grpc-default-executor-1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState
datanode2_1  | 2021-07-12 10:40:07,154 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990 replies to ELECTION vote request: 5244f159-1b5c-4bd3-a569-521c9d7b4032<-dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6#0:OK-t1. Peer's state: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990:t1, leader=null, voted=5244f159-1b5c-4bd3-a569-521c9d7b4032, raftlog=dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2021-07-12 10:40:07,403 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BF278ABA4990 with new leaderId: 5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode2_1  | 2021-07-12 10:40:07,404 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: change Leader from null to 5244f159-1b5c-4bd3-a569-521c9d7b4032 at term 1 for appendEntries, leader elected after 5439ms
datanode2_1  | 2021-07-12 10:40:07,473 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: set configuration 0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-07-12 10:40:07,476 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-07-12 10:40:07,481 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_0
datanode2_1  | 2021-07-12 10:40:09,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:10,698 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO impl.FollowerState: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5026585204ns, electionTimeout:5015ms
datanode2_1  | 2021-07-12 10:40:10,699 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: shutdown dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState
datanode2_1  | 2021-07-12 10:40:10,699 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2021-07-12 10:40:10,699 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-07-12 10:40:10,699 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-FollowerState] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3
kdc_1        | Jul 12 10:44:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086648, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086652, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:44:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086652, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:44:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086652, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086652, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:19 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:44:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:33 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086673, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:44:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086673, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086673, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086673, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:47 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086687, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:44:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086687, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086687, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:44:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086687, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:45:17 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086717, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:45:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086717, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:45:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:45:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086724, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:45:39 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:45:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:46:06 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086766, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:46:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086766, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:46:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086773, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:46:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086773, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:46:20 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086780, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:46:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086780, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:46:26 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086786, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:46:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086786, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:46:32 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:46:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 2021-07-12 10:40:24,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-07-12 10:40:24,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-07-12 10:40:24,496 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990 does not exist. Creating ...
datanode3_1  | 2021-07-12 10:40:24,496 [Command processor thread] INFO server.RaftServer: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: addNew group-BF278ABA4990:[5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-BF278ABA4990:java.util.concurrent.CompletableFuture@38269676[Not completed]
datanode3_1  | 2021-07-12 10:40:24,500 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/in_use.lock acquired by nodename 7@f311c7ebb23c
datanode3_1  | 2021-07-12 10:40:24,505 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990 has been successfully formatted.
datanode3_1  | 2021-07-12 10:40:24,506 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BF278ABA4990: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-07-12 10:40:24,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-07-12 10:40:24,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-07-12 10:40:24,509 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-07-12 10:40:24,509 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-07-12 10:40:24,509 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990
datanode3_1  | 2021-07-12 10:40:24,509 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:24,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-07-12 10:40:24,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-07-12 10:40:24,510 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990
datanode3_1  | 2021-07-12 10:40:24,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-07-12 10:40:24,512 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-07-12 10:40:24,512 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:24,512 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-07-12 10:40:24,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-07-12 10:40:24,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-07-12 10:40:24,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-07-12 10:40:24,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-07-12 10:40:24,515 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-07-12 10:40:24,517 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-07-12 10:40:24,518 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-07-12 10:40:24,518 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-07-12 10:40:24,527 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-07-12 10:40:24,527 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-07-12 10:40:24,528 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-07-12 10:40:24,528 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-07-12 10:40:24,528 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-07-12 10:40:24,528 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-07-12 10:40:24,533 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990
datanode3_1  | 2021-07-12 10:40:24,535 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990
datanode3_1  | 2021-07-12 10:40:24,537 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: start as a follower, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-07-12 10:40:24,538 [pool-23-thread-1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-07-12 10:40:24,538 [pool-23-thread-1] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: start 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-FollowerState
datanode3_1  | 2021-07-12 10:40:24,542 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF278ABA4990,id=1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode3_1  | 2021-07-12 10:40:24,542 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990
datanode3_1  | 2021-07-12 10:40:24,545 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990
datanode3_1  | 2021-07-12 10:40:24,563 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-3512394411DA->5244f159-1b5c-4bd3-a569-521c9d7b4032
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-07-12 10:39:05,690 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-07-12 10:39:05,772 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-07-12 10:39:14,594 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-07-12 10:39:15,024 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-07-12 10:39:15,027 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-07-12 10:39:15,027 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-07-12 10:39:16,548 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2021-07-12 10:39:16,555 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-07-12 10:39:16,569 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-07-12 10:39:19,146 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2021-07-12 10:39:22,111 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2021-07-12 10:39:22,125 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2021-07-12 10:39:22,126 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2021-07-12 10:39:26,410 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2021-07-12 10:39:26,580 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2021-07-12 10:39:26,583 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2021-07-12 10:39:26,601 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2021-07-12 10:39:26,611 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-07-12 10:39:26,614 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-07-12 10:39:26,619 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-07-12 10:39:26,620 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-07-12 10:39:26,625 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:834b4eb7-146a-4c2a-bac6-4409b0eef822,clusterId:CID-ea67d158-f30d-4de4-8e61-b39e69e4a611,subject:om2
om2_1        | 2021-07-12 10:39:27,448 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2021-07-12 10:39:28,775 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-ea67d158-f30d-4de4-8e61-b39e69e4a611;layoutVersion=0
om2_1        | 2021-07-12 10:39:28,916 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-07-12 10:39:37,257 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-07-12 10:39:37,301 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-07-12 10:39:44,749 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-07-12 10:39:45,136 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-07-12 10:39:45,143 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-07-12 10:39:45,143 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-07-12 10:39:45,180 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-07-12 10:39:45,335 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om2_1        | 2021-07-12 10:39:46,572 [main] INFO reflections.Reflections: Reflections took 818 ms to scan 1 urls, producing 94 keys and 256 values [using 2 cores]
om2_1        | 2021-07-12 10:39:48,301 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2021-07-12 10:39:48,301 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-07-12 10:39:48,358 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-07-12 10:39:54,942 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2021-07-12 10:39:55,445 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2021-07-12 10:39:55,458 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2530584589045.crt.
om2_1        | 2021-07-12 10:39:55,468 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2617493978675.crt.
om2_1        | 2021-07-12 10:39:55,613 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-07-12 10:39:56,642 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-07-12 10:39:56,650 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-07-12 10:39:57,870 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2021-07-12 10:39:57,899 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2021-07-12 10:39:58,413 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
datanode3_1  | 2021-07-12 10:40:24,696 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-07-12 10:40:24,697 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-2F3F08F5B040->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode3_1  | 2021-07-12 10:40:24,914 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:550)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-07-12 10:40:24,916 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990.
datanode3_1  | 2021-07-12 10:40:25,007 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BF278ABA4990 with new leaderId: 5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode3_1  | 2021-07-12 10:40:25,007 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: change Leader from null to 5244f159-1b5c-4bd3-a569-521c9d7b4032 at term 1 for appendEntries, leader elected after 498ms
datanode3_1  | 2021-07-12 10:40:25,015 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode3_1  | 2021-07-12 10:40:25,026 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: inconsistency entries. Reply:5244f159-1b5c-4bd3-a569-521c9d7b4032<-1ab7aeaf-7670-4a86-9686-feb8bb11c16a#9:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode3_1  | 2021-07-12 10:40:25,065 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: set configuration 0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-07-12 10:40:25,075 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-07-12 10:40:25,180 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_0
datanode3_1  | 2021-07-12 10:40:25,972 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8025B34C7403 with new leaderId: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode3_1  | 2021-07-12 10:40:25,972 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403: change Leader from null to dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6 at term 2 for appendEntries, leader elected after 2103ms
datanode3_1  | 2021-07-12 10:40:25,973 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403: Failed appendEntries as previous log entry ((t:2, i:0)) is not found
datanode3_1  | 2021-07-12 10:40:25,973 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403: inconsistency entries. Reply:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6<-1ab7aeaf-7670-4a86-9686-feb8bb11c16a#8:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode3_1  | 2021-07-12 10:40:25,978 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403: set configuration 0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2021-07-12 10:40:25,978 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-07-12 10:40:25,981 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-8025B34C7403-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403/current/log_inprogress_0
datanode3_1  | 2021-07-12 10:40:27,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:28,198 [grpc-default-executor-0] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: shutdown 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-FollowerState
datanode3_1  | 2021-07-12 10:40:28,200 [grpc-default-executor-0] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode3_1  | 2021-07-12 10:40:28,203 [grpc-default-executor-0] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: start 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1
datanode3_1  | 2021-07-12 10:40:28,205 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: change Leader from 5244f159-1b5c-4bd3-a569-521c9d7b4032 to null at term 1 for ELECTION
datanode3_1  | 2021-07-12 10:40:28,208 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO impl.LeaderElection: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-07-12 10:40:28,233 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-FollowerState] INFO impl.FollowerState: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om2_1        | 2021-07-12 10:39:58,475 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-07-12 10:39:58,476 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2021-07-12 10:39:58,489 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2021-07-12 10:39:59,180 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2021-07-12 10:39:59,361 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-07-12 10:39:59,494 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om2:9872, om1:9872, om3:9872
om2_1        | 2021-07-12 10:39:59,546 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2021-07-12 10:40:00,636 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2021-07-12 10:40:00,992 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2021-07-12 10:40:00,994 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-07-12 10:40:00,999 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2021-07-12 10:40:01,000 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-07-12 10:40:01,002 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-07-12 10:40:01,005 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2021-07-12 10:40:01,011 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-07-12 10:40:01,015 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2021-07-12 10:40:01,023 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-07-12 10:40:05,464 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2021-07-12 10:40:05,468 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-07-12 10:40:05,476 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-07-12 10:40:05,543 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-07-12 10:40:05,619 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@16c6d5a2[Not completed]
om2_1        | 2021-07-12 10:40:05,620 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2021-07-12 10:40:05,758 [pool-24-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2021-07-12 10:40:05,782 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2021-07-12 10:40:05,815 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2021-07-12 10:40:05,815 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2021-07-12 10:40:05,815 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-07-12 10:40:05,827 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-07-12 10:40:05,827 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2021-07-12 10:40:05,828 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-07-12 10:40:05,853 [pool-24-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2021-07-12 10:40:05,854 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-07-12 10:40:05,879 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2021-07-12 10:40:05,891 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2021-07-12 10:40:05,926 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2021-07-12 10:40:05,976 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2021-07-12 10:40:06,007 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2021-07-12 10:40:06,234 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2021-07-12 10:40:06,261 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2021-07-12 10:40:06,282 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2021-07-12 10:40:06,335 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2021-07-12 10:40:06,356 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-07-12 10:40:06,366 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om2@group-562213E44849
om2_1        | 2021-07-12 10:40:06,456 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-07-12 10:40:06,615 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2021-07-12 10:40:06,641 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2021-07-12 10:40:06,703 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2021-07-12 10:40:06,704 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2021-07-12 10:40:28,545 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: Completed APPEND_ENTRIES, lastRequest: 5244f159-1b5c-4bd3-a569-521c9d7b4032->1ab7aeaf-7670-4a86-9686-feb8bb11c16a#10-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
datanode3_1  | 2021-07-12 10:40:28,594 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO impl.LeaderElection: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2021-07-12 10:40:28,594 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO impl.LeaderElection:   Response 0: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a<-5244f159-1b5c-4bd3-a569-521c9d7b4032#0:OK-t2
datanode3_1  | 2021-07-12 10:40:28,594 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO impl.LeaderElection: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1 ELECTION round 0: result PASSED
datanode3_1  | 2021-07-12 10:40:28,595 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: shutdown 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1
datanode3_1  | 2021-07-12 10:40:28,598 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
kdc_1        | Jul 12 10:47:57 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086877, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:48:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086877, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:48:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086893, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:48:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086893, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:48:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626086907, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:48:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626086907, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:53:32 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626087212, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:53:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626087212, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:56:53 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626087413, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:56:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1626087413, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jul 12 10:57:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626087421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jul 12 10:57:01 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1626087421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-07-12 10:39:38,385 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-07-12 10:39:45,517 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-07-12 10:39:45,827 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-07-12 10:39:45,827 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-07-12 10:39:45,827 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-07-12 10:39:45,845 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-07-12 10:39:45,962 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om1_1        | 2021-07-12 10:39:47,641 [main] INFO reflections.Reflections: Reflections took 1529 ms to scan 1 urls, producing 94 keys and 256 values [using 2 cores]
om1_1        | 2021-07-12 10:39:49,004 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2021-07-12 10:39:49,005 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-07-12 10:39:49,005 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-07-12 10:39:55,085 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2021-07-12 10:39:55,412 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2021-07-12 10:39:55,431 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2618766934346.crt.
om1_1        | 2021-07-12 10:39:55,458 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2530584589045.crt.
om1_1        | 2021-07-12 10:39:55,634 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-07-12 10:39:56,495 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-07-12 10:39:56,497 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-07-12 10:39:57,647 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2021-07-12 10:39:57,647 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2021-07-12 10:39:58,348 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
datanode2_1  | 2021-07-12 10:40:10,705 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2021-07-12 10:40:10,735 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode2_1  | 2021-07-12 10:40:10,749 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3: ELECTION PASSED received 1 response(s) and 1 exception(s):
datanode2_1  | 2021-07-12 10:40:10,754 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO impl.LeaderElection:   Response 0: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6<-5244f159-1b5c-4bd3-a569-521c9d7b4032#0:OK-t2
datanode2_1  | 2021-07-12 10:40:10,754 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode2_1  | 2021-07-12 10:40:10,754 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO impl.LeaderElection: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3 ELECTION round 0: result PASSED
datanode2_1  | 2021-07-12 10:40:10,754 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: shutdown dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3
datanode2_1  | 2021-07-12 10:40:10,755 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode2_1  | 2021-07-12 10:40:10,755 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8025B34C7403 with new leaderId: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode2_1  | 2021-07-12 10:40:10,755 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: change Leader from null to dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6 at term 2 for becomeLeader, leader elected after 13948ms
datanode2_1  | 2021-07-12 10:40:10,756 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2021-07-12 10:40:10,756 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode2_1  | 2021-07-12 10:40:10,757 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403
datanode2_1  | 2021-07-12 10:40:10,757 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2021-07-12 10:40:10,757 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode2_1  | 2021-07-12 10:40:10,757 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2021-07-12 10:40:10,757 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2021-07-12 10:40:10,758 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2021-07-12 10:40:10,763 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2021-07-12 10:40:10,764 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-07-12 10:40:10,765 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2021-07-12 10:40:10,774 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2021-07-12 10:40:10,774 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-07-12 10:40:10,775 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-07-12 10:40:10,775 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403
datanode2_1  | 2021-07-12 10:40:10,784 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2021-07-12 10:40:10,784 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-07-12 10:40:10,784 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2021-07-12 10:40:10,784 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2021-07-12 10:40:10,785 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-07-12 10:40:10,785 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-07-12 10:40:10,792 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderStateImpl
datanode2_1  | 2021-07-12 10:40:10,792 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-07-12 10:40:10,795 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403/current/log_inprogress_0
datanode2_1  | 2021-07-12 10:40:10,806 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403-LeaderElection3] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403: set configuration 0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2021-07-12 10:40:12,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:15,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:18,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:22,079 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:25,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:25,976 [grpc-default-executor-1] INFO leader.FollowerInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a: nextIndex: updateUnconditionally 1 -> 0
datanode2_1  | 2021-07-12 10:40:28,215 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:28,577 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: Completed APPEND_ENTRIES, lastRequest: 5244f159-1b5c-4bd3-a569-521c9d7b4032->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
datanode2_1  | 2021-07-12 10:40:28,792 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: receive requestVote(ELECTION, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a, group-BF278ABA4990, 2, (t:1, i:0))
datanode2_1  | 2021-07-12 10:40:28,792 [grpc-default-executor-1] INFO impl.VoteContext: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FOLLOWER: accept ELECTION from 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-07-12 10:40:28,792 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: change Leader from 5244f159-1b5c-4bd3-a569-521c9d7b4032 to null at term 2 for updateCurrentTerm
datanode2_1  | 2021-07-12 10:40:28,792 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode2_1  | 2021-07-12 10:40:28,793 [grpc-default-executor-1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: shutdown dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState
datanode2_1  | 2021-07-12 10:40:28,793 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState] INFO impl.FollowerState: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2021-07-12 10:40:28,793 [grpc-default-executor-1] INFO impl.RoleInfo: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: start dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-FollowerState
datanode2_1  | 2021-07-12 10:40:28,799 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990 replies to ELECTION vote request: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a<-dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6#0:OK-t2. Peer's state: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990:t2, leader=null, voted=1ab7aeaf-7670-4a86-9686-feb8bb11c16a, raftlog=dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-07-12 10:40:28,866 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BF278ABA4990 with new leaderId: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode2_1  | 2021-07-12 10:40:28,866 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: change Leader from null to 1ab7aeaf-7670-4a86-9686-feb8bb11c16a at term 2 for appendEntries, leader elected after 73ms
datanode2_1  | 2021-07-12 10:40:28,897 [grpc-default-executor-1] INFO server.RaftServer$Division: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990: set configuration 1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-07-12 10:40:28,898 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode2_1  | 2021-07-12 10:40:28,900 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_0 to /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_0-0
datanode2_1  | 2021-07-12 10:40:28,905 [dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-BF278ABA4990-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_1
datanode2_1  | 2021-07-12 10:40:31,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:34,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:37,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:39,500 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode2_1  | java.net.NoRouteToHostException: No Route to Host from  ccdb996b39f4/172.25.0.103 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:855)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode2_1  | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
datanode2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
om2_1        | 2021-07-12 10:40:06,704 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2021-07-12 10:40:06,708 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-07-12 10:40:06,715 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2021-07-12 10:40:06,768 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-07-12 10:39:06,686 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-07-12 10:39:06,839 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-07-12 10:39:15,624 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-07-12 10:39:16,026 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-07-12 10:39:16,031 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-07-12 10:39:16,031 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-07-12 10:39:17,350 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2021-07-12 10:39:17,483 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-07-12 10:39:17,510 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-07-12 10:39:19,718 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2021-07-12 10:39:22,485 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2021-07-12 10:39:22,513 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2021-07-12 10:39:22,514 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2021-07-12 10:39:24,714 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2021-07-12 10:39:25,046 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2021-07-12 10:39:25,075 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2021-07-12 10:39:25,077 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2021-07-12 10:39:25,083 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-07-12 10:39:25,087 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-07-12 10:39:25,088 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-07-12 10:39:25,090 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-07-12 10:39:25,092 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:834b4eb7-146a-4c2a-bac6-4409b0eef822,clusterId:CID-ea67d158-f30d-4de4-8e61-b39e69e4a611,subject:om3
om3_1        | 2021-07-12 10:39:25,991 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2021-07-12 10:39:27,781 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-ea67d158-f30d-4de4-8e61-b39e69e4a611;layoutVersion=0
om3_1        | 2021-07-12 10:39:27,939 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-07-12 10:39:36,144 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode2_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode2_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:701)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:822)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1647)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1463)
datanode2_1  | 	... 12 more
datanode2_1  | 2021-07-12 10:40:43,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:46,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:49,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:50,387 [ChunkWriter-4-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2616268786630.
datanode2_1  | 2021-07-12 10:40:52,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:55,863 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:40:58,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:02,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:05,079 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:08,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:11,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:14,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:17,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:39:58,394 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-07-12 10:39:58,402 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2021-07-12 10:39:58,415 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2021-07-12 10:39:59,306 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2021-07-12 10:39:59,438 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-07-12 10:39:59,583 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om1:9872, om2:9872, om3:9872
om1_1        | 2021-07-12 10:39:59,626 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2021-07-12 10:40:00,470 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2021-07-12 10:40:00,892 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2021-07-12 10:40:00,893 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-07-12 10:40:00,897 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2021-07-12 10:40:00,897 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-07-12 10:40:00,898 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-07-12 10:40:00,902 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2021-07-12 10:40:00,905 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-07-12 10:40:00,910 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2021-07-12 10:40:00,916 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-07-12 10:40:06,994 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2021-07-12 10:40:07,020 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-07-12 10:40:07,020 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-07-12 10:40:07,079 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-07-12 10:40:07,158 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@54d62c35[Not completed]
om1_1        | 2021-07-12 10:40:07,158 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2021-07-12 10:40:07,287 [pool-24-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2021-07-12 10:40:07,322 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2021-07-12 10:40:07,331 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2021-07-12 10:40:07,331 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2021-07-12 10:40:07,331 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-07-12 10:40:07,334 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-07-12 10:40:07,334 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2021-07-12 10:40:07,339 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-07-12 10:40:07,345 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-07-12 10:40:07,363 [pool-24-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2021-07-12 10:40:07,369 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-07-12 10:40:07,395 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2021-07-12 10:40:07,410 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2021-07-12 10:40:07,416 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2021-07-12 10:40:07,481 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2021-07-12 10:40:07,551 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2021-07-12 10:40:07,558 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2021-07-12 10:40:07,591 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-07-12 10:40:07,636 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2021-07-12 10:40:07,637 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-07-12 10:40:07,671 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om1@group-562213E44849
om1_1        | 2021-07-12 10:40:07,717 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-07-12 10:40:07,815 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2021-07-12 10:40:07,816 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2021-07-12 10:40:07,844 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2021-07-12 10:40:07,859 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-07-12 10:40:07,860 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2021-07-12 10:40:07,863 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-07-12 10:40:07,871 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2021-07-12 10:40:07,875 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2021-07-12 10:40:07,879 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2021-07-12 10:40:07,903 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2021-07-12 10:40:07,903 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2021-07-12 10:40:07,945 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2021-07-12 10:40:07,955 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2021-07-12 10:40:07,971 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2021-07-12 10:40:07,972 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2021-07-12 10:40:07,994 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2021-07-12 10:40:07,997 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2021-07-12 10:40:07,997 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2021-07-12 10:40:07,998 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2021-07-12 10:40:08,000 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2021-07-12 10:40:08,006 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2021-07-12 10:40:08,090 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om1@group-562213E44849
om1_1        | 2021-07-12 10:40:08,101 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om1@group-562213E44849
om1_1        | 2021-07-12 10:40:08,328 [Listener at om1/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om1_1        | 2021-07-12 10:40:08,622 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2021-07-12 10:40:08,681 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2021-07-12 10:40:08,682 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2021-07-12 10:40:08,868 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2021-07-12 10:40:08,873 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2021-07-12 10:40:08,875 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-07-12 10:40:08,878 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2021-07-12 10:40:08,881 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-07-12 10:40:08,886 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2021-07-12 10:40:08,892 [Listener at om1/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om1@group-562213E44849
om1_1        | 2021-07-12 10:40:08,933 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2021-07-12 10:40:09,015 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
datanode2_1  | 2021-07-12 10:41:20,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:23,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:25,977 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:2, i:0)
datanode2_1  | 2021-07-12 10:41:26,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:32,728 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:35,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:38,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:41,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:45,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:48,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:51,159 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:54,228 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:41:57,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:00,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:03,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:06,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:09,591 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:12,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:15,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:21,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:24,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:28,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:31,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:34,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:37,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:40,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:43,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:03,521 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-07-12 10:40:03,521 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-07-12 10:40:03,559 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderStateImpl
datanode1_1  | 2021-07-12 10:40:03,602 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState] INFO impl.FollowerState: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5094588262ns, electionTimeout:5086ms
datanode1_1  | 2021-07-12 10:40:03,604 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: shutdown 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState
datanode1_1  | 2021-07-12 10:40:03,604 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-07-12 10:40:03,604 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-07-12 10:40:03,604 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2
datanode1_1  | 2021-07-12 10:40:03,609 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode1_1  | 2021-07-12 10:40:03,707 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-07-12 10:40:04,061 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-LeaderElection1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2: set configuration 0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-07-12 10:40:04,799 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-DFB2E619C9E2-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/269136cc-c909-477b-8eee-dfb2e619c9e2/current/log_inprogress_0
datanode1_1  | 2021-07-12 10:40:05,213 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:05,419 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode1_1  | 2021-07-12 10:40:05,521 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: receive requestVote(ELECTION, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, group-8025B34C7403, 1, (t:0, i:0))
datanode1_1  | 2021-07-12 10:40:05,522 [grpc-default-executor-0] INFO impl.VoteContext: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-CANDIDATE: reject ELECTION from dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: already has voted for 5244f159-1b5c-4bd3-a569-521c9d7b4032 at current term 1
datanode1_1  | 2021-07-12 10:40:05,568 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403 replies to ELECTION vote request: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6<-5244f159-1b5c-4bd3-a569-521c9d7b4032#0:FAIL-t1. Peer's state: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403:t1, leader=null, voted=5244f159-1b5c-4bd3-a569-521c9d7b4032, raftlog=5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode1_1  | 2021-07-12 10:40:06,169 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode1_1  | 2021-07-12 10:40:06,216 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2: ELECTION REJECTED received 1 response(s) and 1 exception(s):
datanode1_1  | 2021-07-12 10:40:06,216 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection:   Response 0: 5244f159-1b5c-4bd3-a569-521c9d7b4032<-dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6#0:FAIL-t1
datanode1_1  | 2021-07-12 10:40:06,217 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-8025B34C7403 not found.
datanode1_1  | 2021-07-12 10:40:06,217 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2 ELECTION round 0: result REJECTED
datanode1_1  | 2021-07-12 10:40:06,218 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode1_1  | 2021-07-12 10:40:06,218 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: shutdown 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2
datanode1_1  | 2021-07-12 10:40:06,218 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-LeaderElection2] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState
datanode1_1  | 2021-07-12 10:40:07,096 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState] INFO impl.FollowerState: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5143651564ns, electionTimeout:5129ms
datanode1_1  | 2021-07-12 10:40:07,096 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: shutdown 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState
datanode1_1  | 2021-07-12 10:40:07,096 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-07-12 10:40:07,097 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-07-12 10:40:07,097 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3
datanode1_1  | 2021-07-12 10:40:07,106 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode1_1  | 2021-07-12 10:40:07,144 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-BF278ABA4990 not found.
datanode1_1  | 2021-07-12 10:40:07,159 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3: ELECTION PASSED received 1 response(s) and 1 exception(s):
datanode1_1  | 2021-07-12 10:40:07,159 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO impl.LeaderElection:   Response 0: 5244f159-1b5c-4bd3-a569-521c9d7b4032<-dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6#0:OK-t1
datanode1_1  | 2021-07-12 10:40:07,159 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: group-BF278ABA4990 not found.
datanode1_1  | 2021-07-12 10:40:07,159 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO impl.LeaderElection: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3 ELECTION round 0: result PASSED
datanode1_1  | 2021-07-12 10:40:07,160 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: shutdown 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3
datanode1_1  | 2021-07-12 10:40:07,160 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2021-07-12 10:40:07,160 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BF278ABA4990 with new leaderId: 5244f159-1b5c-4bd3-a569-521c9d7b4032
datanode1_1  | 2021-07-12 10:40:07,160 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: change Leader from null to 5244f159-1b5c-4bd3-a569-521c9d7b4032 at term 1 for becomeLeader, leader elected after 5289ms
datanode1_1  | 2021-07-12 10:40:07,160 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-07-12 10:40:07,160 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:07,161 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode1_1  | 2021-07-12 10:40:07,162 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-07-12 10:40:07,165 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode1_1  | 2021-07-12 10:40:07,166 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2021-07-12 10:40:07,166 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-07-12 10:40:07,166 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-07-12 10:40:07,182 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2021-07-12 10:40:07,188 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-07-12 10:40:07,189 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2021-07-12 10:40:07,205 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2021-07-12 10:40:07,206 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-07-12 10:40:07,206 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-07-12 10:40:07,206 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:07,237 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2021-07-12 10:40:07,237 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-07-12 10:40:07,240 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2021-07-12 10:40:07,240 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2021-07-12 10:40:07,240 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-07-12 10:40:07,240 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-07-12 10:40:07,241 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl
datanode1_1  | 2021-07-12 10:40:07,241 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-07-12 10:40:07,252 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_0
datanode1_1  | 2021-07-12 10:40:07,283 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderElection3] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: set configuration 0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-07-12 10:40:08,284 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:10,733 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: receive requestVote(ELECTION, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, group-8025B34C7403, 2, (t:0, i:0))
datanode1_1  | 2021-07-12 10:40:10,733 [grpc-default-executor-0] INFO impl.VoteContext: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FOLLOWER: accept ELECTION from dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: our priority 0 <= candidate's priority 1
datanode1_1  | 2021-07-12 10:40:10,733 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
datanode1_1  | 2021-07-12 10:40:10,733 [grpc-default-executor-0] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: shutdown 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState
datanode1_1  | 2021-07-12 10:40:10,733 [grpc-default-executor-0] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState
datanode1_1  | 2021-07-12 10:40:10,734 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState] INFO impl.FollowerState: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1        | 2021-07-12 10:40:06,770 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2021-07-12 10:40:06,779 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2021-07-12 10:40:06,779 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2021-07-12 10:40:06,843 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2021-07-12 10:40:06,849 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2021-07-12 10:40:06,900 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2021-07-12 10:40:06,911 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2021-07-12 10:40:06,959 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2021-07-12 10:40:06,960 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2021-07-12 10:40:06,960 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2021-07-12 10:40:06,961 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2021-07-12 10:40:06,978 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2021-07-12 10:40:06,979 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2021-07-12 10:40:07,189 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om2@group-562213E44849
om2_1        | 2021-07-12 10:40:07,204 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om2@group-562213E44849
om2_1        | 2021-07-12 10:40:07,678 [Listener at om2/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om2_1        | 2021-07-12 10:40:07,974 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2021-07-12 10:40:08,011 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2021-07-12 10:40:08,011 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2021-07-12 10:40:08,134 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2021-07-12 10:40:08,138 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2021-07-12 10:40:08,139 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-07-12 10:40:08,147 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2021-07-12 10:40:08,149 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-07-12 10:40:08,160 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2021-07-12 10:40:08,161 [Listener at om2/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om2@group-562213E44849
om2_1        | 2021-07-12 10:40:08,197 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2021-07-12 10:40:08,302 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2021-07-12 10:40:08,311 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$392/0x0000000840593440@4ae1ee85] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2021-07-12 10:40:08,311 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2021-07-12 10:40:08,312 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-07-12 10:40:08,313 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2021-07-12 10:40:08,313 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-07-12 10:40:08,324 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2021-07-12 10:40:08,331 [Thread[Thread-16,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2021-07-12 10:40:08,463 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2021-07-12 10:40:08,466 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2021-07-12 10:40:08,468 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2021-07-12 10:40:08,566 [Listener at om2/9862] INFO util.log: Logging initialized @38554ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2021-07-12 10:40:09,001 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2021-07-12 10:40:09,025 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2021-07-12 10:40:09,031 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2021-07-12 10:40:09,037 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2021-07-12 10:40:09,039 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2021-07-12 10:40:09,041 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2021-07-12 10:40:09,178 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2021-07-12 10:40:09,195 [Listener at om2/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om2_1        | 2021-07-12 10:40:09,293 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2021-07-12 10:40:09,294 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2021-07-12 10:40:09,300 [Listener at om2/9862] INFO server.session: node0 Scavenging every 660000ms
om2_1        | 2021-07-12 10:40:09,353 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-07-12 10:39:36,192 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-07-12 10:39:43,159 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-07-12 10:39:43,537 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-07-12 10:39:43,538 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-07-12 10:39:43,539 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-07-12 10:39:43,590 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-07-12 10:39:43,813 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om3_1        | 2021-07-12 10:39:45,188 [main] INFO reflections.Reflections: Reflections took 891 ms to scan 1 urls, producing 94 keys and 256 values [using 2 cores]
om3_1        | 2021-07-12 10:39:46,312 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2021-07-12 10:39:46,317 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-07-12 10:39:46,317 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-07-12 10:39:53,311 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2021-07-12 10:39:53,812 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2021-07-12 10:39:53,839 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2530584589045.crt.
om3_1        | 2021-07-12 10:39:53,864 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2616268786630.crt.
om3_1        | 2021-07-12 10:39:54,135 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-07-12 10:39:54,772 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-07-12 10:39:54,775 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-07-12 10:39:55,863 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2021-07-12 10:39:55,863 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2021-07-12 10:39:56,630 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
datanode3_1  | 2021-07-12 10:40:28,602 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BF278ABA4990 with new leaderId: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode3_1  | 2021-07-12 10:40:28,602 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: change Leader from null to 1ab7aeaf-7670-4a86-9686-feb8bb11c16a at term 2 for becomeLeader, leader elected after 396ms
datanode3_1  | 2021-07-12 10:40:28,607 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-07-12 10:40:28,609 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990
datanode3_1  | 2021-07-12 10:40:28,614 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-07-12 10:40:28,618 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-07-12 10:40:28,628 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-07-12 10:40:28,637 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-07-12 10:40:28,637 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-07-12 10:40:28,676 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-07-12 10:40:28,677 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-07-12 10:40:28,680 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-07-12 10:40:28,693 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-07-12 10:40:28,699 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-07-12 10:40:28,701 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-07-12 10:40:28,702 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990
datanode3_1  | 2021-07-12 10:40:28,727 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-07-12 10:40:28,729 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-07-12 10:40:28,730 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-07-12 10:40:28,730 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-07-12 10:40:28,731 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-07-12 10:40:28,731 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-07-12 10:40:28,739 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: start 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderStateImpl
datanode3_1  | 2021-07-12 10:40:28,804 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode3_1  | 2021-07-12 10:40:28,809 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_0 to /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_0-0
datanode3_1  | 2021-07-12 10:40:28,813 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_1
datanode3_1  | 2021-07-12 10:40:28,831 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990-LeaderElection1] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-BF278ABA4990: set configuration 1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-07-12 10:40:28,841 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-FollowerState] INFO impl.FollowerState: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5037313706ns, electionTimeout:5028ms
datanode3_1  | 2021-07-12 10:40:28,842 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-FollowerState] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: shutdown 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-FollowerState
datanode3_1  | 2021-07-12 10:40:28,842 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-FollowerState] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-07-12 10:40:28,842 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-07-12 10:40:28,843 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-FollowerState] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: start 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2
datanode3_1  | 2021-07-12 10:40:28,903 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO impl.LeaderElection: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-07-12 10:40:28,918 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO impl.LeaderElection: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2021-07-12 10:40:28,919 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: shutdown 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2
datanode3_1  | 2021-07-12 10:40:28,919 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2021-07-12 10:40:28,919 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-1AB14A6AB8A5 with new leaderId: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode3_1  | 2021-07-12 10:40:28,921 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5: change Leader from null to 1ab7aeaf-7670-4a86-9686-feb8bb11c16a at term 1 for becomeLeader, leader elected after 5467ms
datanode3_1  | 2021-07-12 10:40:28,922 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-07-12 10:40:28,922 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode3_1  | 2021-07-12 10:40:28,922 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5
datanode3_1  | 2021-07-12 10:40:28,923 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-07-12 10:40:28,926 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-07-12 10:40:28,926 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-07-12 10:40:28,927 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-07-12 10:40:28,927 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-07-12 10:40:28,930 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO impl.RoleInfo: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: start 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderStateImpl
datanode3_1  | 2021-07-12 10:40:28,931 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-07-12 10:40:28,935 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5/current/log_inprogress_0
datanode3_1  | 2021-07-12 10:40:28,950 [1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5-LeaderElection2] INFO server.RaftServer$Division: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a@group-1AB14A6AB8A5: set configuration 0: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-07-12 10:40:30,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:33,431 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:35,501 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode3_1  | java.net.NoRouteToHostException: No Route to Host from  f311c7ebb23c/172.25.0.104 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:855)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode3_1  | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
datanode3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode3_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode3_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:701)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:822)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1647)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1463)
datanode3_1  | 	... 12 more
om3_1        | 2021-07-12 10:39:56,685 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-07-12 10:39:56,685 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2021-07-12 10:39:56,690 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2021-07-12 10:39:57,387 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2021-07-12 10:39:57,516 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-07-12 10:39:57,692 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om3:9872, om1:9872, om2:9872
om3_1        | 2021-07-12 10:39:57,760 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2021-07-12 10:39:58,948 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2021-07-12 10:39:59,276 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2021-07-12 10:39:59,279 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-07-12 10:39:59,281 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2021-07-12 10:39:59,286 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-07-12 10:39:59,287 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-07-12 10:39:59,288 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2021-07-12 10:39:59,291 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-07-12 10:39:59,299 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2021-07-12 10:39:59,301 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-07-12 10:40:02,799 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2021-07-12 10:40:02,800 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-07-12 10:40:02,807 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-07-12 10:40:02,872 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-07-12 10:40:02,919 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@54d62c35[Not completed]
om3_1        | 2021-07-12 10:40:02,923 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2021-07-12 10:40:03,061 [pool-24-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2021-07-12 10:40:03,073 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2021-07-12 10:40:03,087 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2021-07-12 10:40:03,088 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2021-07-12 10:40:03,090 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-07-12 10:40:03,090 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-07-12 10:40:03,096 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2021-07-12 10:40:03,100 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-07-12 10:40:03,126 [pool-24-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2021-07-12 10:40:03,128 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-07-12 10:40:03,159 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2021-07-12 10:40:03,164 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2021-07-12 10:40:03,219 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2021-07-12 10:40:03,239 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om3
om3_1        | 2021-07-12 10:40:03,271 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2021-07-12 10:40:03,327 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2021-07-12 10:40:03,338 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2021-07-12 10:40:03,363 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2021-07-12 10:40:03,400 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2021-07-12 10:40:03,404 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-07-12 10:40:03,432 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om3@group-562213E44849
om3_1        | 2021-07-12 10:40:03,524 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-07-12 10:40:03,576 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2021-07-12 10:40:03,576 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2021-07-12 10:40:03,694 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2021-07-12 10:40:03,714 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-07-12 10:40:03,722 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2021-07-12 10:40:03,725 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-07-12 10:40:03,729 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2021-07-12 10:40:03,729 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2021-07-12 10:40:03,736 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2021-07-12 10:40:03,741 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2021-07-12 10:40:03,747 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2021-07-12 10:40:03,803 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2021-07-12 10:40:03,803 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2021-07-12 10:40:03,847 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2021-07-12 10:40:03,847 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2021-07-12 10:40:03,876 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2021-07-12 10:40:03,879 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2021-07-12 10:40:03,884 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2021-07-12 10:40:03,885 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2021-07-12 10:40:03,900 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2021-07-12 10:40:03,902 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2021-07-12 10:40:04,066 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om3@group-562213E44849
om3_1        | 2021-07-12 10:40:04,078 [pool-24-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om3@group-562213E44849
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | 2021-07-12 10:40:09,359 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5bbda8aa{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om1_1        | 2021-07-12 10:40:09,031 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$392/0x0000000840592c40@79927a7c] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2021-07-12 10:40:09,032 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2021-07-12 10:40:09,032 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-07-12 10:40:09,034 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om1_1        | 2021-07-12 10:40:09,034 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-07-12 10:40:09,042 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
datanode1_1  | 2021-07-12 10:40:10,746 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403 replies to ELECTION vote request: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6<-5244f159-1b5c-4bd3-a569-521c9d7b4032#0:OK-t2. Peer's state: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403:t2, leader=null, voted=dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, raftlog=5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode1_1  | 2021-07-12 10:40:10,864 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8025B34C7403 with new leaderId: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
om1_1        | 2021-07-12 10:40:09,046 [Thread[Thread-16,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2021-07-12 10:40:09,146 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
datanode1_1  | 2021-07-12 10:40:10,864 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: change Leader from null to dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6 at term 2 for appendEntries, leader elected after 12417ms
datanode1_1  | 2021-07-12 10:40:10,910 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403: set configuration 0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
om1_1        | 2021-07-12 10:40:09,148 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2021-07-12 10:40:09,148 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2021-07-12 10:40:09,367 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@b729651{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2021-07-12 10:40:10,911 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-07-12 10:40:10,938 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-8025B34C7403-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/834b1be7-db7b-48e4-83db-8025b34c7403/current/log_inprogress_0
om2_1        | 2021-07-12 10:40:09,607 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2021-07-12 10:40:09,637 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@14a3d15b{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-5976967718739487647/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2021-07-12 10:40:09,232 [Listener at om1/9862] INFO util.log: Logging initialized @38068ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2021-07-12 10:40:09,592 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2021-07-12 10:40:11,351 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:12,579 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl send StartLeaderElectionRequest to follower:1ab7aeaf-7670-4a86-9686-feb8bb11c16a on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
om2_1        | 2021-07-12 10:40:09,666 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@5d95c7c2{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2021-07-12 10:40:09,667 [Listener at om2/9862] INFO server.Server: Started @39655ms
recon_1      | 2021-07-12 10:37:49,554 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
om1_1        | 2021-07-12 10:40:09,620 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2021-07-12 10:40:09,621 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
datanode1_1  | 2021-07-12 10:40:14,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:17,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:40:09,676 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-07-12 10:40:09,627 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
om2_1        | 2021-07-12 10:40:09,679 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-07-12 10:40:09,627 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2021-07-12 10:40:17,793 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl send StartLeaderElectionRequest to follower:1ab7aeaf-7670-4a86-9686-feb8bb11c16a on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
datanode1_1  | 2021-07-12 10:40:20,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:40:09,680 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2021-07-12 10:40:09,630 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | 2021-07-12 10:40:09,683 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2021-07-12 10:40:09,747 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
datanode1_1  | 2021-07-12 10:40:22,993 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl send StartLeaderElectionRequest to follower:1ab7aeaf-7670-4a86-9686-feb8bb11c16a on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
datanode1_1  | 2021-07-12 10:40:23,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:40:09,953 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2021-07-12 10:40:09,750 [Listener at om1/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.2.0-SNAPSHOT.jar
datanode1_1  | 2021-07-12 10:40:25,051 [grpc-default-executor-0] INFO leader.FollowerInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->1ab7aeaf-7670-4a86-9686-feb8bb11c16a: nextIndex: updateUnconditionally 1 -> 0
om2_1        | 2021-07-12 10:40:09,967 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2021-07-12 10:40:09,992 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7b6bcbee] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2021-07-12 10:40:09,830 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2021-07-12 10:40:26,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
recon_1      | STARTUP_MSG:   java = 11.0.10
om1_1        | 2021-07-12 10:40:09,838 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2021-07-12 10:42:46,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:49,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:52,246 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=292,entriesCount=1,lastEntry=(t:2, i:1)
om2_1        | 2021-07-12 10:40:12,945 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om2
om2_1        | 2021-07-12 10:40:12,991 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-07-12 10:40:13,017 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om3: our priority 0 <= candidate's priority 0
datanode1_1  | 2021-07-12 10:40:28,194 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl send StartLeaderElectionRequest to follower:1ab7aeaf-7670-4a86-9686-feb8bb11c16a on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
datanode1_1  | 2021-07-12 10:40:28,247 [Thread-62] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl received success reply of StartLeaderElectionRequest from follower:1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode1_1  | 2021-07-12 10:40:28,529 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: receive requestVote(ELECTION, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a, group-BF278ABA4990, 2, (t:1, i:0))
datanode1_1  | 2021-07-12 10:40:28,529 [grpc-default-executor-0] INFO impl.VoteContext: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LEADER: accept ELECTION from 1ab7aeaf-7670-4a86-9686-feb8bb11c16a: our priority 0 <= candidate's priority 1
datanode1_1  | 2021-07-12 10:40:28,535 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: change Leader from 5244f159-1b5c-4bd3-a569-521c9d7b4032 to null at term 2 for updateCurrentTerm
om1_1        | 2021-07-12 10:40:09,839 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2021-07-12 10:40:09,888 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-07-12 10:40:09,893 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79228440{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2021-07-12 10:40:09,901 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@c3fd72{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2021-07-12 10:40:10,086 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
recon_1      | ************************************************************/
recon_1      | 2021-07-12 10:37:49,628 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2021-07-12 10:37:52,021 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1      | 2021-07-12 10:37:53,536 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2021-07-12 10:37:53,939 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
datanode2_1  | 2021-07-12 10:42:52,267 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=293,entriesCount=1,lastEntry=(t:2, i:2)
datanode2_1  | 2021-07-12 10:42:52,409 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=294,entriesCount=1,lastEntry=(t:2, i:3)
datanode2_1  | 2021-07-12 10:42:52,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:55,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:42:58,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:01,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:40:13,020 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om3
om2_1        | 2021-07-12 10:40:13,020 [grpc-default-executor-0] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-07-12 10:40:13,024 [grpc-default-executor-0] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-07-12 10:40:13,030 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted: {}
om2_1        | java.lang.InterruptedException: sleep interrupted
om2_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om2_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om2_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om2_1        | 2021-07-12 10:40:13,097 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:OK-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om3, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-07-12 10:40:13,625 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om3 at term 1 for appendEntries, leader elected after 7378ms
datanode1_1  | 2021-07-12 10:40:28,535 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: changes role from    LEADER to FOLLOWER at term 2 for candidate:1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode1_1  | 2021-07-12 10:40:28,535 [grpc-default-executor-0] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: shutdown 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-LeaderStateImpl
datanode1_1  | 2021-07-12 10:40:28,536 [grpc-default-executor-0] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis_grpc.log_appender.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:28,537 [grpc-default-executor-0] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis_grpc.log_appender.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:28,537 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode1_1  | 2021-07-12 10:40:28,537 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode1_1  | 2021-07-12 10:40:28,538 [grpc-default-executor-0] INFO impl.PendingRequests: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-PendingRequests: sendNotLeaderResponses
datanode1_1  | 2021-07-12 10:40:28,540 [grpc-default-executor-0] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:28,542 [grpc-default-executor-0] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990
datanode1_1  | 2021-07-12 10:40:28,543 [grpc-default-executor-0] INFO impl.RoleInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032: start 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-FollowerState
recon_1      | 2021-07-12 10:37:54,277 [main] ERROR recon.ReconServer: Error login in as Recon service. 
recon_1      | org.apache.hadoop.security.KerberosAuthException: failure to login: for principal: recon/recon@EXAMPLE.COM from keytab /etc/security/keytabs/recon.keytab javax.security.auth.login.LoginException: Unable to obtain password from user
recon_1      | 
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1986)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytabAndReturnUGI(UserGroupInformation.java:1361)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:1122)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:315)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.loginReconUser(ReconServer.java:216)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.loginReconUserIfSecurityEnabled(ReconServer.java:191)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:99)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:55)
recon_1      | 	at picocli.CommandLine.executeUserObject(CommandLine.java:1933)
recon_1      | 	at picocli.CommandLine.access$1100(CommandLine.java:145)
recon_1      | 	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2332)
recon_1      | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2326)
recon_1      | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2291)
recon_1      | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:2152)
recon_1      | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:2530)
recon_1      | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:2465)
recon_1      | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:96)
recon_1      | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:87)
om1_1        | 2021-07-12 10:40:10,129 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7960e87a{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-9966305415541784586/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2021-07-12 10:40:10,164 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@54d93fce{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2021-07-12 10:40:10,164 [Listener at om1/9862] INFO server.Server: Started @39001ms
om1_1        | 2021-07-12 10:40:10,170 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-07-12 10:40:10,170 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-07-12 10:40:10,176 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2021-07-12 10:40:10,176 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2021-07-12 10:40:10,235 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2021-07-12 10:40:10,373 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2021-07-12 10:40:10,400 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ea206bc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2021-07-12 10:40:12,930 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om1
om1_1        | 2021-07-12 10:40:13,016 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2021-07-12 10:40:13,024 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: accept ELECTION from om3: our priority 0 <= candidate's priority 0
om1_1        | 2021-07-12 10:40:13,035 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om3
om1_1        | 2021-07-12 10:40:13,035 [grpc-default-executor-0] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2021-07-12 10:40:13,036 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted: {}
om1_1        | java.lang.InterruptedException: sleep interrupted
om1_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om1_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om1_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om1_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om1_1        | 2021-07-12 10:40:13,043 [grpc-default-executor-0] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-07-12 10:40:13,096 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:OK-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om3, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-07-12 10:40:13,613 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om3 at term 1 for appendEntries, leader elected after 6054ms
om1_1        | 2021-07-12 10:40:13,703 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2021-07-12 10:40:13,717 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2021-07-12 10:40:14,029 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2021-07-12 10:40:32,306 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40408
om1_1        | 2021-07-12 10:40:32,333 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:40:45,685 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40470
om1_1        | 2021-07-12 10:40:45,710 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:40:47,237 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
datanode2_1  | 2021-07-12 10:43:04,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:11,028 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:14,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:17,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:20,243 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:23,316 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:26,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:29,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:32,535 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:35,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:38,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:41,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:40:04,757 [Listener at om3/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om3_1        | 2021-07-12 10:40:05,424 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2021-07-12 10:40:05,496 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2021-07-12 10:40:05,497 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2021-07-12 10:40:05,753 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2021-07-12 10:40:05,765 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2021-07-12 10:40:05,767 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-07-12 10:40:05,772 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2021-07-12 10:40:05,775 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-07-12 10:40:05,792 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2021-07-12 10:40:05,796 [Listener at om3/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om3@group-562213E44849
om3_1        | 2021-07-12 10:40:05,851 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2021-07-12 10:40:06,073 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2021-07-12 10:40:06,094 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2021-07-12 10:40:06,095 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-07-12 10:40:06,096 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2021-07-12 10:40:06,096 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-07-12 10:40:06,105 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$392/0x0000000840592c40@79927a7c] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2021-07-12 10:40:06,121 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2021-07-12 10:40:06,123 [Thread[Thread-16,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2021-07-12 10:40:06,302 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2021-07-12 10:40:06,302 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2021-07-12 10:40:06,302 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2021-07-12 10:40:06,404 [Listener at om3/9862] INFO util.log: Logging initialized @37551ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2021-07-12 10:40:06,901 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2021-07-12 10:40:06,926 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2021-07-12 10:40:06,927 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2021-07-12 10:40:06,943 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2021-07-12 10:40:06,943 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2021-07-12 10:40:06,946 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2021-07-12 10:40:07,152 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2021-07-12 10:40:07,157 [Listener at om3/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode1_1  | 2021-07-12 10:40:28,567 [grpc-default-executor-0] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990 replies to ELECTION vote request: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a<-5244f159-1b5c-4bd3-a569-521c9d7b4032#0:OK-t2. Peer's state: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990:t2, leader=null, voted=1ab7aeaf-7670-4a86-9686-feb8bb11c16a, raftlog=5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-07-12 10:40:28,590 [grpc-default-executor-1] INFO server.GrpcLogAppender: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode1_1  | 2021-07-12 10:40:28,590 [grpc-default-executor-2] INFO server.GrpcLogAppender: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode1_1  | 2021-07-12 10:40:28,601 [grpc-default-executor-2] INFO leader.FollowerInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: nextIndex: updateUnconditionally 1 -> 0
datanode1_1  | 2021-07-12 10:40:28,597 [grpc-default-executor-1] INFO leader.FollowerInfo: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990->1ab7aeaf-7670-4a86-9686-feb8bb11c16a: nextIndex: updateUnconditionally 1 -> 0
datanode1_1  | 2021-07-12 10:40:28,888 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BF278ABA4990 with new leaderId: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a
datanode1_1  | 2021-07-12 10:40:28,889 [grpc-default-executor-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: change Leader from null to 1ab7aeaf-7670-4a86-9686-feb8bb11c16a at term 2 for appendEntries, leader elected after 353ms
datanode1_1  | 2021-07-12 10:40:28,912 [grpc-default-executor-1] INFO server.RaftServer$Division: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990: set configuration 1: [5244f159-1b5c-4bd3-a569-521c9d7b4032|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-07-12 10:40:28,913 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode1_1  | 2021-07-12 10:40:28,915 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_0 to /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_0-0
om2_1        | 2021-07-12 10:40:13,709 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-07-12 10:40:13,725 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2021-07-12 10:40:14,095 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2021-07-12 10:40:32,766 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42950
om2_1        | 2021-07-12 10:40:32,776 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:40:45,751 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43014
om2_1        | 2021-07-12 10:40:45,752 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:40:47,526 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-07-12 10:40:55,588 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43080
om2_1        | 2021-07-12 10:40:55,599 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:40:56,104 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43088
om2_1        | 2021-07-12 10:40:56,108 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:00,340 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43110
om2_1        | 2021-07-12 10:41:00,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:43:44,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:47,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:50,967 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:43:54,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:00,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:03,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:06,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:09,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:12,471 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:15,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:18,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:21,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2021-07-12 10:37:49,987 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2021-07-12 10:37:50,003 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2021-07-12 10:37:50,003 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2021-07-12 10:37:50,148 [main] INFO util.log: Logging initialized @3991ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2021-07-12 10:37:50,653 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2021-07-12 10:37:50,695 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2021-07-12 10:37:50,705 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2021-07-12 10:37:50,705 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2021-07-12 10:37:50,711 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2021-07-12 10:40:28,928 [5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5244f159-1b5c-4bd3-a569-521c9d7b4032@group-BF278ABA4990-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc4a04e1-b6f2-444a-9fba-bf278aba4990/current/log_inprogress_1
datanode1_1  | 2021-07-12 10:40:29,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:32,854 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:35,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:38,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:41,068 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode1_1  | java.net.NoRouteToHostException: No Route to Host from  071a21c71cec/172.25.0.102 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:855)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode1_1  | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
datanode1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode1_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode1_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:701)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:822)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1647)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1463)
datanode1_1  | 	... 12 more
datanode1_1  | 2021-07-12 10:40:45,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:48,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:50,384 [ChunkWriter-0-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2616268786630.
datanode1_1  | 2021-07-12 10:40:51,284 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:54,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:40:57,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:00,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:03,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:06,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:09,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:12,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:15,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:18,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:22,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:25,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:28,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:34,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:37,367 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:40,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:43,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:46,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:49,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:71)
recon_1      | Caused by: javax.security.auth.login.LoginException: Unable to obtain password from user
recon_1      | 
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.promptForPass(Krb5LoginModule.java:875)
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:738)
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.login(Krb5LoginModule.java:592)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.invoke(LoginContext.java:726)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext$4.run(LoginContext.java:665)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext$4.run(LoginContext.java:663)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:663)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.login(LoginContext.java:574)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext.login(UserGroupInformation.java:2065)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1975)
recon_1      | 	... 18 more
recon_1      | 2021-07-12 10:37:55,608 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-07-12 10:37:58,599 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2021-07-12 10:37:59,376 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-07-12 10:37:59,407 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2021-07-12 10:37:59,419 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2021-07-12 10:38:01,420 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
om2_1        | 2021-07-12 10:41:00,865 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43118
om2_1        | 2021-07-12 10:41:00,870 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:05,329 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43144
om2_1        | 2021-07-12 10:41:05,342 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:12,071 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43184
om2_1        | 2021-07-12 10:41:12,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:16,879 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43204
om2_1        | 2021-07-12 10:41:16,886 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:17,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43220
om2_1        | 2021-07-12 10:41:17,428 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:21,706 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43252
om2_1        | 2021-07-12 10:41:21,708 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:25,732 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43278
om2_1        | 2021-07-12 10:41:25,738 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:38,538 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43332
om2_1        | 2021-07-12 10:41:38,558 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:39,069 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:12548-source for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-07-12 10:41:42,343 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43356
om2_1        | 2021-07-12 10:41:42,350 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:42,868 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:12548-target for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-07-12 10:41:46,066 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43370
om2_1        | 2021-07-12 10:41:46,070 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:49,538 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43392
om2_1        | 2021-07-12 10:41:49,543 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:41:58,406 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43448
om2_1        | 2021-07-12 10:41:58,443 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:02,208 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43472
om2_1        | 2021-07-12 10:42:02,214 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:44:24,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:27,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:30,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:33,976 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:37,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:40,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:43,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:49,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:52,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:55,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:44:58,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:01,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:04,695 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:07,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 2021-07-12 10:37:50,727 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2021-07-12 10:37:51,162 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
s3g_1        | STARTUP_MSG:   java = 11.0.10
s3g_1        | ************************************************************/
s3g_1        | 2021-07-12 10:37:51,183 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2021-07-12 10:37:51,322 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2021-07-12 10:37:51,344 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2021-07-12 10:37:51,355 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
s3g_1        | 2021-07-12 10:37:51,556 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2021-07-12 10:37:51,557 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2021-07-12 10:37:51,572 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2021-07-12 10:37:51,739 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2021-07-12 10:37:51,847 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4d18aa28{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2021-07-12 10:37:51,850 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@674658f7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2021-07-12 10:37:58,461 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Jul 12, 2021 10:38:01 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2021-07-12 10:38:01,130 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@51af8049{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_2_0-SNAPSHOT_jar-_-any-3795910714874161269/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2021-07-12 10:38:01,155 [main] INFO server.AbstractConnector: Started ServerConnector@2c88b9fc{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2021-07-12 10:38:01,155 [main] INFO server.Server: Started @14999ms
s3g_1        | 2021-07-12 10:38:01,157 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2021-07-12 10:45:23,278 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:23,732 [qtp1363396194-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-66815, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:45:23,774 [qtp1363396194-22] INFO endpoint.BucketEndpoint: Location is /bucket-66815
s3g_1        | 2021-07-12 10:45:28,880 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om3_1        | 2021-07-12 10:40:07,301 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2021-07-12 10:40:07,303 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2021-07-12 10:40:07,310 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
om3_1        | 2021-07-12 10:40:07,425 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-07-12 10:40:55,515 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40538
om1_1        | 2021-07-12 10:40:55,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:40:56,080 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40546
om1_1        | 2021-07-12 10:40:56,082 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:00,269 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40568
om1_1        | 2021-07-12 10:41:00,290 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:40:07,446 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79228440{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2021-07-12 10:40:07,474 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@c3fd72{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2021-07-12 10:40:07,894 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-07-12 10:40:07,934 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7960e87a{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-465667991388719361/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2021-07-12 10:40:07,960 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@54d93fce{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2021-07-12 10:40:07,960 [Listener at om3/9862] INFO server.Server: Started @39107ms
om3_1        | 2021-07-12 10:40:07,976 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2021-07-12 10:40:07,977 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2021-07-12 10:40:07,978 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
datanode2_1  | 2021-07-12 10:45:10,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:13,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:16,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:20,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:23,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:26,195 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:29,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:32,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:38,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:41,559 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:44,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:47,703 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:50,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:53,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:56,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:45:59,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:03,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:06,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:09,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:12,276 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:41:00,845 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40576
om1_1        | 2021-07-12 10:41:00,847 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:05,278 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40602
om1_1        | 2021-07-12 10:41:05,295 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:12,002 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40642
om1_1        | 2021-07-12 10:41:12,032 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:16,843 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40662
om1_1        | 2021-07-12 10:41:16,857 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:17,403 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40676
om1_1        | 2021-07-12 10:41:17,412 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:21,657 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40710
om1_1        | 2021-07-12 10:41:21,671 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:25,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40736
om1_1        | 2021-07-12 10:41:25,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:38,475 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40790
om1_1        | 2021-07-12 10:41:38,496 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:39,078 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:12548-source for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-07-12 10:41:42,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40814
om1_1        | 2021-07-12 10:41:42,304 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:42,855 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:12548-target for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-07-12 10:41:45,962 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40828
om1_1        | 2021-07-12 10:41:45,991 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:49,446 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40850
om1_1        | 2021-07-12 10:41:49,496 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:41:58,347 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40906
om1_1        | 2021-07-12 10:41:58,366 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:02,110 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40930
recon_1      | 2021-07-12 10:38:01,421 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2021-07-12 10:38:01,421 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2021-07-12 10:38:01,434 [main] INFO util.log: Logging initialized @14586ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2021-07-12 10:38:01,584 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2021-07-12 10:38:01,592 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2021-07-12 10:38:01,596 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2021-07-12 10:38:01,599 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2021-07-12 10:38:01,599 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2021-07-12 10:38:01,601 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2021-07-12 10:38:01,800 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2021-07-12 10:38:02,185 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2021-07-12 10:38:02,205 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2021-07-12 10:38:02,266 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2021-07-12 10:38:03,538 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-07-12 10:38:04,074 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-07-12 10:38:04,134 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2021-07-12 10:38:04,140 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2021-07-12 10:38:04,259 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-07-12 10:38:04,504 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
recon_1      | 2021-07-12 10:38:04,727 [main] INFO reflections.Reflections: Reflections took 190 ms to scan 3 urls, producing 103 keys and 210 values 
recon_1      | 2021-07-12 10:38:04,905 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2021-07-12 10:38:04,988 [main] INFO node.SCMNodeManager: Entering startup safe mode.
om3_1        | 2021-07-12 10:40:07,978 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2021-07-12 10:40:08,007 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2021-07-12 10:40:08,203 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2021-07-12 10:40:08,243 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ea206bc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2021-07-12 10:40:10,895 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5122279057ns, electionTimeout:5098ms
om3_1        | 2021-07-12 10:40:10,896 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-07-12 10:40:10,897 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2021-07-12 10:40:10,899 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2021-07-12 10:40:10,899 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2021-07-12 10:40:10,916 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-07-12 10:40:13,190 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
om3_1        | 2021-07-12 10:40:13,202 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:OK-t1
om3_1        | 2021-07-12 10:40:13,202 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result PASSED
om3_1        | 2021-07-12 10:40:13,203 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2021-07-12 10:40:13,204 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om3_1        | 2021-07-12 10:40:13,204 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om3 at term 1 for becomeLeader, leader elected after 9872ms
om3_1        | 2021-07-12 10:40:13,227 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om3_1        | 2021-07-12 10:40:13,239 [om3@group-562213E44849-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.om3@group-562213E44849
om3_1        | 2021-07-12 10:40:13,249 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om3_1        | 2021-07-12 10:40:13,255 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-07-12 10:40:13,274 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om3_1        | 2021-07-12 10:40:13,283 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om3_1        | 2021-07-12 10:40:13,284 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om3_1        | 2021-07-12 10:40:13,331 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om3_1        | 2021-07-12 10:40:13,341 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-07-12 10:40:13,342 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2021-07-12 10:40:13,348 [om3@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2021-07-12 10:40:13,355 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-07-12 10:40:13,356 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-07-12 10:40:13,357 [om3@group-562213E44849-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.om3@group-562213E44849
om3_1        | 2021-07-12 10:40:13,372 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om3_1        | 2021-07-12 10:40:13,374 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-07-12 10:40:13,376 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2021-07-12 10:40:13,377 [om3@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2021-07-12 10:40:13,377 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-07-12 10:42:05,709 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43496
om2_1        | 2021-07-12 10:42:05,726 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:09,888 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43524
om2_1        | 2021-07-12 10:42:09,890 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:13,329 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43546
om2_1        | 2021-07-12 10:42:13,352 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:16,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43560
om2_1        | 2021-07-12 10:42:16,875 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:20,440 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43584
om2_1        | 2021-07-12 10:42:20,457 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:24,134 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43626
om2_1        | 2021-07-12 10:42:24,141 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:27,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43640
om2_1        | 2021-07-12 10:42:27,739 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:31,384 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43666
om2_1        | 2021-07-12 10:42:31,393 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:35,123 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43680
om2_1        | 2021-07-12 10:42:35,131 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-07-12 10:40:39,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:42,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:45,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:48,791 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:50,000 [ChunkWriter-3-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2616268786630.
datanode3_1  | 2021-07-12 10:40:51,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:54,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:40:58,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:01,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:04,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:07,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:10,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:13,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:16,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:19,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:22,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:28,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:31,796 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:34,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:37,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:41,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:44,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:47,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:50,231 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:15,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:18,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:21,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:27,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:30,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:31,283 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=628,entriesCount=1,lastEntry=(t:2, i:4)
datanode2_1  | 2021-07-12 10:46:31,283 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=629,entriesCount=1,lastEntry=(t:2, i:5)
datanode2_1  | 2021-07-12 10:46:31,296 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=630,entriesCount=1,lastEntry=(t:2, i:6)
datanode2_1  | 2021-07-12 10:46:31,304 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=633,entriesCount=1,lastEntry=(t:2, i:7)
datanode2_1  | 2021-07-12 10:46:33,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:34,462 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=882,entriesCount=1,lastEntry=(t:2, i:8)
datanode2_1  | 2021-07-12 10:46:34,462 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=883,entriesCount=1,lastEntry=(t:2, i:9)
datanode2_1  | 2021-07-12 10:46:34,481 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=884,entriesCount=1,lastEntry=(t:2, i:10)
datanode2_1  | 2021-07-12 10:46:34,494 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=886,entriesCount=1,lastEntry=(t:2, i:11)
datanode2_1  | 2021-07-12 10:46:36,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:39,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:42,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:44,739 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1141,entriesCount=1,lastEntry=(t:2, i:12)
datanode2_1  | 2021-07-12 10:46:44,745 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1142,entriesCount=1,lastEntry=(t:2, i:13)
datanode2_1  | 2021-07-12 10:46:44,746 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1143,entriesCount=1,lastEntry=(t:2, i:14)
datanode2_1  | 2021-07-12 10:46:44,778 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1148,entriesCount=1,lastEntry=(t:2, i:15)
datanode2_1  | 2021-07-12 10:46:46,071 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:47,559 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1397,entriesCount=1,lastEntry=(t:2, i:16)
datanode2_1  | 2021-07-12 10:46:47,559 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1398,entriesCount=1,lastEntry=(t:2, i:17)
datanode2_1  | 2021-07-12 10:46:47,559 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1399,entriesCount=1,lastEntry=(t:2, i:18)
datanode2_1  | 2021-07-12 10:46:47,559 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1400,entriesCount=1,lastEntry=(t:2, i:19)
datanode2_1  | 2021-07-12 10:46:49,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
recon_1      | 2021-07-12 10:38:05,012 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2021-07-12 10:38:05,022 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2021-07-12 10:38:05,219 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2021-07-12 10:38:05,371 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2021-07-12 10:38:05,520 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: No pipeline exists in current db
recon_1      | 2021-07-12 10:38:05,678 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2021-07-12 10:38:05,678 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2021-07-12 10:38:05,843 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2021-07-12 10:38:05,883 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2021-07-12 10:38:05,883 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2021-07-12 10:38:06,655 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2021-07-12 10:38:06,657 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
recon_1      | 2021-07-12 10:38:06,782 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2021-07-12 10:38:06,786 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2021-07-12 10:38:06,787 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2021-07-12 10:38:06,833 [Listener at 0.0.0.0/9891] INFO server.session: node0 Stopped scavenging
recon_1      | Problem starting http server
recon_1      | 2021-07-12 10:38:06,900 [shutdown-hook-0] INFO recon.ReconServer: SHUTDOWN_MSG: 
recon_1      | /************************************************************
recon_1      | SHUTDOWN_MSG: Shutting down ReconServer at recon/172.25.0.115
recon_1      | ************************************************************/
om2_1        | 2021-07-12 10:42:38,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43704
om2_1        | 2021-07-12 10:42:38,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:42,446 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43726
om2_1        | 2021-07-12 10:42:42,457 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:45,726 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43742
om2_1        | 2021-07-12 10:42:45,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:51,588 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43772
om2_1        | 2021-07-12 10:42:51,598 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:42:57,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43822
om1_1        | 2021-07-12 10:42:02,175 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:05,632 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40952
om1_1        | 2021-07-12 10:42:05,648 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:09,805 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40972
om1_1        | 2021-07-12 10:42:09,855 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:13,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41004
om1_1        | 2021-07-12 10:42:13,302 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:16,796 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41018
om1_1        | 2021-07-12 10:42:16,812 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:20,378 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41042
om1_1        | 2021-07-12 10:42:20,391 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:24,086 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41082
om1_1        | 2021-07-12 10:42:24,111 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:27,687 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41098
om1_1        | 2021-07-12 10:42:27,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:31,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41124
om1_1        | 2021-07-12 10:42:31,335 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-07-12 10:41:52,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:55,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:41:58,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:01,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:05,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:08,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:11,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:14,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:17,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:23,461 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:26,519 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:29,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:42:57,467 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:03,377 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43854
datanode1_1  | 2021-07-12 10:42:32,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:35,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:38,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:41,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:44,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:48,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:51,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:54,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:42:57,239 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:00,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:03,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:06,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:12,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:15,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:18,743 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:21,815 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:24,887 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:27,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:31,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:34,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:37,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:40,247 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:43,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:46,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:49,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:52,535 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:43:55,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:01,751 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:04,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:07,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:10,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:14,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:17,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:20,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:23,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:40:13,377 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-07-12 10:40:13,386 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderStateImpl
om3_1        | 2021-07-12 10:40:13,445 [om3@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2021-07-12 10:40:13,563 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-07-12 10:40:13,763 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2021-07-12 10:40:33,228 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38796
om3_1        | 2021-07-12 10:40:33,234 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:40:45,773 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38858
om3_1        | 2021-07-12 10:40:45,775 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:40:46,633 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-07-12 10:40:55,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38924
om2_1        | 2021-07-12 10:43:03,388 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:09,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43886
om2_1        | 2021-07-12 10:43:09,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:13,096 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43918
om2_1        | 2021-07-12 10:43:13,107 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:16,971 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43934
datanode3_1  | 2021-07-12 10:41:53,303 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:41:56,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:50,925 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1651,entriesCount=1,lastEntry=(t:2, i:20)
datanode2_1  | 2021-07-12 10:46:51,012 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1652,entriesCount=1,lastEntry=(t:2, i:21)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om3_1        | 2021-07-12 10:40:55,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:40:56,142 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38932
om3_1        | 2021-07-12 10:40:56,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:00,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38954
om3_1        | 2021-07-12 10:41:00,376 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:00,887 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38962
om2_1        | 2021-07-12 10:43:16,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:35,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41138
om1_1        | 2021-07-12 10:42:35,088 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-07-12 10:44:26,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | Sleeping for 5 seconds
datanode2_1  | 2021-07-12 10:46:51,106 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1653,entriesCount=1,lastEntry=(t:2, i:22)
datanode3_1  | 2021-07-12 10:41:59,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:02,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:05,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:43:20,429 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43958
om2_1        | 2021-07-12 10:43:20,436 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:28,906 [qtp1363396194-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-07882, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:45:28,926 [qtp1363396194-17] INFO endpoint.BucketEndpoint: Location is /bucket-07882
s3g_1        | 2021-07-12 10:45:29,386 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
om1_1        | 2021-07-12 10:42:38,791 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41160
om2_1        | 2021-07-12 10:43:24,462 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43998
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
om1_1        | 2021-07-12 10:42:38,876 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:42,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41184
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-07-12 10:37:52,634 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om3_1        | 2021-07-12 10:41:00,897 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:05,370 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38988
om2_1        | 2021-07-12 10:43:24,465 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:28,002 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44014
om2_1        | 2021-07-12 10:43:28,029 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:46:51,108 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1654,entriesCount=1,lastEntry=(t:2, i:23)
datanode2_1  | 2021-07-12 10:46:52,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:46:54,318 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1894,entriesCount=1,lastEntry=(t:2, i:24)
datanode2_1  | 2021-07-12 10:46:54,336 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1895,entriesCount=1,lastEntry=(t:2, i:25)
datanode2_1  | 2021-07-12 10:46:54,446 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1896,entriesCount=1,lastEntry=(t:2, i:26)
datanode2_1  | 2021-07-12 10:46:54,463 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1897,entriesCount=1,lastEntry=(t:2, i:27)
scm1.org_1   | /************************************************************
om1_1        | 2021-07-12 10:42:42,409 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-07-12 10:42:08,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:11,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:17,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:42:45,674 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41200
datanode2_1  | 2021-07-12 10:46:55,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
datanode2_1  | 2021-07-12 10:46:57,391 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2143,entriesCount=1,lastEntry=(t:2, i:28)
om1_1        | 2021-07-12 10:42:45,692 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:42:51,508 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41230
om1_1        | 2021-07-12 10:42:51,553 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-07-12 10:42:20,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:24,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:27,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:30,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:33,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:36,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:39,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
om1_1        | 2021-07-12 10:42:57,419 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41280
datanode2_1  | 2021-07-12 10:46:57,401 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2144,entriesCount=1,lastEntry=(t:2, i:29)
datanode2_1  | 2021-07-12 10:46:57,402 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2145,entriesCount=1,lastEntry=(t:2, i:30)
om2_1        | 2021-07-12 10:43:31,650 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44040
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | 2021-07-12 10:46:57,409 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2147,entriesCount=1,lastEntry=(t:2, i:31)
om1_1        | 2021-07-12 10:42:57,432 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:31,654 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:05,372 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:12,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39028
om3_1        | 2021-07-12 10:41:12,114 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-07-12 10:44:29,396 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:42,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:41:16,907 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39048
om3_1        | 2021-07-12 10:41:16,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:17,449 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39064
om3_1        | 2021-07-12 10:41:17,455 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:03,287 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41312
om1_1        | 2021-07-12 10:43:03,312 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:09,206 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41344
om1_1        | 2021-07-12 10:43:09,257 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:13,016 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41376
om1_1        | 2021-07-12 10:43:13,055 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:16,912 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41392
datanode3_1  | 2021-07-12 10:42:45,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:48,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:51,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:42:54,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
datanode2_1  | 2021-07-12 10:46:58,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:01,069 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2397,entriesCount=1,lastEntry=(t:2, i:32)
om2_1        | 2021-07-12 10:43:35,252 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44054
om2_1        | 2021-07-12 10:43:35,261 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:38,719 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44078
om2_1        | 2021-07-12 10:43:38,728 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:42,540 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44100
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-07-12 10:41:21,729 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39096
om3_1        | 2021-07-12 10:41:21,736 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:25,758 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39122
datanode2_1  | 2021-07-12 10:47:01,302 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2398,entriesCount=1,lastEntry=(t:2, i:33)
datanode2_1  | 2021-07-12 10:47:01,401 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2409,entriesCount=1,lastEntry=(t:2, i:34)
datanode2_1  | 2021-07-12 10:47:01,428 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:01,488 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2419,entriesCount=1,lastEntry=(t:2, i:35)
datanode3_1  | 2021-07-12 10:42:57,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:00,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:07,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:10,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:41:25,763 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:38,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39176
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:30,121 [qtp1363396194-21] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2021-07-12 10:43:16,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:20,371 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41414
om2_1        | 2021-07-12 10:43:42,548 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:46,030 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44114
om2_1        | 2021-07-12 10:43:46,044 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:49,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44138
om3_1        | 2021-07-12 10:41:38,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:39,061 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:12548-source for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-07-12 10:41:42,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39200
om3_1        | 2021-07-12 10:41:42,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:42,850 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:12548-target for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-07-12 10:41:46,089 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39214
datanode2_1  | 2021-07-12 10:47:01,536 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2424,entriesCount=1,lastEntry=(t:2, i:36)
datanode2_1  | 2021-07-12 10:47:01,552 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2427,entriesCount=1,lastEntry=(t:2, i:37)
datanode2_1  | 2021-07-12 10:47:01,578 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2431,entriesCount=1,lastEntry=(t:2, i:38)
datanode2_1  | 2021-07-12 10:47:01,597 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2433,entriesCount=1,lastEntry=(t:2, i:39)
datanode2_1  | 2021-07-12 10:47:04,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:13,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:16,243 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:19,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:22,394 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:43:20,388 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-07-12 10:45:30,147 [qtp1363396194-21] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2021-07-12 10:45:30,147 [qtp1363396194-21] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
om2_1        | 2021-07-12 10:43:49,898 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:53,774 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44172
om1_1        | 2021-07-12 10:43:24,359 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41456
om1_1        | 2021-07-12 10:43:24,428 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:53,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-07-12 10:45:30,155 [qtp1363396194-21] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2021-07-12 10:45:30,155 [qtp1363396194-21] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2021-07-12 10:45:30,381 [qtp1363396194-21] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2021-07-12 10:47:07,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:10,647 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:16,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:18,503 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$327/0x00000008405b2040@71cc59ce] WARN util.JvmPauseMonitor: JvmPauseMonitor-dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6: Detected pause in JVM or host machine (eg GC): pause of approximately 143761549ns.
datanode3_1  | 2021-07-12 10:43:25,463 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:28,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:31,607 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:34,679 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:43:27,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41470
om1_1        | 2021-07-12 10:43:27,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:31,599 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41496
om1_1        | 2021-07-12 10:43:31,613 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:46,094 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:41:49,567 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39236
om3_1        | 2021-07-12 10:41:49,571 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:57,336 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44196
om2_1        | 2021-07-12 10:43:57,338 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:43:57,916 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:12548-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
s3g_1        | 2021-07-12 10:45:30,382 [qtp1363396194-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E84FE14AE691->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:45:30,383 [qtp1363396194-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode2_1  | GC pool 'ParNew' had collection(s): count=1 time=129ms
datanode2_1  | 2021-07-12 10:47:19,861 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:22,933 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:26,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:29,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:32,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:43:35,176 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41512
om1_1        | 2021-07-12 10:43:35,210 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:38,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41534
datanode3_1  | 2021-07-12 10:43:37,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:40,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:43,895 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:46,967 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:50,039 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:41:58,496 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39292
om3_1        | 2021-07-12 10:41:58,503 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:02,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39316
om3_1        | 2021-07-12 10:42:02,236 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-07-12 10:45:34,349 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
om1_1        | 2021-07-12 10:43:38,671 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:42,450 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41558
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 2021-07-12 10:42:05,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39340
om3_1        | 2021-07-12 10:42:05,760 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:09,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39368
om3_1        | 2021-07-12 10:42:09,908 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-07-12 10:43:56,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:43:59,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:02,325 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:05,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:08,471 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:11,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:14,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:17,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:20,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:23,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:26,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:29,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:33,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:36,119 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:39,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:45,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:48,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:51,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:54,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:44:57,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:00,691 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
datanode2_1  | 2021-07-12 10:47:35,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 2021-07-12 10:43:42,505 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:45,975 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41572
om1_1        | 2021-07-12 10:43:45,997 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:49,826 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41596
om1_1        | 2021-07-12 10:43:49,843 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:53,723 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41630
om1_1        | 2021-07-12 10:43:53,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:57,288 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41654
om1_1        | 2021-07-12 10:43:57,305 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:43:57,921 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:12548-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:44:00,768 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41676
om1_1        | 2021-07-12 10:44:00,780 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:04,199 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41690
om1_1        | 2021-07-12 10:44:04,216 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:04,782 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:12548-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:34,405 [qtp1363396194-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-CC44EBAC48BD->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:45:34,406 [qtp1363396194-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:45:37,506 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
datanode2_1  | 2021-07-12 10:47:38,292 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:41,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:41,800 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2700,entriesCount=1,lastEntry=(t:2, i:40)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:44:00,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44218
om2_1        | 2021-07-12 10:44:00,811 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:04,254 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44232
om2_1        | 2021-07-12 10:44:04,265 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:04,786 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:12548-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:44:07,899 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44256
om2_1        | 2021-07-12 10:44:07,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:11,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44284
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
datanode1_1  | 2021-07-12 10:44:32,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:35,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:38,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:42:13,372 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39390
om3_1        | 2021-07-12 10:42:13,374 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:16,902 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39404
om3_1        | 2021-07-12 10:42:16,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:20,485 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39428
om3_1        | 2021-07-12 10:42:20,494 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:24,157 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39470
om3_1        | 2021-07-12 10:42:24,165 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:47:41,810 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2701,entriesCount=1,lastEntry=(t:2, i:41)
datanode2_1  | 2021-07-12 10:47:41,829 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2702,entriesCount=1,lastEntry=(t:2, i:42)
datanode2_1  | 2021-07-12 10:47:41,877 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2703,entriesCount=1,lastEntry=(t:2, i:43)
datanode2_1  | 2021-07-12 10:47:41,883 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2704,entriesCount=1,lastEntry=(t:2, i:44)
datanode2_1  | 2021-07-12 10:47:44,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | ************************************************************/
datanode1_1  | 2021-07-12 10:44:41,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:44,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:50,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:44:53,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:37:52,678 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-07-12 10:37:52,951 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-07-12 10:37:53,090 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-07-12 10:37:53,096 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-07-12 10:37:53,253 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
datanode1_1  | 2021-07-12 10:44:57,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:00,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:47,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:48,846 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2958,entriesCount=1,lastEntry=(t:2, i:45)
datanode2_1  | 2021-07-12 10:47:48,848 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2959,entriesCount=1,lastEntry=(t:2, i:46)
datanode2_1  | 2021-07-12 10:47:48,854 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2960,entriesCount=1,lastEntry=(t:2, i:47)
datanode2_1  | 2021-07-12 10:47:48,857 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2961,entriesCount=1,lastEntry=(t:2, i:48)
datanode2_1  | 2021-07-12 10:47:50,583 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:42:27,756 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39484
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2021-07-12 10:38:07,971 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | 2021-07-12 10:37:53,263 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-07-12 10:37:53,281 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2021-07-12 10:37:55,438 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2021-07-12 10:45:03,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:06,259 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:09,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:12,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:42:27,764 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:31,410 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39510
om3_1        | 2021-07-12 10:42:31,418 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:37:55,438 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2021-07-12 10:37:55,443 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2021-07-12 10:37:58,320 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2021-07-12 10:38:00,573 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-07-12 10:38:00,573 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-07-12 10:38:01,169 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
datanode3_1  | 2021-07-12 10:45:03,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:15,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:18,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:21,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:24,691 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:42:35,158 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39524
om3_1        | 2021-07-12 10:42:35,168 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:38,951 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39548
om3_1        | 2021-07-12 10:42:38,959 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:42,473 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39572
om3_1        | 2021-07-12 10:42:42,475 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:47:53,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:54,404 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3210,entriesCount=1,lastEntry=(t:2, i:49)
datanode2_1  | 2021-07-12 10:47:54,414 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3211,entriesCount=1,lastEntry=(t:2, i:50)
datanode2_1  | 2021-07-12 10:47:54,414 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3212,entriesCount=1,lastEntry=(t:2, i:51)
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
datanode3_1  | 2021-07-12 10:45:06,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:09,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:12,981 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:47:54,435 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3216,entriesCount=1,lastEntry=(t:2, i:52)
datanode2_1  | 2021-07-12 10:47:56,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | Sleeping for 5 seconds
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm3.org_1   | Waiting for the service scm2.org:9894
om3_1        | 2021-07-12 10:42:45,756 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39586
om3_1        | 2021-07-12 10:42:45,763 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:51,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39616
om3_1        | 2021-07-12 10:42:51,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:42:57,486 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39666
om2_1        | 2021-07-12 10:44:11,886 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:15,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44306
om2_1        | 2021-07-12 10:44:15,525 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
datanode1_1  | 2021-07-12 10:45:27,767 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:30,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:33,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:40,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:16,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:44:19,171 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44330
om2_1        | 2021-07-12 10:44:19,180 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:22,578 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44362
om2_1        | 2021-07-12 10:44:22,584 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:25,956 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44384
om2_1        | 2021-07-12 10:44:25,962 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-07-12 10:45:43,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:01,179 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-07-12 10:38:01,181 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:834b4eb7-146a-4c2a-bac6-4409b0eef822,clusterId:CID-ea67d158-f30d-4de4-8e61-b39e69e4a611,subject:scm-sub@scm1.org
scm1.org_1   | 2021-07-12 10:38:01,390 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2021-07-12 10:38:01,835 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2021-07-12 10:38:02,074 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-07-12 10:38:02,075 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-07-12 10:38:02,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
datanode3_1  | 2021-07-12 10:45:19,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
om1_1        | 2021-07-12 10:44:07,827 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41714
om1_1        | 2021-07-12 10:44:07,874 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:11,790 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41742
om1_1        | 2021-07-12 10:44:11,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:15,438 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41764
datanode2_1  | 2021-07-12 10:47:59,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:00,394 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3467,entriesCount=1,lastEntry=(t:2, i:53)
datanode2_1  | 2021-07-12 10:48:00,440 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3468,entriesCount=1,lastEntry=(t:2, i:54)
datanode2_1  | 2021-07-12 10:48:00,462 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3469,entriesCount=1,lastEntry=(t:2, i:55)
datanode2_1  | 2021-07-12 10:48:00,482 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3470,entriesCount=1,lastEntry=(t:2, i:56)
datanode2_1  | 2021-07-12 10:48:00,489 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3471,entriesCount=1,lastEntry=(t:2, i:57)
datanode2_1  | 2021-07-12 10:48:00,497 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3472,entriesCount=1,lastEntry=(t:2, i:58)
datanode2_1  | 2021-07-12 10:48:03,573 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3725,entriesCount=1,lastEntry=(t:2, i:59)
datanode2_1  | 2021-07-12 10:48:03,581 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3726,entriesCount=1,lastEntry=(t:2, i:60)
om2_1        | 2021-07-12 10:44:29,404 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44398
om2_1        | 2021-07-12 10:44:29,412 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:32,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44424
om2_1        | 2021-07-12 10:44:32,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:37,983 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-07-12 10:42:57,493 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:03,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39700
om3_1        | 2021-07-12 10:43:03,428 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-07-12 10:45:46,195 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:49,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:41,093 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm2.org_1   | ************************************************************/
scm1.org_1   | 2021-07-12 10:38:02,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-07-12 10:38:02,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-07-12 10:38:02,087 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-07-12 10:38:02,093 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-07-12 10:38:02,098 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-07-12 10:38:02,104 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-07-12 10:38:02,924 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-07-12 10:38:02,926 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-07-12 10:38:02,926 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-07-12 10:38:03,024 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-07-12 10:38:03,055 [main] INFO server.RaftServer: 834b4eb7-146a-4c2a-bac6-4409b0eef822: addNew group-B39E69E4A611:[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|priority:0] returns group-B39E69E4A611:java.util.concurrent.CompletableFuture@3c78e551[Not completed]
scm1.org_1   | 2021-07-12 10:38:03,198 [pool-2-thread-1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822: new RaftServerImpl for group-B39E69E4A611:[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-07-12 10:38:03,200 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-07-12 10:38:03,200 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-07-12 10:45:52,341 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:55,428 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:45:58,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:01,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:04,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:07,699 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:10,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:13,847 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:16,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:19,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:23,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:29,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:32,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:35,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:22,195 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:25,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:28,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:34,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:37,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:40,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:43,699 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:46,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:49,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:52,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:55,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:45:59,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:02,133 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:05,209 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:08,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:11,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:14,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:17,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:23,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:26,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:29,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:43:09,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39730
om1_1        | 2021-07-12 10:44:15,453 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:36,267 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44440
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
scm1.org_1   | 2021-07-12 10:38:03,201 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-07-12 10:46:32,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:07,985 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2021-07-12 10:48:03,590 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3727,entriesCount=1,lastEntry=(t:2, i:61)
datanode1_1  | 2021-07-12 10:46:38,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:41,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:44,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:47,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:50,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:53,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:56,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:46:59,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:03,594 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3728,entriesCount=1,lastEntry=(t:2, i:62)
datanode2_1  | 2021-07-12 10:48:05,940 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:09,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:12,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:12,546 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3979,entriesCount=1,lastEntry=(t:2, i:63)
datanode2_1  | 2021-07-12 10:48:12,548 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3980,entriesCount=1,lastEntry=(t:2, i:64)
datanode2_1  | 2021-07-12 10:48:12,552 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3981,entriesCount=1,lastEntry=(t:2, i:65)
datanode2_1  | 2021-07-12 10:48:12,553 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3982,entriesCount=1,lastEntry=(t:2, i:66)
datanode2_1  | 2021-07-12 10:48:15,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:18,167 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4232,entriesCount=1,lastEntry=(t:2, i:67)
datanode2_1  | 2021-07-12 10:48:18,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:18,306 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4233,entriesCount=1,lastEntry=(t:2, i:68)
datanode2_1  | 2021-07-12 10:48:18,319 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4234,entriesCount=1,lastEntry=(t:2, i:69)
datanode2_1  | 2021-07-12 10:48:18,330 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4235,entriesCount=1,lastEntry=(t:2, i:70)
datanode2_1  | 2021-07-12 10:48:18,536 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4239,entriesCount=1,lastEntry=(t:2, i:71)
datanode2_1  | 2021-07-12 10:48:18,592 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4243,entriesCount=1,lastEntry=(t:2, i:72)
datanode2_1  | 2021-07-12 10:48:18,600 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4245,entriesCount=1,lastEntry=(t:2, i:73)
datanode2_1  | 2021-07-12 10:48:18,625 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4247,entriesCount=1,lastEntry=(t:2, i:74)
datanode2_1  | 2021-07-12 10:48:18,654 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4250,entriesCount=1,lastEntry=(t:2, i:75)
datanode2_1  | 2021-07-12 10:48:18,899 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4258,entriesCount=1,lastEntry=(t:2, i:76)
datanode2_1  | 2021-07-12 10:48:18,899 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4259,entriesCount=1,lastEntry=(t:2, i:77)
datanode2_1  | 2021-07-12 10:48:18,899 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4260,entriesCount=1,lastEntry=(t:2, i:78)
datanode2_1  | 2021-07-12 10:48:21,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:24,388 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:24,529 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4508,entriesCount=1,lastEntry=(t:2, i:79)
datanode2_1  | 2021-07-12 10:48:24,580 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4509,entriesCount=1,lastEntry=(t:2, i:80)
om1_1        | 2021-07-12 10:44:19,100 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41788
om1_1        | 2021-07-12 10:44:19,115 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:22,540 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41802
om1_1        | 2021-07-12 10:44:22,555 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:36,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:39,720 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44462
om2_1        | 2021-07-12 10:44:39,725 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:45,235 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44492
om2_1        | 2021-07-12 10:44:45,237 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:50,823 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44522
om2_1        | 2021-07-12 10:44:50,833 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:54,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44556
om2_1        | 2021-07-12 10:44:54,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:44:58,066 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44580
om2_1        | 2021-07-12 10:44:58,075 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:19,525 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44806
om2_1        | 2021-07-12 10:45:19,532 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:23,263 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:23,268 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38170
om2_1        | 2021-07-12 10:45:23,274 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:26,673 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44862
om2_1        | 2021-07-12 10:45:26,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:28,867 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:28,868 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38204
om2_1        | 2021-07-12 10:45:28,872 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:29,378 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:29,378 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38214
om2_1        | 2021-07-12 10:45:29,384 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:34,344 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:34,345 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38244
om2_1        | 2021-07-12 10:45:34,347 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:37,496 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:43:09,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:13,125 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39762
om3_1        | 2021-07-12 10:43:13,134 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:16,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39778
om3_1        | 2021-07-12 10:43:16,995 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:20,449 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39802
om3_1        | 2021-07-12 10:43:20,451 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm3.org_1   | ************************************************************/
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:38,487 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om1_1        | 2021-07-12 10:44:25,909 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41842
om1_1        | 2021-07-12 10:44:25,926 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:29,353 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41856
om1_1        | 2021-07-12 10:44:29,374 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:38:08,092 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2021-07-12 10:38:08,092 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
om3_1        | 2021-07-12 10:43:24,488 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39842
om3_1        | 2021-07-12 10:43:24,495 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:38:41,110 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2021-07-12 10:38:41,361 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2021-07-12 10:38:08,155 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2021-07-12 10:38:08,155 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
om3_1        | 2021-07-12 10:43:28,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39858
scm3.org_1   | 2021-07-12 10:38:41,367 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
om1_1        | 2021-07-12 10:44:32,793 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41882
om1_1        | 2021-07-12 10:44:32,805 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:38:08,161 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-07-12 10:38:41,512 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
om3_1        | 2021-07-12 10:43:28,056 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:31,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39884
om3_1        | 2021-07-12 10:43:31,682 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:35,273 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39898
om3_1        | 2021-07-12 10:43:35,277 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:38,780 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39922
om3_1        | 2021-07-12 10:43:38,786 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:42,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39944
om3_1        | 2021-07-12 10:43:42,578 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:46,064 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39958
om3_1        | 2021-07-12 10:43:46,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:49,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39982
om3_1        | 2021-07-12 10:43:49,934 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:53,800 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40016
om3_1        | 2021-07-12 10:43:53,807 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:57,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40040
scm2.org_1   | 2021-07-12 10:38:08,350 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2021-07-12 10:38:08,350 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2021-07-12 10:38:10,627 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-07-12 10:38:12,629 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-07-12 10:38:14,631 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-07-12 10:38:16,633 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-07-12 10:38:18,646 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-07-12 10:38:20,805 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:834b4eb7-146a-4c2a-bac6-4409b0eef822 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:196)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:108)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13937)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-07-12 10:38:22,807 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-07-12 10:38:24,810 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-07-12 10:38:26,898 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2021-07-12 10:38:27,375 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2021-07-12 10:38:27,375 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2021-07-12 10:38:27,376 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2021-07-12 10:38:28,178 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2021-07-12 10:38:28,218 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2021-07-12 10:38:28,218 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2021-07-12 10:38:28,221 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:1c300e12-e25b-4eac-b361-75629ac63c82,clusterId:CID-ea67d158-f30d-4de4-8e61-b39e69e4a611,subject:scm-sub@scm2.org
scm2.org_1   | 2021-07-12 10:38:29,973 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2021-07-12 10:38:29,987 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-ea67d158-f30d-4de4-8e61-b39e69e4a611, SCMID 1c300e12-e25b-4eac-b361-75629ac63c82
scm2.org_1   | 2021-07-12 10:38:29,988 [main] INFO server.StorageContainerManager: Primary SCM Node ID 834b4eb7-146a-4c2a-bac6-4409b0eef822
scm2.org_1   | 2021-07-12 10:38:30,023 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | 2021-07-12 10:44:36,215 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41896
om1_1        | 2021-07-12 10:44:36,231 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:39,655 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41920
om1_1        | 2021-07-12 10:44:39,670 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:45,172 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41950
om1_1        | 2021-07-12 10:44:45,184 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:50,760 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41980
om1_1        | 2021-07-12 10:44:50,781 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:54,237 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42014
om1_1        | 2021-07-12 10:44:54,255 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:44:58,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42038
om1_1        | 2021-07-12 10:44:58,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:38:41,526 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2021-07-12 10:38:41,549 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-07-12 10:38:42,098 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2021-07-12 10:38:42,101 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2021-07-12 10:38:43,076 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2021-07-12 10:38:44,403 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2021-07-12 10:38:44,423 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2021-07-12 10:38:44,424 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2021-07-12 10:38:46,496 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2021-07-12 10:38:46,547 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2021-07-12 10:38:46,547 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2021-07-12 10:38:46,550 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:235f349a-aabc-4dff-b4dd-941abcfde3d9,clusterId:CID-ea67d158-f30d-4de4-8e61-b39e69e4a611,subject:scm-sub@scm3.org
scm1.org_1   | 2021-07-12 10:38:03,201 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-07-12 10:38:03,201 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-07-12 10:38:03,201 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2021-07-12 10:38:03,201 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-07-12 10:38:03,205 [pool-2-thread-1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: ConfigurationManager, init=-1: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-07-12 10:38:03,205 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-07-12 10:38:03,232 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-07-12 10:38:03,234 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611 does not exist. Creating ...
scm1.org_1   | 2021-07-12 10:38:03,282 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/in_use.lock acquired by nodename 87@scm1.org
scm1.org_1   | 2021-07-12 10:38:03,304 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611 has been successfully formatted.
scm1.org_1   | 2021-07-12 10:38:03,318 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-07-12 10:38:03,335 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-07-12 10:38:03,353 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-07-12 10:38:03,353 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-07-12 10:38:03,399 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:43,754 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
datanode3_1  | 2021-07-12 10:46:35,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:38,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:42,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:45,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:48,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:51,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:54,359 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:46:57,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:00,500 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:03,572 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:06,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:12,789 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:15,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:18,935 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:22,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:25,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:28,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:31,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:34,295 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:37,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:40,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:43,508 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:46,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:49,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:52,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:47:55,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:01,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:05,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:08,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:11,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:14,231 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:17,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:20,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:23,448 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:26,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:29,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:32,680 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:35,735 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:45:19,475 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42264
om1_1        | 2021-07-12 10:45:19,500 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:48:24,599 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4510,entriesCount=1,lastEntry=(t:2, i:81)
datanode2_1  | 2021-07-12 10:48:24,685 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4511,entriesCount=1,lastEntry=(t:2, i:82)
datanode2_1  | 2021-07-12 10:48:24,693 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4512,entriesCount=1,lastEntry=(t:2, i:83)
datanode2_1  | 2021-07-12 10:48:24,699 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4513,entriesCount=1,lastEntry=(t:2, i:84)
datanode2_1  | 2021-07-12 10:48:27,447 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:28,400 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4766,entriesCount=1,lastEntry=(t:2, i:85)
datanode2_1  | 2021-07-12 10:48:28,418 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4767,entriesCount=1,lastEntry=(t:2, i:86)
datanode2_1  | 2021-07-12 10:48:28,437 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4768,entriesCount=1,lastEntry=(t:2, i:87)
datanode2_1  | 2021-07-12 10:48:28,443 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4769,entriesCount=1,lastEntry=(t:2, i:88)
datanode2_1  | 2021-07-12 10:48:28,455 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4770,entriesCount=1,lastEntry=(t:2, i:89)
datanode2_1  | 2021-07-12 10:48:28,456 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4771,entriesCount=1,lastEntry=(t:2, i:90)
datanode2_1  | 2021-07-12 10:48:30,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:32,818 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5023,entriesCount=1,lastEntry=(t:2, i:91)
datanode2_1  | 2021-07-12 10:48:32,938 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5024,entriesCount=1,lastEntry=(t:2, i:92)
datanode2_1  | 2021-07-12 10:48:32,949 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5025,entriesCount=1,lastEntry=(t:2, i:93)
scm3.org_1   | 2021-07-12 10:38:47,313 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2021-07-12 10:38:47,335 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-ea67d158-f30d-4de4-8e61-b39e69e4a611, SCMID 235f349a-aabc-4dff-b4dd-941abcfde3d9
om1_1        | 2021-07-12 10:45:23,204 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:23,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33606
om3_1        | 2021-07-12 10:43:57,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:43:57,903 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:12548-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 2021-07-12 10:45:37,497 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38268
om2_1        | 2021-07-12 10:45:37,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:37,969 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:37,973 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38278
om2_1        | 2021-07-12 10:45:37,981 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:38,478 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:38,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38286
om2_1        | 2021-07-12 10:45:38,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:38:47,335 [main] INFO server.StorageContainerManager: Primary SCM Node ID 834b4eb7-146a-4c2a-bac6-4409b0eef822
scm3.org_1   | 2021-07-12 10:38:47,353 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2021-07-12 10:38:48,646 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm3.org_1   | ************************************************************/
scm3.org_1   | 2021-07-12 10:38:48,653 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2021-07-12 10:38:48,731 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2021-07-12 10:38:48,731 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2021-07-12 10:38:48,779 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2021-07-12 10:38:48,779 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2021-07-12 10:38:48,815 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-07-12 10:38:48,853 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm3.org_1   | 2021-07-12 10:38:49,065 [main] INFO reflections.Reflections: Reflections took 94 ms to scan 3 urls, producing 103 keys and 210 values 
scm3.org_1   | 2021-07-12 10:38:49,971 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2021-07-12 10:38:50,157 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2021-07-12 10:38:50,161 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2021-07-12 10:38:50,171 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2576161594099.crt.
scm3.org_1   | 2021-07-12 10:38:50,373 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2021-07-12 10:38:50,373 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2021-07-12 10:38:50,398 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-07-12 10:38:50,665 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-07-12 10:38:50,945 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2021-07-12 10:38:50,945 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2021-07-12 10:38:51,150 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:235f349a-aabc-4dff-b4dd-941abcfde3d9
scm3.org_1   | 2021-07-12 10:38:51,336 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2021-07-12 10:38:51,539 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2021-07-12 10:38:51,544 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-07-12 10:38:51,544 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2021-07-12 10:45:23,218 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:26,625 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42320
om1_1        | 2021-07-12 10:45:26,641 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:28,856 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:28,857 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33640
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:44:00,829 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40062
om3_1        | 2021-07-12 10:44:00,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:04,286 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40076
om3_1        | 2021-07-12 10:44:04,295 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:04,779 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:12548-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
scm1.org_1   | 2021-07-12 10:38:03,400 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:03,402 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:03,417 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
om1_1        | 2021-07-12 10:45:28,862 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:29,364 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:29,366 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33650
datanode1_1  | 2021-07-12 10:47:02,999 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:03,441 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-07-12 10:38:03,441 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-07-12 10:38:03,445 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611
scm1.org_1   | 2021-07-12 10:38:03,446 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
datanode1_1  | 2021-07-12 10:47:06,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:45:29,372 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:41,564 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44970
datanode2_1  | 2021-07-12 10:48:32,957 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5026,entriesCount=1,lastEntry=(t:2, i:94)
datanode2_1  | 2021-07-12 10:48:32,960 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5027,entriesCount=1,lastEntry=(t:2, i:95)
datanode2_1  | 2021-07-12 10:48:33,046 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5034,entriesCount=1,lastEntry=(t:2, i:96)
datanode2_1  | 2021-07-12 10:48:33,080 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5037,entriesCount=1,lastEntry=(t:2, i:97)
datanode2_1  | 2021-07-12 10:48:33,588 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:03,446 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-07-12 10:38:03,463 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-07-12 10:38:03,464 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm1.org_1   | 2021-07-12 10:38:03,464 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2021-07-12 10:38:03,471 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2021-07-12 10:45:34,332 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:34,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33680
om1_1        | 2021-07-12 10:45:34,336 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:37,480 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:37,481 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33704
om1_1        | 2021-07-12 10:45:37,492 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:37,949 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:37,950 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33714
om1_1        | 2021-07-12 10:45:37,964 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:38,455 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:38,456 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33722
om1_1        | 2021-07-12 10:45:38,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:41,509 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42428
om1_1        | 2021-07-12 10:45:41,526 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:43,742 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:43,743 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33758
om1_1        | 2021-07-12 10:45:43,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:44,274 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:44,274 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33766
om1_1        | 2021-07-12 10:45:44,283 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:44,350 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:44,351 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33772
om2_1        | 2021-07-12 10:45:41,568 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:43,750 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:43,751 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38322
om2_1        | 2021-07-12 10:45:43,752 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:44,288 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:44,290 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38330
om2_1        | 2021-07-12 10:45:44,295 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:44,370 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:44,371 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38336
om2_1        | 2021-07-12 10:45:44,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:44,622 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:44,622 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38348
om2_1        | 2021-07-12 10:45:44,630 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:47,408 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:47,409 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38362
om2_1        | 2021-07-12 10:45:47,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:50,127 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:50,128 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38384
om2_1        | 2021-07-12 10:45:50,129 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:50,313 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:50,314 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38390
om2_1        | 2021-07-12 10:45:50,318 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:50,392 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:50,394 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38398
om2_1        | 2021-07-12 10:45:50,405 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:53,674 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:53,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38432
om2_1        | 2021-07-12 10:45:53,677 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:53,834 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:53,835 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38438
om2_1        | 2021-07-12 10:45:53,839 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:53,992 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:53,992 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38446
om2_1        | 2021-07-12 10:45:53,999 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:54,032 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:54,032 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38452
om2_1        | 2021-07-12 10:45:54,035 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:57,030 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:57,031 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38476
om2_1        | 2021-07-12 10:45:57,032 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:57,088 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:57,088 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38482
om2_1        | 2021-07-12 10:45:57,092 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:57,134 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
datanode1_1  | 2021-07-12 10:47:09,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:12,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:18,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:21,431 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:24,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:27,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:30,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:33,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:36,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:39,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:42,935 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:46,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:49,078 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:52,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:55,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:47:58,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:01,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:07,511 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:10,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:13,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:16,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:19,799 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:22,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:25,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:29,015 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:32,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:35,156 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:38,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:41,303 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:44,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:47,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:50,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:56,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:48:59,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:02,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:05,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:08,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:12,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:15,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:18,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:21,239 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:24,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:27,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:30,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:33,524 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:36,599 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:39,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:45,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode2_1  | 2021-07-12 10:48:36,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:37,952 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5288,entriesCount=1,lastEntry=(t:2, i:98)
datanode2_1  | 2021-07-12 10:48:37,954 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5289,entriesCount=1,lastEntry=(t:2, i:99)
datanode2_1  | 2021-07-12 10:48:37,962 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5290,entriesCount=1,lastEntry=(t:2, i:100)
datanode2_1  | 2021-07-12 10:48:37,972 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5291,entriesCount=1,lastEntry=(t:2, i:101)
datanode2_1  | 2021-07-12 10:48:39,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:42,477 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5542,entriesCount=1,lastEntry=(t:2, i:102)
datanode2_1  | 2021-07-12 10:48:42,554 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5543,entriesCount=1,lastEntry=(t:2, i:103)
datanode2_1  | 2021-07-12 10:48:42,563 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5544,entriesCount=1,lastEntry=(t:2, i:104)
datanode2_1  | 2021-07-12 10:48:42,626 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5546,entriesCount=1,lastEntry=(t:2, i:105)
datanode2_1  | 2021-07-12 10:48:42,637 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5548,entriesCount=1,lastEntry=(t:2, i:106)
datanode2_1  | 2021-07-12 10:48:42,723 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5556,entriesCount=1,lastEntry=(t:2, i:107)
datanode2_1  | 2021-07-12 10:48:42,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:43,344 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5618,entriesCount=1,lastEntry=(t:2, i:108)
datanode2_1  | 2021-07-12 10:48:43,344 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5619,entriesCount=1,lastEntry=(t:2, i:109)
datanode2_1  | 2021-07-12 10:48:45,879 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:44:07,917 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40102
om3_1        | 2021-07-12 10:44:07,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:11,902 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40128
om3_1        | 2021-07-12 10:44:11,904 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:12,284 [IPC Server handler 3 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket /12548-target/unreadable-link/null
om3_1        | 2021-07-12 10:44:15,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40150
om3_1        | 2021-07-12 10:44:15,566 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:19,193 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40174
om3_1        | 2021-07-12 10:44:19,202 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:19,609 [IPC Server handler 7 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket /12548-source/unreadable-bucket/
om3_1        | 2021-07-12 10:44:22,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40206
om3_1        | 2021-07-12 10:44:22,606 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:25,979 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40228
om3_1        | 2021-07-12 10:44:25,991 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:29,424 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40244
om3_1        | 2021-07-12 10:44:29,425 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:32,871 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40268
om3_1        | 2021-07-12 10:44:32,878 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:36,305 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40292
om3_1        | 2021-07-12 10:44:36,310 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:39,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40306
om3_1        | 2021-07-12 10:44:39,758 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:45,248 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40336
om3_1        | 2021-07-12 10:44:45,253 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:50,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40366
om3_1        | 2021-07-12 10:44:50,848 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:54,346 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40400
om3_1        | 2021-07-12 10:44:54,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:44:58,099 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40424
om3_1        | 2021-07-12 10:44:58,105 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:19,552 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40650
scm1.org_1   | 2021-07-12 10:38:03,475 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2021-07-12 10:38:03,475 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2021-07-12 10:38:03,508 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2021-07-12 10:38:03,509 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2021-07-12 10:38:03,551 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-07-12 10:38:03,551 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-07-12 10:38:03,554 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2021-07-12 10:38:03,560 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-07-12 10:38:03,560 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-07-12 10:38:03,563 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2021-07-12 10:38:03,564 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2021-07-12 10:38:03,565 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-07-12 10:38:03,709 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:03,709 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:03,712 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:03,723 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:03,728 [main] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: start as a follower, conf=-1: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2021-07-12 10:38:03,740 [main] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2021-07-12 10:38:03,760 [main] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: start 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState
scm1.org_1   | 2021-07-12 10:38:04,014 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B39E69E4A611,id=834b4eb7-146a-4c2a-bac6-4409b0eef822
scm1.org_1   | 2021-07-12 10:38:04,043 [main] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:04,044 [main] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:04,065 [main] INFO server.RaftServer: 834b4eb7-146a-4c2a-bac6-4409b0eef822: start RPC server
scm1.org_1   | 2021-07-12 10:38:04,246 [main] INFO server.GrpcService: 834b4eb7-146a-4c2a-bac6-4409b0eef822: GrpcService started, listening on 9894
scm1.org_1   | 2021-07-12 10:38:04,276 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$331/0x000000084030cc40@443faa85] INFO util.JvmPauseMonitor: JvmPauseMonitor-834b4eb7-146a-4c2a-bac6-4409b0eef822: Started
scm1.org_1   | 2021-07-12 10:38:08,931 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO impl.FollowerState: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5171404843ns, electionTimeout:5138ms
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:43,764 [qtp1363396194-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-74817, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:45:43,782 [qtp1363396194-21] INFO endpoint.BucketEndpoint: Location is /bucket-74817
s3g_1        | 2021-07-12 10:45:44,297 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:44,310 [qtp1363396194-20] INFO rpc.RpcClient: Creating Bucket: s3v/boto-bucket999, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:45:44,326 [qtp1363396194-20] INFO endpoint.BucketEndpoint: Location is /boto-bucket999
s3g_1        | 2021-07-12 10:45:44,382 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:44,446 [qtp1363396194-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-866402368AA4->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:45:44,446 [qtp1363396194-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:45:44,633 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:44,712 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-DE2F0D5F268E->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:45:44,713 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:45:47,422 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
datanode3_1  | 2021-07-12 10:48:38,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:41,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:44,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:51,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:48:54,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2021-07-12 10:38:32,294 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | ************************************************************/
scm2.org_1   | 2021-07-12 10:38:32,319 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2021-07-12 10:38:32,463 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2021-07-12 10:38:32,464 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2021-07-12 10:38:32,587 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2021-07-12 10:38:32,595 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2021-07-12 10:38:32,660 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-07-12 10:38:32,723 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm2.org_1   | 2021-07-12 10:38:33,128 [main] INFO reflections.Reflections: Reflections took 187 ms to scan 3 urls, producing 103 keys and 210 values 
scm2.org_1   | 2021-07-12 10:38:34,051 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2021-07-12 10:38:34,288 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2557888870808.crt.
scm2.org_1   | 2021-07-12 10:38:34,292 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
datanode2_1  | 2021-07-12 10:48:47,982 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5867,entriesCount=1,lastEntry=(t:2, i:110)
datanode2_1  | 2021-07-12 10:48:48,130 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5868,entriesCount=1,lastEntry=(t:2, i:111)
datanode2_1  | 2021-07-12 10:48:48,158 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5869,entriesCount=1,lastEntry=(t:2, i:112)
datanode2_1  | 2021-07-12 10:48:48,235 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5874,entriesCount=1,lastEntry=(t:2, i:113)
datanode2_1  | 2021-07-12 10:48:48,246 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5876,entriesCount=1,lastEntry=(t:2, i:114)
datanode2_1  | 2021-07-12 10:48:48,272 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5880,entriesCount=1,lastEntry=(t:2, i:115)
datanode2_1  | 2021-07-12 10:48:48,287 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5882,entriesCount=1,lastEntry=(t:2, i:116)
datanode2_1  | 2021-07-12 10:48:48,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:51,458 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6133,entriesCount=1,lastEntry=(t:2, i:117)
datanode2_1  | 2021-07-12 10:48:51,466 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6134,entriesCount=1,lastEntry=(t:2, i:118)
datanode2_1  | 2021-07-12 10:48:51,467 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6135,entriesCount=1,lastEntry=(t:2, i:119)
datanode2_1  | 2021-07-12 10:48:55,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:48:58,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:01,252 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:04,308 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:07,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:08,033 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6385,entriesCount=1,lastEntry=(t:2, i:120)
datanode2_1  | 2021-07-12 10:49:08,041 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6386,entriesCount=1,lastEntry=(t:2, i:121)
datanode2_1  | 2021-07-12 10:49:08,055 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6387,entriesCount=1,lastEntry=(t:2, i:122)
datanode2_1  | 2021-07-12 10:49:08,055 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6388,entriesCount=1,lastEntry=(t:2, i:123)
datanode2_1  | 2021-07-12 10:49:10,460 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:13,561 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:16,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:19,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:22,743 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:24,309 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6643,entriesCount=1,lastEntry=(t:2, i:124)
datanode2_1  | 2021-07-12 10:49:24,322 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6644,entriesCount=1,lastEntry=(t:2, i:125)
datanode2_1  | 2021-07-12 10:49:24,329 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6645,entriesCount=1,lastEntry=(t:2, i:126)
datanode2_1  | 2021-07-12 10:49:24,339 [java.util.concurrent.ThreadPoolExecutor$Worker@65e20ff5[State = -1, empty queue]] WARN server.GrpcLogAppender: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403->1ab7aeaf-7670-4a86-9686-feb8bb11c16a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6647,entriesCount=1,lastEntry=(t:2, i:127)
datanode2_1  | 2021-07-12 10:49:25,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:28,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:31,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:35,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:38,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:44,243 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:47,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:45:44,362 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:44,607 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:44,608 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33784
om1_1        | 2021-07-12 10:45:44,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:47,357 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:47,399 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33798
om1_1        | 2021-07-12 10:45:47,401 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:50,121 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:50,121 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33820
om1_1        | 2021-07-12 10:45:50,124 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:50,268 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:50,274 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33826
om1_1        | 2021-07-12 10:45:50,297 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:50,354 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:50,354 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33832
om1_1        | 2021-07-12 10:45:50,367 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:53,668 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:53,669 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33868
om1_1        | 2021-07-12 10:45:53,671 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:53,821 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:53,822 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33874
om1_1        | 2021-07-12 10:45:53,829 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:53,968 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:53,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33882
om1_1        | 2021-07-12 10:45:53,984 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:54,015 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:54,015 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33888
om1_1        | 2021-07-12 10:45:54,017 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:57,017 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:57,018 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33912
om1_1        | 2021-07-12 10:45:57,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:57,083 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:57,084 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33918
om1_1        | 2021-07-12 10:45:57,084 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:57,126 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:57,126 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33924
om1_1        | 2021-07-12 10:45:57,128 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:57,185 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:57,186 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33930
om1_1        | 2021-07-12 10:45:57,191 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:57,231 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:57,231 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33936
om1_1        | 2021-07-12 10:45:57,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:57,310 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:57,310 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33942
om1_1        | 2021-07-12 10:45:57,318 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:45:59,955 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:45:59,956 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33954
om1_1        | 2021-07-12 10:45:59,961 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:00,090 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:00,091 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33964
om1_1        | 2021-07-12 10:46:00,093 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:00,146 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:00,147 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33970
om1_1        | 2021-07-12 10:46:00,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:00,352 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:00,352 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33978
om1_1        | 2021-07-12 10:46:00,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:00,425 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:00,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33984
om1_1        | 2021-07-12 10:46:00,429 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:00,476 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:00,477 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33990
om1_1        | 2021-07-12 10:46:00,483 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:00,541 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:00,542 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33996
om1_1        | 2021-07-12 10:46:00,546 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:04,159 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:04,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34022
om1_1        | 2021-07-12 10:46:04,162 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:05,319 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
datanode3_1  | 2021-07-12 10:48:57,239 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:00,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:03,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:06,455 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:09,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:12,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:15,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:18,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:21,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:24,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:27,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:31,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:34,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:40,244 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:43,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:46,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:49,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:52,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:55,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:49:58,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:01,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:04,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:07,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:10,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:14,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:17,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:20,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:23,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:29,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:32,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:35,543 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:38,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:41,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:44,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:47,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:50,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:53,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:50:57,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:00,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:03,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:06,259 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:09,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:12,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:18,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:21,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:24,695 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:27,768 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:30,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:33,909 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:36,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:40,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:43,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:51,545 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-07-12 10:38:51,545 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-07-12 10:38:51,549 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2021-07-12 10:38:51,551 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2021-07-12 10:38:51,561 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2021-07-12 10:38:51,562 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2021-07-12 10:38:53,184 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2021-07-12 10:38:53,189 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2021-07-12 10:38:53,190 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2021-07-12 10:38:53,238 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2021-07-12 10:38:53,244 [main] INFO server.RaftServer: 235f349a-aabc-4dff-b4dd-941abcfde3d9: addNew group-B39E69E4A611:[] returns group-B39E69E4A611:java.util.concurrent.CompletableFuture@6c07add6[Not completed]
scm3.org_1   | 2021-07-12 10:38:53,260 [pool-13-thread-1] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9: new RaftServerImpl for group-B39E69E4A611:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2021-07-12 10:38:53,262 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2021-07-12 10:38:53,262 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2021-07-12 10:38:53,262 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2021-07-12 10:38:53,262 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2021-07-12 10:38:53,262 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2021-07-12 10:38:53,262 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2021-07-12 10:38:53,267 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2021-07-12 10:38:53,271 [pool-13-thread-1] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2021-07-12 10:38:53,271 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2021-07-12 10:38:53,274 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2021-07-12 10:38:53,275 [pool-13-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611 does not exist. Creating ...
scm3.org_1   | 2021-07-12 10:38:53,296 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2021-07-12 10:38:53,315 [pool-13-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611 has been successfully formatted.
scm3.org_1   | 2021-07-12 10:38:53,318 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2021-07-12 10:38:53,320 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-07-12 10:38:08,932 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: shutdown 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState
scm1.org_1   | 2021-07-12 10:38:08,932 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2021-07-12 10:45:57,137 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38488
om2_1        | 2021-07-12 10:45:57,139 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:57,195 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:57,196 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38494
om2_1        | 2021-07-12 10:45:57,199 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:57,246 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:57,247 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38500
om2_1        | 2021-07-12 10:45:57,255 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:57,323 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:57,324 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38506
om2_1        | 2021-07-12 10:45:57,325 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:45:59,967 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:45:59,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38518
om2_1        | 2021-07-12 10:45:59,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:00,096 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:00,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38528
om2_1        | 2021-07-12 10:46:00,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:00,158 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:00,159 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38534
om2_1        | 2021-07-12 10:46:00,160 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:00,363 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:00,364 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38542
om2_1        | 2021-07-12 10:46:00,367 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:00,432 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:00,432 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38548
om2_1        | 2021-07-12 10:46:00,433 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:00,488 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
datanode1_1  | 2021-07-12 10:49:48,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:51,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:55,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:49:58,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:01,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:04,243 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:07,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:10,391 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:13,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:16,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:19,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:22,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:25,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:28,823 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:34,964 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:38,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:41,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:44,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:47,255 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:50,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:53,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:56,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:50:59,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:02,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:05,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:08,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:11,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:14,903 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:17,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:24,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:27,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:30,263 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:33,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:36,404 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:39,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:42,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:45,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:48,691 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:51,767 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:54,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:51:57,911 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:00,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:04,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:07,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:13,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:16,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:19,411 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:22,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:25,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:28,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:31,699 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:34,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:37,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:40,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:43,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:47,063 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:50,131 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:53,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:52:56,279 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:02,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:05,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:08,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:11,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:14,711 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:17,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:20,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:23,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:26,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:30,071 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:33,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:36,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:39,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:08,936 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2021-07-12 10:38:08,936 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: start 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1
scm1.org_1   | 2021-07-12 10:38:08,942 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO impl.LeaderElection: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2021-07-12 10:38:08,943 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO impl.LeaderElection: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2021-07-12 10:38:08,943 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: shutdown 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1
scm1.org_1   | 2021-07-12 10:38:08,944 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2021-07-12 10:38:08,944 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: change Leader from null to 834b4eb7-146a-4c2a-bac6-4409b0eef822 at term 1 for becomeLeader, leader elected after 5626ms
scm1.org_1   | 2021-07-12 10:38:08,948 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2021-07-12 10:38:08,951 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm2.org_1   | 2021-07-12 10:38:34,301 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2021-07-12 10:38:34,602 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2021-07-12 10:38:34,602 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2021-07-12 10:38:34,645 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-07-12 10:38:34,883 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-07-12 10:38:35,221 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2021-07-12 10:38:35,221 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
om3_1        | 2021-07-12 10:45:19,564 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:23,304 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:23,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60302
om3_1        | 2021-07-12 10:45:23,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:26,689 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40706
om3_1        | 2021-07-12 10:45:26,692 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:28,885 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:28,886 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60336
om3_1        | 2021-07-12 10:45:28,894 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:29,389 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:29,391 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60346
om3_1        | 2021-07-12 10:45:29,408 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:34,352 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:34,352 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60376
om3_1        | 2021-07-12 10:45:34,364 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:37,508 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:38:53,331 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2021-07-12 10:38:53,341 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2021-07-12 10:38:53,354 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2021-07-12 10:38:53,355 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611
scm3.org_1   | 2021-07-12 10:38:53,356 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-07-12 10:38:53,367 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm3.org_1   | 2021-07-12 10:38:53,371 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2021-07-12 10:38:53,375 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2021-07-12 10:38:53,385 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611
scm3.org_1   | 2021-07-12 10:38:53,385 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2021-07-12 10:38:53,386 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2021-07-12 10:38:53,387 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm3.org_1   | 2021-07-12 10:38:53,388 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm3.org_1   | 2021-07-12 10:38:53,390 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2021-07-12 10:38:53,398 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2021-07-12 10:38:53,399 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2021-07-12 10:38:53,400 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2021-07-12 10:38:53,405 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2021-07-12 10:38:53,405 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2021-07-12 10:38:53,411 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-07-12 10:38:08,951 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-07-12 10:38:35,411 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:1c300e12-e25b-4eac-b361-75629ac63c82
scm1.org_1   | 2021-07-12 10:38:08,953 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-07-12 10:38:08,953 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2021-07-12 10:38:35,505 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2021-07-12 10:38:35,591 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-07-12 10:38:08,965 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2021-07-12 10:38:08,965 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2021-07-12 10:38:08,965 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2021-07-12 10:38:08,971 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: start 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl
scm1.org_1   | 2021-07-12 10:38:08,989 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2021-07-12 10:38:09,029 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: set configuration 0: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-07-12 10:38:35,592 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-07-12 10:38:35,592 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2021-07-12 10:38:35,592 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-07-12 10:38:35,593 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-07-12 10:38:35,593 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2021-07-12 10:38:35,594 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2021-07-12 10:38:35,595 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2021-07-12 10:38:35,596 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2021-07-12 10:38:36,173 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2021-07-12 10:38:36,174 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2021-07-12 10:38:36,174 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2021-07-12 10:38:36,183 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2021-07-12 10:38:36,201 [main] INFO server.RaftServer: 1c300e12-e25b-4eac-b361-75629ac63c82: addNew group-B39E69E4A611:[] returns group-B39E69E4A611:java.util.concurrent.CompletableFuture@6c07add6[Not completed]
scm2.org_1   | 2021-07-12 10:38:36,218 [pool-13-thread-1] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82: new RaftServerImpl for group-B39E69E4A611:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2021-07-12 10:38:36,220 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2021-07-12 10:38:36,221 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2021-07-12 10:38:36,221 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2021-07-12 10:38:36,222 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2021-07-12 10:38:36,223 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2021-07-12 10:38:36,223 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2021-07-12 10:38:36,223 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2021-07-12 10:38:36,227 [pool-13-thread-1] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2021-07-12 10:38:36,227 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2021-07-12 10:38:36,230 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2021-07-12 10:38:36,231 [pool-13-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611 does not exist. Creating ...
scm2.org_1   | 2021-07-12 10:38:36,242 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/in_use.lock acquired by nodename 8@scm2.org
scm2.org_1   | 2021-07-12 10:38:36,271 [pool-13-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611 has been successfully formatted.
scm2.org_1   | 2021-07-12 10:38:36,273 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2021-07-12 10:38:36,275 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2021-07-12 10:38:36,281 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2021-07-12 10:38:36,281 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2021-07-12 10:38:36,287 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2021-07-12 10:38:36,287 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611
scm2.org_1   | 2021-07-12 10:38:36,288 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-07-12 10:38:36,290 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm2.org_1   | 2021-07-12 10:38:36,294 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2021-07-12 10:38:36,294 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2021-07-12 10:38:36,298 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611
scm2.org_1   | 2021-07-12 10:38:36,299 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2021-07-12 10:38:36,299 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2021-07-12 10:38:36,300 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm2.org_1   | 2021-07-12 10:38:36,300 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm2.org_1   | 2021-07-12 10:38:36,301 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2021-07-12 10:38:36,302 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2021-07-12 10:38:36,302 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2021-07-12 10:38:36,302 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2021-07-12 10:38:36,307 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2021-07-12 10:38:36,307 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2021-07-12 10:38:36,312 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-07-12 10:38:36,312 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-07-12 10:38:36,315 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2021-07-12 10:38:36,315 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2021-07-12 10:38:36,316 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2021-07-12 10:38:36,316 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2021-07-12 10:38:36,317 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2021-07-12 10:38:36,318 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2021-07-12 10:38:36,337 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611
scm2.org_1   | 2021-07-12 10:38:36,337 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-07-12 10:38:36,340 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611
scm2.org_1   | 2021-07-12 10:38:36,340 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-07-12 10:38:36,359 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2021-07-12 10:38:36,362 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2021-07-12 10:38:36,366 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2021-07-12 10:38:36,631 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm2.org_1   | 2021-07-12 10:38:36,633 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2021-07-12 10:38:36,636 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
datanode2_1  | 2021-07-12 10:49:50,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:53,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:56,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:49:59,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:45:37,509 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60400
scm1.org_1   | 2021-07-12 10:38:09,095 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_0
datanode2_1  | 2021-07-12 10:50:02,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:45:37,516 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:37,986 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:37,986 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60410
om3_1        | 2021-07-12 10:45:37,995 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:38,490 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:38,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60420
om3_1        | 2021-07-12 10:45:38,493 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:41,584 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40816
om3_1        | 2021-07-12 10:45:41,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:43,757 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:43,757 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60454
om3_1        | 2021-07-12 10:45:43,759 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:44,299 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:44,301 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60462
om3_1        | 2021-07-12 10:45:44,303 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:44,386 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:44,386 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60468
om3_1        | 2021-07-12 10:45:44,389 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:44,636 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:44,636 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60482
om3_1        | 2021-07-12 10:45:44,639 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:47,426 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:47,427 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60494
om3_1        | 2021-07-12 10:45:47,434 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:50,133 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:50,134 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60516
om3_1        | 2021-07-12 10:45:50,136 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:50,336 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:50,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60526
om3_1        | 2021-07-12 10:45:50,341 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:50,419 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:50,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60530
om3_1        | 2021-07-12 10:45:50,422 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:53,681 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:53,681 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60564
om3_1        | 2021-07-12 10:45:53,682 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:10,289 [main] INFO server.RaftServer: 834b4eb7-146a-4c2a-bac6-4409b0eef822: close
scm1.org_1   | 2021-07-12 10:38:10,290 [main] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: shutdown
scm1.org_1   | 2021-07-12 10:38:10,291 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B39E69E4A611,id=834b4eb7-146a-4c2a-bac6-4409b0eef822
scm1.org_1   | 2021-07-12 10:38:10,291 [main] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: shutdown 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl
scm1.org_1   | 2021-07-12 10:38:10,298 [main] INFO impl.PendingRequests: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2021-07-12 10:38:10,298 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:10,299 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:10,300 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO impl.StateMachineUpdater: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2021-07-12 10:38:10,300 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO impl.StateMachineUpdater: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2021-07-12 10:38:10,300 [main] INFO impl.StateMachineUpdater: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2021-07-12 10:38:10,305 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:10,307 [main] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: closes. applyIndex: 0
scm1.org_1   | 2021-07-12 10:38:10,308 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2021-07-12 10:38:10,309 [main] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker close()
scm1.org_1   | 2021-07-12 10:38:10,309 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:10,309 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:10,309 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:10,310 [main] INFO server.GrpcService: 834b4eb7-146a-4c2a-bac6-4409b0eef822: shutdown server with port 9894 now
scm1.org_1   | 2021-07-12 10:38:10,313 [main] INFO server.GrpcService: 834b4eb7-146a-4c2a-bac6-4409b0eef822: shutdown server with port 9894 successfully
scm1.org_1   | 2021-07-12 10:38:10,313 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$331/0x000000084030cc40@443faa85] INFO util.JvmPauseMonitor: JvmPauseMonitor-834b4eb7-146a-4c2a-bac6-4409b0eef822: Stopped
datanode2_1  | 2021-07-12 10:50:05,760 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:45:53,845 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:53,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60570
om3_1        | 2021-07-12 10:45:53,860 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:00,489 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38554
om2_1        | 2021-07-12 10:46:00,495 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:00,553 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:00,553 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38560
om2_1        | 2021-07-12 10:46:00,554 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:04,167 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:04,168 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38586
scm3.org_1   | 2021-07-12 10:38:53,419 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-07-12 10:50:08,823 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:11,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:14,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:18,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:46,199 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:49,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:52,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:05,319 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34038
scm1.org_1   | 2021-07-12 10:38:10,313 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-07-12 10:38:10,317 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-ea67d158-f30d-4de4-8e61-b39e69e4a611; layoutVersion=2; scmId=834b4eb7-146a-4c2a-bac6-4409b0eef822
scm1.org_1   | 2021-07-12 10:38:10,329 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm3.org_1   | 2021-07-12 10:38:53,426 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2021-07-12 10:38:53,429 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
om2_1        | 2021-07-12 10:46:04,171 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:05,333 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
datanode3_1  | 2021-07-12 10:51:55,415 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:51:58,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:01,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:07,699 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:10,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:13,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:16,919 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:21,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:24,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:27,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:33,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:36,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:53,429 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2021-07-12 10:46:05,334 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38602
om2_1        | 2021-07-12 10:46:05,338 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:09,055 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45294
om2_1        | 2021-07-12 10:46:09,065 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:11,311 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:11,312 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38646
datanode2_1  | 2021-07-12 10:50:39,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:42,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:45,687 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:48,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:51,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:54,903 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:50:57,975 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:01,047 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:53,430 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-07-12 10:51:04,116 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:07,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:19,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1        | 2021-07-12 10:46:05,326 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-07-12 10:38:11,886 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | 2021-07-12 10:38:53,432 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2021-07-12 10:38:53,433 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2021-07-12 10:46:08,993 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42752
scm3.org_1   | 2021-07-12 10:38:53,462 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611
datanode1_1  | 2021-07-12 10:53:42,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:46:11,317 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:11,777 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:11,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38656
om2_1        | 2021-07-12 10:46:11,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:12,281 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm3.org_1   | 2021-07-12 10:38:53,462 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode1_1  | 2021-07-12 10:53:45,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:53:51,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:10,278 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:23,063 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:26,131 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:29,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:32,279 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:53,465 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611
scm3.org_1   | 2021-07-12 10:38:53,465 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 2021-07-12 10:46:12,282 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38666
om2_1        | 2021-07-12 10:46:12,287 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
datanode3_1  | 2021-07-12 10:52:35,348 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:45:54,012 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:38:36,638 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2021-07-12 10:38:36,686 [main] INFO node.SCMNodeManager: Entering startup safe mode.
datanode1_1  | 2021-07-12 10:53:54,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:13,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:16,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode3_1  | 2021-07-12 10:52:38,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:41,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:09,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:11,302 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:11,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34082
om1_1        | 2021-07-12 10:46:11,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:11,765 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:11,770 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34092
scm3.org_1   | 2021-07-12 10:38:53,470 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2021-07-12 10:38:53,471 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-07-12 10:45:54,015 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60578
om3_1        | 2021-07-12 10:45:54,027 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-07-12 10:52:44,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:52:47,637 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:11,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-07-12 10:53:57,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:54:00,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:46:12,310 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-99894 in volume:s3v
scm3.org_1   | 2021-07-12 10:38:53,475 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2021-07-12 10:38:53,902 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm3.org_1   | 2021-07-12 10:38:53,903 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
datanode2_1  | 2021-07-12 10:51:22,551 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/de23d45d4457280600c34bc04dbf00f927bb3557 ; compiled by 'runner' on 2021-07-12T09:47Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
om1_1        | 2021-07-12 10:46:12,273 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om3_1        | 2021-07-12 10:45:54,046 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:54,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60584
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
datanode3_1  | 2021-07-12 10:52:50,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:25,623 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:28,691 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:45:54,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:38:53,906 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2021-07-12 10:38:53,908 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2021-07-12 10:38:54,035 [main] INFO node.SCMNodeManager: Entering startup safe mode.
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm3.org_1   | 2021-07-12 10:38:54,060 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2021-07-12 10:38:54,075 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
datanode3_1  | 2021-07-12 10:52:56,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2021-07-12 10:38:36,697 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2021-07-12 10:38:36,706 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
om3_1        | 2021-07-12 10:45:57,038 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:57,038 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60608
om3_1        | 2021-07-12 10:45:57,039 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:57,095 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:38:54,148 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2021-07-12 10:38:54,166 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
datanode3_1  | 2021-07-12 10:52:59,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:46:12,757 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:38:36,744 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2021-07-12 10:38:36,750 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2021-07-12 10:38:36,750 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2021-07-12 10:38:36,808 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
datanode1_1  | 2021-07-12 10:54:03,860 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:12,274 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34100
scm3.org_1   | 2021-07-12 10:38:54,173 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2021-07-12 10:38:54,244 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
datanode3_1  | 2021-07-12 10:53:02,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:06,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:09,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:12,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | ************************************************************/
datanode2_1  | 2021-07-12 10:51:31,767 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:32,731 [Thread-630] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-0567C008EC42->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=186, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-0567C008EC42->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=186, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 186 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6:c138, 5244f159-1b5c-4bd3-a569-521c9d7b4032:c138, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a:c127]
datanode1_1  | 2021-07-12 10:54:06,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:12,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:12,313 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-99894 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:47,487 [qtp1363396194-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-EB00BA4163FD->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
om2_1        | 2021-07-12 10:46:12,758 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38674
datanode2_1  | 2021-07-12 10:51:34,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:37,914 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:40,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:54,322 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2021-07-12 10:38:54,346 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2021-07-12 10:38:36,842 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
om3_1        | 2021-07-12 10:45:57,095 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60614
datanode1_1  | 2021-07-12 10:54:10,007 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 2021-07-12 10:45:47,487 [qtp1363396194-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:45:50,131 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-07-12 10:38:11,904 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-07-12 10:38:12,019 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-07-12 10:38:12,020 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
datanode3_1  | 2021-07-12 10:53:15,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:18,359 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
datanode1_1  | 2021-07-12 10:54:13,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
datanode2_1  | 2021-07-12 10:51:44,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:47,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:50,195 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:53,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
om2_1        | 2021-07-12 10:46:12,763 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:16,099 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45368
datanode1_1  | 2021-07-12 10:54:16,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:56,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:51:59,411 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:02,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:05,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:11,703 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
scm1.org_1   | 2021-07-12 10:38:12,088 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-07-12 10:38:54,365 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2021-07-12 10:38:54,385 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 0 containers.
datanode3_1  | 2021-07-12 10:53:21,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:24,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:27,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-07-12 10:38:54,396 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2021-07-12 10:38:54,406 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:38:54,415 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2021-07-12 10:38:54,463 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2021-07-12 10:38:54,521 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-07-12 10:38:54,627 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2021-07-12 10:38:36,850 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2021-07-12 10:38:36,853 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2021-07-12 10:38:36,861 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm2.org_1   | 2021-07-12 10:38:36,864 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2021-07-12 10:38:36,867 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:38:36,869 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om3_1        | 2021-07-12 10:45:57,096 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:16,104 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:18,400 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
datanode1_1  | 2021-07-12 10:54:19,223 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:54:22,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:36,891 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2021-07-12 10:38:36,914 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-07-12 10:38:36,945 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
datanode3_1  | 2021-07-12 10:53:30,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om3_1        | 2021-07-12 10:45:57,145 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:57,146 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60620
om3_1        | 2021-07-12 10:45:57,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:57,205 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:18,400 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38710
om2_1        | 2021-07-12 10:46:18,401 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:18,862 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:38:12,091 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-07-12 10:38:12,134 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-07-12 10:38:12,180 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm1.org_1   | 2021-07-12 10:38:12,384 [main] INFO reflections.Reflections: Reflections took 101 ms to scan 3 urls, producing 103 keys and 210 values 
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode1_1  | 2021-07-12 10:54:25,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:54:28,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:54:31,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:54:34,583 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:12,749 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:12,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34110
datanode3_1  | 2021-07-12 10:53:33,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:36,791 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:39,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:46,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:14,788 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:17,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:20,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:23,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:27,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:37,707 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-07-12 10:38:37,716 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2021-07-12 10:38:37,748 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2021-07-12 10:46:18,864 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38720
scm1.org_1   | 2021-07-12 10:38:13,039 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2021-07-12 10:38:13,177 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
datanode2_1  | 2021-07-12 10:52:30,131 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:33,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:49,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:52,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:55,858 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-07-12 10:38:37,755 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2021-07-12 10:38:37,792 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode1_1  | 2021-07-12 10:54:40,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:46:18,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:19,353 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:19,353 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38736
datanode2_1  | 2021-07-12 10:52:33,729 [Thread-666] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-099FF08C3BF7->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=190, seq=0, Watch-ALL_COMMITTED(133), Message:<EMPTY>, reply=RaftClientReply:client-099FF08C3BF7->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=190, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 190 and log index 133 is not yet replicated to ALL_COMMITTED, logIndex=133, commits[dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6:c142, 5244f159-1b5c-4bd3-a569-521c9d7b4032:c142, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a:c127]
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
datanode3_1  | 2021-07-12 10:53:55,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:53:58,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:55,898 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2021-07-12 10:38:55,928 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode1_1  | 2021-07-12 10:54:43,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:46:19,359 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:13,180 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
om1_1        | 2021-07-12 10:46:12,751 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:16,051 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42826
om1_1        | 2021-07-12 10:46:16,065 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm3.org_1   | 2021-07-12 10:38:55,928 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2021-07-12 10:38:55,989 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-07-12 10:38:55,994 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
om3_1        | 2021-07-12 10:45:57,206 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60626
om1_1        | 2021-07-12 10:46:18,390 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:50,333 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
om3_1        | 2021-07-12 10:45:57,207 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:13,184 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2530584589045.crt.
scm1.org_1   | 2021-07-12 10:38:13,345 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2021-07-12 10:38:13,346 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2021-07-12 10:38:13,389 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-07-12 10:38:13,523 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-07-12 10:46:18,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34146
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
datanode3_1  | 2021-07-12 10:54:01,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:04,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:07,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:10,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:13,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:18,394 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:18,846 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
datanode2_1  | 2021-07-12 10:52:36,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:39,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:46:19,805 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:19,805 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38746
datanode2_1  | 2021-07-12 10:52:42,423 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:38:56,178 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        true
datanode3_1  | 2021-07-12 10:54:16,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:19,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:45:57,259 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:57,260 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60632
om3_1        | 2021-07-12 10:45:57,267 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:52:45,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:37,797 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2021-07-12 10:38:37,898 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | 2021-07-12 10:38:13,718 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2021-07-12 10:38:13,718 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode1_1  | 2021-07-12 10:54:46,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:54:49,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:46:19,807 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:19,838 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
datanode2_1  | 2021-07-12 10:52:48,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:52:51,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                            Value
scm3.org_1   | Threshold                      0.1
scm3.org_1   | Max Datanodes to Balance       5
scm3.org_1   | Max Size to Move               10737418240B
scm3.org_1   | 
datanode1_1  | 2021-07-12 10:54:53,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:54:56,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:54:59,159 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:02,231 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:05,303 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:22,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:25,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        true
datanode2_1  | 2021-07-12 10:52:54,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:00,855 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:03,924 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
scm1.org_1   | 2021-07-12 10:38:13,851 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:834b4eb7-146a-4c2a-bac6-4409b0eef822
scm1.org_1   | 2021-07-12 10:38:13,963 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2021-07-12 10:54:29,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:35,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:38,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:41,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:44,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 2021-07-12 10:45:57,328 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:57,329 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60638
datanode1_1  | 2021-07-12 10:55:08,375 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:11,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:14,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:17,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:20,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:23,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:14,055 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-07-12 10:38:14,055 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-07-12 10:38:14,056 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2021-07-12 10:38:14,056 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-07-12 10:38:14,056 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                            Value
scm2.org_1   | Threshold                      0.1
scm2.org_1   | Max Datanodes to Balance       5
scm2.org_1   | Max Size to Move               10737418240B
scm2.org_1   | 
om3_1        | 2021-07-12 10:45:57,329 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:45:59,982 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:45:59,982 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60650
om3_1        | 2021-07-12 10:45:59,986 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:00,106 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:46:22,902 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45446
om2_1        | 2021-07-12 10:46:22,904 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:24,997 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:24,997 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38798
scm3.org_1   | 2021-07-12 10:38:56,183 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-07-12 10:38:56,184 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2021-07-12 10:38:56,198 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2021-07-12 10:38:56,205 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2021-07-12 10:38:56,219 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2021-07-12 10:38:56,225 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: changes role from      null to FOLLOWER at term 0 for startInitializing
scm1.org_1   | 2021-07-12 10:38:14,056 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-07-12 10:38:14,058 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-07-12 10:38:14,058 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-07-12 10:38:14,059 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-07-12 10:38:14,728 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-07-12 10:38:14,729 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-07-12 10:38:14,729 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-07-12 10:54:47,447 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:50,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:53,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:56,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:54:59,735 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:02,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:05,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:29,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:32,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:36,023 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:39,095 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:42,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:45,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:37,899 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-07-12 10:38:37,901 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
om2_1        | 2021-07-12 10:46:25,007 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:25,452 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:25,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38808
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 2021-07-12 10:46:18,848 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34156
om1_1        | 2021-07-12 10:46:18,857 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:19,344 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:19,346 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34172
om3_1        | 2021-07-12 10:46:00,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60660
om3_1        | 2021-07-12 10:46:00,111 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:00,168 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:00,168 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60666
om3_1        | 2021-07-12 10:46:00,175 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:38:37,905 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2021-07-12 10:38:37,911 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2021-07-12 10:38:37,913 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2021-07-12 10:38:37,914 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2021-07-12 10:38:56,227 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B39E69E4A611,id=235f349a-aabc-4dff-b4dd-941abcfde3d9
scm3.org_1   | 2021-07-12 10:38:56,244 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611
scm3.org_1   | 2021-07-12 10:38:56,251 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-07-12 10:38:56,270 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 235f349a-aabc-4dff-b4dd-941abcfde3d9: start RPC server
scm1.org_1   | 2021-07-12 10:38:14,738 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-07-12 10:38:14,740 [main] INFO server.RaftServer: 834b4eb7-146a-4c2a-bac6-4409b0eef822: found a subdirectory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611
scm1.org_1   | 2021-07-12 10:38:14,762 [main] INFO server.RaftServer: 834b4eb7-146a-4c2a-bac6-4409b0eef822: addNew group-B39E69E4A611:[] returns group-B39E69E4A611:java.util.concurrent.CompletableFuture@57a667c8[Not completed]
om1_1        | 2021-07-12 10:46:19,349 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:19,794 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:19,794 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34182
om1_1        | 2021-07-12 10:46:19,802 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:19,840 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
datanode2_1  | 2021-07-12 10:53:06,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:10,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:13,143 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:46:00,373 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:00,373 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60674
om3_1        | 2021-07-12 10:46:00,375 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:00,437 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:00,437 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60680
om2_1        | 2021-07-12 10:46:25,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:25,882 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:25,883 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38816
om2_1        | 2021-07-12 10:46:25,884 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:28,987 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45498
om2_1        | 2021-07-12 10:46:28,994 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:31,093 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
datanode1_1  | 2021-07-12 10:55:48,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:51,383 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:54,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:55:57,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:00,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:03,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:06,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:50,415 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
datanode3_1  | 2021-07-12 10:55:08,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:12,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:15,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:18,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:24,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:37,916 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B39E69E4A611,id=1c300e12-e25b-4eac-b361-75629ac63c82
scm2.org_1   | 2021-07-12 10:38:37,918 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611
scm2.org_1   | 2021-07-12 10:38:37,918 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-07-12 10:38:37,923 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 1c300e12-e25b-4eac-b361-75629ac63c82: start RPC server
scm2.org_1   | 2021-07-12 10:38:38,042 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 1c300e12-e25b-4eac-b361-75629ac63c82: GrpcService started, listening on 9894
scm2.org_1   | 2021-07-12 10:38:38,060 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-07-12 10:38:38,060 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-07-12 10:38:38,060 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2021-07-12 10:38:38,063 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$402/0x0000000840502440@18d63996] INFO util.JvmPauseMonitor: JvmPauseMonitor-1c300e12-e25b-4eac-b361-75629ac63c82: Started
scm2.org_1   | 2021-07-12 10:38:40,357 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.1c300e12-e25b-4eac-b361-75629ac63c82
scm2.org_1   | 2021-07-12 10:38:40,357 [grpc-default-executor-0] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-07-12 10:38:40,418 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2021-07-12 10:38:40,418 [grpc-default-executor-0] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: change Leader from null to 834b4eb7-146a-4c2a-bac6-4409b0eef822 at term 2 for appendEntries, leader elected after 4145ms
scm2.org_1   | 2021-07-12 10:38:40,420 [grpc-default-executor-0] INFO impl.RoleInfo: 1c300e12-e25b-4eac-b361-75629ac63c82: start 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-FollowerState
scm2.org_1   | 2021-07-12 10:38:40,481 [grpc-default-executor-0] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: set configuration 0: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-07-12 10:38:40,481 [grpc-default-executor-0] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: set configuration 1: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-07-12 10:38:40,484 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2021-07-12 10:38:40,508 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2021-07-12 10:38:56,413 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 235f349a-aabc-4dff-b4dd-941abcfde3d9: GrpcService started, listening on 9894
scm3.org_1   | 2021-07-12 10:38:56,424 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$402/0x0000000840501840@1eda12b3] INFO util.JvmPauseMonitor: JvmPauseMonitor-235f349a-aabc-4dff-b4dd-941abcfde3d9: Started
scm3.org_1   | 2021-07-12 10:38:56,430 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-07-12 10:38:56,431 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-07-12 10:38:56,431 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 2021-07-12 10:53:16,215 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:19,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:22,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:25,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:28,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:31,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:14,782 [pool-13-thread-1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822: new RaftServerImpl for group-B39E69E4A611:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-07-12 10:38:14,784 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-07-12 10:38:14,785 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2021-07-12 10:38:14,785 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2021-07-12 10:38:14,786 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-07-12 10:38:14,786 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-07-12 10:38:14,786 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2021-07-12 10:38:14,787 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-07-12 10:38:14,791 [pool-13-thread-1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-07-12 10:38:14,791 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-07-12 10:38:14,793 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-07-12 10:38:14,802 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/in_use.lock acquired by nodename 7@scm1.org
scm1.org_1   | 2021-07-12 10:38:14,806 [pool-13-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=834b4eb7-146a-4c2a-bac6-4409b0eef822} from /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/raft-meta
scm1.org_1   | 2021-07-12 10:38:14,830 [pool-13-thread-1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: set configuration 0: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-07-12 10:38:14,831 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-07-12 10:38:14,832 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-07-12 10:38:14,838 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-07-12 10:38:14,839 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-07-12 10:38:14,845 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2021-07-12 10:38:14,845 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:14,846 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:14,848 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
datanode3_1  | 2021-07-12 10:55:27,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:30,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:33,530 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-07-12 10:39:00,218 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.235f349a-aabc-4dff-b4dd-941abcfde3d9
scm3.org_1   | 2021-07-12 10:39:00,220 [grpc-default-executor-0] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-07-12 10:39:00,562 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2021-07-12 10:39:00,564 [grpc-default-executor-0] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: change Leader from null to 834b4eb7-146a-4c2a-bac6-4409b0eef822 at term 2 for appendEntries, leader elected after 7244ms
scm3.org_1   | 2021-07-12 10:39:00,585 [grpc-default-executor-0] INFO impl.RoleInfo: 235f349a-aabc-4dff-b4dd-941abcfde3d9: start 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-FollowerState
scm3.org_1   | 2021-07-12 10:39:00,957 [grpc-default-executor-0] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: set configuration 0: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-07-12 10:39:00,966 [grpc-default-executor-0] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: set configuration 1: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-07-12 10:39:00,969 [grpc-default-executor-0] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: set configuration 5: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-07-12 10:39:00,973 [grpc-default-executor-0] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: set configuration 7: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-07-12 10:39:00,988 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2021-07-12 10:39:01,078 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2021-07-12 10:39:01,371 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_0
scm3.org_1   | 2021-07-12 10:39:01,380 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_0 to /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_0-0
scm3.org_1   | 2021-07-12 10:39:01,415 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_1
scm3.org_1   | 2021-07-12 10:39:01,472 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:01,473 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2021-07-12 10:39:01,493 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om3_1        | 2021-07-12 10:46:00,439 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:00,498 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:00,498 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60686
om3_1        | 2021-07-12 10:46:00,503 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:00,558 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:00,558 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60692
om3_1        | 2021-07-12 10:46:00,563 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:04,175 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:04,175 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60718
om3_1        | 2021-07-12 10:46:04,178 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:05,341 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:05,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60734
om3_1        | 2021-07-12 10:46:05,344 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:09,096 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41138
om3_1        | 2021-07-12 10:46:09,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:11,320 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:11,321 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60778
om3_1        | 2021-07-12 10:46:11,322 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:11,783 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:11,785 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60788
om3_1        | 2021-07-12 10:46:11,791 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:12,291 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:12,292 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60798
om3_1        | 2021-07-12 10:46:12,293 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:12,306 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-99894 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 2021-07-12 10:46:31,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38852
om2_1        | 2021-07-12 10:46:31,097 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:31,520 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:31,520 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38860
om2_1        | 2021-07-12 10:46:31,521 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:34,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45544
om2_1        | 2021-07-12 10:46:34,571 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:36,658 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:36,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38886
om2_1        | 2021-07-12 10:46:36,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:37,127 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:37,128 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38904
om2_1        | 2021-07-12 10:46:37,129 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:37,594 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:37,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38912
om2_1        | 2021-07-12 10:46:37,596 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:38,194 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:38,195 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38920
om2_1        | 2021-07-12 10:46:38,196 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:41,585 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:41,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38940
om2_1        | 2021-07-12 10:46:41,586 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:44,838 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:44,839 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38964
om2_1        | 2021-07-12 10:46:44,847 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:45,401 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:50,611 [qtp1363396194-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-94CF57CD6516->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:45:50,617 [qtp1363396194-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:45:50,676 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-AD672DA024E1->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:45:50,677 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:45:53,679 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:53,841 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
datanode1_1  | 2021-07-12 10:56:09,815 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:12,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:19,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:22,103 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:34,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:34,729 [Thread-708] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-E5F6AAA47AC3->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=194, seq=0, Watch-ALL_COMMITTED(136), Message:<EMPTY>, reply=RaftClientReply:client-E5F6AAA47AC3->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=194, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 194 and log index 136 is not yet replicated to ALL_COMMITTED, logIndex=136, commits[dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6:c146, 5244f159-1b5c-4bd3-a569-521c9d7b4032:c146, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a:c127]
datanode2_1  | 2021-07-12 10:53:37,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:40,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:43,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:50,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:53,079 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:56,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:53:59,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:02,295 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:05,367 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:08,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:11,511 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:14,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:17,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:20,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:23,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:36,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:39,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:42,743 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:45,815 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:48,887 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:51,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:55,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:55:58,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:46:22,857 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42904
om1_1        | 2021-07-12 10:46:22,871 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-07-12 10:56:25,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:28,243 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:31,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:34,388 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:37,463 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:40,532 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:43,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:46,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:49,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:52,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:55,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:56:58,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-07-12 10:57:02,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:24,990 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:24,990 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34234
om1_1        | 2021-07-12 10:46:24,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:25,444 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:25,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34244
om1_1        | 2021-07-12 10:46:25,446 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:25,870 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:25,871 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34252
datanode3_1  | 2021-07-12 10:56:01,176 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:04,247 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:07,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:13,463 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:16,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:19,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:22,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:25,751 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:28,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:40,879 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_0
scm2.org_1   | 2021-07-12 10:38:40,884 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_0 to /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_0-0
scm2.org_1   | 2021-07-12 10:38:40,894 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_1
scm2.org_1   | 2021-07-12 10:38:40,918 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:38:40,935 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2021-07-12 10:38:40,937 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2021-07-12 10:38:40,938 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2021-07-12 10:38:40,943 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-07-12 10:39:01,516 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2021-07-12 10:39:01,571 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2021-07-12 10:39:01,574 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-07-12 10:39:01,667 [grpc-default-executor-0] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: set configuration 11: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-07-12 10:39:01,708 [grpc-default-executor-0] INFO server.RaftServer$Division: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611: set configuration 13: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-07-12 10:39:02,209 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-B39E69E4A611:[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-07-12 10:39:02,414 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2021-07-12 10:39:02,232 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$402/0x0000000840501840@1eda12b3] WARN util.JvmPauseMonitor: JvmPauseMonitor-235f349a-aabc-4dff-b4dd-941abcfde3d9: Detected pause in JVM or host machine (eg GC): pause of approximately 239198944ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=141ms
scm3.org_1   | 2021-07-12 10:39:02,468 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2021-07-12 10:39:02,477 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2021-07-12 10:39:02,819 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:02,847 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2021-07-12 10:39:02,847 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2021-07-12 10:39:03,051 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:03,353 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2021-07-12 10:39:03,462 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2021-07-12 10:39:03,462 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2021-07-12 10:39:05,506 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2021-07-12 10:39:05,509 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-07-12 10:39:05,635 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2021-07-12 10:39:05,856 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2021-07-12 10:39:05,867 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2021-07-12 10:39:05,905 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-07-12 10:39:05,913 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2021-07-12 10:39:06,243 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm3.org_1   | 2021-07-12 10:39:06,244 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2021-07-12 10:39:06,245 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-07-12 10:39:06,245 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2021-07-12 10:39:06,247 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2021-07-12 10:39:06,568 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-07-12 10:39:06,583 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-07-12 10:39:06,590 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2021-07-12 10:39:08,292 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 235f349a-aabc-4dff-b4dd-941abcfde3d9
scm3.org_1   | 2021-07-12 10:39:08,312 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 2530584589045 on Scm Bootstrap Node 235f349a-aabc-4dff-b4dd-941abcfde3d9
scm3.org_1   | 2021-07-12 10:39:08,386 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bd76b79] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2021-07-12 10:39:08,494 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2021-07-12 10:39:08,505 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2021-07-12 10:39:08,506 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2021-07-12 10:39:08,766 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @21114ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2021-07-12 10:39:09,581 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2021-07-12 10:39:09,609 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2021-07-12 10:39:09,647 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2021-07-12 10:39:09,648 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2021-07-12 10:39:09,652 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2021-07-12 10:39:09,789 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2021-07-12 10:39:10,067 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2021-07-12 10:39:10,072 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
scm3.org_1   | 2021-07-12 10:39:10,238 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2021-07-12 10:39:10,250 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2021-07-12 10:39:10,252 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2021-07-12 10:39:10,420 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-07-12 10:39:10,423 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1af6cd73{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2021-07-12 10:39:10,450 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@58cd7486{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2021-07-12 10:39:11,037 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om1_1        | 2021-07-12 10:46:25,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:28,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42956
om1_1        | 2021-07-12 10:46:28,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:31,077 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:31,078 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34288
om1_1        | 2021-07-12 10:46:31,089 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:31,513 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:31,514 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34296
om1_1        | 2021-07-12 10:46:31,515 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:34,511 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43002
om1_1        | 2021-07-12 10:46:34,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:36,651 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:36,652 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34322
om1_1        | 2021-07-12 10:46:36,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:37,121 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:37,122 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34340
om1_1        | 2021-07-12 10:46:37,124 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:14,852 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-07-12 10:38:14,852 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-07-12 10:38:14,856 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611
scm1.org_1   | 2021-07-12 10:38:14,857 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-07-12 10:38:14,859 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-07-12 10:38:14,860 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-07-12 10:38:14,860 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm1.org_1   | 2021-07-12 10:38:14,861 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2021-07-12 10:38:14,862 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2021-07-12 10:38:14,863 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2021-07-12 10:38:14,863 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2021-07-12 10:38:14,871 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2021-07-12 10:38:14,871 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2021-07-12 10:38:14,894 [pool-13-thread-1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: set configuration 0: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-07-12 10:38:14,894 [pool-13-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_0
scm1.org_1   | 2021-07-12 10:38:14,897 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
datanode3_1  | 2021-07-12 10:56:31,895 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:26,871 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-07-12 10:46:45,402 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38974
om2_1        | 2021-07-12 10:46:45,402 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:46:12,772 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:12,773 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60806
om3_1        | 2021-07-12 10:46:12,776 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:16,124 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41212
om3_1        | 2021-07-12 10:46:16,130 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:18,405 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:18,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60842
om3_1        | 2021-07-12 10:46:18,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:18,876 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:18,877 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60856
om3_1        | 2021-07-12 10:46:18,881 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:19,363 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:19,363 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60868
om3_1        | 2021-07-12 10:46:19,364 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:19,821 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:19,821 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60878
om3_1        | 2021-07-12 10:46:19,824 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:19,834 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:46:22,915 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41290
om3_1        | 2021-07-12 10:46:22,916 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:25,012 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:25,014 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60930
om3_1        | 2021-07-12 10:46:25,020 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:25,464 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:38:40,958 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
datanode3_1  | 2021-07-12 10:56:34,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:38,036 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:41,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:44,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:47,255 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:50,327 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:53,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:56:56,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-07-12 10:57:02,615 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:29,949 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:33,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:40,995 [grpc-default-executor-0] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: set configuration 5: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-07-12 10:38:41,148 [grpc-default-executor-0] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: set configuration 7: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-07-12 10:38:41,394 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:38:41,394 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2021-07-12 10:38:41,394 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om2_1        | 2021-07-12 10:46:48,744 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:48,744 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38990
om2_1        | 2021-07-12 10:46:48,745 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:51,823 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:51,823 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39014
om2_1        | 2021-07-12 10:46:51,824 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:52,287 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:52,288 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39024
om2_1        | 2021-07-12 10:46:52,288 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:53,179 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:53,179 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39056
om2_1        | 2021-07-12 10:46:53,181 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:53,692 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:53,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39064
datanode2_1  | 2021-07-12 10:54:37,729 [Thread-750] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-1907F9A74D3E->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=199, seq=0, Watch-ALL_COMMITTED(140), Message:<EMPTY>, reply=RaftClientReply:client-1907F9A74D3E->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=199, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 199 and log index 140 is not yet replicated to ALL_COMMITTED, logIndex=140, commits[dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6:c150, 5244f159-1b5c-4bd3-a569-521c9d7b4032:c150, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a:c127]
datanode2_1  | 2021-07-12 10:54:39,165 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:42,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:45,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:48,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-07-12 10:38:41,443 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-B39E69E4A611:[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-07-12 10:38:41,444 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2021-07-12 10:38:41,451 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2021-07-12 10:38:41,451 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2021-07-12 10:38:41,839 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2021-07-12 10:38:41,887 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2021-07-12 10:38:41,887 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2021-07-12 10:38:42,512 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2021-07-12 10:38:42,512 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-07-12 10:38:42,515 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2021-07-12 10:38:42,716 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2021-07-12 10:38:42,717 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2021-07-12 10:38:42,729 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-07-12 10:38:42,730 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2021-07-12 10:38:42,829 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm2.org_1   | 2021-07-12 10:38:42,829 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2021-07-12 10:38:42,834 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-07-12 10:38:42,838 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2021-07-12 10:38:42,839 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2021-07-12 10:38:42,960 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-07-12 10:38:42,960 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-07-12 10:38:42,960 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2021-07-12 10:38:43,387 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 1c300e12-e25b-4eac-b361-75629ac63c82
scm2.org_1   | 2021-07-12 10:38:43,411 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 2530584589045 on Scm Bootstrap Node 1c300e12-e25b-4eac-b361-75629ac63c82
om1_1        | 2021-07-12 10:46:37,588 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:38:14,897 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2021-07-12 10:46:53,693 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:54,326 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:54,327 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39076
om2_1        | 2021-07-12 10:46:54,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:57,453 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:46:57,454 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39100
om2_1        | 2021-07-12 10:46:57,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:57,489 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-13754/69181/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2021-07-12 10:46:57,490 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 69181/multipartKey2 in Volume/Bucket s3v/bucket-13754
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 69181/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:463)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
datanode3_1  | 2021-07-12 10:57:05,687 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:37,588 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34348
om1_1        | 2021-07-12 10:46:37,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:38,188 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:38,188 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34356
om1_1        | 2021-07-12 10:46:38,189 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:41,577 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:41,579 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34376
om1_1        | 2021-07-12 10:46:41,580 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:54:51,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:54:54,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:44,833 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:44,833 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34400
datanode2_1  | 2021-07-12 10:54:57,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:14,973 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-07-12 10:55:00,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:03,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 2021-07-12 10:38:43,444 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2976d625] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2021-07-12 10:46:25,465 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60940
om3_1        | 2021-07-12 10:46:25,466 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:25,886 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:25,887 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60948
om3_1        | 2021-07-12 10:46:25,894 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:14,974 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-07-12 10:38:14,975 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-07-12 10:38:14,976 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2021-07-12 10:38:43,491 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
datanode2_1  | 2021-07-12 10:55:06,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:09,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:12,951 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:16,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:19,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:22,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:28,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:31,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:34,453 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-07-12 10:46:44,836 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:45,395 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
datanode2_1  | 2021-07-12 10:55:37,527 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:40,599 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:14,977 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2021-07-12 10:38:14,978 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-07-12 10:38:14,993 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:14,993 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:14,996 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:14,996 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:15,002 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2021-07-12 10:38:15,002 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-07-12 10:46:45,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34410
om1_1        | 2021-07-12 10:46:45,397 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:15,003 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2021-07-12 10:38:15,227 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm1.org_1   | 2021-07-12 10:38:15,228 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
datanode2_1  | 2021-07-12 10:55:43,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 2021-07-12 10:46:48,735 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:48,736 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34426
om1_1        | 2021-07-12 10:46:48,741 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:51,818 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:51,818 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34450
om1_1        | 2021-07-12 10:46:51,820 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:46:57,962 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:29,019 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41342
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-07-12 10:38:43,492 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2021-07-12 10:55:46,729 [Thread-792] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-D4DFB40BA693->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=211, seq=0, Watch-ALL_COMMITTED(144), Message:<EMPTY>, reply=RaftClientReply:client-D4DFB40BA693->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=211, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 211 and log index 144 is not yet replicated to ALL_COMMITTED, logIndex=144, commits[dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6:c157, 5244f159-1b5c-4bd3-a569-521c9d7b4032:c157, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a:c127]
datanode2_1  | 2021-07-12 10:55:46,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:49,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:52,887 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:46:29,026 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:57,962 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39110
om2_1        | 2021-07-12 10:46:57,971 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:58,452 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:38:43,493 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
datanode2_1  | 2021-07-12 10:55:55,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:55:59,031 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:02,103 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-07-12 10:46:31,099 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:52,273 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:52,276 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34460
om1_1        | 2021-07-12 10:46:52,283 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:56:05,172 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 2021-07-12 10:45:54,004 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
om2_1        | 2021-07-12 10:46:58,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39120
scm1.org_1   | 2021-07-12 10:38:15,231 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2021-07-12 10:38:15,234 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2021-07-12 10:38:15,288 [main] INFO node.SCMNodeManager: Entering startup safe mode.
om3_1        | 2021-07-12 10:46:31,100 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60984
datanode2_1  | 2021-07-12 10:56:08,243 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om2_1        | 2021-07-12 10:46:58,455 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:54,040 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om2_1        | 2021-07-12 10:46:58,492 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-13754/49112/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
scm1.org_1   | 2021-07-12 10:38:15,301 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2021-07-12 10:38:15,310 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
scm1.org_1   | 2021-07-12 10:38:15,349 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2021-07-12 10:38:15,357 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2021-07-12 10:38:15,357 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2021-07-12 10:38:15,407 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2021-07-12 10:38:15,430 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2021-07-12 10:38:15,439 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2021-07-12 10:38:15,444 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-07-12 10:38:15,453 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
om2_1        | partName: "etag1"
scm1.org_1   | 2021-07-12 10:38:15,455 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2021-07-12 10:38:43,568 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @13239ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2021-07-12 10:46:53,175 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:53,175 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34492
om1_1        | 2021-07-12 10:46:53,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:53,683 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:53,683 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34500
om1_1        | 2021-07-12 10:46:53,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:54,322 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:54,322 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34512
om1_1        | 2021-07-12 10:46:54,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:38:43,857 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2021-07-12 10:38:43,890 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2021-07-12 10:38:43,907 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2021-07-12 10:38:43,908 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2021-07-12 10:38:43,908 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2021-07-12 10:38:43,910 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2021-07-12 10:38:44,016 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2021-07-12 10:38:44,016 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
scm2.org_1   | 2021-07-12 10:38:44,130 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2021-07-12 10:38:44,138 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2021-07-12 10:38:44,140 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm2.org_1   | 2021-07-12 10:38:44,172 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2021-07-12 10:38:44,175 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2c226db0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2021-07-12 10:38:44,176 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1911427a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2021-07-12 10:38:44,405 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2021-07-12 10:38:44,434 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@8551ee6{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-9442920958478685751/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2021-07-12 10:38:44,467 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@650ee893{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2021-07-12 10:38:44,467 [Listener at 0.0.0.0/9860] INFO server.Server: Started @14139ms
scm2.org_1   | 2021-07-12 10:38:44,469 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2021-07-12 10:38:44,475 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2021-07-12 10:38:44,476 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2021-07-12 10:38:47,251 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:01,613 [grpc-default-executor-0] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: set configuration 11: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-07-12 10:39:01,674 [grpc-default-executor-0] INFO server.RaftServer$Division: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611: set configuration 13: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-07-12 10:39:17,397 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:23,543 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:25,881 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:26,354 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:27,244 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:28,477 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:29,741 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:46,936 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43906
scm3.org_1   | 2021-07-12 10:39:11,119 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@13c147f8{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-13278383769287921801/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2021-07-12 10:39:11,185 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@58179860{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2021-07-12 10:39:11,195 [Listener at 0.0.0.0/9860] INFO server.Server: Started @23543ms
scm3.org_1   | 2021-07-12 10:39:11,206 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2021-07-12 10:39:11,210 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2021-07-12 10:39:11,215 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2021-07-12 10:39:17,398 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:23,576 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:25,862 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:26,356 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-07-12 10:46:31,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:31,523 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:31,524 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:60992
scm3.org_1   | 2021-07-12 10:39:27,213 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:28,462 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:29,732 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:46,876 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54616
datanode2_1  | 2021-07-12 10:56:11,326 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:17,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:20,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
scm2.org_1   | 2021-07-12 10:39:47,006 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:39:46,959 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:38:15,460 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:38:15,464 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
scm2.org_1   | 2021-07-12 10:39:50,499 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52224
scm2.org_1   | 2021-07-12 10:39:50,570 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:39:50,962 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1ab7aeaf-7670-4a86-9686-feb8bb11c16a
om1_1        | 2021-07-12 10:46:57,441 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:57,442 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34536
scm3.org_1   | 2021-07-12 10:39:47,240 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$402/0x0000000840501840@1eda12b3] WARN util.JvmPauseMonitor: JvmPauseMonitor-235f349a-aabc-4dff-b4dd-941abcfde3d9: Detected pause in JVM or host machine (eg GC): pause of approximately 169642535ns.
scm1.org_1   | 2021-07-12 10:38:15,492 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2021-07-12 10:38:15,500 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2021-07-12 10:38:15,501 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 2530584589045 on primary SCM
om3_1        | 2021-07-12 10:46:31,524 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:34,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41388
datanode2_1  | 2021-07-12 10:56:23,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:26,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:29,751 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
scm2.org_1   | 2021-07-12 10:39:50,995 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2612531528108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-07-12 10:39:51,054 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1        | 2021-07-12 10:46:57,450 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:15,509 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2021-07-12 10:38:15,540 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-07-12 10:38:15,573 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2021-07-12 10:38:16,371 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-07-12 10:38:16,372 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2021-07-12 10:39:51,110 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om3_1        | 2021-07-12 10:46:34,597 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:16,392 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | ]
om2_1        | 2021-07-12 10:46:58,493 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3
om1_1        | 2021-07-12 10:46:57,484 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-13754/69181/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2021-07-12 10:46:57,485 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 69181/multipartKey2 in Volume/Bucket s3v/bucket-13754
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 69181/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:463)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
datanode2_1  | 2021-07-12 10:56:32,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:35,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:38,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:39,729 [Thread-822] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-71ADBFF1C185->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=216, seq=0, Watch-ALL_COMMITTED(148), Message:<EMPTY>, reply=RaftClientReply:client-71ADBFF1C185->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6@group-8025B34C7403, cid=216, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 216 and log index 148 is not yet replicated to ALL_COMMITTED, logIndex=148, commits[dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6:c157, 5244f159-1b5c-4bd3-a569-521c9d7b4032:c157, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a:c127]
datanode2_1  | 2021-07-12 10:56:42,058 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 2021-07-12 10:46:36,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:36,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32786
scm2.org_1   | 2021-07-12 10:39:51,788 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5, Nodes: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:51.311Z[UTC]].
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-07-12 10:38:16,395 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2021-07-12 10:38:16,416 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=218ms
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
datanode2_1  | 2021-07-12 10:56:45,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:48,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
datanode2_1  | 2021-07-12 10:56:51,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:56:54,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-07-12 10:38:16,417 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2021-07-12 10:38:16,512 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        true
scm1.org_1   | Container Balancer Configuration values:
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 2021-07-12 10:46:36,669 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:37,134 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:37,134 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32804
om3_1        | 2021-07-12 10:46:37,137 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:37,599 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:37,599 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32812
om3_1        | 2021-07-12 10:46:37,601 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:38,199 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 2021-07-12 10:46:38,199 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32820
om3_1        | 2021-07-12 10:46:38,203 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-07-12 10:56:57,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-07-12 10:57:00,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
scm3.org_1   | 2021-07-12 10:39:50,509 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38420
scm3.org_1   | 2021-07-12 10:39:50,575 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:46:41,590 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:41,590 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32840
om3_1        | 2021-07-12 10:46:41,594 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:44,852 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:57,922 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-07-12 10:39:50,818 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1ab7aeaf-7670-4a86-9686-feb8bb11c16a
scm3.org_1   | 2021-07-12 10:39:50,821 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2612531528108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om1_1        | 2021-07-12 10:46:57,954 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34546
om1_1        | 2021-07-12 10:46:57,957 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:44,852 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32864
om3_1        | 2021-07-12 10:46:44,853 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:39:50,917 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-07-12 10:39:50,920 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2021-07-12 10:39:51,877 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5, Nodes: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:51.311Z[UTC]].
scm1.org_1   | Key                            Value
scm1.org_1   | Threshold                      0.1
om1_1        | 2021-07-12 10:46:58,445 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:39:51,901 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:46:58,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34556
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | Max Datanodes to Balance       5
scm1.org_1   | Max Size to Move               10737418240B
scm1.org_1   | 
scm1.org_1   | 2021-07-12 10:38:16,519 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om3_1        | 2021-07-12 10:46:45,405 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:45,406 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32874
scm3.org_1   | 2021-07-12 10:39:52,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38662
scm3.org_1   | 2021-07-12 10:39:52,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:39:52,593 [IPC Server handler 46 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
om2_1        | 2021-07-12 10:46:58,896 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:39:51,797 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:52,004 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34570
scm2.org_1   | 2021-07-12 10:39:52,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:39:52,593 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
scm2.org_1   | 2021-07-12 10:39:52,594 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2615449502355, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om2_1        | 2021-07-12 10:46:58,897 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39128
om2_1        | 2021-07-12 10:46:58,897 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:46:58,924 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-13754/49112/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om3_1        | 2021-07-12 10:46:45,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:48,748 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:48,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32890
om3_1        | 2021-07-12 10:46:48,750 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:51,828 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:46:58,450 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm3.org_1   | 2021-07-12 10:39:52,599 [IPC Server handler 46 on default port 9861] INFO node.SCMNodeManager: Registered Data node : dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2615449502355, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-07-12 10:39:52,599 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
om2_1        | partName: "etag2"
om2_1        | ]
om3_1        | 2021-07-12 10:46:51,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32914
om3_1        | 2021-07-12 10:46:51,829 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:58,486 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-13754/49112/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-07-12 10:39:52,603 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2021-07-12 10:39:52,838 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c72a7bef-074b-455f-a2d4-05a9f269f8e5, Nodes: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:52.764Z[UTC]].
scm3.org_1   | 2021-07-12 10:39:52,839 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:53,967 [IPC Server handler 16 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5244f159-1b5c-4bd3-a569-521c9d7b4032
scm2.org_1   | 2021-07-12 10:39:52,595 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-07-12 10:39:52,596 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2021-07-12 10:39:52,804 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c72a7bef-074b-455f-a2d4-05a9f269f8e5, Nodes: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:52.764Z[UTC]].
scm2.org_1   | 2021-07-12 10:39:52,804 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-07-12 10:46:58,927 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
scm2.org_1   | 2021-07-12 10:39:53,969 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5244f159-1b5c-4bd3-a569-521c9d7b4032
scm2.org_1   | 2021-07-12 10:39:53,970 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2614971215607, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-07-12 10:38:16,519 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-07-12 10:39:53,970 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
scm1.org_1   | 2021-07-12 10:38:16,522 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
s3g_1        | 2021-07-12 10:45:54,178 [qtp1363396194-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C5740C05F608->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:45:54,179 [qtp1363396194-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-07-12 10:39:53,973 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
om1_1        | partName: "etag2"
scm3.org_1   | 2021-07-12 10:39:53,972 [IPC Server handler 16 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2614971215607, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-07-12 10:39:53,972 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-07-12 10:39:53,986 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2021-07-12 10:39:53,986 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2021-07-12 10:39:53,986 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2021-07-12 10:38:16,526 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
om3_1        | 2021-07-12 10:46:52,291 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:52,292 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32924
om3_1        | 2021-07-12 10:46:52,292 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
scm1.org_1   | 2021-07-12 10:38:16,539 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: start as a follower, conf=0: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om1_1        | ]
om1_1        | 2021-07-12 10:46:58,486 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
scm3.org_1   | 2021-07-12 10:39:53,986 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-07-12 10:39:53,973 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2021-07-12 10:39:53,973 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2021-07-12 10:39:53,973 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-07-12 10:38:16,540 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm3.org_1   | 2021-07-12 10:39:54,006 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2021-07-12 10:39:54,009 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-07-12 10:39:54,089 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 269136cc-c909-477b-8eee-dfb2e619c9e2, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:53.997Z[UTC]].
s3g_1        | 2021-07-12 10:45:54,237 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-9F1768E0CA6F->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:45:54,245 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:45:57,036 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 2021-07-12 10:46:53,185 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:53,186 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32956
om3_1        | 2021-07-12 10:46:53,187 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
scm1.org_1   | 2021-07-12 10:38:16,542 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: start 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState
scm1.org_1   | 2021-07-12 10:38:16,564 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B39E69E4A611,id=834b4eb7-146a-4c2a-bac6-4409b0eef822
om3_1        | 2021-07-12 10:46:53,698 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
scm1.org_1   | 2021-07-12 10:38:16,565 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 2021-07-12 10:46:53,699 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32964
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
scm1.org_1   | 2021-07-12 10:38:16,566 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:46:53,699 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
om2_1        | 2021-07-12 10:46:59,394 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:46:58,892 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:39:54,089 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:54,144 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]].
scm3.org_1   | 2021-07-12 10:39:54,151 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om2_1        | 2021-07-12 10:46:59,395 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39136
om1_1        | 2021-07-12 10:46:58,893 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34564
om1_1        | 2021-07-12 10:46:58,894 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:46:58,924 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-13754/49112/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
scm2.org_1   | 2021-07-12 10:39:53,987 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2021-07-12 10:39:53,999 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om2_1        | 2021-07-12 10:46:59,398 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:00,275 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:38:16,573 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 834b4eb7-146a-4c2a-bac6-4409b0eef822: start RPC server
scm1.org_1   | 2021-07-12 10:38:16,653 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 834b4eb7-146a-4c2a-bac6-4409b0eef822: GrpcService started, listening on 9894
scm1.org_1   | 2021-07-12 10:38:16,660 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-07-12 10:38:16,661 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2021-07-12 10:38:16,661 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$421/0x0000000840523040@4246f904] INFO util.JvmPauseMonitor: JvmPauseMonitor-834b4eb7-146a-4c2a-bac6-4409b0eef822: Started
scm1.org_1   | 2021-07-12 10:38:16,662 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
om2_1        | 2021-07-12 10:47:00,276 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39148
om2_1        | 2021-07-12 10:47:00,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:54,330 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm3.org_1   | 2021-07-12 10:39:54,208 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: Rolling segment log-1_36 to index:36
scm3.org_1   | 2021-07-12 10:39:54,212 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_1 to /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_1-36
scm3.org_1   | 2021-07-12 10:39:54,234 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_37
scm3.org_1   | 2021-07-12 10:39:54,279 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fc4a04e1-b6f2-444a-9fba-bf278aba4990, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:54.134Z[UTC]].
scm2.org_1   | 2021-07-12 10:39:54,049 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 269136cc-c909-477b-8eee-dfb2e619c9e2, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:53.997Z[UTC]].
scm2.org_1   | 2021-07-12 10:39:54,061 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:38:16,662 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2021-07-12 10:38:16,748 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2021-07-12 10:46:54,330 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:32976
om3_1        | 2021-07-12 10:46:54,331 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm3.org_1   | 2021-07-12 10:39:54,279 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:55,717 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: c72a7bef-074b-455f-a2d4-05a9f269f8e5, Nodes: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:52.764Z[UTC]] moved to OPEN state
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om2_1        | 2021-07-12 10:47:03,485 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:38:16,761 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2021-07-12 10:38:16,761 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
om3_1        | 2021-07-12 10:46:57,457 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:57,458 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33000
om3_1        | 2021-07-12 10:46:57,458 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:57,478 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-13754/69181/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
scm2.org_1   | 2021-07-12 10:39:54,128 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]].
scm2.org_1   | 2021-07-12 10:39:54,128 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om3_1        | 2021-07-12 10:46:57,482 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 69181/multipartKey2 in Volume/Bucket s3v/bucket-13754
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 69181/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:463)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 2021-07-12 10:47:03,486 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39172
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om1_1        | ]
om1_1        | 2021-07-12 10:46:58,931 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
scm2.org_1   | 2021-07-12 10:39:54,201 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: Rolling segment log-1_36 to index:36
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2021-07-12 10:39:55,830 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@7f707c40, cost 111483.632us
scm1.org_1   | 2021-07-12 10:38:17,025 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2021-07-12 10:38:17,031 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-07-12 10:38:17,039 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2021-07-12 10:39:54,203 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_1 to /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_1-36
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 2021-07-12 10:45:57,093 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
scm2.org_1   | 2021-07-12 10:39:54,205 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_37
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:46:57,982 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3
scm1.org_1   | 2021-07-12 10:38:17,067 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2021-07-12 10:38:17,068 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2021-07-12 10:38:17,073 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-07-12 10:39:54,241 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fc4a04e1-b6f2-444a-9fba-bf278aba4990, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:54.134Z[UTC]].
om3_1        | 2021-07-12 10:46:57,983 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33010
om2_1        | 2021-07-12 10:47:03,487 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:06,590 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
scm1.org_1   | 2021-07-12 10:38:17,074 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
om2_1        | 2021-07-12 10:47:06,590 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39188
scm2.org_1   | 2021-07-12 10:39:54,241 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:55,723 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: c72a7bef-074b-455f-a2d4-05a9f269f8e5, Nodes: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:52.764Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-07-12 10:38:17,101 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm1.org_1   | 2021-07-12 10:38:17,101 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2021-07-12 10:38:17,102 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-07-12 10:47:06,597 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:06,626 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-13754/49112/multipartKey3106567225797509153
scm2.org_1   | 2021-07-12 10:39:55,833 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76fddaa, cost 108233.235us
scm2.org_1   | 2021-07-12 10:39:55,983 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:39:56,016 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
scm3.org_1   | 2021-07-12 10:39:56,831 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-07-12 10:39:57,553 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 2021-07-12 10:38:17,108 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2021-07-12 10:39:56,854 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-07-12 10:39:57,518 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 269136cc-c909-477b-8eee-dfb2e619c9e2, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:5244f159-1b5c-4bd3-a569-521c9d7b4032, CreationTimestamp2021-07-12T10:39:53.997Z[UTC]] moved to OPEN state
om3_1        | 2021-07-12 10:46:57,988 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:58,458 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:58,459 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33020
om3_1        | 2021-07-12 10:46:58,464 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:58,481 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-13754/49112/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
scm3.org_1   | 2021-07-12 10:39:57,595 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-07-12 10:39:58,454 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-07-12 10:40:01,853 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
scm3.org_1   | 2021-07-12 10:40:01,879 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-07-12 10:38:17,124 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2021-07-12 10:38:17,213 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d4aadc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2021-07-12 10:38:17,214 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2021-07-12 10:38:17,214 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | partName: "etag2"
scm3.org_1   | 2021-07-12 10:40:17,241 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:40:22,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54812
scm3.org_1   | 2021-07-12 10:40:22,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | ]
scm2.org_1   | 2021-07-12 10:39:57,519 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76fddaa, cost 784.923us
scm3.org_1   | 2021-07-12 10:40:23,440 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5, Nodes: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1ab7aeaf-7670-4a86-9686-feb8bb11c16a, CreationTimestamp2021-07-12T10:39:51.311Z[UTC]] moved to OPEN state
scm3.org_1   | 2021-07-12 10:40:23,441 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@7f707c40, cost 780.023us
scm1.org_1   | 2021-07-12 10:38:17,215 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2021-07-12 10:38:17,237 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @6401ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2021-07-12 10:38:17,326 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2021-07-12 10:38:17,331 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2021-07-12 10:38:17,332 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2021-07-12 10:39:57,566 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:39:58,458 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-07-12 10:38:17,332 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2021-07-12 10:38:17,332 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2021-07-12 10:38:17,334 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2021-07-12 10:40:23,540 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:40:23,862 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-07-12 10:40:24,477 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
om3_1        | 2021-07-12 10:46:58,481 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om1_1        | 2021-07-12 10:46:59,390 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:07,054 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:07,055 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39198
scm2.org_1   | 2021-07-12 10:40:01,987 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-07-12 10:40:01,987 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-07-12 10:40:17,229 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:40:22,377 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44096
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3
om1_1        | 2021-07-12 10:46:59,391 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34572
om1_1        | 2021-07-12 10:46:59,392 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om2_1        | 2021-07-12 10:47:07,059 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om1_1        | 2021-07-12 10:47:00,271 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:07,107 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-13754/49112/multipartKey3106567225854722082
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
scm3.org_1   | 2021-07-12 10:40:24,510 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38618
scm3.org_1   | 2021-07-12 10:40:24,527 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om1_1        | 2021-07-12 10:47:00,271 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34584
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
scm1.org_1   | 2021-07-12 10:38:17,364 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2021-07-12 10:40:24,529 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:00,273 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:57,100 [qtp1363396194-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-teummrlhfv, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:45:57,113 [qtp1363396194-17] INFO endpoint.BucketEndpoint: Location is /bucket-teummrlhfv
scm2.org_1   | 2021-07-12 10:40:22,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
scm1.org_1   | 2021-07-12 10:38:17,365 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
scm3.org_1   | 2021-07-12 10:40:24,537 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-07-12 10:40:24,538 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2021-07-12 10:40:24,538 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2021-07-12 10:40:24,538 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2021-07-12 10:40:23,448 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5, Nodes: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1ab7aeaf-7670-4a86-9686-feb8bb11c16a, CreationTimestamp2021-07-12T10:39:51.311Z[UTC]] moved to OPEN state
scm2.org_1   | 2021-07-12 10:40:23,449 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76fddaa, cost 692.52us
scm2.org_1   | 2021-07-12 10:40:23,493 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:40:23,869 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 2021-07-12 10:40:24,459 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:40:24,535 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-07-12 10:40:24,556 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52420
s3g_1        | 2021-07-12 10:45:57,144 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om1_1        | 2021-07-12 10:47:03,480 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
scm1.org_1   | 2021-07-12 10:38:17,392 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2021-07-12 10:38:17,392 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2021-07-12 10:38:17,393 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2021-07-12 10:47:03,480 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34608
om1_1        | 2021-07-12 10:47:03,483 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:06,586 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:06,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34624
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-07-12 10:40:24,538 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-07-12 10:38:17,408 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-07-12 10:40:24,538 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-07-12 10:40:24,538 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2021-07-12 10:40:24,558 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:40:24,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-07-12 10:40:24,564 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2021-07-12 10:40:24,564 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
om1_1        | 2021-07-12 10:47:06,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:58,900 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:58,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33028
scm1.org_1   | 2021-07-12 10:38:17,414 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3d41449a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2021-07-12 10:38:17,415 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44a972b4{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2021-07-12 10:38:17,488 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:47:07,512 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:07,512 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39214
om2_1        | 2021-07-12 10:47:07,513 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:17,498 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@38503309{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-17845812826191269018/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2021-07-12 10:38:17,505 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@6ad2cb6d{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2021-07-12 10:38:17,506 [Listener at 0.0.0.0/9860] INFO server.Server: Started @6670ms
scm1.org_1   | 2021-07-12 10:38:17,507 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2021-07-12 10:38:17,507 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2021-07-12 10:40:25,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38858
scm3.org_1   | 2021-07-12 10:40:25,981 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om1_1        | 2021-07-12 10:47:06,631 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
scm3.org_1   | 2021-07-12 10:40:25,982 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: fc4a04e1-b6f2-444a-9fba-bf278aba4990, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:5244f159-1b5c-4bd3-a569-521c9d7b4032, CreationTimestamp2021-07-12T10:39:54.134Z[UTC]] moved to OPEN state
scm3.org_1   | 2021-07-12 10:40:25,984 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@7f707c40, cost 1479.444us
scm3.org_1   | 2021-07-12 10:40:37,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38918
scm2.org_1   | 2021-07-12 10:40:24,564 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2021-07-12 10:40:24,565 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-13754/49112/multipartKey3106567225797509153
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2021-07-12 10:47:07,533 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-13754/49112/multipartKey3
om2_1        | 2021-07-12 10:47:07,538 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:411)
scm2.org_1   | 2021-07-12 10:40:24,565 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om3_1        | 2021-07-12 10:46:58,903 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:46:58,919 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-13754/49112/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
scm2.org_1   | 2021-07-12 10:40:24,565 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2021-07-12 10:40:37,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:40:40,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38708
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
scm1.org_1   | 2021-07-12 10:38:17,509 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2021-07-12 10:38:19,658 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41260
scm2.org_1   | 2021-07-12 10:40:26,029 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34772
scm3.org_1   | 2021-07-12 10:40:40,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | partName: "etag2"
om3_1        | ]
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
scm3.org_1   | 2021-07-12 10:40:47,356 [235f349a-aabc-4dff-b4dd-941abcfde3d9@group-B39E69E4A611-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm3.org_1   | 2021-07-12 10:40:50,813 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38990
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 2021-07-12 10:46:58,919 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-07-12 10:40:50,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:40:52,422 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54990
scm3.org_1   | 2021-07-12 10:40:52,431 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
scm1.org_1   | 2021-07-12 10:38:19,686 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:38:20,761 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38618
scm1.org_1   | 2021-07-12 10:38:20,773 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:38:21,598 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO impl.FollowerState: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5056495072ns, electionTimeout:5031ms
scm1.org_1   | 2021-07-12 10:38:21,599 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: shutdown 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState
scm1.org_1   | 2021-07-12 10:38:21,600 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
scm2.org_1   | 2021-07-12 10:40:26,045 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2021-07-12 10:38:21,602 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2021-07-12 10:38:21,602 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-FollowerState] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: start 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1
scm3.org_1   | 2021-07-12 10:41:20,530 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55166
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:47:07,047 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:40:37,240 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34832
scm2.org_1   | 2021-07-12 10:40:37,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:40:40,828 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52504
scm2.org_1   | 2021-07-12 10:40:40,841 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:38:21,614 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO impl.LeaderElection: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-07-12 10:41:20,545 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:41:20,792 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39182
scm3.org_1   | 2021-07-12 10:41:20,818 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 2021-07-12 10:47:07,047 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34634
om1_1        | 2021-07-12 10:47:07,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:07,105 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-13754/49112/multipartKey3106567225854722082
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:57,202 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-07-12 10:38:21,614 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO impl.LeaderElection: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm3.org_1   | 2021-07-12 10:41:20,837 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38966
scm3.org_1   | 2021-07-12 10:41:20,881 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:41:50,489 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55336
scm3.org_1   | 2021-07-12 10:41:50,507 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:41:50,820 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39136
scm2.org_1   | 2021-07-12 10:40:47,331 [1c300e12-e25b-4eac-b361-75629ac63c82@group-B39E69E4A611-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm2.org_1   | 2021-07-12 10:40:50,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34906
scm2.org_1   | 2021-07-12 10:40:50,927 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:40:52,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44278
scm2.org_1   | 2021-07-12 10:40:52,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:46:59,409 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:46:59,410 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33036
scm1.org_1   | 2021-07-12 10:38:21,615 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: shutdown 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1
scm1.org_1   | 2021-07-12 10:38:21,615 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2021-07-12 10:38:21,615 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2021-07-12 10:38:21,615 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2021-07-12 10:38:21,617 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: change Leader from null to 834b4eb7-146a-4c2a-bac6-4409b0eef822 at term 2 for becomeLeader, leader elected after 6784ms
om3_1        | 2021-07-12 10:46:59,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:00,286 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:47:07,951 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:07,952 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39224
scm2.org_1   | 2021-07-12 10:41:20,530 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44450
scm2.org_1   | 2021-07-12 10:41:20,535 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:41:20,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35098
scm2.org_1   | 2021-07-12 10:41:20,815 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:41:20,835 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52766
scm2.org_1   | 2021-07-12 10:41:20,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
scm3.org_1   | 2021-07-12 10:41:50,826 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39354
scm3.org_1   | 2021-07-12 10:41:50,834 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:41:50,850 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:42:22,419 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39548
scm2.org_1   | 2021-07-12 10:41:50,490 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44624
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2021-07-12 10:38:21,622 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2021-07-12 10:38:21,624 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
scm1.org_1   | 2021-07-12 10:38:21,624 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2021-07-12 10:47:07,953 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:08,402 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:08,402 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39232
om2_1        | 2021-07-12 10:47:08,407 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:09,177 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:09,177 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39250
om2_1        | 2021-07-12 10:47:09,179 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:00,286 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33048
om3_1        | 2021-07-12 10:47:00,287 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:03,490 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:42:22,429 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55528
scm3.org_1   | 2021-07-12 10:42:22,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:42:22,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:42:22,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39326
scm3.org_1   | 2021-07-12 10:42:22,515 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:42:52,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39734
scm1.org_1   | 2021-07-12 10:38:21,654 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-07-12 10:38:21,655 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2021-07-12 10:41:50,519 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:38:21,659 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om3_1        | 2021-07-12 10:47:03,490 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33072
om3_1        | 2021-07-12 10:47:03,491 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:06,601 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:06,601 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33088
om2_1        | 2021-07-12 10:47:09,663 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:09,663 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39258
om2_1        | 2021-07-12 10:47:09,664 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:10,140 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-07-12 10:42:52,402 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55714
scm3.org_1   | 2021-07-12 10:42:52,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39512
scm1.org_1   | 2021-07-12 10:38:21,659 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2021-07-12 10:38:21,660 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2021-07-12 10:38:21,665 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO impl.RoleInfo: 834b4eb7-146a-4c2a-bac6-4409b0eef822: start 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl
scm1.org_1   | 2021-07-12 10:38:21,670 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2021-07-12 10:38:21,674 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_0 to /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_0-0
scm1.org_1   | 2021-07-12 10:38:21,680 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_1
scm1.org_1   | 2021-07-12 10:38:21,681 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderElection1] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: set configuration 1: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-07-12 10:38:21,685 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2021-07-12 10:38:21,686 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 2021-07-12 10:47:06,607 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:06,623 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-13754/49112/multipartKey3106567225797509153
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:47:07,508 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:07,508 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34650
om1_1        | 2021-07-12 10:47:07,509 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:07,534 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-13754/49112/multipartKey3
om1_1        | 2021-07-12 10:47:07,541 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3 because parts are in Invalid order.
scm2.org_1   | 2021-07-12 10:41:50,786 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35268
scm2.org_1   | 2021-07-12 10:41:50,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:41:50,846 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52932
scm2.org_1   | 2021-07-12 10:41:50,880 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:10,140 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39276
om2_1        | 2021-07-12 10:47:10,142 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:10,174 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 28327/multipartKey5 in VolumeName/Bucket s3v/bucket-13754
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-13754key: 28327/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
scm3.org_1   | 2021-07-12 10:42:52,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:42:52,454 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:42:52,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:43:22,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55908
scm3.org_1   | 2021-07-12 10:43:22,419 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39912
scm3.org_1   | 2021-07-12 10:43:22,436 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39702
s3g_1        | 2021-07-12 10:45:57,257 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2021-07-12 10:42:22,389 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44816
scm2.org_1   | 2021-07-12 10:42:22,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35458
scm2.org_1   | 2021-07-12 10:42:22,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53126
scm2.org_1   | 2021-07-12 10:42:22,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:42:22,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:42:22,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:42:52,449 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53314
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
scm1.org_1   | 2021-07-12 10:38:21,687 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:38:21,687 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2021-07-12 10:38:21,688 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2021-07-12 10:38:21,688 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2021-07-12 10:38:21,699 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:411)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 2021-07-12 10:43:22,443 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:43:22,451 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:42:52,452 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35644
scm2.org_1   | 2021-07-12 10:42:52,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:38:21,734 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-07-12 10:38:28,445 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:47150
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm3.org_1   | 2021-07-12 10:43:22,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:43:52,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40104
scm3.org_1   | 2021-07-12 10:43:52,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56086
scm3.org_1   | 2021-07-12 10:43:52,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:43:52,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
scm1.org_1   | 2021-07-12 10:38:28,454 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:38:28,540 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 1c300e12-e25b-4eac-b361-75629ac63c82
scm1.org_1   | 2021-07-12 10:38:28,782 [IPC Server handler 0 on default port 9961] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C6065BCDBC19->834b4eb7-146a-4c2a-bac6-4409b0eef822
om3_1        | 2021-07-12 10:47:07,062 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-07-12 10:42:52,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45002
scm2.org_1   | 2021-07-12 10:42:52,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:42:52,505 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:43:22,443 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45192
scm2.org_1   | 2021-07-12 10:43:22,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35826
scm2.org_1   | 2021-07-12 10:43:22,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:43:22,468 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53502
scm2.org_1   | 2021-07-12 10:43:22,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:07,062 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33098
scm3.org_1   | 2021-07-12 10:43:52,506 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39884
scm3.org_1   | 2021-07-12 10:43:52,553 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:10,590 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:10,590 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39284
om2_1        | 2021-07-12 10:47:10,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:10,610 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-13754, Key67372/multipartKey. Exception:{}
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 2021-07-12 10:38:28,782 [IPC Server handler 0 on default port 9961] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:29,791 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.834b4eb7-146a-4c2a-bac6-4409b0eef822
scm1.org_1   | 2021-07-12 10:38:29,791 [grpc-default-executor-0] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:29,885 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-07-12 10:43:22,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-07-12 10:38:29,885 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2021-07-12 10:38:29,886 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-07-12 10:43:54,386 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm3.org_1   | 2021-07-12 10:44:22,387 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40292
scm3.org_1   | 2021-07-12 10:44:22,431 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:44:22,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56292
scm3.org_1   | 2021-07-12 10:44:22,458 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40072
scm3.org_1   | 2021-07-12 10:44:22,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:44:22,492 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:44:52,408 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40480
scm3.org_1   | 2021-07-12 10:44:52,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56464
scm3.org_1   | 2021-07-12 10:44:52,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:38:29,896 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 1238434.936us
scm3.org_1   | 2021-07-12 10:44:52,483 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40266
scm3.org_1   | 2021-07-12 10:44:52,493 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:44:52,496 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:45:22,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40770
om3_1        | 2021-07-12 10:47:07,063 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:07,092 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-13754/49112/multipartKey3106567225854722082
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2021-07-12 10:38:34,800 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41514
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 2021-07-12 10:47:07,946 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:07,946 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34660
om1_1        | 2021-07-12 10:47:07,949 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:08,393 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:08,393 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34668
om1_1        | 2021-07-12 10:47:08,399 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:57,326 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
scm2.org_1   | 2021-07-12 10:43:36,861 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2021-07-12 10:43:52,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36014
scm1.org_1   | 2021-07-12 10:38:34,826 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:38:38,673 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38910
om1_1        | 2021-07-12 10:47:09,168 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:09,171 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34686
om1_1        | 2021-07-12 10:47:09,174 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
scm1.org_1   | 2021-07-12 10:38:38,771 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-07-12 10:43:52,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45370
scm1.org_1   | 2021-07-12 10:38:38,773 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: 834b4eb7-146a-4c2a-bac6-4409b0eef822: Submitting SetConfiguration request to Ratis server with new SCM peers list: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0]
scm2.org_1   | 2021-07-12 10:43:52,463 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53684
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:45:57,364 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-D2E1E950256F->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:45:57,365 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:45:59,978 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-07-12 10:38:38,780 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: receive setConfiguration SetConfigurationRequest:client-FE012A9CA6AF->834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611, cid=0, seq=0, RW, null, peers:[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0]
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:47:09,655 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:09,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34694
om1_1        | 2021-07-12 10:47:09,660 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:47:11,042 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:45:22,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56752
scm3.org_1   | 2021-07-12 10:45:22,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40552
scm1.org_1   | 2021-07-12 10:38:38,783 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-FE012A9CA6AF->834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611, cid=0, seq=0, RW, null, peers:[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0]
scm2.org_1   | 2021-07-12 10:43:52,483 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:43:52,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:11,043 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39294
om2_1        | 2021-07-12 10:47:11,048 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:11,625 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:07,516 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:07,516 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33114
scm1.org_1   | 2021-07-12 10:38:38,805 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2021-07-12 10:38:38,808 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-07-12 10:47:10,136 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:45:22,450 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:45:22,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:11,626 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39302
om3_1        | 2021-07-12 10:47:07,517 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:07,530 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-13754/49112/multipartKey3
om3_1        | 2021-07-12 10:47:07,531 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 49112/multipartKey3 in Volume/Bucket s3v/bucket-13754
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:411)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 2021-07-12 10:47:11,628 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-07-12 10:47:12,421 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:12,422 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39314
scm2.org_1   | 2021-07-12 10:43:52,552 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:44:22,380 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36202
scm2.org_1   | 2021-07-12 10:44:22,397 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:44:22,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45576
scm3.org_1   | 2021-07-12 10:45:22,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:45:52,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40816
scm3.org_1   | 2021-07-12 10:45:52,463 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57012
om1_1        | 2021-07-12 10:47:10,136 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34712
om1_1        | 2021-07-12 10:47:10,137 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:10,170 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 28327/multipartKey5 in VolumeName/Bucket s3v/bucket-13754
scm3.org_1   | 2021-07-12 10:45:52,479 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41032
om3_1        | 2021-07-12 10:47:07,956 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:07,956 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33124
om3_1        | 2021-07-12 10:47:07,957 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-13754key: 28327/multipartKey5
scm2.org_1   | 2021-07-12 10:44:22,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:44:22,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53868
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
om2_1        | 2021-07-12 10:47:12,423 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:15,535 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:15,536 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39338
om2_1        | 2021-07-12 10:47:15,537 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:08,409 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:08,409 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33132
om3_1        | 2021-07-12 10:47:08,410 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:09,182 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
scm1.org_1   | 2021-07-12 10:38:38,809 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 33554432 (custom)
scm2.org_1   | 2021-07-12 10:44:22,492 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:44:52,392 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36390
om3_1        | 2021-07-12 10:47:09,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33150
om3_1        | 2021-07-12 10:47:09,183 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
scm1.org_1   | 2021-07-12 10:38:39,495 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm2.org_1   | 2021-07-12 10:44:52,401 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:44:52,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54062
om3_1        | 2021-07-12 10:47:09,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:45:52,491 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:45:52,496 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:45:52,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:46:22,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41370
scm3.org_1   | 2021-07-12 10:46:22,412 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:46:22,425 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41158
scm1.org_1   | 2021-07-12 10:38:39,511 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-07-12 10:38:39,512 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2021-07-12 10:46:22,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57368
scm3.org_1   | 2021-07-12 10:46:22,443 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:46:22,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:38:39,513 [IPC Server handler 0 on default port 9863] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2021-07-12 10:46:52,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57632
scm3.org_1   | 2021-07-12 10:46:52,460 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41654
scm3.org_1   | 2021-07-12 10:46:52,491 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41436
scm1.org_1   | 2021-07-12 10:38:39,517 [IPC Server handler 0 on default port 9863] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:40,945 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: set configuration 5: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0], old=[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
om3_1        | 2021-07-12 10:47:09,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33158
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2021-07-12 10:44:52,436 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45760
scm2.org_1   | 2021-07-12 10:44:52,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:44:52,461 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:16,049 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:16,049 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39348
om3_1        | 2021-07-12 10:47:09,675 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:41,125 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: set configuration 7: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0], old=null
scm2.org_1   | 2021-07-12 10:45:22,419 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46040
om3_1        | 2021-07-12 10:47:10,145 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:45:22,472 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36684
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:47:10,586 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:10,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34720
om1_1        | 2021-07-12 10:47:10,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:38:41,297 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 1c300e12-e25b-4eac-b361-75629ac63c82.
scm3.org_1   | 2021-07-12 10:46:52,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:16,050 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:16,533 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:16,533 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39356
om2_1        | 2021-07-12 10:47:16,537 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:16,999 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:17,000 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39366
om2_1        | 2021-07-12 10:47:17,000 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:17,649 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-07-12 10:47:10,146 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33176
om3_1        | 2021-07-12 10:47:10,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:10,169 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 28327/multipartKey5 in VolumeName/Bucket s3v/bucket-13754
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-13754key: 28327/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:47:10,594 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:10,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33184
om3_1        | 2021-07-12 10:47:10,595 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:10,608 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-13754, Key67372/multipartKey. Exception:{}
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-07-12 10:47:11,057 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:11,057 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33194
om3_1        | 2021-07-12 10:47:11,058 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:11,631 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:11,631 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33202
om3_1        | 2021-07-12 10:47:11,632 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:12,426 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:12,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33214
om3_1        | 2021-07-12 10:47:12,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:15,541 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:15,542 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33238
om3_1        | 2021-07-12 10:47:15,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:16,052 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:16,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33248
om3_1        | 2021-07-12 10:47:16,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:16,541 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:16,541 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33256
om3_1        | 2021-07-12 10:47:16,542 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:17,003 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:17,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33266
om3_1        | 2021-07-12 10:47:17,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:17,653 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:17,653 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33274
om3_1        | 2021-07-12 10:47:17,653 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:17,760 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:46:52,514 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:46:52,516 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:47:22,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42052
scm3.org_1   | 2021-07-12 10:47:22,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58034
scm3.org_1   | 2021-07-12 10:47:22,490 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41836
scm3.org_1   | 2021-07-12 10:47:22,500 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:47:22,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:10,613 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-13754, Key67372/multipartKey. Exception:{}
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om2_1        | 2021-07-12 10:47:17,649 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39374
om3_1        | 2021-07-12 10:47:17,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33280
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm3.org_1   | 2021-07-12 10:47:22,557 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:17,650 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:17,752 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:17,752 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39380
om2_1        | 2021-07-12 10:47:17,753 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:17,834 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:17,834 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39392
om2_1        | 2021-07-12 10:47:17,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:47:52,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58374
scm3.org_1   | 2021-07-12 10:47:52,449 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42380
om2_1        | 2021-07-12 10:47:17,856 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:17,856 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39394
om2_1        | 2021-07-12 10:47:17,860 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:21,931 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:21,932 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39424
om2_1        | 2021-07-12 10:47:21,934 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:22,419 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:22,419 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39452
om2_1        | 2021-07-12 10:47:22,425 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:22,580 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:22,581 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39470
om2_1        | 2021-07-12 10:47:22,584 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:22,584 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39472
scm3.org_1   | 2021-07-12 10:47:52,455 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42170
scm3.org_1   | 2021-07-12 10:47:52,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:47:52,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:22,584 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:22,593 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:22,594 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:22,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39474
om2_1        | 2021-07-12 10:47:22,598 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:23,652 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:23,652 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39494
om2_1        | 2021-07-12 10:47:23,653 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:24,313 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:24,314 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39502
om2_1        | 2021-07-12 10:47:24,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:27,649 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:27,649 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39528
om2_1        | 2021-07-12 10:47:27,650 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:17,761 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:47:52,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:48:22,395 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58748
scm2.org_1   | 2021-07-12 10:45:22,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:45:22,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:45:22,492 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54352
scm2.org_1   | 2021-07-12 10:45:22,516 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:45:52,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46302
scm3.org_1   | 2021-07-12 10:48:22,421 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42764
scm3.org_1   | 2021-07-12 10:48:22,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:17,862 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:17,862 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33294
om3_1        | 2021-07-12 10:47:17,864 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:17,864 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33296
om3_1        | 2021-07-12 10:47:17,868 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:17,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:21,937 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:48:22,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:48:22,511 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42548
om3_1        | 2021-07-12 10:47:21,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33324
om3_1        | 2021-07-12 10:47:21,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:22,433 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:22,433 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33352
om3_1        | 2021-07-12 10:47:22,436 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:22,595 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:48:22,547 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:47:28,170 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:28,170 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39538
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm3.org_1   | 2021-07-12 10:48:52,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58972
scm3.org_1   | 2021-07-12 10:48:52,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42988
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-07-12 10:45:52,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:45:52,475 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36946
scm2.org_1   | 2021-07-12 10:45:52,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:45:52,499 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54612
scm2.org_1   | 2021-07-12 10:45:52,504 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:48:52,479 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42774
scm3.org_1   | 2021-07-12 10:48:52,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-07-12 10:38:42,907 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:42020
scm1.org_1   | 2021-07-12 10:38:42,947 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:38:43,275 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:47374
scm1.org_1   | 2021-07-12 10:38:43,289 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:38:46,481 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41682
scm1.org_1   | 2021-07-12 10:38:46,524 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:38:46,871 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:52848
scm1.org_1   | 2021-07-12 10:38:46,885 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:472)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:291)
scm1.org_1   | 2021-07-12 10:38:46,886 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 235f349a-aabc-4dff-b4dd-941abcfde3d9
scm1.org_1   | 2021-07-12 10:38:46,980 [IPC Server handler 0 on default port 9961] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-56BA74BBA9B5->834b4eb7-146a-4c2a-bac6-4409b0eef822
scm1.org_1   | 2021-07-12 10:38:46,980 [IPC Server handler 0 on default port 9961] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-07-12 10:38:47,239 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:38:47,255 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 294570.782us
scm1.org_1   | 2021-07-12 10:38:55,967 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41820
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-07-12 10:48:52,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:48:52,495 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:46:22,489 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37286
scm2.org_1   | 2021-07-12 10:46:22,490 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46652
scm2.org_1   | 2021-07-12 10:46:22,495 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54960
scm1.org_1   | 2021-07-12 10:38:55,999 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:38:57,570 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:42218
om3_1        | 2021-07-12 10:47:22,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33374
scm3.org_1   | 2021-07-12 10:48:54,387 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm3.org_1   | 2021-07-12 10:49:22,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59100
scm3.org_1   | 2021-07-12 10:49:22,470 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43116
scm3.org_1   | 2021-07-12 10:49:22,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:49:22,487 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42900
scm3.org_1   | 2021-07-12 10:49:22,503 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:49:22,519 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:49:52,463 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43248
scm3.org_1   | 2021-07-12 10:49:52,469 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59230
scm3.org_1   | 2021-07-12 10:49:52,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:49:52,478 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43030
scm3.org_1   | 2021-07-12 10:49:52,504 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:49:52,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:50:22,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43374
scm3.org_1   | 2021-07-12 10:50:22,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59356
scm3.org_1   | 2021-07-12 10:50:22,436 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43154
scm3.org_1   | 2021-07-12 10:50:22,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-07-12 10:47:11,037 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:11,038 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34730
om1_1        | 2021-07-12 10:47:11,039 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:11,614 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:11,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34738
scm3.org_1   | 2021-07-12 10:50:22,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:50:22,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:50:52,452 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43504
scm3.org_1   | 2021-07-12 10:50:52,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43288
scm3.org_1   | 2021-07-12 10:50:52,464 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59486
om2_1        | 2021-07-12 10:47:28,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:31,455 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:31,455 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39556
om2_1        | 2021-07-12 10:47:31,456 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:31,925 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:38:57,808 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:38:57,809 [IPC Server handler 49 on default port 9863] INFO ha.SCMRatisServerImpl: 834b4eb7-146a-4c2a-bac6-4409b0eef822: Submitting SetConfiguration request to Ratis server with new SCM peers list: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2021-07-12 10:38:57,809 [IPC Server handler 49 on default port 9863] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: receive setConfiguration SetConfigurationRequest:client-FE012A9CA6AF->834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611, cid=1, seq=0, RW, null, peers:[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2021-07-12 10:38:57,810 [IPC Server handler 49 on default port 9863] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-FE012A9CA6AF->834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611, cid=1, seq=0, RW, null, peers:[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2021-07-12 10:38:57,810 [IPC Server handler 49 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm2.org_1   | 2021-07-12 10:46:22,520 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:46:22,524 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:46:22,534 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:46:52,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55232
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:00,104 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
scm3.org_1   | 2021-07-12 10:50:52,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:50:52,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:50:52,485 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:11,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:12,417 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:12,418 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34750
om2_1        | 2021-07-12 10:47:31,926 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39574
om2_1        | 2021-07-12 10:47:31,927 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:46:52,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46920
scm2.org_1   | 2021-07-12 10:46:52,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37564
scm2.org_1   | 2021-07-12 10:46:52,501 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:46:52,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:46:52,531 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:38:57,810 [IPC Server handler 49 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
scm3.org_1   | 2021-07-12 10:51:22,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43632
scm3.org_1   | 2021-07-12 10:51:22,432 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43414
om2_1        | 2021-07-12 10:47:32,687 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:32,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39586
om2_1        | 2021-07-12 10:47:32,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:36,033 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:36,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39602
om3_1        | 2021-07-12 10:47:22,600 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:22,601 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33376
om3_1        | 2021-07-12 10:47:22,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:22,605 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:12,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:15,527 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:15,528 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34774
om1_1        | 2021-07-12 10:47:15,533 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:16,041 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:16,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34784
scm1.org_1   | 2021-07-12 10:38:57,810 [IPC Server handler 49 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 33554432 (custom)
scm1.org_1   | 2021-07-12 10:38:58,081 [IPC Server handler 49 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2021-07-12 10:38:58,087 [IPC Server handler 49 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-07-12 10:38:58,088 [IPC Server handler 49 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm3.org_1   | 2021-07-12 10:51:22,456 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:51:22,468 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59616
scm3.org_1   | 2021-07-12 10:51:22,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:51:22,514 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:51:52,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43772
scm2.org_1   | 2021-07-12 10:47:22,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37966
scm2.org_1   | 2021-07-12 10:47:22,458 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47322
scm2.org_1   | 2021-07-12 10:47:22,488 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55638
om3_1        | 2021-07-12 10:47:22,605 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:38:58,935 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$421/0x0000000840523040@4246f904] WARN util.JvmPauseMonitor: JvmPauseMonitor-834b4eb7-146a-4c2a-bac6-4409b0eef822: Detected pause in JVM or host machine (eg GC): pause of approximately 126738869ns.
scm1.org_1   | GC pool 'ParNew' had collection(s): count=1 time=92ms
om2_1        | 2021-07-12 10:47:36,037 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:22,605 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33378
om1_1        | 2021-07-12 10:47:16,046 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:16,529 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om2_1        | 2021-07-12 10:47:36,518 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:36,519 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39610
om2_1        | 2021-07-12 10:47:36,521 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:51:52,434 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:51:52,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43554
scm3.org_1   | 2021-07-12 10:51:52,440 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59754
scm3.org_1   | 2021-07-12 10:51:52,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:51:52,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:47:22,502 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:47:22,506 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:22,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:23,658 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:01,608 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: set configuration 11: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|priority:0], old=[834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2021-07-12 10:39:01,656 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-LeaderStateImpl] INFO server.RaftServer$Division: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611: set configuration 13: [834b4eb7-146a-4c2a-bac6-4409b0eef822|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 1c300e12-e25b-4eac-b361-75629ac63c82|rpc:scm2.org:9894|priority:0, 235f349a-aabc-4dff-b4dd-941abcfde3d9|rpc:scm3.org:9894|priority:0], old=null
scm1.org_1   | 2021-07-12 10:39:01,691 [IPC Server handler 49 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 235f349a-aabc-4dff-b4dd-941abcfde3d9.
scm1.org_1   | 2021-07-12 10:39:05,796 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$421/0x0000000840523040@4246f904] WARN util.JvmPauseMonitor: JvmPauseMonitor-834b4eb7-146a-4c2a-bac6-4409b0eef822: Detected pause in JVM or host machine (eg GC): pause of approximately 132801733ns. No GCs detected.
om1_1        | 2021-07-12 10:47:16,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34792
om1_1        | 2021-07-12 10:47:16,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-07-12 10:47:23,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33394
om3_1        | 2021-07-12 10:47:23,660 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:24,320 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:24,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33402
om3_1        | 2021-07-12 10:47:24,320 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:47:22,525 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:47:52,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47656
scm2.org_1   | 2021-07-12 10:47:52,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38300
om1_1        | 2021-07-12 10:47:16,989 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:16,989 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34802
scm1.org_1   | 2021-07-12 10:39:08,019 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:53022
scm3.org_1   | 2021-07-12 10:52:22,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43892
scm3.org_1   | 2021-07-12 10:52:22,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om2_1        | 2021-07-12 10:47:37,780 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:37,780 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39634
om2_1        | 2021-07-12 10:47:37,786 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:40,955 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:08,083 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-07-12 10:47:16,997 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:39:17,338 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:47:52,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55966
scm2.org_1   | 2021-07-12 10:47:52,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:27,657 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:52:22,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43682
scm3.org_1   | 2021-07-12 10:52:22,474 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59884
om2_1        | 2021-07-12 10:47:40,956 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39652
om2_1        | 2021-07-12 10:47:40,962 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:00,164 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
om3_1        | 2021-07-12 10:47:27,657 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33428
om3_1        | 2021-07-12 10:47:27,665 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:28,182 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:52:22,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:17,645 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:17,462 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 150886.831us
om2_1        | 2021-07-12 10:47:41,454 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:41,454 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39662
om2_1        | 2021-07-12 10:47:41,459 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:47:52,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:17,646 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34810
scm1.org_1   | 2021-07-12 10:39:18,837 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:38124
om3_1        | 2021-07-12 10:47:28,183 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33438
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
scm2.org_1   | 2021-07-12 10:47:52,492 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
om3_1        | 2021-07-12 10:47:28,186 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:31,466 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:52:22,500 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:52:52,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44060
scm1.org_1   | 2021-07-12 10:39:18,941 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:39:19,343 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:35482
scm2.org_1   | 2021-07-12 10:48:22,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48032
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1        | 2021-07-12 10:47:17,646 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:17,736 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:17,736 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34816
om2_1        | 2021-07-12 10:47:42,375 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:48:22,449 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38682
om3_1        | 2021-07-12 10:47:31,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33458
scm3.org_1   | 2021-07-12 10:52:52,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60042
scm2.org_1   | 2021-07-12 10:48:22,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:31,467 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:31,930 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:19,456 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om2_1        | 2021-07-12 10:47:42,375 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39674
om2_1        | 2021-07-12 10:47:42,376 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:46,297 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om1_1        | 2021-07-12 10:47:17,749 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:17,821 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:52:52,449 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:52:52,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43840
scm3.org_1   | 2021-07-12 10:52:52,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:48:22,492 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56350
scm1.org_1   | 2021-07-12 10:39:19,719 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36164
scm1.org_1   | 2021-07-12 10:39:19,877 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om2_1        | 2021-07-12 10:47:46,297 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39700
om2_1        | 2021-07-12 10:47:46,306 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:46,785 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:46,786 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39710
om2_1        | 2021-07-12 10:47:46,790 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:17,821 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34824
om1_1        | 2021-07-12 10:47:17,822 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 2021-07-12 10:39:23,168 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34570
scm1.org_1   | 2021-07-12 10:39:23,197 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:39:23,198 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn f311c7ebb23c, UUID: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a
scm1.org_1   | 2021-07-12 10:39:23,546 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-07-12 10:52:52,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:53:22,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44180
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2021-07-12 10:47:17,823 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34828
scm2.org_1   | 2021-07-12 10:48:22,504 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:48:22,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:48:36,862 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2021-07-12 10:48:52,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38902
scm2.org_1   | 2021-07-12 10:48:52,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56570
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 2021-07-12 10:47:17,827 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:17,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:53:22,475 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43970
scm3.org_1   | 2021-07-12 10:53:22,492 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:31,930 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33474
om3_1        | 2021-07-12 10:47:31,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:39:23,550 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 110325.911us
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om2_1        | 2021-07-12 10:47:47,254 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:47,254 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39718
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-07-12 10:39:25,348 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32956
om3_1        | 2021-07-12 10:47:32,692 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:48:52,435 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:21,927 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:53:22,502 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60176
s3g_1        | 2021-07-12 10:46:00,369 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-07-12 10:39:25,423 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-07-12 10:47:32,692 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33486
scm2.org_1   | 2021-07-12 10:48:52,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48256
om2_1        | 2021-07-12 10:47:47,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:47,756 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:47,757 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39728
scm1.org_1   | 2021-07-12 10:39:25,425 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 071a21c71cec, UUID: 5244f159-1b5c-4bd3-a569-521c9d7b4032
scm2.org_1   | 2021-07-12 10:48:52,451 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:48:52,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:21,927 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34860
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
scm3.org_1   | 2021-07-12 10:53:22,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:53:22,522 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:53:52,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60328
scm3.org_1   | 2021-07-12 10:53:52,452 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44128
scm3.org_1   | 2021-07-12 10:53:52,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44346
scm1.org_1   | 2021-07-12 10:39:25,858 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:39:25,927 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 123471.304us
om1_1        | 2021-07-12 10:47:21,928 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:22,402 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:53:52,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:32,693 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:36,040 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:36,040 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33502
om3_1        | 2021-07-12 10:47:36,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:36,523 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:36,523 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33510
om3_1        | 2021-07-12 10:47:36,528 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:37,798 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:37,798 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33534
om1_1        | 2021-07-12 10:47:22,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34882
om2_1        | 2021-07-12 10:47:47,757 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:51,323 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:49:22,429 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39032
scm2.org_1   | 2021-07-12 10:49:22,451 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:49:22,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48388
scm2.org_1   | 2021-07-12 10:49:22,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56700
om1_1        | 2021-07-12 10:47:22,416 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:22,569 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:22,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34900
om1_1        | 2021-07-12 10:47:22,571 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:22,572 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34902
scm1.org_1   | 2021-07-12 10:39:26,066 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54540
scm1.org_1   | 2021-07-12 10:39:26,127 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:39:26,127 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn ccdb996b39f4, UUID: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
scm1.org_1   | 2021-07-12 10:39:26,340 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-07-12 10:47:51,323 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39754
om2_1        | 2021-07-12 10:47:51,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:54,454 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:53:52,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:22,575 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:22,579 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:22,580 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34906
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-07-12 10:53:52,487 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:53:54,387 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
om2_1        | 2021-07-12 10:47:54,454 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39790
om2_1        | 2021-07-12 10:47:54,455 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:54,907 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:54,907 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39798
om2_1        | 2021-07-12 10:47:54,908 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:37,799 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:40,973 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:26,353 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 76956.609us
om1_1        | 2021-07-12 10:47:22,580 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-07-12 10:54:22,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44474
scm3.org_1   | 2021-07-12 10:54:22,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44252
scm3.org_1   | 2021-07-12 10:54:22,438 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:54:22,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:39:26,869 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:54742
scm1.org_1   | 2021-07-12 10:39:26,901 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-07-12 10:47:22,585 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:23,648 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:49:22,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:49:22,518 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:49:52,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39156
scm2.org_1   | 2021-07-12 10:49:52,443 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:49:52,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48520
scm2.org_1   | 2021-07-12 10:49:52,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56826
scm2.org_1   | 2021-07-12 10:49:52,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:40,974 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33552
om3_1        | 2021-07-12 10:47:40,974 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:41,481 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:41,482 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33562
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om2_1        | 2021-07-12 10:47:55,624 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:55,625 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39812
om2_1        | 2021-07-12 10:47:55,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:23,648 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34930
scm1.org_1   | 2021-07-12 10:39:26,915 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 9303d272-fcee-48ed-bb6b-234b939c5b37
scm1.org_1   | 2021-07-12 10:39:27,194 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:39:27,248 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 119056.171us
scm2.org_1   | 2021-07-12 10:49:52,507 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:23,649 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:24,307 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:24,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34938
om1_1        | 2021-07-12 10:47:24,311 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:54:22,447 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60452
scm3.org_1   | 2021-07-12 10:54:22,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:54:52,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44612
scm3.org_1   | 2021-07-12 10:54:52,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:54:52,474 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60586
om3_1        | 2021-07-12 10:47:41,483 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:42,379 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:42,380 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33574
om3_1        | 2021-07-12 10:47:42,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:56,150 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:56,151 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39830
om2_1        | 2021-07-12 10:47:56,152 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:47:56,688 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:47:56,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39838
om2_1        | 2021-07-12 10:47:56,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:46,308 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:46,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33600
om3_1        | 2021-07-12 10:47:46,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:46,794 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:28,174 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:57638
scm1.org_1   | 2021-07-12 10:39:28,208 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:39:28,208 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 6c02d105-209d-4ad8-a253-7c8372ecaa2a
scm1.org_1   | 2021-07-12 10:39:28,468 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:39:28,468 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 90925.827us
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-07-12 10:54:52,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44380
scm3.org_1   | 2021-07-12 10:54:52,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:50:22,392 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39284
scm2.org_1   | 2021-07-12 10:50:22,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56956
om1_1        | 2021-07-12 10:47:27,639 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:27,639 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34964
scm2.org_1   | 2021-07-12 10:50:22,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:50:22,456 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:50:22,473 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48644
scm2.org_1   | 2021-07-12 10:50:22,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:50:52,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57088
scm3.org_1   | 2021-07-12 10:54:52,503 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:55:22,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44730
scm3.org_1   | 2021-07-12 10:55:22,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60714
scm3.org_1   | 2021-07-12 10:55:22,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:55:22,476 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44516
scm3.org_1   | 2021-07-12 10:55:22,481 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:48:00,181 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46524
om1_1        | 2021-07-12 10:47:27,641 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:28,154 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:28,154 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34974
om1_1        | 2021-07-12 10:47:28,167 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:31,449 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:29,143 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41922
scm1.org_1   | 2021-07-12 10:39:29,371 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:39:29,440 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41334
om2_1        | 2021-07-12 10:48:00,190 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-07-12 10:46:00,434 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
om3_1        | 2021-07-12 10:47:46,795 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33610
scm2.org_1   | 2021-07-12 10:50:52,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39418
om2_1        | 2021-07-12 10:48:02,361 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:02,361 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39876
om2_1        | 2021-07-12 10:48:02,366 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2021-07-12 10:47:46,796 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1        | 2021-07-12 10:47:31,450 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34992
om1_1        | 2021-07-12 10:47:31,452 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:31,909 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:31,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35010
om1_1        | 2021-07-12 10:47:31,922 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:32,683 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:29,463 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:39:29,464 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 55608f7f-ae22-46a3-9263-0081f5c7684e
scm1.org_1   | 2021-07-12 10:39:29,748 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-07-12 10:47:47,261 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:02,799 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm3.org_1   | 2021-07-12 10:55:22,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:55:52,413 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44860
scm1.org_1   | 2021-07-12 10:39:29,754 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 220251.804us
om3_1        | 2021-07-12 10:47:47,262 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33618
om3_1        | 2021-07-12 10:47:47,268 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:50:52,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:50:52,463 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48776
scm2.org_1   | 2021-07-12 10:50:52,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om2_1        | 2021-07-12 10:48:02,800 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39884
om2_1        | 2021-07-12 10:48:02,800 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:03,243 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:03,243 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39892
om2_1        | 2021-07-12 10:48:03,244 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:55:52,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60838
scm3.org_1   | 2021-07-12 10:55:52,446 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:55:52,458 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44648
scm3.org_1   | 2021-07-12 10:55:52,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:55:52,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:39:32,223 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34598
scm1.org_1   | 2021-07-12 10:39:32,279 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2021-07-12 10:50:52,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:51:22,408 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39546
scm2.org_1   | 2021-07-12 10:51:22,431 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48910
scm2.org_1   | 2021-07-12 10:51:22,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:32,683 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35022
om1_1        | 2021-07-12 10:47:32,685 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:51:22,479 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57216
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 2021-07-12 10:39:35,336 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32994
scm1.org_1   | 2021-07-12 10:39:35,398 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:39:35,491 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54578
scm3.org_1   | 2021-07-12 10:56:22,415 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44984
om1_1        | 2021-07-12 10:47:36,027 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm2.org_1   | 2021-07-12 10:51:22,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:39:35,608 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-07-12 10:47:47,760 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:47,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33628
scm3.org_1   | 2021-07-12 10:56:22,426 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60976
om2_1        | 2021-07-12 10:48:03,900 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:03,900 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39906
om1_1        | 2021-07-12 10:47:36,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35038
om1_1        | 2021-07-12 10:47:36,030 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:47,761 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 2021-07-12 10:39:46,610 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41862
scm1.org_1   | 2021-07-12 10:39:46,681 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:39:50,138 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:35564
scm1.org_1   | 2021-07-12 10:39:50,209 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:39:50,507 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46696
om3_1        | 2021-07-12 10:47:51,332 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:51,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33654
scm1.org_1   | 2021-07-12 10:39:50,648 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-07-12 10:51:22,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:51:52,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39686
om2_1        | 2021-07-12 10:48:03,901 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:04,341 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:51,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:54,458 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:54,458 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33690
om1_1        | 2021-07-12 10:47:36,499 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:36,499 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35046
om1_1        | 2021-07-12 10:47:36,515 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-07-12 10:51:52,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49050
om3_1        | 2021-07-12 10:47:54,460 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-07-12 10:56:22,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44768
scm3.org_1   | 2021-07-12 10:56:22,447 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:56:22,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:56:22,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:56:52,432 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33050
scm1.org_1   | 2021-07-12 10:39:51,010 [IPC Server handler 65 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-07-12 10:47:54,912 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:54,912 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33698
om3_1        | 2021-07-12 10:47:54,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:47:55,629 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:55,630 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33714
om3_1        | 2021-07-12 10:47:55,632 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:39:51,194 [IPC Server handler 65 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2612531528108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:00,496 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
scm3.org_1   | 2021-07-12 10:56:52,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45076
scm3.org_1   | 2021-07-12 10:56:52,451 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:39:51,301 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
om2_1        | 2021-07-12 10:48:04,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39914
om2_1        | 2021-07-12 10:48:04,350 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:07,466 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:07,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39930
om2_1        | 2021-07-12 10:48:07,469 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:07,909 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:07,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39948
scm3.org_1   | 2021-07-12 10:56:52,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-07-12 10:56:52,470 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45288
scm3.org_1   | 2021-07-12 10:56:52,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:39:51,302 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-07-12 10:39:51,326 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5 to datanode:1ab7aeaf-7670-4a86-9686-feb8bb11c16a
scm1.org_1   | 2021-07-12 10:39:51,565 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:38220
scm1.org_1   | 2021-07-12 10:39:51,645 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5, Nodes: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:51.311Z[UTC]].
scm1.org_1   | 2021-07-12 10:39:51,678 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
om1_1        | 2021-07-12 10:47:37,765 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:51,692 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 178043.824us
scm2.org_1   | 2021-07-12 10:51:52,445 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:56,160 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
om1_1        | 2021-07-12 10:47:37,770 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35070
scm1.org_1   | 2021-07-12 10:39:51,764 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:39:51,867 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36258
scm1.org_1   | 2021-07-12 10:39:51,973 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
om1_1        | 2021-07-12 10:47:37,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:07,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:39:52,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41380
scm2.org_1   | 2021-07-12 10:51:52,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:47:56,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33730
om1_1        | 2021-07-12 10:47:40,952 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:11,034 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:52,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:51:52,471 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57356
om3_1        | 2021-07-12 10:47:56,163 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1        | 2021-07-12 10:47:40,952 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35088
om1_1        | 2021-07-12 10:47:40,953 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:41,443 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:52,607 [IPC Server handler 27 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
scm2.org_1   | 2021-07-12 10:51:52,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:52:22,443 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39802
scm2.org_1   | 2021-07-12 10:52:22,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49174
om3_1        | 2021-07-12 10:47:56,695 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:47:56,696 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33738
om3_1        | 2021-07-12 10:47:56,697 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:39:52,671 [IPC Server handler 27 on default port 9861] INFO node.SCMNodeManager: Registered Data node : dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2615449502355, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-07-12 10:39:52,690 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm2.org_1   | 2021-07-12 10:52:22,465 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:41,443 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35098
om1_1        | 2021-07-12 10:47:41,451 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:42,362 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:42,363 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35110
om1_1        | 2021-07-12 10:47:42,371 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:46,280 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:00,210 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42368
om3_1        | 2021-07-12 10:48:00,218 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:02,369 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:02,369 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33776
scm2.org_1   | 2021-07-12 10:52:22,480 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57478
scm1.org_1   | 2021-07-12 10:39:52,724 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
om3_1        | 2021-07-12 10:48:02,374 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:46,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35136
scm2.org_1   | 2021-07-12 10:52:22,483 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:52:22,491 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:47:46,295 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
scm2.org_1   | 2021-07-12 10:52:52,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39970
om1_1        | 2021-07-12 10:47:46,767 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:46,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35146
om3_1        | 2021-07-12 10:48:02,803 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:02,803 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33784
om3_1        | 2021-07-12 10:48:02,804 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:39:52,764 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c72a7bef-074b-455f-a2d4-05a9f269f8e5 to datanode:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
scm1.org_1   | 2021-07-12 10:39:52,796 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c72a7bef-074b-455f-a2d4-05a9f269f8e5, Nodes: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:52.764Z[UTC]].
om2_1        | 2021-07-12 10:48:11,035 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39980
om2_1        | 2021-07-12 10:48:11,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:11,475 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:11,475 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39990
scm2.org_1   | 2021-07-12 10:52:52,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:48:03,247 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:03,247 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33792
om3_1        | 2021-07-12 10:48:03,248 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:03,905 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:03,905 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33806
om3_1        | 2021-07-12 10:48:03,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:04,353 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:52,807 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-07-12 10:52:52,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57640
scm2.org_1   | 2021-07-12 10:52:52,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49326
scm2.org_1   | 2021-07-12 10:52:52,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:52:52,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:53:22,431 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40094
scm2.org_1   | 2021-07-12 10:53:22,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49460
scm2.org_1   | 2021-07-12 10:53:22,473 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57766
scm2.org_1   | 2021-07-12 10:53:22,481 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:53:22,508 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:53:22,526 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:53:36,863 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2021-07-12 10:53:52,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49616
scm2.org_1   | 2021-07-12 10:53:52,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57928
scm2.org_1   | 2021-07-12 10:53:52,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40260
scm2.org_1   | 2021-07-12 10:53:52,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:53:52,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:53:52,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:54:22,443 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40384
scm2.org_1   | 2021-07-12 10:54:22,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49740
scm2.org_1   | 2021-07-12 10:54:22,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58052
scm2.org_1   | 2021-07-12 10:54:22,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:54:22,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:54:22,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:54:52,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49870
scm2.org_1   | 2021-07-12 10:54:52,473 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40522
scm2.org_1   | 2021-07-12 10:54:52,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:54:52,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58180
scm2.org_1   | 2021-07-12 10:54:52,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:54:52,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:55:22,434 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50008
scm2.org_1   | 2021-07-12 10:55:22,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40640
scm2.org_1   | 2021-07-12 10:55:22,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:55:22,468 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58312
scm2.org_1   | 2021-07-12 10:55:22,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:55:22,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:55:52,417 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40770
scm2.org_1   | 2021-07-12 10:55:52,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:55:52,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50126
scm2.org_1   | 2021-07-12 10:55:52,464 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58444
scm2.org_1   | 2021-07-12 10:55:52,471 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:55:52,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:56:22,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40894
scm2.org_1   | 2021-07-12 10:56:22,422 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50254
scm2.org_1   | 2021-07-12 10:56:22,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58568
scm2.org_1   | 2021-07-12 10:56:22,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:56:22,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:56:22,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:56:52,433 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41204
scm2.org_1   | 2021-07-12 10:56:52,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50560
scm2.org_1   | 2021-07-12 10:56:52,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58876
scm2.org_1   | 2021-07-12 10:56:52,471 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:56:52,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-07-12 10:56:52,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1        | 2021-07-12 10:47:46,782 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:47,248 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:47,248 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35154
om1_1        | 2021-07-12 10:47:47,251 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:47,752 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:47,753 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35164
om1_1        | 2021-07-12 10:47:47,753 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om2_1        | 2021-07-12 10:48:11,475 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:11,956 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:11,956 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39998
om2_1        | 2021-07-12 10:48:11,957 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:51,309 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:04,354 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33814
om3_1        | 2021-07-12 10:48:04,355 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:07,474 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:52,816 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 45611.163us
scm1.org_1   | 2021-07-12 10:39:53,986 [IPC Server handler 28 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5244f159-1b5c-4bd3-a569-521c9d7b4032
om2_1        | 2021-07-12 10:48:12,430 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:12,431 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40008
om2_1        | 2021-07-12 10:48:12,434 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:12,902 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:51,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35190
om1_1        | 2021-07-12 10:47:51,319 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:54,446 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:54,446 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35226
scm1.org_1   | 2021-07-12 10:39:53,987 [IPC Server handler 28 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2614971215607, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-07-12 10:39:53,991 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-07-12 10:39:53,997 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=269136cc-c909-477b-8eee-dfb2e619c9e2 to datanode:5244f159-1b5c-4bd3-a569-521c9d7b4032
scm1.org_1   | 2021-07-12 10:39:54,015 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2021-07-12 10:39:54,015 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2021-07-12 10:39:54,021 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2021-07-12 10:39:54,021 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-07-12 10:39:54,021 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2021-07-12 10:39:54,021 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-07-12 10:39:54,036 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 269136cc-c909-477b-8eee-dfb2e619c9e2, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:53.997Z[UTC]].
scm1.org_1   | 2021-07-12 10:39:54,037 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:39:54,042 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 42130.959us
scm1.org_1   | 2021-07-12 10:39:54,073 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403 to datanode:5244f159-1b5c-4bd3-a569-521c9d7b4032
scm1.org_1   | 2021-07-12 10:39:54,075 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403 to datanode:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
scm1.org_1   | 2021-07-12 10:39:54,077 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403 to datanode:1ab7aeaf-7670-4a86-9686-feb8bb11c16a
scm1.org_1   | 2021-07-12 10:39:54,116 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]].
scm1.org_1   | 2021-07-12 10:39:54,123 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:39:54,127 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 49861.59us
scm1.org_1   | 2021-07-12 10:39:54,134 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990 to datanode:5244f159-1b5c-4bd3-a569-521c9d7b4032
scm1.org_1   | 2021-07-12 10:39:54,143 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990 to datanode:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
scm1.org_1   | 2021-07-12 10:39:54,148 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990 to datanode:1ab7aeaf-7670-4a86-9686-feb8bb11c16a
om3_1        | 2021-07-12 10:48:07,474 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33830
om3_1        | 2021-07-12 10:48:07,475 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:07,912 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:07,912 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33848
om1_1        | 2021-07-12 10:47:54,451 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:54,896 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:54,896 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35234
om2_1        | 2021-07-12 10:48:12,903 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40016
om2_1        | 2021-07-12 10:48:12,903 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:07,913 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:15,920 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46708
om2_1        | 2021-07-12 10:48:15,926 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:18,043 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:18,044 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40050
om1_1        | 2021-07-12 10:47:54,903 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:55,621 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:55,621 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35248
om1_1        | 2021-07-12 10:47:55,622 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:11,047 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:11,047 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33880
om3_1        | 2021-07-12 10:48:11,048 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:18,050 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:18,530 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:11,480 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:56,144 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:56,144 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35266
om2_1        | 2021-07-12 10:48:18,532 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40060
om2_1        | 2021-07-12 10:48:18,532 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:11,480 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33890
om3_1        | 2021-07-12 10:48:11,480 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:56,147 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:56,684 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:47:56,684 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35274
om2_1        | 2021-07-12 10:48:19,101 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:19,101 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40072
om2_1        | 2021-07-12 10:48:19,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:19,554 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:19,554 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40080
om2_1        | 2021-07-12 10:48:19,555 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:11,960 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:11,961 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33898
om3_1        | 2021-07-12 10:48:11,962 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:12,437 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:12,438 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33908
om3_1        | 2021-07-12 10:48:12,447 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:12,906 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:12,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33916
om3_1        | 2021-07-12 10:48:12,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:15,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42552
om3_1        | 2021-07-12 10:48:15,954 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:47:56,685 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:00,126 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43982
om1_1        | 2021-07-12 10:48:00,149 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:02,352 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:20,042 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:20,043 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40098
om2_1        | 2021-07-12 10:48:20,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:20,483 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:20,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40108
om1_1        | 2021-07-12 10:48:02,357 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35312
scm1.org_1   | 2021-07-12 10:39:54,149 [RatisPipelineUtilsThread - 0] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: Rolling segment log-1_36 to index:36
scm1.org_1   | 2021-07-12 10:39:54,190 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_1 to /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_1-36
scm1.org_1   | 2021-07-12 10:39:54,196 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/ea67d158-f30d-4de4-8e61-b39e69e4a611/current/log_inprogress_37
om1_1        | 2021-07-12 10:48:02,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:02,796 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:02,797 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35320
om1_1        | 2021-07-12 10:48:02,797 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:03,238 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:54,228 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fc4a04e1-b6f2-444a-9fba-bf278aba4990, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-07-12T10:39:54.134Z[UTC]].
scm1.org_1   | 2021-07-12 10:39:54,228 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:39:54,244 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 94424.922us
scm1.org_1   | 2021-07-12 10:39:54,252 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerV2Impl: Pipeline: PipelineID=fc4a04e1-b6f2-444a-9fba-bf278aba4990 contains same datanodes as previous pipelines: PipelineID=834b1be7-db7b-48e4-83db-8025b34c7403 nodeIds: 5244f159-1b5c-4bd3-a569-521c9d7b4032, dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, 1ab7aeaf-7670-4a86-9686-feb8bb11c16a
om2_1        | 2021-07-12 10:48:20,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:20,935 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:20,936 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40116
om2_1        | 2021-07-12 10:48:20,936 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:18,059 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:18,064 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33950
om1_1        | 2021-07-12 10:48:03,238 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35328
om2_1        | 2021-07-12 10:48:21,378 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:55,869 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: c72a7bef-074b-455f-a2d4-05a9f269f8e5, Nodes: dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:52.764Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-07-12 10:39:55,991 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:39:55,995 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 104203.415us
scm1.org_1   | 2021-07-12 10:39:56,079 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om3_1        | 2021-07-12 10:48:18,078 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:18,535 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:18,535 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33960
om3_1        | 2021-07-12 10:48:18,538 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:03,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:21,379 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40126
om2_1        | 2021-07-12 10:48:21,379 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:21,809 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:03,891 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:03,891 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35342
om1_1        | 2021-07-12 10:48:03,898 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:04,331 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:04,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35350
scm1.org_1   | 2021-07-12 10:39:56,847 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om3_1        | 2021-07-12 10:48:19,105 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:19,105 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33972
om3_1        | 2021-07-12 10:48:19,106 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:21,810 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40134
om2_1        | 2021-07-12 10:48:21,811 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:22,382 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:22,383 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40154
scm1.org_1   | 2021-07-12 10:39:57,527 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 269136cc-c909-477b-8eee-dfb2e619c9e2, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:5244f159-1b5c-4bd3-a569-521c9d7b4032, CreationTimestamp2021-07-12T10:39:53.997Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-07-12 10:39:57,547 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-07-12 10:48:04,337 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om3_1        | 2021-07-12 10:48:19,559 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:19,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33980
om1_1        | 2021-07-12 10:48:07,457 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:07,457 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35366
om1_1        | 2021-07-12 10:48:07,463 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:07,906 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:39:57,581 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 47896.731us
scm1.org_1   | 2021-07-12 10:39:57,584 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-07-12 10:39:58,401 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:54848
scm1.org_1   | 2021-07-12 10:39:58,420 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:39:58,470 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om2_1        | 2021-07-12 10:48:22,399 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:22,930 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:22,930 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40172
om2_1        | 2021-07-12 10:48:22,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:23,338 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om3_1        | 2021-07-12 10:48:19,560 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:20,051 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:20,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:33998
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-07-12 10:40:00,079 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41442
scm1.org_1   | 2021-07-12 10:40:00,112 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:40:00,115 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42040
scm1.org_1   | 2021-07-12 10:40:00,164 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:57760
scm1.org_1   | 2021-07-12 10:40:00,202 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:40:00,312 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:40:01,849 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-07-12 10:40:01,872 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-07-12 10:40:14,475 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42130
om1_1        | 2021-07-12 10:48:07,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35384
om1_1        | 2021-07-12 10:48:07,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:11,030 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:20,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:20,486 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:20,486 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34008
om2_1        | 2021-07-12 10:48:23,338 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40180
om2_1        | 2021-07-12 10:48:23,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:23,774 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:23,775 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40190
om2_1        | 2021-07-12 10:48:23,775 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om1_1        | 2021-07-12 10:48:11,031 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35416
om3_1        | 2021-07-12 10:48:20,491 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:11,032 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:11,468 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:11,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35426
om2_1        | 2021-07-12 10:48:24,236 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:24,236 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40198
om3_1        | 2021-07-12 10:48:20,940 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:20,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34016
om3_1        | 2021-07-12 10:48:20,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-07-12 10:46:00,555 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
om1_1        | 2021-07-12 10:48:11,472 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:24,237 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:24,832 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:24,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40210
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
om1_1        | 2021-07-12 10:48:11,953 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:11,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35434
om1_1        | 2021-07-12 10:48:11,954 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:12,416 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:21,382 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:21,383 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34026
om3_1        | 2021-07-12 10:48:21,383 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:21,813 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:21,814 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34034
scm1.org_1   | 2021-07-12 10:40:14,489 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:40:17,220 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 2021-07-12 10:40:17,220 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 12742.88us
scm1.org_1   | 2021-07-12 10:40:20,796 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42156
scm1.org_1   | 2021-07-12 10:40:20,808 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:40:22,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42052
scm1.org_1   | 2021-07-12 10:40:22,375 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:48:24,833 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:25,238 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:25,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40218
om2_1        | 2021-07-12 10:48:25,239 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:21,814 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:22,429 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:22,429 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34062
om3_1        | 2021-07-12 10:48:22,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:12,416 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35444
om1_1        | 2021-07-12 10:48:12,428 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:12,894 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:12,895 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35452
om1_1        | 2021-07-12 10:48:12,900 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-07-12 10:40:23,476 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 73ea529e-0d3b-470f-8c2e-1ab14a6ab8a5, Nodes: 1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1ab7aeaf-7670-4a86-9686-feb8bb11c16a, CreationTimestamp2021-07-12T10:39:51.311Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-07-12 10:40:23,489 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:40:23,490 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 13109.09us
om2_1        | 2021-07-12 10:48:25,645 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:25,646 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40226
om3_1        | 2021-07-12 10:48:22,933 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:22,933 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34072
om3_1        | 2021-07-12 10:48:22,934 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:23,345 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:23,346 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34080
om3_1        | 2021-07-12 10:48:23,346 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:40:23,509 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-07-12 10:40:23,860 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-07-12 10:40:24,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46888
scm1.org_1   | 2021-07-12 10:40:24,409 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:40:24,412 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]] moved to OPEN state
om2_1        | 2021-07-12 10:48:25,646 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:26,063 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:26,064 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40244
om2_1        | 2021-07-12 10:48:26,064 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:26,531 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:15,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44166
om1_1        | 2021-07-12 10:48:15,888 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:18,027 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:18,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35486
om1_1        | 2021-07-12 10:48:18,039 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:00,846 [qtp1363396194-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1E804EA279AB->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
om3_1        | 2021-07-12 10:48:23,778 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:23,778 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34090
om3_1        | 2021-07-12 10:48:23,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:24,239 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:24,240 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34098
scm1.org_1   | 2021-07-12 10:40:24,412 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-07-12 10:40:24,448 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2021-07-12 10:40:24,478 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 65128.939us
om2_1        | 2021-07-12 10:48:26,531 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40254
om2_1        | 2021-07-12 10:48:26,532 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:29,534 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46936
om2_1        | 2021-07-12 10:48:29,543 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:18,516 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:18,518 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35496
om1_1        | 2021-07-12 10:48:18,520 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:19,096 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 2021-07-12 10:46:00,847 [qtp1363396194-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:46:04,172 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
scm1.org_1   | 2021-07-12 10:40:24,478 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
om3_1        | 2021-07-12 10:48:24,242 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:19,097 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35508
om1_1        | 2021-07-12 10:48:19,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:19,545 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:31,697 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:31,697 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40278
scm1.org_1   | 2021-07-12 10:40:24,478 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2021-07-12 10:40:24,478 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2021-07-12 10:40:24,478 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om2_1        | 2021-07-12 10:48:31,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:48:32,224 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:48:32,224 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40298
om2_1        | 2021-07-12 10:48:32,225 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:49:32,904 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:24,835 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:19,546 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35516
om1_1        | 2021-07-12 10:48:19,550 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:20,033 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:20,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35534
scm1.org_1   | 2021-07-12 10:40:24,479 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om3_1        | 2021-07-12 10:48:24,836 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34110
om3_1        | 2021-07-12 10:48:24,836 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:25,242 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:25,243 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34118
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 2021-07-12 10:40:24,493 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
om2_1        | 2021-07-12 10:49:32,905 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40556
om2_1        | 2021-07-12 10:49:32,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:25,243 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:20,039 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:40:24,493 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2021-07-12 10:40:25,910 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41572
scm1.org_1   | 2021-07-12 10:40:25,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:40:25,956 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: fc4a04e1-b6f2-444a-9fba-bf278aba4990, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:5244f159-1b5c-4bd3-a569-521c9d7b4032, CreationTimestamp2021-07-12T10:39:54.134Z[UTC]] moved to OPEN state
om2_1        | 2021-07-12 10:50:34,151 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:20,479 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:25,650 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:25,650 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34126
om3_1        | 2021-07-12 10:48:25,651 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:26,066 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:26,067 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34144
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2021-07-12 10:50:34,152 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40816
om2_1        | 2021-07-12 10:50:34,152 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:51:37,419 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:51:37,419 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41084
om2_1        | 2021-07-12 10:51:37,420 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:20,480 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35544
om1_1        | 2021-07-12 10:48:20,480 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:20,930 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:20,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35552
om1_1        | 2021-07-12 10:48:20,932 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:40:25,993 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 37344.912us
scm1.org_1   | 2021-07-12 10:40:27,755 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42208
scm1.org_1   | 2021-07-12 10:40:27,775 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om3_1        | 2021-07-12 10:48:26,067 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:26,534 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 2021-07-12 10:40:37,204 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41632
scm1.org_1   | 2021-07-12 10:40:37,230 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:48:21,374 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:21,374 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35562
om2_1        | 2021-07-12 10:52:42,703 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:52:42,703 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41368
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2021-07-12 10:40:40,848 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46982
om2_1        | 2021-07-12 10:52:42,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:52:43,423 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:26,535 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34154
om3_1        | 2021-07-12 10:48:26,542 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:21,376 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:04,414 [qtp1363396194-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-2A45A30B5F69->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:46:04,414 [qtp1363396194-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:46:05,339 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-07-12 10:40:40,860 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:40:47,099 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:35894
scm1.org_1   | 2021-07-12 10:40:47,104 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:40:47,194 [IPC Server handler 69 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 50185.591us
scm1.org_1   | 2021-07-12 10:40:47,198 [IPC Server handler 69 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
om3_1        | 2021-07-12 10:48:29,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42780
om3_1        | 2021-07-12 10:48:29,575 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:21,805 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:21,806 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35570
om1_1        | 2021-07-12 10:48:21,807 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:22,372 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:22,372 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35590
om1_1        | 2021-07-12 10:48:22,374 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:52:43,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41386
om2_1        | 2021-07-12 10:52:43,425 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:52:46,551 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:52:46,552 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41410
om2_1        | 2021-07-12 10:52:46,553 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:53:36,322 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48304
om2_1        | 2021-07-12 10:53:36,330 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:53:38,540 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:53:38,541 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41646
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
om3_1        | 2021-07-12 10:48:31,710 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:31,711 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34178
scm1.org_1   | 2021-07-12 10:40:47,264 [IPC Server handler 69 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 43981.806us
om3_1        | 2021-07-12 10:48:31,719 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:48:32,232 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:48:32,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34198
om3_1        | 2021-07-12 10:48:32,239 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:49:32,909 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:22,919 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:22,920 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35608
om1_1        | 2021-07-12 10:48:22,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:23,334 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
scm1.org_1   | 2021-07-12 10:40:47,322 [834b4eb7-146a-4c2a-bac6-4409b0eef822@group-B39E69E4A611-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm1.org_1   | 2021-07-12 10:40:47,332 [IPC Server handler 69 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 30868.217us
scm1.org_1   | 2021-07-12 10:40:47,344 [IPC Server handler 69 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 10146.102us
scm1.org_1   | 2021-07-12 10:40:47,347 [IPC Server handler 69 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 107544261427200000 to 107544261427201000.
scm1.org_1   | 2021-07-12 10:40:50,046 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34982
scm1.org_1   | 2021-07-12 10:40:50,068 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om3_1        | 2021-07-12 10:49:32,909 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34456
om3_1        | 2021-07-12 10:49:32,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:50:34,155 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:23,334 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35616
om3_1        | 2021-07-12 10:50:34,156 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34716
om2_1        | 2021-07-12 10:53:38,541 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:53:39,029 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:53:39,029 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41654
om1_1        | 2021-07-12 10:48:23,335 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:50:34,157 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:40:50,460 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33368
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om3_1        | 2021-07-12 10:51:32,344 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:40:50,473 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54952
scm1.org_1   | 2021-07-12 10:40:50,479 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-07-12 10:40:50,483 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-07-12 10:51:32,362 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34956
om2_1        | 2021-07-12 10:53:39,030 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:53:47,414 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:53:47,414 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41700
om2_1        | 2021-07-12 10:53:47,417 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:54:39,334 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om3_1        | 2021-07-12 10:51:32,365 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:23,769 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:23,770 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35626
om1_1        | 2021-07-12 10:48:23,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:40:50,857 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41708
scm1.org_1   | 2021-07-12 10:40:50,890 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:40:52,403 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42232
om2_1        | 2021-07-12 10:54:39,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41926
om2_1        | 2021-07-12 10:54:39,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:11,318 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om2_1        | 2021-07-12 10:55:39,904 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:55:39,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42184
om3_1        | 2021-07-12 10:51:37,423 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:51:37,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:34984
om3_1        | 2021-07-12 10:51:37,424 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:52:33,132 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:24,232 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:24,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35634
om1_1        | 2021-07-12 10:48:24,233 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:24,829 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:24,829 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35646
om1_1        | 2021-07-12 10:48:24,830 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:40:52,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:41:17,219 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 11054.627us
scm1.org_1   | 2021-07-12 10:41:20,549 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42412
scm1.org_1   | 2021-07-12 10:41:20,556 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
om2_1        | 2021-07-12 10:55:39,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:40,878 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:41:20,795 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41900
scm1.org_1   | 2021-07-12 10:41:20,826 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
om3_1        | 2021-07-12 10:52:33,132 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35222
om3_1        | 2021-07-12 10:52:33,133 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:52:42,707 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:52:42,708 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35268
om3_1        | 2021-07-12 10:52:42,709 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:52:43,428 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:40,878 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42458
om2_1        | 2021-07-12 10:56:40,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:41,551 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:41,551 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42478
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
om2_1        | 2021-07-12 10:56:41,558 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:25,235 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:25,235 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35654
om1_1        | 2021-07-12 10:48:25,236 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:25,641 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
scm1.org_1   | 2021-07-12 10:41:20,851 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47236
scm1.org_1   | 2021-07-12 10:41:20,881 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:48:25,641 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35662
om1_1        | 2021-07-12 10:48:25,642 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:26,060 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:26,060 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35680
om1_1        | 2021-07-12 10:48:26,061 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1        | 2021-07-12 10:48:26,528 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:52:43,428 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35286
scm1.org_1   | 2021-07-12 10:41:26,218 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:32788
scm1.org_1   | 2021-07-12 10:41:26,231 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:41:50,110 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:36264
scm1.org_1   | 2021-07-12 10:41:50,115 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:41:50,140 [IPC Server handler 36 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 23715.7us
om3_1        | 2021-07-12 10:52:43,429 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:52:46,556 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:52:46,557 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35310
om2_1        | 2021-07-12 10:56:42,094 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:42,094 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42488
om1_1        | 2021-07-12 10:48:26,528 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35690
om1_1        | 2021-07-12 10:48:26,529 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:29,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44394
om1_1        | 2021-07-12 10:48:29,511 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:31,677 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:52:46,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:53:34,320 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:42,095 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:42,769 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:31,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35714
om3_1        | 2021-07-12 10:53:34,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35524
om3_1        | 2021-07-12 10:53:34,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:42,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42496
om2_1        | 2021-07-12 10:56:42,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:43,545 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:43,545 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42506
om2_1        | 2021-07-12 10:56:43,546 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:31,694 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-07-12 10:53:36,345 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44148
scm1.org_1   | 2021-07-12 10:41:50,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42578
scm1.org_1   | 2021-07-12 10:41:50,530 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:53:36,354 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:48:32,219 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:48:32,220 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35734
om1_1        | 2021-07-12 10:48:32,221 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:49:32,900 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:49:32,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35992
om1_1        | 2021-07-12 10:49:32,902 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om3_1        | 2021-07-12 10:53:38,545 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:50:34,147 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:41:50,824 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42068
scm1.org_1   | 2021-07-12 10:41:50,837 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47410
om2_1        | 2021-07-12 10:56:44,279 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:50:34,147 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36252
scm1.org_1   | 2021-07-12 10:41:50,862 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:41:50,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:53:38,545 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35546
om2_1        | 2021-07-12 10:56:44,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42520
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om1_1        | 2021-07-12 10:50:34,148 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:51:37,415 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-07-12 10:42:06,328 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:36366
scm1.org_1   | 2021-07-12 10:42:06,340 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2021-07-12 10:51:37,415 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36520
om1_1        | 2021-07-12 10:51:37,416 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:44,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:44,843 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:44,843 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42530
om2_1        | 2021-07-12 10:56:44,844 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:45,382 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:45,382 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42542
om2_1        | 2021-07-12 10:56:45,383 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:45,925 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:45,926 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42552
om2_1        | 2021-07-12 10:56:45,926 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:46,474 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:46,474 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42560
om2_1        | 2021-07-12 10:56:46,475 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:47,148 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:47,149 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42580
om2_1        | 2021-07-12 10:56:47,149 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:47,791 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:47,792 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42592
om2_1        | 2021-07-12 10:56:47,796 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:48,404 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:48,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42604
om2_1        | 2021-07-12 10:56:48,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:49,014 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:49,015 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42614
om2_1        | 2021-07-12 10:56:49,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:49,610 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:49,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42624
om2_1        | 2021-07-12 10:56:49,617 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:50,204 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:50,205 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42636
om2_1        | 2021-07-12 10:56:50,206 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:50,852 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:50,853 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42648
om2_1        | 2021-07-12 10:56:50,862 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:51,476 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:51,477 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42660
om2_1        | 2021-07-12 10:56:51,477 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:52,028 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:52,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42668
om3_1        | 2021-07-12 10:53:38,547 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:53:39,034 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:53:39,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35554
om3_1        | 2021-07-12 10:53:39,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:53:47,420 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:53:47,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35600
om3_1        | 2021-07-12 10:53:47,420 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:54:37,664 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:54:37,664 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35814
om3_1        | 2021-07-12 10:54:37,666 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:54:39,348 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:54:39,349 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:35826
om3_1        | 2021-07-12 10:54:39,354 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:55:39,909 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:55:39,911 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36084
om3_1        | 2021-07-12 10:55:39,917 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:55:46,656 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:55:46,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36118
om3_1        | 2021-07-12 10:55:46,658 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:39,146 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:39,146 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36340
om3_1        | 2021-07-12 10:56:39,158 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:40,883 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:40,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36358
om3_1        | 2021-07-12 10:56:40,884 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:41,563 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:41,564 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36378
om3_1        | 2021-07-12 10:56:41,564 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:42,099 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:42,099 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36388
om3_1        | 2021-07-12 10:56:42,100 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:42,774 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:42,774 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36396
om3_1        | 2021-07-12 10:56:42,775 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:43,550 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:43,550 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36406
om3_1        | 2021-07-12 10:56:43,552 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:44,284 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:44,285 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36420
om3_1        | 2021-07-12 10:56:44,286 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 2021-07-12 10:52:42,699 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:52:42,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36804
om1_1        | 2021-07-12 10:52:42,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:52:43,418 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:52:43,418 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36822
om1_1        | 2021-07-12 10:52:43,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:52:46,547 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:52:46,548 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36846
om1_1        | 2021-07-12 10:52:46,549 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:53:36,283 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45760
om1_1        | 2021-07-12 10:53:36,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:53:38,536 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:53:38,537 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37082
om1_1        | 2021-07-12 10:53:38,538 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:53:39,025 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:53:39,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37090
om1_1        | 2021-07-12 10:53:39,026 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:53:47,408 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:53:47,408 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37136
om1_1        | 2021-07-12 10:53:47,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:54:39,323 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:54:39,324 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37362
om1_1        | 2021-07-12 10:54:39,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:55:39,897 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:55:39,899 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37620
om1_1        | 2021-07-12 10:55:39,899 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:40,873 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:40,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37894
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:11,328 [qtp1363396194-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-99894, with Versioning false and Storage Type set to DISK and Encryption set to false 
om1_1        | 2021-07-12 10:56:40,874 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:41,547 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:52,029 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-07-12 10:56:52,687 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:42:06,385 [IPC Server handler 69 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 18922.057us
scm1.org_1   | 2021-07-12 10:42:06,385 [IPC Server handler 69 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2021-07-12 10:42:06,438 [IPC Server handler 69 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 20016.19us
scm1.org_1   | 2021-07-12 10:42:17,221 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 13336.993us
scm1.org_1   | 2021-07-12 10:42:22,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42770
scm1.org_1   | 2021-07-12 10:42:22,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42260
s3g_1        | 2021-07-12 10:46:11,346 [qtp1363396194-23] INFO endpoint.BucketEndpoint: Location is /bucket-99894
s3g_1        | 2021-07-12 10:46:11,780 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-07-12 10:56:44,847 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:44,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36430
om1_1        | 2021-07-12 10:56:41,548 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37914
om1_1        | 2021-07-12 10:56:41,548 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
om3_1        | 2021-07-12 10:56:44,847 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:45,386 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:56:52,687 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42694
om1_1        | 2021-07-12 10:56:42,088 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:45,386 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36442
scm1.org_1   | 2021-07-12 10:42:22,456 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-07-12 10:56:52,688 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:42,088 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37924
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
om3_1        | 2021-07-12 10:56:45,387 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:42,091 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:42,764 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
scm1.org_1   | 2021-07-12 10:42:22,461 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:56:42,765 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37932
om3_1        | 2021-07-12 10:56:45,929 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:45,930 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36452
om3_1        | 2021-07-12 10:56:45,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:46,484 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:46,484 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36460
scm1.org_1   | 2021-07-12 10:42:22,493 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47602
scm1.org_1   | 2021-07-12 10:42:22,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:42:46,206 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:36612
scm1.org_1   | 2021-07-12 10:42:46,210 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:42:52,117 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:33284
scm1.org_1   | 2021-07-12 10:42:52,139 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:42:52,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42956
scm1.org_1   | 2021-07-12 10:42:52,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:42:52,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42446
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 2021-07-12 10:42:52,483 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47786
scm1.org_1   | 2021-07-12 10:42:52,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 2021-07-12 10:42:52,518 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:42:58,061 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:36694
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-07-12 10:42:58,063 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:43:03,965 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:33366
scm1.org_1   | 2021-07-12 10:43:03,967 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:43:15,454 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
s3g_1        | 2021-07-12 10:46:11,795 [qtp1363396194-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-36612, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:46:11,808 [qtp1363396194-23] INFO endpoint.BucketEndpoint: Location is /bucket-36612
s3g_1        | 2021-07-12 10:46:12,289 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
scm1.org_1   | 2021-07-12 10:43:17,225 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 17250.605us
scm1.org_1   | 2021-07-12 10:43:22,475 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42626
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 2021-07-12 10:43:22,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:43:22,483 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47972
scm1.org_1   | 2021-07-12 10:43:22,484 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43148
om2_1        | 2021-07-12 10:56:58,567 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49394
om2_1        | 2021-07-12 10:56:58,576 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:42,766 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om2_1        | 2021-07-12 10:57:01,347 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:57:01,348 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42744
om3_1        | 2021-07-12 10:56:46,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:47,153 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:47,153 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36480
om3_1        | 2021-07-12 10:56:47,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:47,804 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:47,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36492
scm1.org_1   | 2021-07-12 10:43:22,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:43:22,493 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:56:47,805 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:48,410 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:48,410 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36504
om3_1        | 2021-07-12 10:56:48,412 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:49,019 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:49,019 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36514
om3_1        | 2021-07-12 10:56:49,020 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:49,620 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om2_1        | 2021-07-12 10:57:01,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:49,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36524
om3_1        | 2021-07-12 10:56:49,627 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:50,216 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:50,217 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36536
scm1.org_1   | 2021-07-12 10:43:52,469 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43326
om3_1        | 2021-07-12 10:56:50,218 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:50,872 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:50,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36548
om3_1        | 2021-07-12 10:56:50,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:51,480 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:43:52,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:56:51,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36560
om3_1        | 2021-07-12 10:56:51,488 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:52,033 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:52,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36568
om3_1        | 2021-07-12 10:56:52,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:52,691 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:56:52,692 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36594
scm1.org_1   | 2021-07-12 10:43:52,512 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42816
om1_1        | 2021-07-12 10:56:43,539 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:43,540 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37942
om1_1        | 2021-07-12 10:56:43,540 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:44,274 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:44,275 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37956
om1_1        | 2021-07-12 10:56:44,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:43:52,523 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48154
om1_1        | 2021-07-12 10:56:44,839 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:44,839 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37966
om1_1        | 2021-07-12 10:56:44,840 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:45,371 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:45,372 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37978
om1_1        | 2021-07-12 10:56:45,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:45,921 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:43:52,536 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:56:45,922 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37988
om1_1        | 2021-07-12 10:56:45,922 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:46,470 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:46,470 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:37996
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 2021-07-12 10:43:52,554 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:44:06,306 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:37116
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:12,298 [qtp1363396194-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-99894, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:46:12,315 [qtp1363396194-23] INFO endpoint.BucketEndpoint: Location is /bucket-99894
s3g_1        | 2021-07-12 10:46:12,764 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1        | 2021-07-12 10:56:46,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:47,145 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:47,145 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38016
om1_1        | 2021-07-12 10:56:47,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om1_1        | 2021-07-12 10:56:47,783 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:44:06,312 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:44:06,334 [IPC Server handler 53 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 20624.801us
om1_1        | 2021-07-12 10:56:47,783 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38028
om1_1        | 2021-07-12 10:56:47,787 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:52,692 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-07-12 10:56:58,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45238
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2021-07-12 10:56:48,400 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:44:17,229 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 20543.299us
scm1.org_1   | 2021-07-12 10:44:22,392 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43004
scm1.org_1   | 2021-07-12 10:44:22,448 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-07-12 10:56:58,610 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:48,401 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38040
om1_1        | 2021-07-12 10:56:48,402 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:49,006 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:57:01,367 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om3_1        | 2021-07-12 10:57:01,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:36644
om3_1        | 2021-07-12 10:57:01,368 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:12,781 [qtp1363396194-23] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
scm1.org_1   | 2021-07-12 10:44:22,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48346
om1_1        | 2021-07-12 10:56:49,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38050
om1_1        | 2021-07-12 10:56:49,011 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:49,607 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:49,607 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38060
om1_1        | 2021-07-12 10:56:49,608 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:50,194 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
scm1.org_1   | 2021-07-12 10:44:22,483 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43532
scm1.org_1   | 2021-07-12 10:44:22,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:44:22,496 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:44:40,313 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:37334
scm1.org_1   | 2021-07-12 10:44:40,321 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:519)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:463)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:454)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:385)
scm1.org_1   | 2021-07-12 10:44:45,687 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34006
scm1.org_1   | 2021-07-12 10:44:45,691 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2021-07-12 10:56:50,195 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38072
om1_1        | 2021-07-12 10:56:50,199 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:50,846 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:50,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38084
s3g_1        | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:94)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:239)
scm1.org_1   | 2021-07-12 10:44:52,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48540
scm1.org_1   | 2021-07-12 10:44:52,478 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43716
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
om1_1        | 2021-07-12 10:56:50,847 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:51,473 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:51,473 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38096
scm1.org_1   | 2021-07-12 10:44:52,481 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43198
scm1.org_1   | 2021-07-12 10:44:52,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:44:52,496 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:44:52,511 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:45:17,217 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 8804.255us
scm1.org_1   | 2021-07-12 10:45:22,385 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43484
om1_1        | 2021-07-12 10:56:51,474 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:52,023 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:56:52,024 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38104
om1_1        | 2021-07-12 10:56:52,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:56:52,682 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm1.org_1   | 2021-07-12 10:45:22,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:45:22,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43994
scm1.org_1   | 2021-07-12 10:45:22,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-07-12 10:56:52,682 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38130
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om1_1        | 2021-07-12 10:56:52,683 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-07-12 10:45:22,487 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48822
scm1.org_1   | 2021-07-12 10:45:22,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:45:29,478 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:37754
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om1_1        | 2021-07-12 10:56:58,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46850
om1_1        | 2021-07-12 10:56:58,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-07-12 10:57:01,336 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 7efc38b83ca62da7862ef9df31c20a933aae282b6ab27f40e5b1daafedb9a258
om1_1        | 2021-07-12 10:57:01,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38180
om1_1        | 2021-07-12 10:57:01,344 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm1.org_1   | 2021-07-12 10:45:29,480 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:45:44,410 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:37876
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm1.org_1   | 2021-07-12 10:45:44,413 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:45:52,424 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44258
scm1.org_1   | 2021-07-12 10:45:52,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49084
scm1.org_1   | 2021-07-12 10:45:52,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43746
scm1.org_1   | 2021-07-12 10:45:52,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:45:52,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:45:52,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm1.org_1   | 2021-07-12 10:46:00,040 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34700
scm1.org_1   | 2021-07-12 10:46:00,046 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:46:06,298 [IPC Server handler 39 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 8910.858us
scm1.org_1   | 2021-07-12 10:46:17,226 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 17002.091us
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm1.org_1   | 2021-07-12 10:46:22,419 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44088
scm1.org_1   | 2021-07-12 10:46:22,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:46:22,490 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49432
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2021-07-12 10:46:22,490 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44608
scm1.org_1   | 2021-07-12 10:46:22,526 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:46:22,527 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:46:38,242 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:38460
scm1.org_1   | 2021-07-12 10:46:38,248 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:46:52,348 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:35204
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm1.org_1   | 2021-07-12 10:46:52,349 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:46:52,384 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44366
scm1.org_1   | 2021-07-12 10:46:52,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49704
scm1.org_1   | 2021-07-12 10:46:52,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44880
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2021-07-12 10:46:52,456 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:46:52,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:46:52,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:47:06,297 [IPC Server handler 42 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 11087.22us
scm1.org_1   | 2021-07-12 10:47:08,465 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:35412
scm1.org_1   | 2021-07-12 10:47:08,467 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:47:17,229 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 20447.79us
scm1.org_1   | 2021-07-12 10:47:22,468 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44766
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
scm1.org_1   | 2021-07-12 10:47:22,472 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45276
scm1.org_1   | 2021-07-12 10:47:22,504 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:47:22,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:47:22,527 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:35632
scm1.org_1   | 2021-07-12 10:47:22,530 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50110
scm1.org_1   | 2021-07-12 10:47:22,536 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:47:22,560 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
scm1.org_1   | 2021-07-12 10:47:52,425 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45610
scm1.org_1   | 2021-07-12 10:47:52,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50438
scm1.org_1   | 2021-07-12 10:47:52,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:47:52,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45098
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 2021-07-12 10:47:52,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
scm1.org_1   | 2021-07-12 10:47:52,511 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:48:03,301 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39432
scm1.org_1   | 2021-07-12 10:48:03,307 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:48:06,294 [IPC Server handler 59 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 7456.014us
scm1.org_1   | 2021-07-12 10:48:08,100 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:34976
scm1.org_1   | 2021-07-12 10:48:08,103 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:33384
scm1.org_1   | 2021-07-12 10:48:08,103 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:48:08,115 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:48:15,457 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 2 containers.
scm1.org_1   | 2021-07-12 10:48:17,231 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 22361.143us
scm1.org_1   | 2021-07-12 10:48:18,555 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39600
scm1.org_1   | 2021-07-12 10:48:18,556 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:48:22,431 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45988
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:13,026 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidBucketName</Code>
s3g_1        |   <Message>The specified bucket is not valid.</Message>
s3g_1        |   <Resource>bucket_1</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:88)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm1.org_1   | 2021-07-12 10:48:22,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:48:22,494 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45478
scm1.org_1   | 2021-07-12 10:48:22,512 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50822
scm1.org_1   | 2021-07-12 10:48:22,515 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:48:22,551 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:48:52,392 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45702
scm1.org_1   | 2021-07-12 10:48:52,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:48:52,469 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46224
scm1.org_1   | 2021-07-12 10:48:52,483 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51042
scm1.org_1   | 2021-07-12 10:48:52,504 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:48:52,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:49:06,352 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39964
scm1.org_1   | 2021-07-12 10:49:06,357 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:49:06,367 [IPC Server handler 50 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 9695.778us
scm1.org_1   | 2021-07-12 10:49:17,215 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 6459.585us
scm1.org_1   | 2021-07-12 10:49:22,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51170
scm1.org_1   | 2021-07-12 10:49:22,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45834
scm1.org_1   | 2021-07-12 10:49:22,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46342
scm1.org_1   | 2021-07-12 10:49:22,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:49:22,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:49:22,519 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:49:33,030 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40096
scm1.org_1   | 2021-07-12 10:49:33,038 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm1.org_1   | 2021-07-12 10:49:52,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45966
scm1.org_1   | 2021-07-12 10:49:52,455 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:49:52,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46472
scm1.org_1   | 2021-07-12 10:49:52,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51304
scm1.org_1   | 2021-07-12 10:49:52,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm1.org_1   | 2021-07-12 10:49:52,515 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:50:17,217 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 8192.634us
scm1.org_1   | 2021-07-12 10:50:22,387 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46092
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm1.org_1   | 2021-07-12 10:50:22,417 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46598
scm1.org_1   | 2021-07-12 10:50:22,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51428
scm1.org_1   | 2021-07-12 10:50:22,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:50:22,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-07-12 10:50:22,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:50:34,231 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40356
scm1.org_1   | 2021-07-12 10:50:34,236 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:50:52,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46224
scm1.org_1   | 2021-07-12 10:50:52,431 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51558
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
scm1.org_1   | 2021-07-12 10:50:52,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:50:52,449 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:50:52,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46732
scm1.org_1   | 2021-07-12 10:50:52,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:51:17,216 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 6705.492us
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-07-12 10:51:22,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46346
scm1.org_1   | 2021-07-12 10:51:22,425 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46858
scm1.org_1   | 2021-07-12 10:51:22,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51688
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-07-12 10:51:22,461 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:51:22,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:51:22,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:51:37,499 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40624
scm1.org_1   | 2021-07-12 10:51:37,517 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm1.org_1   | 2021-07-12 10:51:37,546 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:34518
scm1.org_1   | 2021-07-12 10:51:37,551 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:36110
scm1.org_1   | 2021-07-12 10:51:37,553 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:51:37,556 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:37266
scm1.org_1   | 2021-07-12 10:51:37,570 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:51:37,576 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
scm1.org_1   | 2021-07-12 10:51:52,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46486
scm1.org_1   | 2021-07-12 10:51:52,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47000
scm1.org_1   | 2021-07-12 10:51:52,411 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:51:52,432 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51828
scm1.org_1   | 2021-07-12 10:51:52,449 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
scm1.org_1   | 2021-07-12 10:51:52,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:52:17,217 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 7982.327us
scm1.org_1   | 2021-07-12 10:52:22,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46610
scm1.org_1   | 2021-07-12 10:52:22,424 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47130
scm1.org_1   | 2021-07-12 10:52:22,427 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm1.org_1   | 2021-07-12 10:52:22,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51950
scm1.org_1   | 2021-07-12 10:52:22,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:52:22,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:52:42,778 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40908
scm1.org_1   | 2021-07-12 10:52:42,783 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
scm1.org_1   | 2021-07-12 10:52:42,824 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:36396
scm1.org_1   | 2021-07-12 10:52:42,826 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:34800
scm1.org_1   | 2021-07-12 10:52:42,832 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:37550
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
scm1.org_1   | 2021-07-12 10:52:42,836 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:52:42,845 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:52:42,854 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-07-12 10:52:52,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46772
scm1.org_1   | 2021-07-12 10:52:52,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-07-12 10:46:18,402 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
scm1.org_1   | 2021-07-12 10:52:52,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47282
scm1.org_1   | 2021-07-12 10:52:52,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52110
scm1.org_1   | 2021-07-12 10:52:52,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:52:52,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:53:15,458 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2021-07-12 10:53:17,216 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 6161.675us
scm1.org_1   | 2021-07-12 10:53:22,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46894
scm1.org_1   | 2021-07-12 10:53:22,447 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47416
scm1.org_1   | 2021-07-12 10:53:22,472 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52238
scm1.org_1   | 2021-07-12 10:53:22,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:53:22,502 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:53:22,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:53:39,050 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41194
scm1.org_1   | 2021-07-12 10:53:39,057 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:53:52,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47570
scm1.org_1   | 2021-07-12 10:53:52,452 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52398
scm1.org_1   | 2021-07-12 10:53:52,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:53:52,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:53:52,479 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47060
scm1.org_1   | 2021-07-12 10:53:52,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:54:17,215 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 5231.848us
scm1.org_1   | 2021-07-12 10:54:22,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52528
scm1.org_1   | 2021-07-12 10:54:22,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47186
scm1.org_1   | 2021-07-12 10:54:22,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47700
scm1.org_1   | 2021-07-12 10:54:22,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:54:22,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:54:22,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:54:39,464 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41466
scm1.org_1   | 2021-07-12 10:54:39,467 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:54:52,438 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47324
scm1.org_1   | 2021-07-12 10:54:52,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:54:52,471 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47832
scm1.org_1   | 2021-07-12 10:54:52,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52650
scm1.org_1   | 2021-07-12 10:54:52,491 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:54:52,513 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:55:17,220 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 10118.487us
scm1.org_1   | 2021-07-12 10:55:22,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47964
scm1.org_1   | 2021-07-12 10:55:22,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47440
scm1.org_1   | 2021-07-12 10:55:22,448 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:55:22,461 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:55:22,464 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52784
scm1.org_1   | 2021-07-12 10:55:22,491 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:55:40,012 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41724
scm1.org_1   | 2021-07-12 10:55:40,014 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:18,411 [qtp1363396194-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-90687, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:46:18,422 [qtp1363396194-22] INFO endpoint.BucketEndpoint: Location is /bucket-90687
s3g_1        | 2021-07-12 10:46:18,870 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2021-07-12 10:55:52,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47572
scm1.org_1   | 2021-07-12 10:55:52,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48086
scm1.org_1   | 2021-07-12 10:55:52,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:55:52,460 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52916
scm1.org_1   | 2021-07-12 10:55:52,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:55:52,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:18,890 [qtp1363396194-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-55898, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:46:18,903 [qtp1363396194-23] INFO endpoint.BucketEndpoint: Location is /bucket-55898
s3g_1        | 2021-07-12 10:46:19,361 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-07-12 10:56:17,219 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@6cbd6d2b, cost 9384.366us
scm1.org_1   | 2021-07-12 10:56:22,424 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48218
scm1.org_1   | 2021-07-12 10:56:22,440 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53038
scm1.org_1   | 2021-07-12 10:56:22,443 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47694
scm1.org_1   | 2021-07-12 10:56:22,450 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:56:22,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-07-12 10:56:22,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:56:40,958 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41998
scm1.org_1   | 2021-07-12 10:56:40,961 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-07-12 10:56:40,983 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35890
scm1.org_1   | 2021-07-12 10:56:40,993 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:38640
scm1.org_1   | 2021-07-12 10:56:41,000 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:56:41,012 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:56:41,017 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:37486
scm1.org_1   | 2021-07-12 10:56:41,038 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-07-12 10:56:52,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48006
scm1.org_1   | 2021-07-12 10:56:52,463 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53346
scm1.org_1   | 2021-07-12 10:56:52,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:56:52,491 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-07-12 10:56:52,491 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48528
scm1.org_1   | 2021-07-12 10:56:52,493 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:19,819 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:19,835 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>nosuchbucket</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:25,008 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:25,025 [qtp1363396194-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-06357, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:46:25,042 [qtp1363396194-22] INFO endpoint.BucketEndpoint: Location is /bucket-06357
s3g_1        | 2021-07-12 10:46:25,462 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:25,885 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:25,901 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>ozonenosuchbucketqqweqwe</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:25,902 [qtp1363396194-23] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:131)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:68)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:295)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:31,098 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:31,110 [qtp1363396194-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-34856, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:46:31,120 [qtp1363396194-23] INFO endpoint.BucketEndpoint: Location is /bucket-34856
s3g_1        | 2021-07-12 10:46:31,521 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:36,662 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:36,675 [qtp1363396194-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-13754, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:46:36,686 [qtp1363396194-23] INFO endpoint.BucketEndpoint: Location is /bucket-13754
s3g_1        | 2021-07-12 10:46:37,131 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:37,597 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:38,197 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:38,292 [qtp1363396194-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E20536DCD83A->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:46:38,292 [qtp1363396194-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:46:41,587 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:41,699 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-8F575425963F->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:46:41,699 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:46:44,850 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:45,403 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:45,470 [qtp1363396194-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-91F5FF408829->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:46:45,471 [qtp1363396194-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:46:48,746 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:48,807 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BC83711B4D10->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:46:48,807 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:46:51,825 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:52,289 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:53,182 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:53,694 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:53,759 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0C1223B82B0B->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:46:53,759 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:46:54,328 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:54,378 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-8906FB9747CB->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:46:54,378 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:46:57,455 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:57,491 [qtp1363396194-23] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-13754, , key: 69181/multipartKey2
s3g_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 69181/multipartKey2. Entity too small.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:985)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:57,500 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>EntityTooSmall</Code>
s3g_1        |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
s3g_1        |   <Resource>69181/multipartKey2</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:102)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:57,972 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:58,456 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:58,483 [qtp1363396194-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-13754, , key: 49112/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:985)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:58,487 [qtp1363396194-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>49112/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:58,899 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:58,927 [qtp1363396194-23] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-13754, , key: 49112/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:985)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:58,928 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>49112/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:46:59,407 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:46:59,480 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5A84AD16C1DA->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:46:59,480 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:00,284 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:00,338 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6512B07F110C->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:00,338 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:03,488 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:03,540 [qtp1363396194-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6B52712C49ED->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:03,545 [qtp1363396194-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:06,598 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:06,626 [qtp1363396194-23] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-13754, , key: 49112/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-13754/49112/multipartKey3106567225797509153
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:985)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:06,629 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>49112/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:07,060 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:07,093 [qtp1363396194-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-13754, , key: 49112/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-13754/49112/multipartKey3106567225854722082
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:985)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:07,094 [qtp1363396194-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>49112/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:07,513 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:07,542 [qtp1363396194-23] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-13754, , key: 49112/multipartKey3
s3g_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-13754 key: 49112/multipartKey3 because parts are in Invalid order.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:985)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:07,543 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPartOrder</Code>
s3g_1        |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
s3g_1        |   <Resource>49112/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:97)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:07,954 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:08,408 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:09,180 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:09,665 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:10,143 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:10,177 [qtp1363396194-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:10,592 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:10,611 [qtp1363396194-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:11,051 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:11,629 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:11,695 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A0BEF54B7A07->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:47:11,695 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:12,424 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:12,493 [qtp1363396194-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-829AAEDC3C9C->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:12,493 [qtp1363396194-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:15,538 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:16,051 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:16,538 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:17,001 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:17,651 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:17,754 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:17,855 [qtp1363396194-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B8913D44BB87->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:17,856 [qtp1363396194-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:17,856 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:17,863 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:18,016 [qtp1363396194-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-14EF2A64FA90->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:47:18,016 [qtp1363396194-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:18,068 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-3B83728417CB->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:18,083 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:21,935 [qtp1363396194-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:22,428 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:22,586 [qtp1363396194-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:22,595 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:22,601 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:23,654 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:24,316 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:24,371 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1B6F8013B2FC->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:24,371 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:27,651 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:28,178 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:28,324 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0B0B05B453B2->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:28,324 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:31,457 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:31,928 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:32,690 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:32,735 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-916862484D38->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:32,735 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:36,038 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:36,521 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:36,712 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6C27378E52A6->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:47:36,713 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:37,792 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:37,909 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C0EF5CD608DB->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:37,911 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:40,963 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:41,460 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:42,377 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:42,425 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-11BD275188A6->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:42,427 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:46,307 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:46,792 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:46,829 [qtp1363396194-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-13754/00143/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:47,260 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:47,323 [qtp1363396194-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-13754/00143/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:47:47,758 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:47,885 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B5CD9127C69C->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:47,885 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:51,328 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:51,433 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B3A9C27FE78B->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:47:51,438 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:47:54,456 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:54,909 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:55,627 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:56,154 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:47:56,691 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:02,367 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:02,378 [qtp1363396194-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-44711, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:48:02,384 [qtp1363396194-17] INFO endpoint.BucketEndpoint: Location is /bucket-44711
s3g_1        | 2021-07-12 10:48:02,801 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:02,807 [qtp1363396194-20] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-38730, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:48:02,813 [qtp1363396194-20] INFO endpoint.BucketEndpoint: Location is /destbucket-38730
s3g_1        | 2021-07-12 10:48:03,245 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:03,340 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4ABB5000AE9A->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:48:03,340 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:48:03,902 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:04,351 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:04,417 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5E2F5EA7898A->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:48:04,417 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:48:07,470 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:07,911 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:07,990 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6A6A5DDCA8E9->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:48:07,990 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:48:11,041 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:11,478 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:11,488 [qtp1363396194-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:48:11,958 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:11,967 [qtp1363396194-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:48:12,435 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:12,904 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:12,917 [qtp1363396194-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchKey</Code>
s3g_1        |   <Message>The specified key does not exist</Message>
s3g_1        |   <Resource>nonnonexistentkey</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:48:18,051 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:18,081 [qtp1363396194-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-85901, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:48:18,095 [qtp1363396194-17] INFO endpoint.BucketEndpoint: Location is /bucket-85901
s3g_1        | 2021-07-12 10:48:18,533 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:18,597 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-2BE457BA58BE->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:48:18,598 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:48:19,103 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:19,556 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:20,044 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:20,485 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:20,937 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:21,381 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:21,811 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:21,841 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-50747E2579F5->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:48:21,841 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:48:22,401 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:22,931 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:23,344 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:23,776 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:24,238 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:24,276 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-AB5F0FC7E171->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:48:24,276 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:48:24,834 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:25,240 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:25,648 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:26,065 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:26,533 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:26,545 [qtp1363396194-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>bucket-85901-nosuchbucket</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:48:31,704 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:31,724 [qtp1363396194-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-85404, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:48:31,736 [qtp1363396194-20] INFO endpoint.BucketEndpoint: Location is /bucket-85404
s3g_1        | 2021-07-12 10:48:32,226 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:48:32,273 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0567C008EC42->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:48:32,274 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:49:32,907 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:49:33,061 [qtp1363396194-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-099FF08C3BF7->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:49:33,061 [qtp1363396194-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:50:34,153 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:50:34,257 [qtp1363396194-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E5F6AAA47AC3->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:50:34,257 [qtp1363396194-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:51:32,336 [qtp1363396194-17] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #186 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:381)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:225)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #186 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:367)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:372)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:367)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:356)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-07-12 10:51:32,341 [qtp1363396194-17] INFO scm.XceiverClientRatis: Could not commit index 129 on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]] to all the nodes. Server 1ab7aeaf-7670-4a86-9686-feb8bb11c16a has failed. Committed by majority.
s3g_1        | 2021-07-12 10:51:32,342 [qtp1363396194-17] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 107544261427200048 bcsId: 129 on Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]. Failed nodes: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-07-12 10:51:37,421 [qtp1363396194-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:51:37,587 [qtp1363396194-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1907F9A74D3E->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:51:37,587 [qtp1363396194-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:52:33,123 [qtp1363396194-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #190 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:381)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:225)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #190 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:367)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:372)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:367)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:356)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-07-12 10:52:33,128 [qtp1363396194-23] INFO scm.XceiverClientRatis: Could not commit index 133 on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]] to all the nodes. Server 1ab7aeaf-7670-4a86-9686-feb8bb11c16a has failed. Committed by majority.
s3g_1        | 2021-07-12 10:52:33,129 [qtp1363396194-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 107544261427200049 bcsId: 133 on Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]. Failed nodes: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-07-12 10:52:42,705 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:52:42,879 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-93C911050F6C->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:52:42,879 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:52:43,426 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:52:43,465 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E494AFA08E45->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:52:43,466 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:52:46,554 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:52:46,598 [qtp1363396194-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-D4DFB40BA693->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:52:46,599 [qtp1363396194-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:53:34,306 [qtp1363396194-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #194 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:381)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:225)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #194 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:367)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:372)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:367)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:356)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-07-12 10:53:34,315 [qtp1363396194-21] INFO scm.XceiverClientRatis: Could not commit index 136 on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]] to all the nodes. Server 1ab7aeaf-7670-4a86-9686-feb8bb11c16a has failed. Committed by majority.
s3g_1        | 2021-07-12 10:53:34,317 [qtp1363396194-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 107544261427200050 bcsId: 136 on Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]. Failed nodes: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-07-12 10:53:38,543 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:53:38,550 [qtp1363396194-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-28842, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:53:38,561 [qtp1363396194-17] INFO endpoint.BucketEndpoint: Location is /bucket-28842
s3g_1        | 2021-07-12 10:53:39,031 [qtp1363396194-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:53:39,080 [qtp1363396194-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-71ADBFF1C185->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:53:39,080 [qtp1363396194-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:53:47,418 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:53:47,452 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-EB20AC914130->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:53:47,453 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:54:37,646 [qtp1363396194-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #199 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:381)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:225)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #199 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:367)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:372)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:367)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:356)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-07-12 10:54:37,661 [qtp1363396194-20] INFO scm.XceiverClientRatis: Could not commit index 140 on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]] to all the nodes. Server 1ab7aeaf-7670-4a86-9686-feb8bb11c16a has failed. Committed by majority.
s3g_1        | 2021-07-12 10:54:37,661 [qtp1363396194-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 107544261427200051 bcsId: 140 on Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]. Failed nodes: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-07-12 10:54:39,345 [qtp1363396194-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:54:39,499 [qtp1363396194-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-459195D6C06A->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:54:39,499 [qtp1363396194-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:55:39,907 [qtp1363396194-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:55:40,039 [qtp1363396194-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-48D0B4F425AC->dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6
s3g_1        | 2021-07-12 10:55:40,039 [qtp1363396194-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:55:46,649 [qtp1363396194-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #211 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:381)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:225)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #211 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:367)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:372)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:367)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:356)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-07-12 10:55:46,653 [qtp1363396194-23] INFO scm.XceiverClientRatis: Could not commit index 144 on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]] to all the nodes. Server 1ab7aeaf-7670-4a86-9686-feb8bb11c16a has failed. Committed by majority.
s3g_1        | 2021-07-12 10:55:46,653 [qtp1363396194-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 107544261427200054 bcsId: 144 on Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]. Failed nodes: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-07-12 10:56:39,131 [qtp1363396194-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #216 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:381)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:225)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #216 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:367)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:372)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:367)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:356)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-07-12 10:56:39,143 [qtp1363396194-22] INFO scm.XceiverClientRatis: Could not commit index 148 on pipeline Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]] to all the nodes. Server 1ab7aeaf-7670-4a86-9686-feb8bb11c16a has failed. Committed by majority.
s3g_1        | 2021-07-12 10:56:39,143 [qtp1363396194-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 107544261427200055 bcsId: 148 on Pipeline[ Id: 834b1be7-db7b-48e4-83db-8025b34c7403, Nodes: 5244f159-1b5c-4bd3-a569-521c9d7b4032{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:dc1e489d-3e2b-4bb4-8ca3-3d22bbaeb9d6, CreationTimestamp2021-07-12T10:39:54.073Z[UTC]]. Failed nodes: [1ab7aeaf-7670-4a86-9686-feb8bb11c16a{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-07-12 10:56:40,881 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:41,028 [qtp1363396194-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-556053D7D75E->1ab7aeaf-7670-4a86-9686-feb8bb11c16a
s3g_1        | 2021-07-12 10:56:41,029 [qtp1363396194-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-07-12 10:56:41,558 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:42,097 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:42,772 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:43,548 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:44,281 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:44,845 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:45,384 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:45,928 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:45,943 [qtp1363396194-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=10000-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:56:46,477 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:47,150 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:47,798 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:48,407 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:49,017 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:49,618 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:50,211 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:50,864 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:51,478 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:51,501 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-0</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:56:52,031 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:52,040 [qtp1363396194-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-1</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:56:52,689 [qtp1363396194-23] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:56:52,697 [qtp1363396194-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-07-12 10:57:01,364 [qtp1363396194-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:214)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:201)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:194)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:134)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-07-12 10:57:01,376 [qtp1363396194-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-79856, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-07-12 10:57:01,388 [qtp1363396194-17] INFO endpoint.BucketEndpoint: Location is /bucket-79856
