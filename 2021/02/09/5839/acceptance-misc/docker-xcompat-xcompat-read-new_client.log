Attaching to xcompat_recon_1, xcompat_om_1, xcompat_old_client_1_0_0_1, xcompat_s3g_1, xcompat_old_client_0_5_0_1, xcompat_new_client_1, xcompat_datanode_2, xcompat_datanode_1, xcompat_datanode_3, xcompat_scm_1
datanode_1          | 2021-02-09 12:04:27 INFO  HddsDatanodeService:51 - STARTUP_MSG: 
datanode_1          | /************************************************************
datanode_1          | STARTUP_MSG: Starting HddsDatanodeService
datanode_1          | STARTUP_MSG:   host = d5919a0b6ddb/172.29.0.8
datanode_1          | STARTUP_MSG:   args = []
datanode_1          | STARTUP_MSG:   version = 3.2.0
datanode_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-beta.jar
datanode_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1          | STARTUP_MSG:   java = 11.0.3
datanode_1          | ************************************************************/
datanode_1          | 2021-02-09 12:04:27 INFO  HddsDatanodeService:51 - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1          | 2021-02-09 12:04:28 INFO  MetricRegistries:64 - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1          | 2021-02-09 12:04:29 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
datanode_1          | 2021-02-09 12:04:30 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
datanode_1          | 2021-02-09 12:04:30 INFO  MetricsSystemImpl:191 - HddsDatanode metrics system started
datanode_1          | 2021-02-09 12:04:31 INFO  HddsDatanodeService:204 - HddsDatanodeService host:d5919a0b6ddb ip:172.29.0.8
datanode_1          | 2021-02-09 12:04:32 INFO  SaveSpaceUsageToFile:94 - Cached usage info file /data/hdds/scmUsed not found
datanode_1          | 2021-02-09 12:04:32 INFO  HddsVolume:173 - Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1          | 2021-02-09 12:04:32 INFO  VolumeSet:180 - Added Volume : /data/hdds/hdds to VolumeSet
datanode_1          | 2021-02-09 12:04:32 INFO  ThrottledAsyncChecker:141 - Scheduling a check for /data/hdds/hdds
datanode_1          | 2021-02-09 12:04:32 INFO  HddsVolumeChecker:199 - Scheduled health check for volume /data/hdds/hdds
datanode_1          | 2021-02-09 12:04:36 WARN  ServerUtils:237 - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1          | 2021-02-09 12:04:36 INFO  RaftServerProxy:43 - raft.rpc.type = GRPC (default)
datanode_1          | 2021-02-09 12:04:37 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.port = 9858 (custom)
datanode_1          | 2021-02-09 12:04:37 INFO  GrpcService:43 - raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1          | 2021-02-09 12:04:37 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1          | 2021-02-09 12:04:37 INFO  GrpcService:43 - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1          | 2021-02-09 12:04:37 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
datanode_1          | 2021-02-09 12:04:38 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1          | 2021-02-09 12:04:38 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
datanode_1          | 2021-02-09 12:04:38 INFO  BaseHttpServer:170 - Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1          | 2021-02-09 12:04:38 INFO  log:169 - Logging initialized @16764ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1          | 2021-02-09 12:04:39 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1          | 2021-02-09 12:04:39 INFO  HttpRequestLog:86 - Http request log for http.requests.hddsDatanode is not defined
datanode_1          | 2021-02-09 12:04:39 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1          | 2021-02-09 12:04:39 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1          | 2021-02-09 12:04:39 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1          | 2021-02-09 12:04:39 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1          | 2021-02-09 12:04:39 INFO  HttpServer2:1188 - Jetty bound to port 9882
datanode_1          | 2021-02-09 12:04:39 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
datanode_1          | 2021-02-09 12:04:39 INFO  session:333 - DefaultSessionIdManager workerName=node0
datanode_1          | 2021-02-09 12:04:39 INFO  session:338 - No SessionScavenger set, using defaults
datanode_1          | 2021-02-09 12:04:39 INFO  session:140 - node0 Scavenging every 600000ms
datanode_1          | 2021-02-09 12:04:40 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@5b3bb1f7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1          | 2021-02-09 12:04:40 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@6c101cc1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/static,AVAILABLE}
datanode_1          | 2021-02-09 12:04:40 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@60a19573{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_5_0-beta_jar-_-any-461745936025956718.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/hddsDatanode}
datanode_1          | 2021-02-09 12:04:40 INFO  AbstractConnector:330 - Started ServerConnector@5399f6c5{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1          | 2021-02-09 12:04:40 INFO  Server:399 - Started @18561ms
datanode_1          | 2021-02-09 12:04:40 INFO  MetricsSinkAdapter:204 - Sink prometheus started
datanode_1          | 2021-02-09 12:04:40 INFO  MetricsSystemImpl:301 - Registered sink prometheus
datanode_1          | 2021-02-09 12:04:40 INFO  BaseHttpServer:284 - HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1          | 2021-02-09 12:04:40 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
datanode_1          | 2021-02-09 12:04:41 INFO  SCMConnectionManager:142 - Adding Recon Server : recon/172.29.0.3:9891
datanode_1          | 2021-02-09 12:04:41 INFO  InitDatanodeState:147 - DatanodeDetails is persisted to /data/datanode.id
datanode_1          | 2021-02-09 12:04:44 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1          | 2021-02-09 12:04:45 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1          | 2021-02-09 12:04:46 WARN  EndpointStateMachine:217 - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1          | java.net.SocketTimeoutException: Call From d5919a0b6ddb/172.29.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.29.0.8:52112 remote=scm/172.29.0.4:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_1          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_1          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_1          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_1          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_1          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_1          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_1          | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_1          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1          | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1          | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.29.0.8:52112 remote=scm/172.29.0.4:9861]
datanode_1          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_1          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_1          | 2021-02-09 12:04:46 INFO  OzoneContainer:230 - Attempting to start container services.
datanode_1          | 2021-02-09 12:04:46 INFO  OzoneContainer:194 - Background container scanner has been disabled.
datanode_1          | 2021-02-09 12:04:46 INFO  XceiverServerRatis:415 - Starting XceiverServerRatis 7795933c-0ec9-4552-88bf-a8f0b72b5dcd at port 9858
datanode_1          | 2021-02-09 12:04:46 INFO  RaftServerProxy:299 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: start RPC server
datanode_1          | 2021-02-09 12:04:46 INFO  GrpcService:158 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1          | 2021-02-09 12:04:49 INFO  RaftServerProxy:89 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: addNew group-4611C4F4D88A:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858] returns group-4611C4F4D88A:java.util.concurrent.CompletableFuture@d36cbd5[Not completed]
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerImpl:97 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: new RaftServerImpl for group-4611C4F4D88A:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858] with ContainerStateMachine:uninitialized
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerImpl:103 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A: ConfigurationManager, init=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/fefaf19a-195d-49fe-9b98-4611c4f4d88a does not exist. Creating ...
datanode_1          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/fefaf19a-195d-49fe-9b98-4611c4f4d88a/in_use.lock acquired by nodename 8@d5919a0b6ddb
datanode_1          | 2021-02-09 12:04:50 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/fefaf19a-195d-49fe-9b98-4611c4f4d88a has been successfully formatted.
datanode_1          | 2021-02-09 12:04:50 INFO  ContainerStateMachine:228 - group-4611C4F4D88A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_worker.7795933c-0ec9-4552-88bf-a8f0b72b5dcd
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:176 - new 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fefaf19a-195d-49fe-9b98-4611c4f4d88a
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:129 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A
datanode_1          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerImpl:183 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A: start as a follower, conf=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858], old=null
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerImpl:172 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1          | 2021-02-09 12:04:50 INFO  RoleInfo:143 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: start FollowerState
datanode_1          | 2021-02-09 12:04:50 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4611C4F4D88A,id=7795933c-0ec9-4552-88bf-a8f0b72b5dcd
datanode_1          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A
datanode_1          | 2021-02-09 12:04:50 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS ONE #id: "fefaf19a-195d-49fe-9b98-4611c4f4d88a"
datanode_1          | .
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerProxy:89 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: addNew group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] returns group-BB72A3DFD61C:java.util.concurrent.CompletableFuture@2308e70e[Not completed]
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerImpl:97 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: new RaftServerImpl for group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] with ContainerStateMachine:uninitialized
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerImpl:103 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C: ConfigurationManager, init=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c does not exist. Creating ...
datanode_1          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c/in_use.lock acquired by nodename 8@d5919a0b6ddb
datanode_1          | 2021-02-09 12:04:50 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c has been successfully formatted.
datanode_1          | 2021-02-09 12:04:50 INFO  ContainerStateMachine:228 - group-BB72A3DFD61C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:176 - new 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1          | 2021-02-09 12:04:51 INFO  SegmentedRaftLogWorker:129 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C
datanode_1          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerImpl:183 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C: start as a follower, conf=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null
datanode_1          | 2021-02-09 12:04:51 INFO  RaftServerImpl:172 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1          | 2021-02-09 12:04:51 INFO  RoleInfo:143 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: start FollowerState
datanode_1          | 2021-02-09 12:04:51 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BB72A3DFD61C,id=7795933c-0ec9-4552-88bf-a8f0b72b5dcd
datanode_1          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C
datanode_1          | 2021-02-09 12:04:52 WARN  RaftServerProxy:390 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: Failed groupAdd* GroupManagementRequest:client-C00FD9D055AE->7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C, cid=0, seq=0, RW, null, Add:group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858]
datanode_1          | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_1          | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1          | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1          | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1          | 	... 13 more
datanode_1          | 2021-02-09 12:04:52 WARN  RaftServerProxy:390 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: Failed groupAdd* GroupManagementRequest:client-4F50782E6CA1->7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C, cid=0, seq=0, RW, null, Add:group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858]
datanode_1          | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_1          | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1          | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1          | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1          | 	... 13 more
datanode_1          | 2021-02-09 12:04:53 WARN  CreatePipelineCommandHandler:106 - Add group failed for a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}
datanode_1          | org.apache.ratis.protocol.AlreadyExistsException: a0f1ab47-147d-4412-93a3-e8c518629eda: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1          | 2021-02-09 12:04:53 WARN  CreatePipelineCommandHandler:106 - Add group failed for cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
datanode_1          | org.apache.ratis.protocol.AlreadyExistsException: cfb3058e-3b88-4ed2-9e16-b0a6a7378325: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1          | 2021-02-09 12:04:53 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS THREE #id: "f4c032ab-45d5-43a3-a799-bb72a3dfd61c"
datanode_1          | .
datanode_1          | 2021-02-09 12:04:56 INFO  FollowerState:108 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A-FollowerState: change to CANDIDATE, lastRpcTime:5228ms, electionTimeout:5197ms
datanode_1          | 2021-02-09 12:04:56 INFO  RoleInfo:121 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: shutdown FollowerState
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerImpl:172 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1          | 2021-02-09 12:04:56 INFO  RoleInfo:143 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: start LeaderElection
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerImpl:172 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_1          | 2021-02-09 12:04:56 INFO  RoleInfo:121 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: shutdown FollowerState
datanode_1          | 2021-02-09 12:04:56 INFO  RoleInfo:143 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: start FollowerState
datanode_1          | 2021-02-09 12:04:56 INFO  FollowerState:117 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1          | 2021-02-09 12:04:56 INFO  LeaderElection:206 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A-LeaderElection1: begin an election at term 1 for -1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858], old=null
datanode_1          | 2021-02-09 12:04:56 INFO  RoleInfo:134 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: shutdown LeaderElection
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerImpl:172 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1          | 2021-02-09 12:04:56 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-4611C4F4D88A with new leaderId: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerImpl:255 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A: change Leader from null to 7795933c-0ec9-4552-88bf-a8f0b72b5dcd at term 1 for becomeLeader, leader elected after 5935ms
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.staging.catchup.gap = 1000 (default)
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.rpc.sleep.time = 25ms (default)
datanode_1          | 2021-02-09 12:04:56 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_appender.7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.write.element-limit = 1024 (custom)
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.write.byte-limit = 1073741824 (custom)
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout = 180s (custom)
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout.denomination = 1s (default)
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.element-limit = 65536 (default)
datanode_1          | 2021-02-09 12:04:56 INFO  RoleInfo:143 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: start LeaderState
datanode_1          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:391 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerImpl:356 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A: set configuration 0: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858], old=null at 0
datanode_1          | 2021-02-09 12:04:56 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-BB72A3DFD61C with new leaderId: cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerImpl:255 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C: change Leader from null to cfb3058e-3b88-4ed2-9e16-b0a6a7378325 at term 1 for appendEntries, leader elected after 5219ms
datanode_1          | 2021-02-09 12:04:56 INFO  RaftServerImpl:356 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C: set configuration 0: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null at 0
datanode_1          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:391 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:583 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-BB72A3DFD61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c/current/log_inprogress_0
datanode_1          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:583 - 7795933c-0ec9-4552-88bf-a8f0b72b5dcd@group-4611C4F4D88A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fefaf19a-195d-49fe-9b98-4611c4f4d88a/current/log_inprogress_0
datanode_1          | 2021-02-09 12:05:42 INFO  Client:948 - Retrying connect to server: recon/172.29.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=60000 MILLISECONDS)
datanode_2          | 2021-02-09 12:04:27 INFO  HddsDatanodeService:51 - STARTUP_MSG: 
datanode_2          | /************************************************************
datanode_2          | STARTUP_MSG: Starting HddsDatanodeService
datanode_2          | STARTUP_MSG:   host = a277492c44f8/172.29.0.9
datanode_2          | STARTUP_MSG:   args = []
datanode_2          | STARTUP_MSG:   version = 3.2.0
datanode_2          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-beta.jar
datanode_2          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2          | STARTUP_MSG:   java = 11.0.3
datanode_2          | ************************************************************/
datanode_2          | 2021-02-09 12:04:27 INFO  HddsDatanodeService:51 - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2          | 2021-02-09 12:04:28 INFO  MetricRegistries:64 - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2          | 2021-02-09 12:04:29 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
datanode_2          | 2021-02-09 12:04:30 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
datanode_2          | 2021-02-09 12:04:30 INFO  MetricsSystemImpl:191 - HddsDatanode metrics system started
datanode_2          | 2021-02-09 12:04:31 INFO  HddsDatanodeService:204 - HddsDatanodeService host:a277492c44f8 ip:172.29.0.9
datanode_2          | 2021-02-09 12:04:32 INFO  SaveSpaceUsageToFile:94 - Cached usage info file /data/hdds/scmUsed not found
datanode_2          | 2021-02-09 12:04:32 INFO  HddsVolume:173 - Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2          | 2021-02-09 12:04:32 INFO  VolumeSet:180 - Added Volume : /data/hdds/hdds to VolumeSet
datanode_2          | 2021-02-09 12:04:32 INFO  ThrottledAsyncChecker:141 - Scheduling a check for /data/hdds/hdds
datanode_2          | 2021-02-09 12:04:32 INFO  HddsVolumeChecker:199 - Scheduled health check for volume /data/hdds/hdds
datanode_2          | 2021-02-09 12:04:37 WARN  ServerUtils:237 - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2          | 2021-02-09 12:04:37 INFO  RaftServerProxy:43 - raft.rpc.type = GRPC (default)
datanode_2          | 2021-02-09 12:04:37 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.port = 9858 (custom)
datanode_2          | 2021-02-09 12:04:37 INFO  GrpcService:43 - raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2          | 2021-02-09 12:04:37 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2021-02-09 12:04:37 INFO  GrpcService:43 - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2          | 2021-02-09 12:04:37 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
datanode_2          | 2021-02-09 12:04:38 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2          | 2021-02-09 12:04:39 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
datanode_2          | 2021-02-09 12:04:39 INFO  BaseHttpServer:170 - Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2          | 2021-02-09 12:04:39 INFO  log:169 - Logging initialized @17733ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2          | 2021-02-09 12:04:40 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2          | 2021-02-09 12:04:40 INFO  HttpRequestLog:86 - Http request log for http.requests.hddsDatanode is not defined
datanode_2          | 2021-02-09 12:04:40 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2          | 2021-02-09 12:04:40 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2          | 2021-02-09 12:04:40 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2          | 2021-02-09 12:04:40 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2          | 2021-02-09 12:04:40 INFO  HttpServer2:1188 - Jetty bound to port 9882
datanode_2          | 2021-02-09 12:04:40 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
datanode_2          | 2021-02-09 12:04:40 INFO  session:333 - DefaultSessionIdManager workerName=node0
datanode_2          | 2021-02-09 12:04:40 INFO  session:338 - No SessionScavenger set, using defaults
datanode_2          | 2021-02-09 12:04:40 INFO  session:140 - node0 Scavenging every 600000ms
datanode_2          | 2021-02-09 12:04:40 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@4e682398{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2          | 2021-02-09 12:04:40 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@3f1a4795{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/static,AVAILABLE}
datanode_2          | 2021-02-09 12:04:41 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@3166f664{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_5_0-beta_jar-_-any-4779790111945723786.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/hddsDatanode}
datanode_2          | 2021-02-09 12:04:41 INFO  AbstractConnector:330 - Started ServerConnector@77c233af{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2          | 2021-02-09 12:04:41 INFO  Server:399 - Started @19099ms
datanode_2          | 2021-02-09 12:04:41 INFO  MetricsSinkAdapter:204 - Sink prometheus started
datanode_2          | 2021-02-09 12:04:41 INFO  MetricsSystemImpl:301 - Registered sink prometheus
datanode_2          | 2021-02-09 12:04:41 INFO  BaseHttpServer:284 - HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2          | 2021-02-09 12:04:41 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
datanode_2          | 2021-02-09 12:04:41 INFO  SCMConnectionManager:142 - Adding Recon Server : recon/172.29.0.3:9891
datanode_2          | 2021-02-09 12:04:41 INFO  InitDatanodeState:147 - DatanodeDetails is persisted to /data/datanode.id
datanode_2          | 2021-02-09 12:04:44 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2          | 2021-02-09 12:04:45 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2          | 2021-02-09 12:04:46 INFO  OzoneContainer:230 - Attempting to start container services.
datanode_2          | 2021-02-09 12:04:46 INFO  OzoneContainer:194 - Background container scanner has been disabled.
datanode_2          | 2021-02-09 12:04:46 INFO  XceiverServerRatis:415 - Starting XceiverServerRatis a0f1ab47-147d-4412-93a3-e8c518629eda at port 9858
datanode_2          | 2021-02-09 12:04:46 INFO  RaftServerProxy:299 - a0f1ab47-147d-4412-93a3-e8c518629eda: start RPC server
datanode_2          | 2021-02-09 12:04:46 INFO  GrpcService:158 - a0f1ab47-147d-4412-93a3-e8c518629eda: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerProxy:89 - a0f1ab47-147d-4412-93a3-e8c518629eda: addNew group-DA0908A8982B:[a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858] returns group-DA0908A8982B:java.util.concurrent.CompletableFuture@23c56639[Not completed]
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerImpl:97 - a0f1ab47-147d-4412-93a3-e8c518629eda: new RaftServerImpl for group-DA0908A8982B:[a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858] with ContainerStateMachine:uninitialized
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerImpl:103 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B: ConfigurationManager, init=-1: [a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/8b539453-2a7a-494f-a60d-da0908a8982b does not exist. Creating ...
datanode_2          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/8b539453-2a7a-494f-a60d-da0908a8982b/in_use.lock acquired by nodename 6@a277492c44f8
datanode_2          | 2021-02-09 12:04:50 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/8b539453-2a7a-494f-a60d-da0908a8982b has been successfully formatted.
datanode_2          | 2021-02-09 12:04:50 INFO  ContainerStateMachine:228 - group-DA0908A8982B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_worker.a0f1ab47-147d-4412-93a3-e8c518629eda
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:176 - new a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/8b539453-2a7a-494f-a60d-da0908a8982b
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:129 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B
datanode_2          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerImpl:183 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B: start as a follower, conf=-1: [a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858], old=null
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerImpl:172 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2          | 2021-02-09 12:04:51 INFO  RoleInfo:143 - a0f1ab47-147d-4412-93a3-e8c518629eda: start FollowerState
datanode_2          | 2021-02-09 12:04:51 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DA0908A8982B,id=a0f1ab47-147d-4412-93a3-e8c518629eda
datanode_2          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B
datanode_2          | 2021-02-09 12:04:51 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS ONE #id: "8b539453-2a7a-494f-a60d-da0908a8982b"
datanode_2          | .
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerProxy:89 - a0f1ab47-147d-4412-93a3-e8c518629eda: addNew group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] returns group-BB72A3DFD61C:java.util.concurrent.CompletableFuture@18bddfb4[Not completed]
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerImpl:97 - a0f1ab47-147d-4412-93a3-e8c518629eda: new RaftServerImpl for group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerImpl:103 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C: ConfigurationManager, init=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c does not exist. Creating ...
datanode_2          | 2021-02-09 12:04:51 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c/in_use.lock acquired by nodename 6@a277492c44f8
datanode_2          | 2021-02-09 12:04:51 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c has been successfully formatted.
datanode_2          | 2021-02-09 12:04:51 INFO  ContainerStateMachine:228 - group-BB72A3DFD61C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  SegmentedRaftLogWorker:176 - new a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  SegmentedRaftLogWorker:129 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C
datanode_2          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerImpl:183 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C: start as a follower, conf=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null
datanode_2          | 2021-02-09 12:04:51 INFO  RaftServerImpl:172 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2          | 2021-02-09 12:04:51 INFO  RoleInfo:143 - a0f1ab47-147d-4412-93a3-e8c518629eda: start FollowerState
datanode_2          | 2021-02-09 12:04:51 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BB72A3DFD61C,id=a0f1ab47-147d-4412-93a3-e8c518629eda
datanode_2          | 2021-02-09 12:04:51 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C
datanode_2          | 2021-02-09 12:04:52 WARN  RaftServerProxy:390 - a0f1ab47-147d-4412-93a3-e8c518629eda: Failed groupAdd* GroupManagementRequest:client-631BA6F9ABA8->a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C, cid=0, seq=0, RW, null, Add:group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858]
datanode_2          | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: a0f1ab47-147d-4412-93a3-e8c518629eda: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_2          | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2          | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2          | Caused by: org.apache.ratis.protocol.AlreadyExistsException: a0f1ab47-147d-4412-93a3-e8c518629eda: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2          | 	... 13 more
datanode_2          | 2021-02-09 12:04:52 WARN  RaftServerProxy:390 - a0f1ab47-147d-4412-93a3-e8c518629eda: Failed groupAdd* GroupManagementRequest:client-446B60164A1C->a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C, cid=1, seq=0, RW, null, Add:group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858]
datanode_3          | 2021-02-09 12:04:20 INFO  HddsDatanodeService:51 - STARTUP_MSG: 
datanode_3          | /************************************************************
datanode_3          | STARTUP_MSG: Starting HddsDatanodeService
datanode_3          | STARTUP_MSG:   host = 581a8437fa40/172.29.0.2
datanode_3          | STARTUP_MSG:   args = []
datanode_3          | STARTUP_MSG:   version = 3.2.0
datanode_3          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-beta.jar
datanode_2          | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: a0f1ab47-147d-4412-93a3-e8c518629eda: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_2          | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2          | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2          | Caused by: org.apache.ratis.protocol.AlreadyExistsException: a0f1ab47-147d-4412-93a3-e8c518629eda: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2          | 	... 13 more
datanode_2          | 2021-02-09 12:04:53 WARN  CreatePipelineCommandHandler:106 - Add group failed for 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}
datanode_2          | org.apache.ratis.protocol.AlreadyExistsException: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2          | 2021-02-09 12:04:53 WARN  CreatePipelineCommandHandler:106 - Add group failed for cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
datanode_2          | org.apache.ratis.protocol.AlreadyExistsException: cfb3058e-3b88-4ed2-9e16-b0a6a7378325: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2          | 2021-02-09 12:04:53 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS THREE #id: "f4c032ab-45d5-43a3-a799-bb72a3dfd61c"
datanode_2          | .
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerImpl:172 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_2          | 2021-02-09 12:04:56 INFO  RoleInfo:121 - a0f1ab47-147d-4412-93a3-e8c518629eda: shutdown FollowerState
datanode_2          | 2021-02-09 12:04:56 INFO  FollowerState:117 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3          | STARTUP_MSG:   java = 11.0.3
datanode_3          | ************************************************************/
datanode_3          | 2021-02-09 12:04:20 INFO  HddsDatanodeService:51 - registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3          | 2021-02-09 12:04:21 INFO  MetricRegistries:64 - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3          | 2021-02-09 12:04:21 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
datanode_3          | 2021-02-09 12:04:22 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
datanode_3          | 2021-02-09 12:04:22 INFO  MetricsSystemImpl:191 - HddsDatanode metrics system started
datanode_3          | 2021-02-09 12:04:24 INFO  HddsDatanodeService:204 - HddsDatanodeService host:581a8437fa40 ip:172.29.0.2
datanode_3          | 2021-02-09 12:04:24 INFO  SaveSpaceUsageToFile:94 - Cached usage info file /data/hdds/scmUsed not found
datanode_3          | 2021-02-09 12:04:24 INFO  HddsVolume:173 - Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3          | 2021-02-09 12:04:24 INFO  VolumeSet:180 - Added Volume : /data/hdds/hdds to VolumeSet
datanode_3          | 2021-02-09 12:04:24 INFO  ThrottledAsyncChecker:141 - Scheduling a check for /data/hdds/hdds
datanode_3          | 2021-02-09 12:04:24 INFO  HddsVolumeChecker:199 - Scheduled health check for volume /data/hdds/hdds
datanode_3          | 2021-02-09 12:04:30 WARN  ServerUtils:237 - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3          | 2021-02-09 12:04:30 INFO  RaftServerProxy:43 - raft.rpc.type = GRPC (default)
datanode_3          | 2021-02-09 12:04:31 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.port = 9858 (custom)
datanode_3          | 2021-02-09 12:04:31 INFO  GrpcService:43 - raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3          | 2021-02-09 12:04:31 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2021-02-09 12:04:31 INFO  GrpcService:43 - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3          | 2021-02-09 12:04:31 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
datanode_3          | 2021-02-09 12:04:32 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3          | 2021-02-09 12:04:32 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
datanode_3          | 2021-02-09 12:04:33 INFO  BaseHttpServer:170 - Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3          | 2021-02-09 12:04:33 INFO  log:169 - Logging initialized @13855ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3          | 2021-02-09 12:04:33 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3          | 2021-02-09 12:04:33 INFO  HttpRequestLog:86 - Http request log for http.requests.hddsDatanode is not defined
datanode_3          | 2021-02-09 12:04:33 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3          | 2021-02-09 12:04:33 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3          | 2021-02-09 12:04:33 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3          | 2021-02-09 12:04:33 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3          | 2021-02-09 12:04:33 INFO  HttpServer2:1188 - Jetty bound to port 9882
datanode_3          | 2021-02-09 12:04:33 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
datanode_3          | 2021-02-09 12:04:33 INFO  session:333 - DefaultSessionIdManager workerName=node0
datanode_3          | 2021-02-09 12:04:33 INFO  session:338 - No SessionScavenger set, using defaults
datanode_3          | 2021-02-09 12:04:33 INFO  session:140 - node0 Scavenging every 600000ms
datanode_3          | 2021-02-09 12:04:33 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@670b3ca{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3          | 2021-02-09 12:04:33 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@6a6f6c7e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/static,AVAILABLE}
datanode_3          | 2021-02-09 12:04:34 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@47ac613b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_5_0-beta_jar-_-any-1933951231781250480.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/hddsDatanode}
datanode_3          | 2021-02-09 12:04:34 INFO  AbstractConnector:330 - Started ServerConnector@37b56ac7{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3          | 2021-02-09 12:04:34 INFO  Server:399 - Started @15116ms
datanode_3          | 2021-02-09 12:04:34 INFO  MetricsSinkAdapter:204 - Sink prometheus started
datanode_3          | 2021-02-09 12:04:34 INFO  MetricsSystemImpl:301 - Registered sink prometheus
datanode_3          | 2021-02-09 12:04:34 INFO  BaseHttpServer:284 - HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3          | 2021-02-09 12:04:34 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
datanode_3          | 2021-02-09 12:04:35 INFO  SCMConnectionManager:142 - Adding Recon Server : recon/172.29.0.3:9891
datanode_3          | 2021-02-09 12:04:35 INFO  InitDatanodeState:147 - DatanodeDetails is persisted to /data/datanode.id
datanode_3          | 2021-02-09 12:04:38 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3          | 2021-02-09 12:04:39 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3          | 2021-02-09 12:04:40 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3          | 2021-02-09 12:04:41 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3          | 2021-02-09 12:04:42 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3          | 2021-02-09 12:04:43 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3          | 2021-02-09 12:04:44 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3          | 2021-02-09 12:04:45 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3          | 2021-02-09 12:04:46 WARN  EndpointStateMachine:217 - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2          | 2021-02-09 12:04:56 INFO  RoleInfo:143 - a0f1ab47-147d-4412-93a3-e8c518629eda: start FollowerState
datanode_2          | 2021-02-09 12:04:56 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-BB72A3DFD61C with new leaderId: cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerImpl:255 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C: change Leader from null to cfb3058e-3b88-4ed2-9e16-b0a6a7378325 at term 1 for appendEntries, leader elected after 4902ms
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerImpl:356 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C: set configuration 0: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null at 0
datanode_2          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:391 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:583 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-BB72A3DFD61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c/current/log_inprogress_0
datanode_2          | 2021-02-09 12:04:56 INFO  FollowerState:108 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B-FollowerState: change to CANDIDATE, lastRpcTime:5229ms, electionTimeout:5179ms
datanode_2          | 2021-02-09 12:04:56 INFO  RoleInfo:121 - a0f1ab47-147d-4412-93a3-e8c518629eda: shutdown FollowerState
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerImpl:172 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2          | 2021-02-09 12:04:56 INFO  RoleInfo:143 - a0f1ab47-147d-4412-93a3-e8c518629eda: start LeaderElection
datanode_2          | 2021-02-09 12:04:56 INFO  LeaderElection:206 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B-LeaderElection1: begin an election at term 1 for -1: [a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858], old=null
datanode_2          | 2021-02-09 12:04:56 INFO  RoleInfo:134 - a0f1ab47-147d-4412-93a3-e8c518629eda: shutdown LeaderElection
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerImpl:172 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2          | 2021-02-09 12:04:56 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-DA0908A8982B with new leaderId: a0f1ab47-147d-4412-93a3-e8c518629eda
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerImpl:255 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B: change Leader from null to a0f1ab47-147d-4412-93a3-e8c518629eda at term 1 for becomeLeader, leader elected after 5884ms
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.staging.catchup.gap = 1000 (default)
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.rpc.sleep.time = 25ms (default)
datanode_2          | 2021-02-09 12:04:56 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_appender.a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.write.element-limit = 1024 (custom)
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.write.byte-limit = 1073741824 (custom)
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout = 180s (custom)
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout.denomination = 1s (default)
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.element-limit = 65536 (default)
datanode_2          | 2021-02-09 12:04:56 INFO  RoleInfo:143 - a0f1ab47-147d-4412-93a3-e8c518629eda: start LeaderState
datanode_2          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:391 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2          | 2021-02-09 12:04:56 INFO  RaftServerImpl:356 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B: set configuration 0: [a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858], old=null at 0
datanode_2          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:583 - a0f1ab47-147d-4412-93a3-e8c518629eda@group-DA0908A8982B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8b539453-2a7a-494f-a60d-da0908a8982b/current/log_inprogress_0
datanode_2          | 2021-02-09 12:05:43 INFO  Client:948 - Retrying connect to server: recon/172.29.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=60000 MILLISECONDS)
datanode_3          | java.net.SocketTimeoutException: Call From 581a8437fa40/172.29.0.2 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.29.0.2:46368 remote=scm/172.29.0.4:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_3          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_3          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_3          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_3          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_3          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_3          | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_3          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_3          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_3          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3          | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3          | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.29.0.2:46368 remote=scm/172.29.0.4:9861]
datanode_3          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_3          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_3          | 2021-02-09 12:04:46 INFO  OzoneContainer:230 - Attempting to start container services.
datanode_3          | 2021-02-09 12:04:46 INFO  OzoneContainer:194 - Background container scanner has been disabled.
datanode_3          | 2021-02-09 12:04:46 INFO  XceiverServerRatis:415 - Starting XceiverServerRatis cfb3058e-3b88-4ed2-9e16-b0a6a7378325 at port 9858
datanode_3          | 2021-02-09 12:04:46 INFO  RaftServerProxy:299 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: start RPC server
datanode_3          | 2021-02-09 12:04:46 INFO  GrpcService:158 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerProxy:89 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: addNew group-B85B210C214C:[cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] returns group-B85B210C214C:java.util.concurrent.CompletableFuture@8ffedec[Not completed]
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerImpl:97 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: new RaftServerImpl for group-B85B210C214C:[cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerImpl:103 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C: ConfigurationManager, init=-1: [cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3          | 2021-02-09 12:04:49 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/926c10b0-5799-49ed-af11-b85b210c214c does not exist. Creating ...
datanode_3          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/926c10b0-5799-49ed-af11-b85b210c214c/in_use.lock acquired by nodename 8@581a8437fa40
datanode_3          | 2021-02-09 12:04:50 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/926c10b0-5799-49ed-af11-b85b210c214c has been successfully formatted.
datanode_3          | 2021-02-09 12:04:50 INFO  ContainerStateMachine:228 - group-B85B210C214C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_worker.cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:176 - new cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/926c10b0-5799-49ed-af11-b85b210c214c
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:129 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C
datanode_3          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerImpl:183 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C: start as a follower, conf=-1: [cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerImpl:172 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3          | 2021-02-09 12:04:50 INFO  RoleInfo:143 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: start FollowerState
datanode_3          | 2021-02-09 12:04:50 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B85B210C214C,id=cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_3          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C
datanode_3          | 2021-02-09 12:04:50 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS ONE #id: "926c10b0-5799-49ed-af11-b85b210c214c"
datanode_3          | .
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerProxy:89 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: addNew group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] returns group-BB72A3DFD61C:java.util.concurrent.CompletableFuture@56088269[Not completed]
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerImpl:97 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: new RaftServerImpl for group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerImpl:103 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C: ConfigurationManager, init=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c does not exist. Creating ...
datanode_3          | 2021-02-09 12:04:50 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c/in_use.lock acquired by nodename 8@581a8437fa40
datanode_3          | 2021-02-09 12:04:50 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c has been successfully formatted.
datanode_3          | 2021-02-09 12:04:50 INFO  ContainerStateMachine:228 - group-BB72A3DFD61C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:176 - new cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  SegmentedRaftLogWorker:129 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C
datanode_3          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerImpl:183 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C: start as a follower, conf=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null
datanode_3          | 2021-02-09 12:04:50 INFO  RaftServerImpl:172 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3          | 2021-02-09 12:04:50 INFO  RoleInfo:143 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: start FollowerState
datanode_3          | 2021-02-09 12:04:50 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BB72A3DFD61C,id=cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_3          | 2021-02-09 12:04:50 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C
datanode_3          | 2021-02-09 12:04:52 WARN  CreatePipelineCommandHandler:106 - Add group failed for 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}
datanode_3          | org.apache.ratis.protocol.AlreadyExistsException: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3          | 2021-02-09 12:04:53 WARN  CreatePipelineCommandHandler:106 - Add group failed for a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}
datanode_3          | org.apache.ratis.protocol.AlreadyExistsException: a0f1ab47-147d-4412-93a3-e8c518629eda: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3          | 2021-02-09 12:04:53 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS THREE #id: "f4c032ab-45d5-43a3-a799-bb72a3dfd61c"
datanode_3          | .
datanode_3          | 2021-02-09 12:04:53 WARN  RaftServerProxy:390 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: Failed groupAdd* GroupManagementRequest:client-9C94850FD19F->cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C, cid=1, seq=0, RW, null, Add:group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858]
datanode_3          | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: cfb3058e-3b88-4ed2-9e16-b0a6a7378325: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_3          | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3          | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
om_1                | 2021-02-09 12:04:26 INFO  OzoneManagerStarter:51 - STARTUP_MSG: 
om_1                | /************************************************************
om_1                | STARTUP_MSG: Starting OzoneManager
om_1                | STARTUP_MSG:   host = ee6189d13ae0/172.29.0.11
om_1                | STARTUP_MSG:   args = [--init]
om_1                | STARTUP_MSG:   version = 3.2.0
datanode_3          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3          | Caused by: org.apache.ratis.protocol.AlreadyExistsException: cfb3058e-3b88-4ed2-9e16-b0a6a7378325: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3          | 	... 13 more
datanode_3          | 2021-02-09 12:04:53 WARN  RaftServerProxy:390 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: Failed groupAdd* GroupManagementRequest:client-B8EC02E81BA0->cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C, cid=1, seq=0, RW, null, Add:group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858]
datanode_3          | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: cfb3058e-3b88-4ed2-9e16-b0a6a7378325: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_3          | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3          | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3          | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3          | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3          | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3          | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3          | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3          | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3          | Caused by: org.apache.ratis.protocol.AlreadyExistsException: cfb3058e-3b88-4ed2-9e16-b0a6a7378325: Failed to add group-BB72A3DFD61C:[7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858] since the group already exists in the map.
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3          | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3          | 	... 13 more
datanode_3          | 2021-02-09 12:04:55 INFO  FollowerState:108 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C-FollowerState: change to CANDIDATE, lastRpcTime:5200ms, electionTimeout:5195ms
datanode_3          | 2021-02-09 12:04:55 INFO  RoleInfo:121 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: shutdown FollowerState
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerImpl:172 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3          | 2021-02-09 12:04:55 INFO  RoleInfo:143 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: start LeaderElection
datanode_3          | 2021-02-09 12:04:55 INFO  LeaderElection:206 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C-LeaderElection1: begin an election at term 1 for -1: [cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null
datanode_3          | 2021-02-09 12:04:55 INFO  RoleInfo:134 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: shutdown LeaderElection
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerImpl:172 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3          | 2021-02-09 12:04:55 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-B85B210C214C with new leaderId: cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerImpl:255 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C: change Leader from null to cfb3058e-3b88-4ed2-9e16-b0a6a7378325 at term 1 for becomeLeader, leader elected after 5744ms
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerConfigKeys:43 - raft.server.staging.catchup.gap = 1000 (default)
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerConfigKeys:43 - raft.server.rpc.sleep.time = 25ms (default)
datanode_3          | 2021-02-09 12:04:55 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_appender.cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerConfigKeys:43 - raft.server.write.element-limit = 1024 (custom)
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerConfigKeys:43 - raft.server.write.byte-limit = 1073741824 (custom)
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout = 180s (custom)
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout.denomination = 1s (default)
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerConfigKeys:43 - raft.server.watch.element-limit = 65536 (default)
datanode_3          | 2021-02-09 12:04:55 INFO  RoleInfo:143 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: start LeaderState
datanode_3          | 2021-02-09 12:04:55 INFO  SegmentedRaftLogWorker:391 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerImpl:356 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C: set configuration 0: [cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null at 0
om_1                | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-beta.jar
om_1                | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1                | STARTUP_MSG:   java = 11.0.3
om_1                | ************************************************************/
om_1                | 2021-02-09 12:04:26 INFO  OzoneManagerStarter:51 - registered UNIX signal handlers for [TERM, HUP, INT]
om_1                | 2021-02-09 12:04:31 INFO  OMHANodeDetails:104 - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1                | 2021-02-09 12:04:31 INFO  OMHANodeDetails:207 - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.29.0.11:9862
om_1                | 2021-02-09 12:04:31 INFO  OMHANodeDetails:237 - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1                | 2021-02-09 12:04:31 WARN  ServerUtils:225 - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1                | 2021-02-09 12:04:31 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
om_1                | 2021-02-09 12:04:33 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:34 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:35 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:36 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:37 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:38 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:39 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:40 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:41 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:42 INFO  Client:948 - Retrying connect to server: scm/172.29.0.4:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1                | 2021-02-09 12:04:42 INFO  RetriableTask:62 - Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1                | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-fbf6fe82-91d7-436f-8e5f-321c52f3e9d4
om_1                | 2021-02-09 12:04:47 INFO  OzoneManagerStarter:51 - SHUTDOWN_MSG: 
om_1                | /************************************************************
om_1                | SHUTDOWN_MSG: Shutting down OzoneManager at ee6189d13ae0/172.29.0.11
om_1                | ************************************************************/
om_1                | 2021-02-09 12:04:48 INFO  OzoneManagerStarter:51 - STARTUP_MSG: 
om_1                | /************************************************************
om_1                | STARTUP_MSG: Starting OzoneManager
om_1                | STARTUP_MSG:   host = ee6189d13ae0/172.29.0.11
om_1                | STARTUP_MSG:   args = []
om_1                | STARTUP_MSG:   version = 3.2.0
datanode_3          | 2021-02-09 12:04:55 INFO  SegmentedRaftLogWorker:583 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-B85B210C214C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/926c10b0-5799-49ed-af11-b85b210c214c/current/log_inprogress_0
datanode_3          | 2021-02-09 12:04:55 INFO  FollowerState:108 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C-FollowerState: change to CANDIDATE, lastRpcTime:5190ms, electionTimeout:5167ms
datanode_3          | 2021-02-09 12:04:55 INFO  RoleInfo:121 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: shutdown FollowerState
datanode_3          | 2021-02-09 12:04:55 INFO  RaftServerImpl:172 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3          | 2021-02-09 12:04:55 INFO  RoleInfo:143 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: start LeaderElection
datanode_3          | 2021-02-09 12:04:55 INFO  LeaderElection:206 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C-LeaderElection2: begin an election at term 1 for -1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null
datanode_3          | 2021-02-09 12:04:56 INFO  LeaderElection:61 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C-LeaderElection2: Election PASSED; received 1 response(s) [cfb3058e-3b88-4ed2-9e16-b0a6a7378325<-a0f1ab47-147d-4412-93a3-e8c518629eda#0:OK-t1] and 0 exception(s); cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C:t1, leader=null, voted=cfb3058e-3b88-4ed2-9e16-b0a6a7378325, raftlog=cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null
datanode_3          | 2021-02-09 12:04:56 INFO  RoleInfo:134 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: shutdown LeaderElection
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerImpl:172 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3          | 2021-02-09 12:04:56 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-BB72A3DFD61C with new leaderId: cfb3058e-3b88-4ed2-9e16-b0a6a7378325
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerImpl:255 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C: change Leader from null to cfb3058e-3b88-4ed2-9e16-b0a6a7378325 at term 1 for becomeLeader, leader elected after 5328ms
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.staging.catchup.gap = 1000 (default)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.rpc.sleep.time = 25ms (default)
datanode_3          | 2021-02-09 12:04:56 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_appender.cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.write.element-limit = 1024 (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.write.byte-limit = 1073741824 (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout = 180s (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout.denomination = 1s (default)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.watch.element-limit = 65536 (default)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2021-02-09 12:04:56 INFO  RoleInfo:143 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325: start LeaderState
datanode_3          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:391 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3          | 2021-02-09 12:04:56 INFO  SegmentedRaftLogWorker:583 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f4c032ab-45d5-43a3-a799-bb72a3dfd61c/current/log_inprogress_0
datanode_3          | 2021-02-09 12:04:56 INFO  RaftServerImpl:356 - cfb3058e-3b88-4ed2-9e16-b0a6a7378325@group-BB72A3DFD61C: set configuration 0: [7795933c-0ec9-4552-88bf-a8f0b72b5dcd:172.29.0.8:9858, a0f1ab47-147d-4412-93a3-e8c518629eda:172.29.0.9:9858, cfb3058e-3b88-4ed2-9e16-b0a6a7378325:172.29.0.2:9858], old=null at 0
datanode_3          | 2021-02-09 12:05:37 INFO  Client:948 - Retrying connect to server: recon/172.29.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=60000 MILLISECONDS)
om_1                | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-beta.jar
om_1                | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1                | STARTUP_MSG:   java = 11.0.3
om_1                | ************************************************************/
om_1                | 2021-02-09 12:04:48 INFO  OzoneManagerStarter:51 - registered UNIX signal handlers for [TERM, HUP, INT]
om_1                | 2021-02-09 12:04:50 INFO  OMHANodeDetails:104 - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1                | 2021-02-09 12:04:51 INFO  OMHANodeDetails:207 - Configuration either no ozone.om.address set. Falling back to the default OM address om/172.29.0.11:9862
om_1                | 2021-02-09 12:04:51 INFO  OMHANodeDetails:237 - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1                | 2021-02-09 12:04:51 WARN  ServerUtils:225 - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1                | 2021-02-09 12:04:51 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
om_1                | 2021-02-09 12:04:51 WARN  ServerUtils:225 - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1                | 2021-02-09 12:04:53 WARN  ServerUtils:225 - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1                | 2021-02-09 12:04:54 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1                | 2021-02-09 12:04:54 INFO  Server:1074 - Starting Socket Reader #1 for port 9862
om_1                | 2021-02-09 12:04:54 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
om_1                | 2021-02-09 12:04:54 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
om_1                | 2021-02-09 12:04:54 INFO  MetricsSystemImpl:191 - OzoneManager metrics system started
om_1                | 2021-02-09 12:04:54 INFO  OzoneManager:1105 - OzoneManager RPC server is listening at om/172.29.0.11:9862
om_1                | 2021-02-09 12:04:54 INFO  Server:1314 - IPC Server Responder: starting
om_1                | 2021-02-09 12:04:54 INFO  Server:1153 - IPC Server listener on 9862: starting
om_1                | 2021-02-09 12:04:54 INFO  BaseHttpServer:170 - Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1                | 2021-02-09 12:04:54 INFO  log:169 - Logging initialized @6762ms to org.eclipse.jetty.util.log.Slf4jLog
om_1                | 2021-02-09 12:04:54 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1                | 2021-02-09 12:04:54 INFO  HttpRequestLog:86 - Http request log for http.requests.ozoneManager is not defined
om_1                | 2021-02-09 12:04:54 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1                | 2021-02-09 12:04:54 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1                | 2021-02-09 12:04:54 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
om_1                | 2021-02-09 12:04:54 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
om_1                | 2021-02-09 12:04:54 INFO  HttpServer2:1188 - Jetty bound to port 9874
om_1                | 2021-02-09 12:04:54 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
om_1                | 2021-02-09 12:04:54 INFO  session:333 - DefaultSessionIdManager workerName=node0
om_1                | 2021-02-09 12:04:54 INFO  session:338 - No SessionScavenger set, using defaults
om_1                | 2021-02-09 12:04:54 INFO  session:140 - node0 Scavenging every 600000ms
s3g_1               | 2021-02-09 12:04:28 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
s3g_1               | 2021-02-09 12:04:29 INFO  BaseHttpServer:170 - Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1               | 2021-02-09 12:04:29 INFO  log:169 - Logging initialized @7057ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1               | 2021-02-09 12:04:29 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1               | 2021-02-09 12:04:30 INFO  HttpRequestLog:86 - Http request log for http.requests.s3gateway is not defined
s3g_1               | 2021-02-09 12:04:30 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1               | 2021-02-09 12:04:30 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1               | 2021-02-09 12:04:30 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1               | 2021-02-09 12:04:30 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1               | 2021-02-09 12:04:30 INFO  Gateway:58 - Starting Ozone S3 gateway
s3g_1               | 2021-02-09 12:04:30 INFO  HttpServer2:1188 - Jetty bound to port 9878
s3g_1               | 2021-02-09 12:04:30 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
s3g_1               | 2021-02-09 12:04:30 INFO  session:333 - DefaultSessionIdManager workerName=node0
s3g_1               | 2021-02-09 12:04:30 INFO  session:338 - No SessionScavenger set, using defaults
s3g_1               | 2021-02-09 12:04:30 INFO  session:140 - node0 Scavenging every 600000ms
s3g_1               | 2021-02-09 12:04:30 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@626abbd0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1               | 2021-02-09 12:04:30 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@14dd7b39{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-beta.jar!/webapps/static,AVAILABLE}
s3g_1               | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1               | WARNING: An illegal reflective access operation has occurred
s3g_1               | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1               | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1               | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1               | WARNING: All illegal access operations will be denied in a future release
s3g_1               | Feb 09, 2021 12:04:43 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1               | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1               | 
s3g_1               | 2021-02-09 12:04:43 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@4bf80c29{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_5_0-beta_jar-_-any-12573140735448458201.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-beta.jar!/webapps/s3gateway}
s3g_1               | 2021-02-09 12:04:43 INFO  AbstractConnector:330 - Started ServerConnector@4ef74c30{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1               | 2021-02-09 12:04:43 INFO  Server:399 - Started @21226ms
s3g_1               | 2021-02-09 12:04:43 INFO  BaseHttpServer:284 - HTTP server of s3gateway listening at http://0.0.0.0:9878
om_1                | 2021-02-09 12:04:54 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@506a1372{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1                | 2021-02-09 12:04:54 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@5399f6c5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-beta.jar!/webapps/static,AVAILABLE}
om_1                | 2021-02-09 12:04:54 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@326e0b8e{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_5_0-beta_jar-_-any-6692909222272232418.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-beta.jar!/webapps/ozoneManager}
om_1                | 2021-02-09 12:04:54 INFO  AbstractConnector:330 - Started ServerConnector@541179e7{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1                | 2021-02-09 12:04:54 INFO  Server:399 - Started @7045ms
om_1                | 2021-02-09 12:04:55 INFO  MetricsSinkAdapter:204 - Sink prometheus started
om_1                | 2021-02-09 12:04:55 INFO  MetricsSystemImpl:301 - Registered sink prometheus
om_1                | 2021-02-09 12:04:55 INFO  BaseHttpServer:284 - HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1                | 2021-02-09 12:05:02 INFO  OMVolumeCreateRequest:207 - created volume:vol1 for user:hadoop
om_1                | 2021-02-09 12:05:45 INFO  OMDBCheckpointServlet:95 - Received request to obtain OM DB checkpoint snapshot
om_1                | 2021-02-09 12:05:45 INFO  RDBCheckpointManager:86 - Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1612872345916 in 14 milliseconds
om_1                | 2021-02-09 12:05:45 INFO  OMDBCheckpointServlet:162 - Time taken to write the checkpoint to response output stream: 45 milliseconds
om_1                | 2021-02-09 12:05:45 INFO  RocksDBCheckpoint:80 - Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1612872345916
recon_1             | WARNING: An illegal reflective access operation has occurred
recon_1             | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1             | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1             | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1             | WARNING: All illegal access operations will be denied in a future release
recon_1             | 2021-02-09 12:04:29 INFO  ReconRestServletModule:75 - rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1             | 2021-02-09 12:04:31 INFO  ReconServer:73 - Initializing Recon server...
recon_1             | 2021-02-09 12:04:35 INFO  ReconServer:81 - Creating Recon Schema.
recon_1             | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1             | 2021-02-09 12:04:38 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
recon_1             | 2021-02-09 12:04:38 INFO  BaseHttpServer:170 - Starting Web-server for recon at: http://0.0.0.0:9888
recon_1             | 2021-02-09 12:04:38 INFO  log:169 - Logging initialized @15067ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1             | 2021-02-09 12:04:39 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1             | 2021-02-09 12:04:39 WARN  HttpRequestLog:103 - Jetty request log can only be enabled using Log4j
recon_1             | 2021-02-09 12:04:39 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1             | 2021-02-09 12:04:39 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1             | 2021-02-09 12:04:39 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
recon_1             | 2021-02-09 12:04:39 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1             | 2021-02-09 12:04:39 INFO  ReconTaskControllerImpl:81 - Registered task ContainerKeyMapperTask with controller.
recon_1             | 2021-02-09 12:04:41 INFO  ReconTaskControllerImpl:81 - Registered task FileSizeCountTask with controller.
recon_1             | 2021-02-09 12:04:41 WARN  ReconUtils:88 - ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2021-02-09 12:04:41 INFO  deprecation:1394 - No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1             | 2021-02-09 12:04:43 WARN  ReconUtils:88 - ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2021-02-09 12:04:43 INFO  NodeSchemaLoader:126 - Loading file from java.lang.CompoundEnumeration@5d5a51b1
recon_1             | 2021-02-09 12:04:43 INFO  NodeSchemaLoader:172 - Loading network topology layer schema file
recon_1             | 2021-02-09 12:04:43 INFO  SCMNodeManager:116 - Entering startup safe mode.
recon_1             | 2021-02-09 12:04:43 WARN  ReconUtils:88 - ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2021-02-09 12:04:43 INFO  ReconNodeManager:93 - Loaded 0 nodes from node DB.
recon_1             | 2021-02-09 12:04:43 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1             | 2021-02-09 12:04:43 INFO  Server:1074 - Starting Socket Reader #1 for port 9891
recon_1             | 2021-02-09 12:04:43 WARN  ReconUtils:88 - ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2021-02-09 12:04:43 INFO  SCMPipelineManager:150 - No pipeline exists in current db
recon_1             | 2021-02-09 12:04:43 WARN  ReconUtils:88 - ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2021-02-09 12:04:43 INFO  ReconScmTask:49 - Registered MissingContainerTask task 
recon_1             | 2021-02-09 12:04:43 INFO  ReconScmTask:49 - Registered PipelineSyncTask task 
recon_1             | 2021-02-09 12:04:43 INFO  ReconServer:89 - Recon server initialized successfully!
recon_1             | 2021-02-09 12:04:43 INFO  ReconServer:114 - Starting Recon server
recon_1             | 2021-02-09 12:04:43 INFO  HttpServer2:1188 - Jetty bound to port 9888
recon_1             | 2021-02-09 12:04:43 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
recon_1             | 2021-02-09 12:04:43 INFO  session:333 - DefaultSessionIdManager workerName=node0
recon_1             | 2021-02-09 12:04:43 INFO  session:338 - No SessionScavenger set, using defaults
recon_1             | 2021-02-09 12:04:43 INFO  session:140 - node0 Scavenging every 600000ms
recon_1             | 2021-02-09 12:04:43 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@1f44ddab{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1             | 2021-02-09 12:04:43 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@5b275174{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.5.0-beta.jar!/webapps/static,AVAILABLE}
recon_1             | 2021-02-09 12:04:45 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@7548e1fb{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_5_0-beta_jar-_-any-6181211261977180948.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.5.0-beta.jar!/webapps/recon}
recon_1             | 2021-02-09 12:04:45 INFO  AbstractConnector:330 - Started ServerConnector@33d53216{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
recon_1             | 2021-02-09 12:04:45 INFO  Server:399 - Started @22136ms
recon_1             | 2021-02-09 12:04:45 INFO  BaseHttpServer:284 - HTTP server of recon listening at http://0.0.0.0:9888
recon_1             | 2021-02-09 12:04:45 INFO  OzoneManagerServiceProviderImpl:203 - Starting Ozone Manager Service Provider.
recon_1             | 2021-02-09 12:04:45 INFO  OzoneManagerServiceProviderImpl:181 - Registered OmDeltaRequest task 
recon_1             | 2021-02-09 12:04:45 INFO  OzoneManagerServiceProviderImpl:191 - Registered OmSnapshotRequest task 
recon_1             | 2021-02-09 12:04:45 INFO  ReconOmMetadataManagerImpl:64 - Starting ReconOMMetadataManagerImpl
recon_1             | 2021-02-09 12:04:45 WARN  ReconUtils:88 - ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2021-02-09 12:04:45 INFO  ReconTaskControllerImpl:230 - Starting Recon Task Controller.
recon_1             | 2021-02-09 12:04:45 INFO  ReconStorageContainerManagerFacade:179 - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1             | 2021-02-09 12:04:46 INFO  ReconStorageContainerManagerFacade:224 - Obtained 0 pipelines from SCM.
recon_1             | 2021-02-09 12:04:46 INFO  ReconPipelineManager:88 - Recon has 0 pipelines in house.
recon_1             | 2021-02-09 12:04:46 INFO  SCMDatanodeProtocolServer:178 - RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1             | 2021-02-09 12:04:46 INFO  Server:1314 - IPC Server Responder: starting
recon_1             | 2021-02-09 12:04:46 INFO  Server:1153 - IPC Server listener on 9891: starting
recon_1             | 2021-02-09 12:04:46 INFO  ReconScmTask:58 - Starting MissingContainerTask Thread.
recon_1             | 2021-02-09 12:04:46 INFO  ReconScmTask:58 - Starting PipelineSyncTask Thread.
recon_1             | 2021-02-09 12:04:46 INFO  PipelineSyncTask:64 - Pipeline sync Thread took 12 milliseconds.
recon_1             | 2021-02-09 12:04:46 INFO  MissingContainerTask:72 - Missing Container task Thread took 46 milliseconds for processing 0 containers.
recon_1             | 2021-02-09 12:05:45 INFO  OzoneManagerServiceProviderImpl:331 - Syncing data from Ozone Manager.
recon_1             | 2021-02-09 12:05:45 INFO  OzoneManagerServiceProviderImpl:362 - Obtaining full snapshot from Ozone Manager
recon_1             | 2021-02-09 12:05:46 INFO  OzoneManagerServiceProviderImpl:275 - Got new checkpoint from OM : /data/metadata/om.snapshot.db_1612872345799
recon_1             | 2021-02-09 12:05:46 INFO  ReconOmMetadataManagerImpl:90 - Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1612872345799.
recon_1             | 2021-02-09 12:05:46 INFO  OzoneManagerServiceProviderImpl:374 - Calling reprocess on Recon tasks.
recon_1             | 2021-02-09 12:05:46 INFO  ContainerKeyMapperTask:73 - Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1             | 2021-02-09 12:05:46 INFO  ContainerDBServiceProviderImpl:113 - Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1612872346198
recon_1             | 2021-02-09 12:05:46 INFO  ContainerDBServiceProviderImpl:118 - Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1612872272339.
recon_1             | 2021-02-09 12:05:46 INFO  ContainerKeyMapperTask:89 - Completed 'reprocess' of ContainerKeyMapperTask.
recon_1             | 2021-02-09 12:05:46 INFO  ContainerKeyMapperTask:92 - It took me 0.174 seconds to process 2 keys.
recon_1             | 2021-02-09 12:05:46 INFO  FileSizeCountTask:108 - Completed a 'reprocess' run of FileSizeCountTask.
recon_1             | 2021-02-09 12:06:04 INFO  NetworkTopology:111 - Added a new node: /default-rack/7795933c-0ec9-4552-88bf-a8f0b72b5dcd
recon_1             | 2021-02-09 12:06:04 INFO  SCMNodeManager:268 - Registered Data node : 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}
recon_1             | 2021-02-09 12:06:04 INFO  ReconContainerReportHandler:67 - New container #1 got from 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}.
recon_1             | 2021-02-09 12:06:04 INFO  ReconNodeManager:109 - Adding new node 7795933c-0ec9-4552-88bf-a8f0b72b5dcd to Node DB.
recon_1             | 2021-02-09 12:06:04 INFO  ReconPipelineReportHandler:63 - Unknown pipeline PipelineID=fefaf19a-195d-49fe-9b98-4611c4f4d88a. Trying to get from SCM.
recon_1             | 2021-02-09 12:06:04 INFO  ReconPipelineReportHandler:66 - Adding new pipeline Pipeline[ Id: fefaf19a-195d-49fe-9b98-4611c4f4d88a, Nodes: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:7795933c-0ec9-4552-88bf-a8f0b72b5dcd, CreationTimestamp2021-02-09T12:04:47.114Z] to Recon pipeline metadata.
recon_1             | 2021-02-09 12:06:04 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: fefaf19a-195d-49fe-9b98-4611c4f4d88a, Nodes: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:7795933c-0ec9-4552-88bf-a8f0b72b5dcd, CreationTimestamp2021-02-09T12:04:47.114Z]
recon_1             | 2021-02-09 12:06:04 INFO  ReconPipelineReportHandler:63 - Unknown pipeline PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c. Trying to get from SCM.
recon_1             | 2021-02-09 12:06:04 INFO  ReconPipelineReportHandler:66 - Adding new pipeline Pipeline[ Id: f4c032ab-45d5-43a3-a799-bb72a3dfd61c, Nodes: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:cfb3058e-3b88-4ed2-9e16-b0a6a7378325, CreationTimestamp2021-02-09T12:04:47.300Z] to Recon pipeline metadata.
recon_1             | 2021-02-09 12:06:04 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: f4c032ab-45d5-43a3-a799-bb72a3dfd61c, Nodes: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:cfb3058e-3b88-4ed2-9e16-b0a6a7378325, CreationTimestamp2021-02-09T12:04:47.300Z]
recon_1             | 2021-02-09 12:06:04 INFO  ReconNodeManager:109 - Adding new node cfb3058e-3b88-4ed2-9e16-b0a6a7378325 to Node DB.
recon_1             | 2021-02-09 12:06:04 INFO  NetworkTopology:111 - Added a new node: /default-rack/cfb3058e-3b88-4ed2-9e16-b0a6a7378325
recon_1             | 2021-02-09 12:06:04 INFO  SCMNodeManager:268 - Registered Data node : cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
recon_1             | 2021-02-09 12:06:04 INFO  NetworkTopology:111 - Added a new node: /default-rack/a0f1ab47-147d-4412-93a3-e8c518629eda
recon_1             | 2021-02-09 12:06:04 INFO  SCMNodeManager:268 - Registered Data node : a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}
recon_1             | 2021-02-09 12:06:04 INFO  ReconPipelineReportHandler:63 - Unknown pipeline PipelineID=8b539453-2a7a-494f-a60d-da0908a8982b. Trying to get from SCM.
recon_1             | 2021-02-09 12:06:04 INFO  ReconPipelineReportHandler:66 - Adding new pipeline Pipeline[ Id: 8b539453-2a7a-494f-a60d-da0908a8982b, Nodes: a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:a0f1ab47-147d-4412-93a3-e8c518629eda, CreationTimestamp2021-02-09T12:04:47.294Z] to Recon pipeline metadata.
recon_1             | 2021-02-09 12:06:04 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 8b539453-2a7a-494f-a60d-da0908a8982b, Nodes: a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:a0f1ab47-147d-4412-93a3-e8c518629eda, CreationTimestamp2021-02-09T12:04:47.294Z]
recon_1             | 2021-02-09 12:06:04 INFO  ReconPipelineReportHandler:63 - Unknown pipeline PipelineID=926c10b0-5799-49ed-af11-b85b210c214c. Trying to get from SCM.
recon_1             | 2021-02-09 12:06:04 INFO  ReconPipelineReportHandler:66 - Adding new pipeline Pipeline[ Id: 926c10b0-5799-49ed-af11-b85b210c214c, Nodes: cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:cfb3058e-3b88-4ed2-9e16-b0a6a7378325, CreationTimestamp2021-02-09T12:04:47.054Z] to Recon pipeline metadata.
recon_1             | 2021-02-09 12:06:04 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 926c10b0-5799-49ed-af11-b85b210c214c, Nodes: cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:cfb3058e-3b88-4ed2-9e16-b0a6a7378325, CreationTimestamp2021-02-09T12:04:47.054Z]
recon_1             | 2021-02-09 12:06:04 INFO  ReconNodeManager:109 - Adding new node a0f1ab47-147d-4412-93a3-e8c518629eda to Node DB.
scm_1               | 2021-02-09 12:04:31 INFO  StorageContainerManagerStarter:51 - STARTUP_MSG: 
scm_1               | /************************************************************
scm_1               | STARTUP_MSG: Starting StorageContainerManager
scm_1               | STARTUP_MSG:   host = 885985873ba6/172.29.0.4
scm_1               | STARTUP_MSG:   args = [--init]
scm_1               | STARTUP_MSG:   version = 3.2.0
scm_1               | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-beta.jar
scm_1               | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1               | STARTUP_MSG:   java = 11.0.3
scm_1               | ************************************************************/
scm_1               | 2021-02-09 12:04:31 INFO  StorageContainerManagerStarter:51 - registered UNIX signal handlers for [TERM, HUP, INT]
scm_1               | 2021-02-09 12:04:31 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2021-02-09 12:04:32 INFO  StorageContainerManager:635 - SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-fbf6fe82-91d7-436f-8e5f-321c52f3e9d4
scm_1               | 2021-02-09 12:04:32 INFO  StorageContainerManagerStarter:51 - SHUTDOWN_MSG: 
scm_1               | /************************************************************
scm_1               | SHUTDOWN_MSG: Shutting down StorageContainerManager at 885985873ba6/172.29.0.4
scm_1               | ************************************************************/
scm_1               | 2021-02-09 12:04:41 INFO  StorageContainerManagerStarter:51 - STARTUP_MSG: 
scm_1               | /************************************************************
scm_1               | STARTUP_MSG: Starting StorageContainerManager
scm_1               | STARTUP_MSG:   host = 885985873ba6/172.29.0.4
scm_1               | STARTUP_MSG:   args = []
scm_1               | STARTUP_MSG:   version = 3.2.0
scm_1               | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-beta.jar
scm_1               | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1               | STARTUP_MSG:   java = 11.0.3
scm_1               | ************************************************************/
scm_1               | 2021-02-09 12:04:41 INFO  StorageContainerManagerStarter:51 - registered UNIX signal handlers for [TERM, HUP, INT]
scm_1               | 2021-02-09 12:04:41 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2021-02-09 12:04:41 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2021-02-09 12:04:42 INFO  NodeSchemaLoader:126 - Loading file from java.lang.CompoundEnumeration@4bc222e
scm_1               | 2021-02-09 12:04:42 INFO  NodeSchemaLoader:172 - Loading network topology layer schema file
scm_1               | 2021-02-09 12:04:42 INFO  SCMNodeManager:116 - Entering startup safe mode.
scm_1               | 2021-02-09 12:04:43 INFO  ContainerPlacementPolicyFactory:59 - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1               | 2021-02-09 12:04:43 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2021-02-09 12:04:43 INFO  SCMPipelineManager:150 - No pipeline exists in current db
scm_1               | 2021-02-09 12:04:43 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2021-02-09 12:04:43 INFO  HealthyPipelineSafeModeRule:88 - Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2021-02-09 12:04:43 INFO  OneReplicaPipelineSafeModeRule:79 - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1               | 2021-02-09 12:04:43 WARN  PipelinePlacementPolicy:151 - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1               | 2021-02-09 12:04:43 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
scm_1               | 2021-02-09 12:04:44 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1               | 2021-02-09 12:04:44 INFO  Server:1074 - Starting Socket Reader #1 for port 9861
scm_1               | 2021-02-09 12:04:44 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1               | 2021-02-09 12:04:44 INFO  Server:1074 - Starting Socket Reader #1 for port 9863
scm_1               | 2021-02-09 12:04:44 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1               | 2021-02-09 12:04:44 INFO  Server:1074 - Starting Socket Reader #1 for port 9860
scm_1               | 2021-02-09 12:04:44 INFO  BaseHttpServer:170 - Starting Web-server for scm at: http://0.0.0.0:9876
scm_1               | 2021-02-09 12:04:44 INFO  log:169 - Logging initialized @11096ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1               | 2021-02-09 12:04:45 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1               | 2021-02-09 12:04:45 INFO  HttpRequestLog:86 - Http request log for http.requests.scm is not defined
scm_1               | 2021-02-09 12:04:45 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1               | 2021-02-09 12:04:45 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1               | 2021-02-09 12:04:45 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
scm_1               | 2021-02-09 12:04:45 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1               | 2021-02-09 12:04:45 INFO  StorageContainerManager:773 - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1               | 2021-02-09 12:04:45 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
scm_1               | 2021-02-09 12:04:45 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
scm_1               | 2021-02-09 12:04:45 INFO  MetricsSystemImpl:191 - StorageContainerManager metrics system started
scm_1               | 2021-02-09 12:04:45 INFO  SCMClientProtocolServer:160 - RPC server for Client  is listening at /0.0.0.0:9860
scm_1               | 2021-02-09 12:04:45 INFO  Server:1314 - IPC Server Responder: starting
scm_1               | 2021-02-09 12:04:45 INFO  Server:1153 - IPC Server listener on 9860: starting
scm_1               | 2021-02-09 12:04:45 INFO  StorageContainerManager:785 - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1               | 2021-02-09 12:04:45 INFO  SCMBlockProtocolServer:147 - RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1               | 2021-02-09 12:04:45 INFO  Server:1314 - IPC Server Responder: starting
scm_1               | 2021-02-09 12:04:45 INFO  Server:1153 - IPC Server listener on 9863: starting
scm_1               | 2021-02-09 12:04:45 INFO  StorageContainerManager:791 - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1               | 2021-02-09 12:04:45 INFO  SCMDatanodeProtocolServer:178 - RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1               | 2021-02-09 12:04:45 INFO  Server:1314 - IPC Server Responder: starting
scm_1               | 2021-02-09 12:04:45 INFO  Server:1153 - IPC Server listener on 9861: starting
scm_1               | 2021-02-09 12:04:45 INFO  HttpServer2:1188 - Jetty bound to port 9876
scm_1               | 2021-02-09 12:04:45 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
scm_1               | 2021-02-09 12:04:46 INFO  session:333 - DefaultSessionIdManager workerName=node0
scm_1               | 2021-02-09 12:04:46 INFO  session:338 - No SessionScavenger set, using defaults
scm_1               | 2021-02-09 12:04:46 INFO  session:140 - node0 Scavenging every 660000ms
scm_1               | 2021-02-09 12:04:46 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@1a3e5f23{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1               | 2021-02-09 12:04:46 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@ec1b2e4{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-beta.jar!/webapps/static,AVAILABLE}
scm_1               | 2021-02-09 12:04:46 WARN  Server:1523 - IPC Server handler 0 on 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.29.0.8:52112: output error
scm_1               | 2021-02-09 12:04:46 WARN  Server:1523 - IPC Server handler 1 on 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.29.0.2:46368: output error
scm_1               | 2021-02-09 12:04:46 INFO  Server:2695 - IPC Server handler 1 on 9861 caught an exception
scm_1               | java.nio.channels.AsynchronousCloseException
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1               | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1               | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1               | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1               | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1               | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1               | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1               | 2021-02-09 12:04:46 INFO  Server:2695 - IPC Server handler 0 on 9861 caught an exception
scm_1               | java.nio.channels.AsynchronousCloseException
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1               | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1               | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1               | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1               | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1               | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1               | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1               | 2021-02-09 12:04:46 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@7fe82967{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_5_0-beta_jar-_-any-2513192174136232968.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-beta.jar!/webapps/scm}
scm_1               | 2021-02-09 12:04:46 INFO  NetworkTopology:111 - Added a new node: /default-rack/cfb3058e-3b88-4ed2-9e16-b0a6a7378325
scm_1               | 2021-02-09 12:04:46 INFO  SCMNodeManager:268 - Registered Data node : cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:47 INFO  SCMSafeModeManager:175 - ContainerSafeModeRule rule is successfully validated
scm_1               | 2021-02-09 12:04:47 INFO  SCMSafeModeManager:71 - SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1               | 2021-02-09 12:04:47 INFO  NetworkTopology:111 - Added a new node: /default-rack/7795933c-0ec9-4552-88bf-a8f0b72b5dcd
scm_1               | 2021-02-09 12:04:47 INFO  SCMNodeManager:268 - Registered Data node : 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:47 INFO  SCMSafeModeManager:175 - ContainerSafeModeRule rule is successfully validated
scm_1               | 2021-02-09 12:04:47 INFO  SCMSafeModeManager:71 - SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1               | 2021-02-09 12:04:47 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=926c10b0-5799-49ed-af11-b85b210c214c to datanode:cfb3058e-3b88-4ed2-9e16-b0a6a7378325
scm_1               | 2021-02-09 12:04:47 INFO  AbstractConnector:330 - Started ServerConnector@a20b94b{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1               | 2021-02-09 12:04:47 INFO  Server:399 - Started @13215ms
scm_1               | 2021-02-09 12:04:47 INFO  MetricsSinkAdapter:204 - Sink prometheus started
scm_1               | 2021-02-09 12:04:47 INFO  MetricsSystemImpl:301 - Registered sink prometheus
scm_1               | 2021-02-09 12:04:47 INFO  BaseHttpServer:284 - HTTP server of scm listening at http://0.0.0.0:9876
scm_1               | 2021-02-09 12:04:47 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 926c10b0-5799-49ed-af11-b85b210c214c, Nodes: cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2021-02-09T12:04:47.054291Z]
scm_1               | 2021-02-09 12:04:47 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
scm_1               | 2021-02-09 12:04:47 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=fefaf19a-195d-49fe-9b98-4611c4f4d88a to datanode:7795933c-0ec9-4552-88bf-a8f0b72b5dcd
scm_1               | 2021-02-09 12:04:47 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: fefaf19a-195d-49fe-9b98-4611c4f4d88a, Nodes: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2021-02-09T12:04:47.114408Z]
scm_1               | 2021-02-09 12:04:47 WARN  PipelinePlacementPolicy:151 - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1               | 2021-02-09 12:04:47 INFO  NetworkTopology:111 - Added a new node: /default-rack/a0f1ab47-147d-4412-93a3-e8c518629eda
scm_1               | 2021-02-09 12:04:47 INFO  SCMNodeManager:268 - Registered Data node : a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:47 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=8b539453-2a7a-494f-a60d-da0908a8982b to datanode:a0f1ab47-147d-4412-93a3-e8c518629eda
scm_1               | 2021-02-09 12:04:47 INFO  SCMSafeModeManager:175 - ContainerSafeModeRule rule is successfully validated
scm_1               | 2021-02-09 12:04:47 INFO  SCMSafeModeManager:71 - SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1               | 2021-02-09 12:04:47 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 8b539453-2a7a-494f-a60d-da0908a8982b, Nodes: a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2021-02-09T12:04:47.294950Z]
scm_1               | 2021-02-09 12:04:47 INFO  SCMSafeModeManager:175 - DataNodeSafeModeRule rule is successfully validated
scm_1               | 2021-02-09 12:04:47 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c to datanode:7795933c-0ec9-4552-88bf-a8f0b72b5dcd
scm_1               | 2021-02-09 12:04:47 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c to datanode:a0f1ab47-147d-4412-93a3-e8c518629eda
scm_1               | 2021-02-09 12:04:47 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c to datanode:cfb3058e-3b88-4ed2-9e16-b0a6a7378325
scm_1               | 2021-02-09 12:04:47 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: f4c032ab-45d5-43a3-a799-bb72a3dfd61c, Nodes: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2021-02-09T12:04:47.300383Z]
scm_1               | 2021-02-09 12:04:50 INFO  PipelineReportHandler:117 - Pipeline ONE PipelineID=926c10b0-5799-49ed-af11-b85b210c214c reported by cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:50 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 926c10b0-5799-49ed-af11-b85b210c214c, Nodes: cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:cfb3058e-3b88-4ed2-9e16-b0a6a7378325, CreationTimestamp2021-02-09T12:04:47.054291Z] moved to OPEN state
scm_1               | 2021-02-09 12:04:50 INFO  SCMSafeModeManager:175 - AtleastOneDatanodeReportedRule rule is successfully validated
scm_1               | 2021-02-09 12:04:50 INFO  SCMSafeModeManager:131 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2021-02-09 12:04:50 INFO  PipelineReportHandler:117 - Pipeline ONE PipelineID=fefaf19a-195d-49fe-9b98-4611c4f4d88a reported by 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:50 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: fefaf19a-195d-49fe-9b98-4611c4f4d88a, Nodes: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:7795933c-0ec9-4552-88bf-a8f0b72b5dcd, CreationTimestamp2021-02-09T12:04:47.114408Z] moved to OPEN state
scm_1               | 2021-02-09 12:04:50 INFO  SCMSafeModeManager:175 - AtleastOneDatanodeReportedRule rule is successfully validated
scm_1               | 2021-02-09 12:04:50 INFO  SCMSafeModeManager:131 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2021-02-09 12:04:50 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c reported by cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:50 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c reported by 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:51 INFO  PipelineReportHandler:117 - Pipeline ONE PipelineID=8b539453-2a7a-494f-a60d-da0908a8982b reported by a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:51 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 8b539453-2a7a-494f-a60d-da0908a8982b, Nodes: a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:a0f1ab47-147d-4412-93a3-e8c518629eda, CreationTimestamp2021-02-09T12:04:47.294950Z] moved to OPEN state
scm_1               | 2021-02-09 12:04:51 INFO  SCMSafeModeManager:175 - AtleastOneDatanodeReportedRule rule is successfully validated
scm_1               | 2021-02-09 12:04:51 INFO  SCMSafeModeManager:131 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2021-02-09 12:04:51 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c reported by a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:55 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c reported by cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:56 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=f4c032ab-45d5-43a3-a799-bb72a3dfd61c reported by cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
scm_1               | 2021-02-09 12:04:56 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: f4c032ab-45d5-43a3-a799-bb72a3dfd61c, Nodes: 7795933c-0ec9-4552-88bf-a8f0b72b5dcd{ip: 172.29.0.8, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}a0f1ab47-147d-4412-93a3-e8c518629eda{ip: 172.29.0.9, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}cfb3058e-3b88-4ed2-9e16-b0a6a7378325{ip: 172.29.0.2, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:cfb3058e-3b88-4ed2-9e16-b0a6a7378325, CreationTimestamp2021-02-09T12:04:47.300383Z] moved to OPEN state
scm_1               | 2021-02-09 12:04:56 INFO  SCMSafeModeManager:175 - AtleastOneDatanodeReportedRule rule is successfully validated
scm_1               | 2021-02-09 12:04:56 INFO  SCMSafeModeManager:131 - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1               | 2021-02-09 12:04:56 INFO  SCMSafeModeManager:175 - HealthyPipelineSafeModeRule rule is successfully validated
scm_1               | 2021-02-09 12:04:56 INFO  SCMSafeModeManager:184 - ScmSafeModeManager, all rules are successfully validated
scm_1               | 2021-02-09 12:04:56 INFO  SCMSafeModeManager:200 - SCM exiting safe mode.
