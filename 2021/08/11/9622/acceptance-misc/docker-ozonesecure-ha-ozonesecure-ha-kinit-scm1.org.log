Attaching to ozonesecure-ha_recon_1, ozonesecure-ha_om3_1, ozonesecure-ha_kdc_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_kms_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_om2_1, ozonesecure-ha_om1_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_s3g_1
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2021-08-11 23:08:24,059 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 9858c43d50b5/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2021-08-11 23:08:24,068 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 97f5bd8bbda3/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
datanode2_1  | STARTUP_MSG:   java = 11.0.10
datanode2_1  | ************************************************************/
datanode2_1  | 2021-08-11 23:08:24,212 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2021-08-11 23:08:26,147 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2021-08-11 23:08:27,043 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2021-08-11 23:08:28,101 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2021-08-11 23:08:28,133 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2021-08-11 23:08:29,283 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:97f5bd8bbda3 ip:172.25.0.103
datanode2_1  | 2021-08-11 23:08:32,895 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-08-11 23:08:33,695 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2021-08-11 23:08:33,696 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2021-08-11 23:08:35,773 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2021-08-11 23:08:35,774 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2021-08-11 23:08:35,774 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2021-08-11 23:08:35,790 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2021-08-11 23:08:41,884 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2021-08-11 23:08:42,002 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:97f5bd8bbda3
datanode2_1  | 2021-08-11 23:08:42,002 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2021-08-11 23:08:42,076 [main] ERROR client.DNCertificateClient: Invalid domain 97f5bd8bbda3
datanode2_1  | 2021-08-11 23:08:42,077 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@97f5bd8bbda3
datanode2_1  | 2021-08-11 23:08:46,524 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2021-08-11 23:08:46,602 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2021-08-11 23:08:46,642 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/3016481445845.crt.
datanode2_1  | 2021-08-11 23:08:46,662 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2932114727528.crt.
datanode2_1  | 2021-08-11 23:08:46,662 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2021-08-11 23:08:46,767 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode2_1  | 2021-08-11 23:08:47,674 [main] INFO reflections.Reflections: Reflections took 710 ms to scan 2 urls, producing 85 keys and 170 values 
datanode2_1  | 2021-08-11 23:08:49,049 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2021-08-11 23:08:49,169 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2021-08-11 23:08:49,214 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2021-08-11 23:08:49,230 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2021-08-11 23:08:49,496 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2021-08-11 23:08:49,641 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-08-11 23:08:49,676 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2021-08-11 23:08:49,682 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2021-08-11 23:08:49,682 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2021-08-11 23:08:49,683 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2021-08-11 23:08:49,807 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode2_1  | 2021-08-11 23:08:49,826 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode2_1  | 2021-08-11 23:08:49,829 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2021-08-11 23:08:49,830 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2021-08-11 23:08:55,598 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-08-11 23:08:55,984 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2021-08-11 23:08:56,480 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2021-08-11 23:08:56,480 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2021-08-11 23:08:56,490 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2021-08-11 23:08:56,511 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2021-08-11 23:08:56,516 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-08-11 23:08:56,526 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2021-08-11 23:08:56,526 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-08-11 23:09:03,566 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2021-08-11 23:09:03,578 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-08-11 23:09:03,591 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-08-11 23:09:03,741 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-08-11 23:09:06,490 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2021-08-11 23:09:06,492 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2021-08-11 23:09:06,492 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2021-08-11 23:09:06,784 [main] INFO util.log: Logging initialized @50864ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2021-08-11 23:09:07,421 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2021-08-11 23:09:07,462 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2021-08-11 23:09:07,484 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2021-08-11 23:09:07,487 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2021-08-11 23:09:07,488 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2021-08-11 23:09:07,490 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2021-08-11 23:09:07,734 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2021-08-11 23:09:07,745 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode2_1  | 2021-08-11 23:09:07,921 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2021-08-11 23:09:07,921 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2021-08-11 23:09:07,936 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2021-08-11 23:09:08,021 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-08-11 23:09:08,036 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4101e146{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2021-08-11 23:09:08,038 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@493ed8e6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2021-08-11 23:09:08,462 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-08-11 23:09:08,540 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6888a33{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-18038260293165919202/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2021-08-11 23:09:08,583 [main] INFO server.AbstractConnector: Started ServerConnector@700b035b{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2021-08-11 23:09:08,583 [main] INFO server.Server: Started @52664ms
datanode2_1  | 2021-08-11 23:09:08,593 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2021-08-11 23:09:08,593 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2021-08-11 23:09:08,600 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2021-08-11 23:09:08,753 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72c2ba8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2021-08-11 23:09:09,304 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2021-08-11 23:09:11,234 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2021-08-11 23:09:11,244 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2021-08-11 23:09:11,661 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 95d91451-f44f-4fa4-a508-c399bd523c99
datanode2_1  | 2021-08-11 23:09:11,828 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 95d91451-f44f-4fa4-a508-c399bd523c99: start RPC server
datanode2_1  | 2021-08-11 23:09:11,842 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 95d91451-f44f-4fa4-a508-c399bd523c99: GrpcService started, listening on 9856
datanode2_1  | 2021-08-11 23:09:11,852 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 95d91451-f44f-4fa4-a508-c399bd523c99: GrpcService started, listening on 9857
datanode2_1  | 2021-08-11 23:09:11,871 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 95d91451-f44f-4fa4-a508-c399bd523c99: GrpcService started, listening on 9858
datanode2_1  | 2021-08-11 23:09:11,896 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 95d91451-f44f-4fa4-a508-c399bd523c99 is started using port 9858 for RATIS
datanode2_1  | 2021-08-11 23:09:11,897 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 95d91451-f44f-4fa4-a508-c399bd523c99 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2021-08-11 23:09:11,897 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 95d91451-f44f-4fa4-a508-c399bd523c99 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2021-08-11 23:09:11,897 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$334/0x00000008405a9040@58c886de] INFO util.JvmPauseMonitor: JvmPauseMonitor-95d91451-f44f-4fa4-a508-c399bd523c99: Started
datanode2_1  | 2021-08-11 23:09:11,951 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-08-11 23:09:11,959 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-08-11 23:09:14,873 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode2_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:270)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:456)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2021-08-11 23:08:23,985 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 5f0669529782/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
datanode3_1  | STARTUP_MSG:   java = 11.0.10
datanode3_1  | ************************************************************/
datanode3_1  | 2021-08-11 23:08:24,117 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2021-08-11 23:08:26,097 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2021-08-11 23:08:26,783 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2021-08-11 23:08:27,733 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2021-08-11 23:08:27,736 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2021-08-11 23:08:28,853 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:9858c43d50b5 ip:172.25.0.104
datanode3_1  | 2021-08-11 23:08:32,148 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-08-11 23:08:33,063 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2021-08-11 23:08:33,099 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2021-08-11 23:08:34,709 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2021-08-11 23:08:34,711 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2021-08-11 23:08:34,717 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2021-08-11 23:08:34,719 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2021-08-11 23:08:39,106 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2021-08-11 23:08:39,173 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:9858c43d50b5
datanode3_1  | 2021-08-11 23:08:39,183 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2021-08-11 23:08:39,208 [main] ERROR client.DNCertificateClient: Invalid domain 9858c43d50b5
datanode3_1  | 2021-08-11 23:08:39,215 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@9858c43d50b5
datanode3_1  | 2021-08-11 23:08:43,940 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2021-08-11 23:08:43,989 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2021-08-11 23:08:44,005 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2932114727528.crt.
datanode3_1  | 2021-08-11 23:08:44,024 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/3013808804155.crt.
datanode3_1  | 2021-08-11 23:08:44,024 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2021-08-11 23:08:44,134 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode3_1  | 2021-08-11 23:08:44,941 [main] INFO reflections.Reflections: Reflections took 622 ms to scan 2 urls, producing 85 keys and 170 values 
datanode3_1  | 2021-08-11 23:08:46,454 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2021-08-11 23:08:46,494 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2021-08-11 23:08:46,530 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2021-08-11 23:08:46,546 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2021-08-11 23:08:46,819 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2021-08-11 23:08:46,969 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-08-11 23:08:46,991 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2021-08-11 23:08:47,009 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2021-08-11 23:08:47,009 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2021-08-11 23:08:47,010 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2021-08-11 23:08:47,154 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode3_1  | 2021-08-11 23:08:47,172 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode3_1  | 2021-08-11 23:08:47,179 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2021-08-11 23:08:47,179 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2021-08-11 23:08:53,175 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-08-11 23:08:54,075 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2021-08-11 23:08:54,957 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2021-08-11 23:08:54,963 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2021-08-11 23:08:54,966 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2021-08-11 23:08:55,004 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2021-08-11 23:08:55,014 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-08-11 23:08:55,017 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2021-08-11 23:08:55,050 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-08-11 23:09:01,681 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2021-08-11 23:09:01,748 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-08-11 23:09:01,763 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-08-11 23:09:01,794 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-08-11 23:09:04,368 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2021-08-11 23:09:04,377 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2021-08-11 23:09:04,377 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2021-08-11 23:09:04,569 [main] INFO util.log: Logging initialized @48465ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2021-08-11 23:09:05,274 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2021-08-11 23:09:05,331 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
kdc_1        | Aug 11 23:06:59 kdc krb5kdc[7](info): Loaded
kdc_1        | Aug 11 23:06:59 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Aug 11 23:06:59 kdc krb5kdc[7](info): setting up network...
kdc_1        | Aug 11 23:06:59 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Aug 11 23:06:59 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Aug 11 23:06:59 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Aug 11 23:06:59 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Aug 11 23:07:02 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723222, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:07:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723227, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:07:08 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1628723228, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:07:26 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1628723246, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:07:32 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1628723252, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:07:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723227, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:07:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1628723246, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:07:46 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723266, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:07:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723266, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:07:52 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1628723272, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:07:56 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723276, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:07:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1628723272, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:01 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1628723281, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1628723281, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723276, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:08 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1628723288, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723289, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723289, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1628723288, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:21 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723301, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:32 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1628723312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:32 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1628723312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:33 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1628723313, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:34 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1628723314, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:35 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1628723315, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:37 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1628723317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:08:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1628723314, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1628723315, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1628723312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1628723317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1628723312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1628723313, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723301, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:08:58 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723338, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:09:12 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1628723352, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:09:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1628723353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:09:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1628723353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:09:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1628723352, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-08-11 23:08:26,274 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:09Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-08-11 23:08:26,336 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-08-11 23:08:36,201 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-08-11 23:08:36,653 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-08-11 23:08:36,654 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-08-11 23:08:36,654 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-08-11 23:08:38,141 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2021-08-11 23:08:38,220 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-08-11 23:08:38,246 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-08-11 23:08:41,296 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2021-08-11 23:08:44,834 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2021-08-11 23:08:44,834 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2021-08-11 23:08:44,868 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2021-08-11 23:08:49,146 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2021-08-11 23:08:49,415 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2021-08-11 23:08:49,431 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2021-08-11 23:08:49,437 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2021-08-11 23:08:49,438 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-08-11 23:08:49,438 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-08-11 23:08:49,438 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-08-11 23:08:49,438 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-08-11 23:08:49,463 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:4742394c-da80-4695-95c5-c0a43d189463,clusterId:CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd,subject:om1
om1_1        | 2021-08-11 23:08:50,311 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2021-08-11 23:08:52,355 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd;layoutVersion=0
om1_1        | 2021-08-11 23:08:52,491 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-08-11 23:09:01,947 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
datanode1_1  | STARTUP_MSG:   java = 11.0.10
datanode1_1  | ************************************************************/
datanode1_1  | 2021-08-11 23:08:24,071 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2021-08-11 23:08:26,026 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2021-08-11 23:08:26,642 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2021-08-11 23:08:27,679 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2021-08-11 23:08:27,691 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2021-08-11 23:08:28,504 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:5f0669529782 ip:172.25.0.102
datanode1_1  | 2021-08-11 23:08:32,161 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-08-11 23:08:33,130 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2021-08-11 23:08:33,131 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2021-08-11 23:08:35,032 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2021-08-11 23:08:35,035 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2021-08-11 23:08:35,039 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2021-08-11 23:08:35,040 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2021-08-11 23:08:37,284 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2021-08-11 23:08:37,368 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:5f0669529782
datanode1_1  | 2021-08-11 23:08:37,378 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2021-08-11 23:08:37,399 [main] ERROR client.DNCertificateClient: Invalid domain 5f0669529782
datanode1_1  | 2021-08-11 23:08:37,411 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@5f0669529782
datanode1_1  | 2021-08-11 23:08:42,580 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2021-08-11 23:08:42,671 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2021-08-11 23:08:42,692 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/3012461862885.crt.
datanode1_1  | 2021-08-11 23:08:42,718 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2932114727528.crt.
datanode1_1  | 2021-08-11 23:08:42,718 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2021-08-11 23:08:42,835 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode1_1  | 2021-08-11 23:08:43,682 [main] INFO reflections.Reflections: Reflections took 636 ms to scan 2 urls, producing 85 keys and 170 values 
datanode1_1  | 2021-08-11 23:08:45,289 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2021-08-11 23:08:45,357 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2021-08-11 23:08:45,411 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2021-08-11 23:08:45,416 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2021-08-11 23:08:45,669 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2021-08-11 23:08:45,806 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-08-11 23:08:45,827 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2021-08-11 23:08:45,831 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2021-08-11 23:08:45,831 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2021-08-11 23:08:45,832 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2021-08-11 23:08:46,001 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode1_1  | 2021-08-11 23:08:46,036 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode1_1  | 2021-08-11 23:08:46,079 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2021-08-11 23:08:46,079 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2021-08-11 23:08:52,292 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-08-11 23:08:53,225 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2021-08-11 23:08:53,936 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2021-08-11 23:08:53,937 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2021-08-11 23:08:53,940 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2021-08-11 23:08:53,972 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2021-08-11 23:08:53,990 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-08-11 23:08:54,008 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2021-08-11 23:08:54,017 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-08-11 23:09:00,971 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2021-08-11 23:09:00,973 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-08-11 23:09:00,988 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-08-11 23:09:01,055 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-08-11 23:09:03,872 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2021-08-11 23:09:03,884 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2021-08-11 23:09:03,884 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2021-08-11 23:09:04,169 [main] INFO util.log: Logging initialized @48259ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2021-08-11 23:09:04,784 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2021-08-11 23:09:04,832 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2021-08-11 23:09:04,837 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2021-08-11 23:09:04,837 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2021-08-11 23:09:04,841 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2021-08-11 23:09:04,863 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2021-08-11 23:09:05,102 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2021-08-11 23:09:05,120 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode1_1  | 2021-08-11 23:09:05,303 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2021-08-11 23:09:05,303 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2021-08-11 23:09:05,308 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2021-08-11 23:09:05,486 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-08-11 23:09:05,489 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@74597c37{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2021-08-11 23:09:05,532 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4dcc0e3d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2021-08-11 23:09:06,142 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-08-11 23:09:06,218 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7d661205{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-14092595542327005230/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2021-08-11 23:09:06,281 [main] INFO server.AbstractConnector: Started ServerConnector@472dc215{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2021-08-11 23:09:06,281 [main] INFO server.Server: Started @50371ms
datanode1_1  | 2021-08-11 23:09:06,303 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2021-08-11 23:09:06,303 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2021-08-11 23:09:06,311 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2021-08-11 23:09:06,489 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ab93c3d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2021-08-11 23:09:06,965 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2021-08-11 23:09:10,416 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2021-08-11 23:09:10,441 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2021-08-11 23:09:11,063 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 97333428-a9dc-49fc-bc54-326166febdda
datanode1_1  | 2021-08-11 23:09:11,221 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 97333428-a9dc-49fc-bc54-326166febdda: start RPC server
datanode1_1  | 2021-08-11 23:09:11,228 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 97333428-a9dc-49fc-bc54-326166febdda: GrpcService started, listening on 9856
datanode1_1  | 2021-08-11 23:09:11,235 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 97333428-a9dc-49fc-bc54-326166febdda: GrpcService started, listening on 9857
datanode1_1  | 2021-08-11 23:09:11,238 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 97333428-a9dc-49fc-bc54-326166febdda: GrpcService started, listening on 9858
datanode1_1  | 2021-08-11 23:09:11,259 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 97333428-a9dc-49fc-bc54-326166febdda is started using port 9858 for RATIS
datanode1_1  | 2021-08-11 23:09:11,259 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 97333428-a9dc-49fc-bc54-326166febdda is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2021-08-11 23:09:11,259 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 97333428-a9dc-49fc-bc54-326166febdda is started using port 9856 for RATIS_SERVER
datanode1_1  | 2021-08-11 23:09:11,262 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$334/0x00000008405a9040@5105b25c] INFO util.JvmPauseMonitor: JvmPauseMonitor-97333428-a9dc-49fc-bc54-326166febdda: Started
datanode1_1  | 2021-08-11 23:09:11,312 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-08-11 23:09:11,312 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-08-11 23:09:12,788 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:15,855 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:18,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:22,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:25,028 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 97333428-a9dc-49fc-bc54-326166febdda: Failed requestVote 95d91451-f44f-4fa4-a508-c399bd523c99->97333428-a9dc-49fc-bc54-326166febdda#0
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:09Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-08-11 23:09:02,009 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-08-11 23:09:10,587 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-08-11 23:09:11,050 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-08-11 23:09:11,055 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-08-11 23:09:11,056 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-08-11 23:09:11,095 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-08-11 23:09:11,278 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om1_1        | 2021-08-11 23:09:12,679 [main] INFO reflections.Reflections: Reflections took 1151 ms to scan 1 urls, producing 95 keys and 258 values [using 2 cores]
om1_1        | 2021-08-11 23:09:14,192 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2021-08-11 23:09:14,192 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-08-11 23:09:14,196 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-08-11 23:09:21,247 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2021-08-11 23:09:21,911 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2021-08-11 23:09:21,921 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2932114727528.crt.
om1_1        | 2021-08-11 23:09:21,960 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/3022859217026.crt.
om1_1        | 2021-08-11 23:09:22,252 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-08-11 23:09:23,088 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-08-11 23:09:23,089 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-08-11 23:09:24,431 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2021-08-11 23:09:24,443 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2021-08-11 23:09:25,092 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2021-08-11 23:09:25,677 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-08-11 23:09:25,687 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2021-08-11 23:09:25,766 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2021-08-11 23:09:26,214 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2021-08-11 23:09:26,259 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-08-11 23:09:26,409 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2021-08-11 23:09:26,460 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2021-08-11 23:09:27,308 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2021-08-11 23:09:27,770 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2021-08-11 23:09:27,777 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-08-11 23:09:27,780 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2021-08-11 23:09:27,780 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-08-11 23:09:27,781 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-08-11 23:09:27,791 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2021-08-11 23:09:27,798 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-08-11 23:09:27,811 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2021-08-11 23:09:27,812 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-08-11 23:09:30,855 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2021-08-11 23:09:30,857 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-08-11 23:09:30,888 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-08-11 23:09:30,976 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-08-11 23:09:31,021 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@16acf986[Not completed]
om1_1        | 2021-08-11 23:09:31,021 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2021-08-11 23:09:31,168 [pool-24-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2021-08-11 23:09:31,175 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2021-08-11 23:09:31,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2021-08-11 23:09:31,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2021-08-11 23:09:31,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-08-11 23:09:31,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-08-11 23:09:31,236 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2021-08-11 23:09:31,236 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-08-11 23:09:31,256 [pool-24-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
kdc_1        | Aug 11 23:09:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1628723353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:09:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1628723353, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:09:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723338, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:09:29 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723369, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:09:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723369, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:09:41 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723381, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:09:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723381, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:09:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723388, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:09:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723388, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 11 23:09:53 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:09:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:10:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:10:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:10:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:10:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:10:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:10:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:10:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:10:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:10:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723401, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:11:59 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723519, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:12:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723519, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723519, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:12:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723548, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:12:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723548, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723548, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723562, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:12:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723562, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723562, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:50 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723570, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:12:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723570, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723570, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:12:58 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723578, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723578, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723581, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723581, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:05 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723585, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:41 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723621, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:41 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723621, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	... 1 more
datanode2_1  | 2021-08-11 23:09:15,005 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:15,934 [Command processor thread] INFO server.RaftServer: 95d91451-f44f-4fa4-a508-c399bd523c99: addNew group-6FA1826E58A5:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-6FA1826E58A5:java.util.concurrent.CompletableFuture@29089885[Not completed]
datanode2_1  | 2021-08-11 23:09:16,089 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99: new RaftServerImpl for group-6FA1826E58A5:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-08-11 23:09:16,106 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-08-11 23:09:16,115 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-08-11 23:09:16,115 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-08-11 23:09:16,115 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-08-11 23:09:16,115 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-08-11 23:09:16,116 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-08-11 23:09:16,125 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-08-11 23:09:16,148 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: ConfigurationManager, init=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-08-11 23:09:16,162 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-08-11 23:09:16,203 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-08-11 23:09:16,207 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2021-08-11 23:09:16,216 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5 does not exist. Creating ...
datanode2_1  | 2021-08-11 23:09:16,276 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5/in_use.lock acquired by nodename 7@97f5bd8bbda3
datanode2_1  | 2021-08-11 23:09:16,336 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5 has been successfully formatted.
datanode2_1  | 2021-08-11 23:09:16,420 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-6FA1826E58A5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-08-11 23:09:16,421 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-08-11 23:09:16,477 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-08-11 23:09:16,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-08-11 23:09:16,652 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-08-11 23:09:16,773 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:16,825 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-08-11 23:09:16,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-08-11 23:09:16,871 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5
datanode2_1  | 2021-08-11 23:09:16,873 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-08-11 23:09:16,880 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-08-11 23:09:16,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:16,884 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-08-11 23:09:16,887 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-08-11 23:09:16,892 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-08-11 23:09:16,894 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-08-11 23:09:16,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-08-11 23:09:16,956 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:16,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-08-11 23:09:17,015 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-08-11 23:09:17,026 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-08-11 23:09:17,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-08-11 23:09:17,048 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-08-11 23:09:17,051 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-08-11 23:09:17,055 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-08-11 23:09:17,060 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-08-11 23:09:17,063 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-08-11 23:09:17,368 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: start as a follower, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-08-11 23:09:17,388 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-08-11 23:09:17,397 [pool-23-thread-1] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState
datanode2_1  | 2021-08-11 23:09:17,448 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6FA1826E58A5,id=95d91451-f44f-4fa4-a508-c399bd523c99
datanode2_1  | 2021-08-11 23:09:17,574 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5
datanode2_1  | 2021-08-11 23:09:18,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:20,189 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-08-11 23:09:21,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:21,833 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
kdc_1        | Aug 11 23:13:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723621, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723625, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723625, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723625, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:13:56 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723636, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:13:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723636, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723636, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723636, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723636, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:10 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723650, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:14:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723650, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723650, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723650, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723667, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:14:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723667, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723667, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723667, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:14:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723691, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:14:58 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723698, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:15:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723698, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:15:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723713, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:15:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723713, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:15:47 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723747, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:15:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723747, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:15:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:15:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723755, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:16:02 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723762, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:16:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723762, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:16:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:16:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723768, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:16:14 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723774, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-08-11 23:09:21,837 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5.
datanode2_1  | 2021-08-11 23:09:21,843 [Command processor thread] INFO server.RaftServer: 95d91451-f44f-4fa4-a508-c399bd523c99: addNew group-13E7F8D4BE22:[95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-13E7F8D4BE22:java.util.concurrent.CompletableFuture@6746d23e[Not completed]
datanode2_1  | 2021-08-11 23:09:21,844 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99: new RaftServerImpl for group-13E7F8D4BE22:[95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-08-11 23:09:21,844 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-08-11 23:09:21,844 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22: ConfigurationManager, init=-1: [95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2021-08-11 23:09:21,846 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c604f00f-ba94-42dc-a421-13e7f8d4be22 does not exist. Creating ...
datanode2_1  | 2021-08-11 23:09:21,855 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c604f00f-ba94-42dc-a421-13e7f8d4be22/in_use.lock acquired by nodename 7@97f5bd8bbda3
datanode2_1  | 2021-08-11 23:09:21,860 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c604f00f-ba94-42dc-a421-13e7f8d4be22 has been successfully formatted.
datanode2_1  | 2021-08-11 23:09:21,865 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-13E7F8D4BE22: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-08-11 23:09:21,865 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-08-11 23:09:21,865 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-08-11 23:09:21,866 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-08-11 23:09:21,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-08-11 23:09:21,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:21,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-08-11 23:09:21,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-08-11 23:09:21,906 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c604f00f-ba94-42dc-a421-13e7f8d4be22
datanode2_1  | 2021-08-11 23:09:21,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-08-11 23:09:21,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-08-11 23:09:21,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:21,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-08-11 23:09:21,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-08-11 23:09:21,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-08-11 23:09:21,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-08-11 23:09:21,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-08-11 23:09:21,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:21,949 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-08-11 23:09:21,955 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1        | Aug 11 23:16:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723774, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:17:54 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723874, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:17:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723874, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:18:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723893, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:18:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723893, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:18:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628723914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:18:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628723914, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:23:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628724223, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:23:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628724223, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:24:06 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628724246, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:24:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1628724246, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 11 23:24:14 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628724254, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 11 23:24:14 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1628724254, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
om1_1        | 2021-08-11 23:09:31,256 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-08-11 23:09:31,309 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2021-08-11 23:09:31,313 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-08-11 23:09:31,314 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2021-08-11 23:09:31,332 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2021-08-11 23:09:31,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2021-08-11 23:09:31,591 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om1
om1_1        | 2021-08-11 23:09:31,799 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2021-08-11 23:09:31,802 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2021-08-11 23:09:31,830 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-08-11 23:09:31,880 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2021-08-11 23:09:31,887 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-08-11 23:09:31,997 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-08-11 23:09:32,140 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2021-08-11 23:09:32,154 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-08-11 23:09:05,350 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2021-08-11 23:09:05,350 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2021-08-11 23:09:05,350 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2021-08-11 23:09:05,356 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2021-08-11 23:09:05,606 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2021-08-11 23:09:05,632 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode3_1  | 2021-08-11 23:09:05,863 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2021-08-11 23:09:05,863 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2021-08-11 23:09:05,872 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2021-08-11 23:09:05,996 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-08-11 23:09:06,022 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16df0ebd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2021-08-11 23:09:06,034 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7104b117{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2021-08-11 23:09:06,743 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-08-11 23:09:06,789 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6f7e5e11{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-16793800665943697757/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2021-08-11 23:09:06,860 [main] INFO server.AbstractConnector: Started ServerConnector@7b23aea2{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2021-08-11 23:09:06,860 [main] INFO server.Server: Started @50779ms
datanode3_1  | 2021-08-11 23:09:06,881 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2021-08-11 23:09:06,886 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2021-08-11 23:09:06,896 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2021-08-11 23:09:07,144 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63c4a0c3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2021-08-11 23:09:07,472 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2021-08-11 23:09:10,425 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2021-08-11 23:09:10,436 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2021-08-11 23:09:11,167 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode3_1  | 2021-08-11 23:09:11,359 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: fb8d185f-2f23-4800-ba90-a65832b06bb3: start RPC server
datanode3_1  | 2021-08-11 23:09:11,372 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: fb8d185f-2f23-4800-ba90-a65832b06bb3: GrpcService started, listening on 9856
datanode3_1  | 2021-08-11 23:09:11,374 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: fb8d185f-2f23-4800-ba90-a65832b06bb3: GrpcService started, listening on 9857
datanode3_1  | 2021-08-11 23:09:11,381 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: fb8d185f-2f23-4800-ba90-a65832b06bb3: GrpcService started, listening on 9858
datanode3_1  | 2021-08-11 23:09:11,401 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis fb8d185f-2f23-4800-ba90-a65832b06bb3 is started using port 9858 for RATIS
datanode3_1  | 2021-08-11 23:09:11,402 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis fb8d185f-2f23-4800-ba90-a65832b06bb3 is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2021-08-11 23:09:11,402 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis fb8d185f-2f23-4800-ba90-a65832b06bb3 is started using port 9856 for RATIS_SERVER
datanode3_1  | 2021-08-11 23:09:11,421 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$333/0x00000008405a9c40@792f6f10] INFO util.JvmPauseMonitor: JvmPauseMonitor-fb8d185f-2f23-4800-ba90-a65832b06bb3: Started
datanode3_1  | 2021-08-11 23:09:11,458 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-08-11 23:09:11,459 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-08-11 23:09:13,380 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:16,272 [Command processor thread] INFO server.RaftServer: fb8d185f-2f23-4800-ba90-a65832b06bb3: addNew group-6FA1826E58A5:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-6FA1826E58A5:java.util.concurrent.CompletableFuture@246354d0[Not completed]
datanode3_1  | 2021-08-11 23:09:16,446 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:16,513 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3: new RaftServerImpl for group-6FA1826E58A5:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-08-11 23:09:16,519 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-08-11 23:09:16,527 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-08-11 23:09:16,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-08-11 23:09:16,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
om1_1        | 2021-08-11 23:09:32,163 [Listener at om1/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om1_1        | 2021-08-11 23:09:32,194 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2021-08-11 23:09:32,194 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-08-11 23:09:32,194 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2021-08-11 23:09:32,214 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-08-11 23:09:32,214 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2021-08-11 23:09:32,227 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-08-11 23:09:16,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-08-11 23:09:16,535 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-08-11 23:09:16,536 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-08-11 23:09:16,662 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: ConfigurationManager, init=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-08-11 23:09:16,672 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-08-11 23:09:16,701 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-08-11 23:09:16,711 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2021-08-11 23:09:16,716 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5 does not exist. Creating ...
datanode3_1  | 2021-08-11 23:09:16,779 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5/in_use.lock acquired by nodename 7@9858c43d50b5
datanode3_1  | 2021-08-11 23:09:16,825 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5 has been successfully formatted.
datanode3_1  | 2021-08-11 23:09:16,911 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-6FA1826E58A5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-08-11 23:09:16,927 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-08-11 23:09:16,949 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-08-11 23:09:17,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-08-11 23:09:17,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-08-11 23:09:17,225 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-08-11 23:09:17,262 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-08-11 23:09:17,284 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-08-11 23:09:17,305 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5
datanode3_1  | 2021-08-11 23:09:17,309 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-08-11 23:09:17,311 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-08-11 23:09:17,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-08-11 23:09:17,316 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-08-11 23:09:17,317 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-08-11 23:09:17,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-08-11 23:09:17,336 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-08-11 23:09:17,338 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-08-11 23:09:17,400 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-08-11 23:09:17,408 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-08-11 23:09:17,448 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-08-11 23:09:17,456 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-08-11 23:09:17,474 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-08-11 23:09:17,479 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-08-11 23:09:17,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-08-11 23:09:17,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-08-11 23:09:17,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-08-11 23:09:17,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-08-11 23:09:17,669 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: start as a follower, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-08-11 23:09:17,695 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-08-11 23:09:17,704 [pool-23-thread-1] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState
datanode3_1  | 2021-08-11 23:09:17,729 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6FA1826E58A5,id=fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode3_1  | 2021-08-11 23:09:17,891 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5
datanode3_1  | 2021-08-11 23:09:19,527 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-08-11 23:08:25,113 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:09Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-08-11 23:08:25,179 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-08-11 23:08:33,372 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-08-11 23:08:33,895 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-08-11 23:08:33,904 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-08-11 23:08:33,904 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-08-11 23:08:35,771 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2021-08-11 23:08:35,771 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-08-11 23:08:35,859 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-08-11 23:08:39,317 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2021-08-11 23:08:43,153 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2021-08-11 23:08:43,153 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2021-08-11 23:08:43,175 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2021-08-11 23:08:48,777 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2021-08-11 23:08:48,982 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2021-08-11 23:08:49,006 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2021-08-11 23:08:49,012 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2021-08-11 23:08:49,030 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-08-11 23:08:49,040 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-08-11 23:08:49,047 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-08-11 23:08:49,057 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-08-11 23:08:49,060 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:4742394c-da80-4695-95c5-c0a43d189463,clusterId:CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd,subject:om3
om3_1        | 2021-08-11 23:08:50,022 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
datanode2_1  | 2021-08-11 23:09:21,955 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-08-11 23:09:21,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-08-11 23:09:21,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-08-11 23:09:21,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-08-11 23:09:21,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-08-11 23:09:21,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-08-11 23:09:21,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-08-11 23:09:21,968 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22: start as a follower, conf=-1: [95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-08-11 23:09:21,970 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-08-11 23:09:21,974 [pool-23-thread-1] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-FollowerState
datanode2_1  | 2021-08-11 23:09:22,021 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-13E7F8D4BE22,id=95d91451-f44f-4fa4-a508-c399bd523c99
datanode2_1  | 2021-08-11 23:09:22,024 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=c604f00f-ba94-42dc-a421-13e7f8d4be22
datanode2_1  | 2021-08-11 23:09:22,031 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=c604f00f-ba94-42dc-a421-13e7f8d4be22.
datanode2_1  | 2021-08-11 23:09:22,032 [Command processor thread] INFO server.RaftServer: 95d91451-f44f-4fa4-a508-c399bd523c99: addNew group-8FBFF034B0CD:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-8FBFF034B0CD:java.util.concurrent.CompletableFuture@9664f32[Not completed]
datanode2_1  | 2021-08-11 23:09:22,043 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99: new RaftServerImpl for group-8FBFF034B0CD:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-08-11 23:09:22,064 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-08-11 23:09:22,065 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-08-11 23:09:22,065 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-08-11 23:09:22,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-08-11 23:09:22,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-08-11 23:09:22,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-08-11 23:09:22,071 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-08-11 23:09:22,074 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD: ConfigurationManager, init=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-08-11 23:09:22,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-08-11 23:09:22,077 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-08-11 23:09:22,085 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2021-08-11 23:09:22,085 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd does not exist. Creating ...
datanode2_1  | 2021-08-11 23:09:22,093 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd/in_use.lock acquired by nodename 7@97f5bd8bbda3
datanode2_1  | 2021-08-11 23:09:22,107 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd has been successfully formatted.
datanode2_1  | 2021-08-11 23:09:22,113 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-8FBFF034B0CD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-08-11 23:09:22,124 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-08-11 23:09:22,140 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-08-11 23:09:22,143 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-08-11 23:09:22,144 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-08-11 23:09:22,155 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:22,167 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-08-11 23:09:22,170 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-08-11 23:09:22,171 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd
datanode2_1  | 2021-08-11 23:09:22,171 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-08-11 23:09:22,171 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-08-11 23:09:22,171 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 97333428-a9dc-49fc-bc54-326166febdda: group-6FA1826E58A5 not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-08-11 23:09:25,041 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 97333428-a9dc-49fc-bc54-326166febdda: Failed requestVote fb8d185f-2f23-4800-ba90-a65832b06bb3->97333428-a9dc-49fc-bc54-326166febdda#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 97333428-a9dc-49fc-bc54-326166febdda: group-6FA1826E58A5 not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-08-11 23:09:25,072 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:26,961 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 97333428-a9dc-49fc-bc54-326166febdda: Failed requestVote fb8d185f-2f23-4800-ba90-a65832b06bb3->97333428-a9dc-49fc-bc54-326166febdda#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 97333428-a9dc-49fc-bc54-326166febdda: group-8FBFF034B0CD not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-08-11 23:09:28,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:30,435 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 97333428-a9dc-49fc-bc54-326166febdda: Failed requestVote 95d91451-f44f-4fa4-a508-c399bd523c99->97333428-a9dc-49fc-bc54-326166febdda#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 97333428-a9dc-49fc-bc54-326166febdda: group-6FA1826E58A5 not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode2_1  | 2021-08-11 23:09:22,171 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-08-11 23:09:22,172 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-08-11 23:09:22,175 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-08-11 23:09:22,175 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-08-11 23:09:22,177 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-08-11 23:09:22,190 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:22,191 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-08-11 23:09:22,193 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-08-11 23:09:22,196 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-08-11 23:09:22,196 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-08-11 23:09:22,197 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-08-11 23:09:22,197 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-08-11 23:09:22,198 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-08-11 23:09:22,201 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om1_1        | 2021-08-11 23:09:32,229 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2021-08-11 23:09:32,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2021-08-11 23:09:32,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2021-08-11 23:09:32,359 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2021-08-11 23:09:32,360 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2021-08-11 23:09:32,405 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2021-08-11 23:09:32,422 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2021-08-11 23:09:32,427 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2021-08-11 23:09:32,458 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2021-08-11 23:09:32,463 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2021-08-11 23:09:32,464 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2021-08-11 23:09:32,475 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2021-08-11 23:09:32,507 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2021-08-11 23:09:32,921 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2021-08-11 23:09:32,970 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2021-08-11 23:09:32,970 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2021-08-11 23:09:33,122 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2021-08-11 23:09:33,142 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2021-08-11 23:09:33,144 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-08-11 23:09:33,154 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2021-08-11 23:09:33,159 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-08-11 23:09:33,169 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2021-08-11 23:09:33,231 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2021-08-11 23:09:33,440 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2021-08-11 23:09:33,462 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2021-08-11 23:09:33,462 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-08-11 23:09:33,464 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2021-08-11 23:09:33,464 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-08-11 23:09:33,468 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$393/0x00000008405ba840@2ca2fcb5] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2021-08-11 23:09:33,481 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2021-08-11 23:09:33,543 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2021-08-11 23:09:33,690 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2021-08-11 23:09:33,691 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2021-08-11 23:09:33,691 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2021-08-11 23:09:33,791 [Listener at om1/9862] INFO util.log: Logging initialized @40111ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2021-08-11 23:09:34,196 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2021-08-11 23:09:34,214 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2021-08-11 23:09:34,228 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2021-08-11 23:09:34,231 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2021-08-11 23:09:34,231 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2021-08-11 23:09:34,237 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2021-08-11 23:09:34,380 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2021-08-11 23:09:34,384 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om1_1        | 2021-08-11 23:09:34,508 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2021-08-11 23:09:34,508 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2021-08-11 23:09:34,510 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2021-08-11 23:09:34,588 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-08-11 23:09:34,594 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33681da{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2021-08-11 23:09:34,610 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7118a1b9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2021-08-11 23:09:34,950 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-08-11 23:09:31,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:34,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:37,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:40,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:43,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:45,610 [Command processor thread] INFO server.RaftServer: 97333428-a9dc-49fc-bc54-326166febdda: addNew group-B867116D2715:[97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-B867116D2715:java.util.concurrent.CompletableFuture@1e401e48[Not completed]
datanode1_1  | 2021-08-11 23:09:45,651 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda: new RaftServerImpl for group-B867116D2715:[97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-08-11 23:09:45,653 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-08-11 23:09:45,654 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-08-11 23:09:45,655 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-08-11 23:09:45,655 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-08-11 23:09:45,655 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-08-11 23:09:45,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-08-11 23:09:45,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-08-11 23:09:45,679 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715: ConfigurationManager, init=-1: [97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-08-11 23:09:45,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-08-11 23:09:45,706 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-08-11 23:09:45,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2021-08-11 23:09:45,708 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/79bd80c8-0720-41ff-85aa-b867116d2715 does not exist. Creating ...
datanode1_1  | 2021-08-11 23:09:45,719 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/79bd80c8-0720-41ff-85aa-b867116d2715/in_use.lock acquired by nodename 8@5f0669529782
datanode1_1  | 2021-08-11 23:09:45,733 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/79bd80c8-0720-41ff-85aa-b867116d2715 has been successfully formatted.
datanode1_1  | 2021-08-11 23:09:45,754 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-B867116D2715: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-08-11 23:09:45,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-08-11 23:09:45,780 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-08-11 23:09:45,862 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-08-11 23:09:45,894 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-08-11 23:09:45,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-08-11 23:09:45,945 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-08-11 23:09:45,947 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-08-11 23:09:45,960 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/79bd80c8-0720-41ff-85aa-b867116d2715
datanode1_1  | 2021-08-11 23:09:45,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-08-11 23:09:45,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-08-11 23:09:45,973 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-08-11 23:09:22,203 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-08-11 23:09:22,204 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD: start as a follower, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-08-11 23:09:22,207 [pool-23-thread-1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-08-11 23:09:22,211 [pool-23-thread-1] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-FollowerState
datanode2_1  | 2021-08-11 23:09:22,213 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8FBFF034B0CD,id=95d91451-f44f-4fa4-a508-c399bd523c99
datanode2_1  | 2021-08-11 23:09:22,231 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd
datanode2_1  | 2021-08-11 23:09:22,523 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO impl.FollowerState: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5126615235ns, electionTimeout:5075ms
datanode2_1  | 2021-08-11 23:09:22,524 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: shutdown 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState
datanode2_1  | 2021-08-11 23:09:22,556 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-08-11 23:09:22,563 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-08-11 23:09:22,616 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1
datanode2_1  | 2021-08-11 23:09:22,684 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-08-11 23:09:22,772 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-08-11 23:09:24,122 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-08-11 23:09:24,160 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd.
datanode2_1  | 2021-08-11 23:09:24,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:25,127 [grpc-default-executor-0] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: receive requestVote(ELECTION, fb8d185f-2f23-4800-ba90-a65832b06bb3, group-6FA1826E58A5, 1, (t:0, i:0))
datanode2_1  | 2021-08-11 23:09:25,130 [grpc-default-executor-0] INFO impl.VoteContext: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-CANDIDATE: reject ELECTION from fb8d185f-2f23-4800-ba90-a65832b06bb3: already has voted for 95d91451-f44f-4fa4-a508-c399bd523c99 at current term 1
datanode2_1  | 2021-08-11 23:09:25,205 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 97333428-a9dc-49fc-bc54-326166febdda: group-6FA1826E58A5 not found.
datanode2_1  | 2021-08-11 23:09:25,212 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1: ELECTION REJECTED received 1 response(s) and 1 exception(s):
datanode2_1  | 2021-08-11 23:09:25,216 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection:   Response 0: 95d91451-f44f-4fa4-a508-c399bd523c99<-fb8d185f-2f23-4800-ba90-a65832b06bb3#0:FAIL-t1
datanode2_1  | 2021-08-11 23:09:25,216 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 97333428-a9dc-49fc-bc54-326166febdda: group-6FA1826E58A5 not found.
datanode2_1  | 2021-08-11 23:09:25,216 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1 ELECTION round 0: result REJECTED
datanode3_1  | 2021-08-11 23:09:20,231 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-08-11 23:09:21,810 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode1_1  | 2021-08-11 23:09:45,979 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-08-11 23:09:45,979 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-08-11 23:09:45,980 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-08-11 23:09:45,981 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-08-11 23:09:45,981 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-08-11 23:09:45,997 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-08-11 23:09:45,998 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-08-11 23:09:46,031 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-08-11 23:09:46,032 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-08-11 23:09:46,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-08-11 23:09:46,048 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-08-11 23:09:46,052 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-08-11 23:09:46,052 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-08-11 23:09:46,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-08-11 23:09:46,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-08-11 23:09:46,169 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715: start as a follower, conf=-1: [97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-08-11 23:09:46,170 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-08-11 23:09:46,175 [pool-23-thread-1] INFO impl.RoleInfo: 97333428-a9dc-49fc-bc54-326166febdda: start 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-FollowerState
datanode1_1  | 2021-08-11 23:09:46,189 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B867116D2715,id=97333428-a9dc-49fc-bc54-326166febdda
datanode1_1  | 2021-08-11 23:09:46,272 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=79bd80c8-0720-41ff-85aa-b867116d2715
datanode1_1  | 2021-08-11 23:09:46,275 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=79bd80c8-0720-41ff-85aa-b867116d2715.
datanode1_1  | 2021-08-11 23:09:46,277 [Command processor thread] INFO server.RaftServer: 97333428-a9dc-49fc-bc54-326166febdda: addNew group-6FA1826E58A5:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-6FA1826E58A5:java.util.concurrent.CompletableFuture@83f6e58[Not completed]
datanode1_1  | 2021-08-11 23:09:46,292 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda: new RaftServerImpl for group-6FA1826E58A5:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-08-11 23:09:46,292 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-08-11 23:09:46,292 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-08-11 23:09:46,293 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-08-11 23:09:46,295 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-08-11 23:09:46,295 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-08-11 23:09:46,296 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-08-11 23:09:46,296 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-08-11 23:09:46,296 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5: ConfigurationManager, init=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-08-11 23:09:46,296 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-08-11 23:09:46,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-08-11 23:09:46,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2021-08-11 23:09:46,297 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5 does not exist. Creating ...
datanode1_1  | 2021-08-11 23:09:46,298 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5/in_use.lock acquired by nodename 8@5f0669529782
datanode1_1  | 2021-08-11 23:09:46,302 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5 has been successfully formatted.
datanode1_1  | 2021-08-11 23:09:46,303 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-6FA1826E58A5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-08-11 23:09:46,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-08-11 23:09:46,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-08-11 23:09:46,352 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-08-11 23:09:46,357 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-08-11 23:09:25,232 [grpc-default-executor-0] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5 replies to ELECTION vote request: fb8d185f-2f23-4800-ba90-a65832b06bb3<-95d91451-f44f-4fa4-a508-c399bd523c99#0:FAIL-t1. Peer's state: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5:t1, leader=null, voted=95d91451-f44f-4fa4-a508-c399bd523c99, raftlog=95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-08-11 23:09:25,236 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode2_1  | 2021-08-11 23:09:25,238 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: shutdown 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1
datanode2_1  | 2021-08-11 23:09:25,238 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection1] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState
datanode2_1  | 2021-08-11 23:09:26,967 [grpc-default-executor-0] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD: receive requestVote(ELECTION, fb8d185f-2f23-4800-ba90-a65832b06bb3, group-8FBFF034B0CD, 1, (t:0, i:0))
datanode2_1  | 2021-08-11 23:09:26,967 [grpc-default-executor-0] INFO impl.VoteContext: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-FOLLOWER: accept ELECTION from fb8d185f-2f23-4800-ba90-a65832b06bb3: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-08-11 23:09:26,967 [grpc-default-executor-0] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode2_1  | 2021-08-11 23:09:26,968 [grpc-default-executor-0] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: shutdown 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-FollowerState
datanode2_1  | 2021-08-11 23:09:26,968 [grpc-default-executor-0] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-FollowerState
datanode2_1  | 2021-08-11 23:09:26,968 [95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-FollowerState] INFO impl.FollowerState: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2021-08-11 23:09:26,994 [grpc-default-executor-0] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD replies to ELECTION vote request: fb8d185f-2f23-4800-ba90-a65832b06bb3<-95d91451-f44f-4fa4-a508-c399bd523c99#0:OK-t1. Peer's state: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD:t1, leader=null, voted=fb8d185f-2f23-4800-ba90-a65832b06bb3, raftlog=95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-08-11 23:09:27,183 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-FollowerState] INFO impl.FollowerState: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5208919231ns, electionTimeout:5160ms
datanode2_1  | 2021-08-11 23:09:27,184 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-FollowerState] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: shutdown 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-FollowerState
datanode2_1  | 2021-08-11 23:09:27,184 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-FollowerState] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-08-11 23:09:27,184 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-08-11 23:09:27,184 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-FollowerState] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2
datanode2_1  | 2021-08-11 23:09:27,187 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-08-11 23:09:27,191 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2021-08-11 23:09:27,191 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: shutdown 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2
datanode2_1  | 2021-08-11 23:09:27,191 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2021-08-11 23:09:27,191 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-13E7F8D4BE22 with new leaderId: 95d91451-f44f-4fa4-a508-c399bd523c99
datanode2_1  | 2021-08-11 23:09:27,192 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22: change Leader from null to 95d91451-f44f-4fa4-a508-c399bd523c99 at term 1 for becomeLeader, leader elected after 5325ms
datanode2_1  | 2021-08-11 23:09:27,205 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2021-08-11 23:09:27,221 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2021-08-11 23:09:27,222 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2021-08-11 23:09:27,229 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2021-08-11 23:09:27,241 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2021-08-11 23:09:27,245 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2021-08-11 23:09:27,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:27,325 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderStateImpl
datanode2_1  | 2021-08-11 23:09:27,429 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-08-11 23:09:27,600 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8FBFF034B0CD with new leaderId: fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode2_1  | 2021-08-11 23:09:27,605 [grpc-default-executor-0] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD: change Leader from null to fb8d185f-2f23-4800-ba90-a65832b06bb3 at term 1 for appendEntries, leader elected after 5476ms
datanode2_1  | 2021-08-11 23:09:27,648 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-LeaderElection2] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22: set configuration 0: [95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-08-11 23:09:27,785 [grpc-default-executor-0] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD: set configuration 0: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2021-08-11 23:09:27,791 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-08-11 23:09:28,058 [95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-8FBFF034B0CD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd/current/log_inprogress_0
datanode2_1  | 2021-08-11 23:09:28,058 [95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-13E7F8D4BE22-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c604f00f-ba94-42dc-a421-13e7f8d4be22/current/log_inprogress_0
datanode2_1  | 2021-08-11 23:09:30,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:30,382 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO impl.FollowerState: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5143959992ns, electionTimeout:5118ms
datanode2_1  | 2021-08-11 23:09:30,382 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: shutdown 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState
datanode2_1  | 2021-08-11 23:09:30,383 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2021-08-11 23:09:30,383 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-08-11 23:09:30,383 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-FollowerState] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3
datanode2_1  | 2021-08-11 23:09:30,385 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-08-11 23:09:30,424 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2021-08-11 23:09:30,426 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO impl.LeaderElection:   Response 0: 95d91451-f44f-4fa4-a508-c399bd523c99<-fb8d185f-2f23-4800-ba90-a65832b06bb3#0:OK-t2
datanode2_1  | 2021-08-11 23:09:30,426 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO impl.LeaderElection: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3 ELECTION round 0: result PASSED
datanode2_1  | 2021-08-11 23:09:30,427 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: shutdown 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3
datanode2_1  | 2021-08-11 23:09:30,427 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode2_1  | 2021-08-11 23:09:30,427 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6FA1826E58A5 with new leaderId: 95d91451-f44f-4fa4-a508-c399bd523c99
datanode2_1  | 2021-08-11 23:09:30,430 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode2_1  | 2021-08-11 23:09:30,430 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: change Leader from null to 95d91451-f44f-4fa4-a508-c399bd523c99 at term 2 for becomeLeader, leader elected after 14006ms
datanode2_1  | 2021-08-11 23:09:30,437 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2021-08-11 23:09:30,447 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2021-08-11 23:09:30,448 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2021-08-11 23:09:30,450 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2021-08-11 23:09:30,451 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2021-08-11 23:09:30,451 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-08-11 23:09:46,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-08-11 23:09:46,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-08-11 23:09:46,368 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-08-11 23:09:46,368 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5
datanode1_1  | 2021-08-11 23:09:46,368 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-08-11 23:09:46,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-08-11 23:09:46,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-08-11 23:09:46,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-08-11 23:09:46,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-08-11 23:09:46,371 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-08-11 23:09:46,372 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-08-11 23:09:46,372 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-08-11 23:09:46,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-08-11 23:09:46,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-08-11 23:09:46,374 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-08-11 23:09:46,375 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-08-11 23:09:46,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-08-11 23:09:46,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-08-11 23:09:46,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-08-11 23:09:46,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-08-11 23:09:46,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-08-11 23:09:46,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-08-11 23:09:46,381 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5: start as a follower, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2021-08-11 23:09:46,385 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-08-11 23:09:46,385 [pool-23-thread-1] INFO impl.RoleInfo: 97333428-a9dc-49fc-bc54-326166febdda: start 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5-FollowerState
datanode1_1  | 2021-08-11 23:09:46,386 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6FA1826E58A5,id=97333428-a9dc-49fc-bc54-326166febdda
datanode1_1  | 2021-08-11 23:09:46,390 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5
datanode1_1  | 2021-08-11 23:09:46,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:46,905 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-08-11 23:09:47,057 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2021-08-11 23:07:09,472 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode3_1  | 	... 18 more
datanode3_1  | 2021-08-11 23:09:21,817 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5.
datanode3_1  | 2021-08-11 23:09:21,817 [Command processor thread] INFO server.RaftServer: fb8d185f-2f23-4800-ba90-a65832b06bb3: addNew group-8FBFF034B0CD:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-8FBFF034B0CD:java.util.concurrent.CompletableFuture@580ed4d5[Not completed]
datanode3_1  | 2021-08-11 23:09:21,819 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3: new RaftServerImpl for group-8FBFF034B0CD:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-08-11 23:09:21,821 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-08-11 23:09:21,821 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-08-11 23:09:21,821 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-08-11 23:09:21,821 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-08-11 23:09:21,821 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-08-11 23:09:21,841 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-08-11 23:09:21,841 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-08-11 23:09:21,842 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD: ConfigurationManager, init=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-08-11 23:09:21,842 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-08-11 23:09:21,843 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-08-11 23:09:21,844 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2021-08-11 23:09:21,845 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd does not exist. Creating ...
datanode3_1  | 2021-08-11 23:09:21,854 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd/in_use.lock acquired by nodename 7@9858c43d50b5
datanode3_1  | 2021-08-11 23:09:21,860 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd has been successfully formatted.
datanode3_1  | 2021-08-11 23:09:21,861 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-8FBFF034B0CD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-08-11 23:09:21,885 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-08-11 23:09:21,894 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-08-11 23:09:21,897 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-08-11 23:09:21,900 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-08-11 23:09:21,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-08-11 23:09:21,903 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-08-11 23:09:21,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-08-11 23:09:21,904 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd
datanode3_1  | 2021-08-11 23:09:21,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-08-11 23:09:21,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-08-11 23:09:21,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-08-11 23:09:21,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-08-11 23:09:21,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-08-11 23:09:21,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-08-11 23:09:21,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-08-11 23:09:21,908 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-08-11 23:09:21,908 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-08-11 23:09:21,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-08-11 23:09:21,913 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-08-11 23:09:21,915 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-08-11 23:09:21,925 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-08-11 23:09:21,925 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-08-11 23:09:21,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-08-11 23:09:21,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-08-11 23:09:21,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-08-11 23:09:21,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-08-11 23:09:21,927 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD: start as a follower, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-08-11 23:09:21,930 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2021-08-11 23:08:52,134 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd;layoutVersion=0
om3_1        | 2021-08-11 23:08:52,283 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-08-11 23:09:01,408 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:09Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-08-11 23:09:01,514 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-08-11 23:09:09,333 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-08-11 23:09:09,820 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-08-11 23:09:09,821 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-08-11 23:09:09,826 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-08-11 23:09:09,886 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-08-11 23:09:10,115 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om3_1        | 2021-08-11 23:09:11,701 [main] INFO reflections.Reflections: Reflections took 982 ms to scan 1 urls, producing 95 keys and 258 values [using 2 cores]
om3_1        | 2021-08-11 23:09:12,894 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2021-08-11 23:09:12,915 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-08-11 23:09:12,921 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-08-11 23:09:21,428 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2021-08-11 23:09:22,436 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2021-08-11 23:09:22,479 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2932114727528.crt.
om3_1        | 2021-08-11 23:09:22,490 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/3022345120107.crt.
om3_1        | 2021-08-11 23:09:22,712 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-08-11 23:09:23,489 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-08-11 23:09:23,506 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-08-11 23:09:24,854 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2021-08-11 23:09:24,866 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2021-08-11 23:09:25,366 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2021-08-11 23:09:25,994 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-08-11 23:09:25,996 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2021-08-11 23:09:26,077 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2021-08-11 23:09:26,765 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2021-08-11 23:09:26,798 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-08-11 23:09:26,917 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2021-08-11 23:09:26,978 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2021-08-11 23:09:27,961 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2021-08-11 23:09:28,230 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2021-08-11 23:09:28,242 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-08-11 23:09:28,245 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2021-08-11 23:09:28,250 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-08-11 23:09:28,250 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-08-11 23:09:28,251 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2021-08-11 23:09:28,254 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-08-11 23:09:28,260 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2021-08-11 23:09:28,261 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-08-11 23:09:31,471 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2021-08-11 23:09:31,476 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-08-11 23:09:31,479 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-08-11 23:09:31,651 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-08-11 23:09:31,722 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@605a10fd[Not completed]
om3_1        | 2021-08-11 23:09:31,722 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2021-08-11 23:09:31,875 [pool-24-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2021-08-11 23:09:31,888 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2021-08-11 23:09:31,897 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2021-08-11 23:09:31,900 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2021-08-11 23:09:31,901 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-08-11 23:09:31,907 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-08-11 23:09:31,915 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2021-08-11 23:09:31,919 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-08-11 23:09:31,953 [pool-24-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2021-08-11 23:09:31,990 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-08-11 23:09:32,018 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2021-08-11 23:09:32,027 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2021-08-11 23:09:32,032 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2021-08-11 23:09:32,033 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2021-08-11 23:09:32,076 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om3
om3_1        | 2021-08-11 23:09:32,083 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2021-08-11 23:09:32,204 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2021-08-11 23:09:32,217 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2021-08-11 23:09:32,250 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-08-11 23:09:30,492 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2021-08-11 23:09:30,493 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-08-11 23:09:30,493 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2021-08-11 23:09:30,504 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2021-08-11 23:09:30,514 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-08-11 23:09:30,514 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-08-11 23:09:30,541 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2021-08-11 23:09:30,545 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-08-11 23:09:30,546 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2021-08-11 23:09:30,546 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2021-08-11 23:09:30,551 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-08-11 23:09:30,552 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-08-11 23:09:30,559 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO impl.RoleInfo: 95d91451-f44f-4fa4-a508-c399bd523c99: start 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderStateImpl
datanode2_1  | 2021-08-11 23:09:30,560 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-08-11 23:09:30,567 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5/current/log_inprogress_0
datanode2_1  | 2021-08-11 23:09:30,581 [95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5-LeaderElection3] INFO server.RaftServer$Division: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5: set configuration 0: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2021-08-11 23:09:33,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:36,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:39,567 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:42,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:45,711 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:48,340 [grpc-default-executor-0] INFO leader.FollowerInfo: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda: nextIndex: updateUnconditionally 1 -> 0
datanode2_1  | 2021-08-11 23:09:48,780 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:51,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:54,927 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:09:57,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:00,071 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode2_1  | java.net.NoRouteToHostException: No Route to Host from  97f5bd8bbda3/172.25.0.103 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:855)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode2_1  | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
datanode2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode2_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode2_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:701)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:822)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1647)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1463)
datanode2_1  | 	... 12 more
datanode2_1  | 2021-08-11 23:10:04,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:07,215 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:10,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:13,360 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:16,220 [ChunkWriter-4-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:3023215292325.
datanode2_1  | 2021-08-11 23:10:16,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:19,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:22,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:25,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:28,716 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-08-11 23:08:25,265 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2021-08-11 23:07:08,710 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2021-08-11 23:07:08,710 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2021-08-11 23:07:08,932 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2021-08-11 23:07:08,932 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2021-08-11 23:07:08,932 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2021-08-11 23:07:09,045 [main] INFO util.log: Logging initialized @4793ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2021-08-11 23:07:09,657 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2021-08-11 23:07:09,684 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2021-08-11 23:07:09,685 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2021-08-11 23:07:09,685 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2021-08-11 23:07:09,685 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2021-08-11 23:07:09,712 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2021-08-11 23:07:09,969 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-08-11 23:07:08,125 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
scm1.org_1   | 2021-08-11 23:07:08,185 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-08-11 23:07:08,677 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-08-11 23:07:08,959 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-08-11 23:07:08,993 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-08-11 23:07:09,392 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2021-08-11 23:07:09,392 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-08-11 23:07:09,467 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2021-08-11 23:07:13,453 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2021-08-11 23:07:13,499 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2021-08-11 23:07:13,512 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2021-08-11 23:07:17,744 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2021-08-11 23:07:20,292 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-08-11 23:07:20,292 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-08-11 23:07:20,727 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-08-11 23:07:20,734 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-08-11 23:07:20,735 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:4742394c-da80-4695-95c5-c0a43d189463,clusterId:CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd,subject:scm-sub@scm1.org
scm1.org_1   | 2021-08-11 23:07:21,092 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2021-08-11 23:07:21,649 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2021-08-11 23:07:21,968 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-08-11 23:07:21,971 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-08-11 23:07:21,972 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2021-08-11 23:07:21,972 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-08-11 23:07:21,974 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-08-11 23:07:21,983 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-08-11 23:07:21,984 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-08-11 23:07:21,989 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-08-11 23:07:21,990 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-08-11 23:07:22,754 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-08-11 23:07:22,756 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-08-11 23:07:22,767 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-08-11 23:07:22,791 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-08-11 23:07:22,796 [main] INFO server.RaftServer: 4742394c-da80-4695-95c5-c0a43d189463: addNew group-6C975B8E17FD:[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|priority:0] returns group-6C975B8E17FD:java.util.concurrent.CompletableFuture@58f437b0[Not completed]
scm1.org_1   | 2021-08-11 23:07:22,930 [pool-2-thread-1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463: new RaftServerImpl for group-6C975B8E17FD:[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-08-11 23:07:22,940 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-08-11 23:07:22,951 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2021-08-11 23:07:22,951 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2021-08-11 23:07:22,952 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-08-11 23:07:22,952 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-08-11 23:07:22,952 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2021-08-11 23:07:22,953 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-08-11 23:07:22,957 [pool-2-thread-1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: ConfigurationManager, init=-1: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-08-11 23:07:22,967 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-08-11 23:07:22,980 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-08-11 23:07:22,991 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2021-08-11 23:07:22,993 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd does not exist. Creating ...
scm1.org_1   | 2021-08-11 23:07:23,036 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/in_use.lock acquired by nodename 91@scm1.org
scm1.org_1   | 2021-08-11 23:07:23,071 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd has been successfully formatted.
datanode2_1  | 2021-08-11 23:10:31,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:34,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:37,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:41,007 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:44,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:47,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:48,342 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:2, i:0)
datanode2_1  | 2021-08-11 23:10:53,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:56,364 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:10:59,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:21,930 [pool-23-thread-1] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-FollowerState
datanode3_1  | 2021-08-11 23:09:21,939 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8FBFF034B0CD,id=fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode3_1  | 2021-08-11 23:09:21,959 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd
datanode3_1  | 2021-08-11 23:09:22,581 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:22,621 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-08-11 23:09:22,837 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState] INFO impl.FollowerState: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5138846920ns, electionTimeout:5101ms
datanode3_1  | 2021-08-11 23:09:22,852 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: shutdown fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState
datanode3_1  | 2021-08-11 23:09:22,866 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-08-11 23:09:22,869 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-08-11 23:09:22,869 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1
datanode3_1  | 2021-08-11 23:09:22,935 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-08-11 23:09:23,615 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-08-11 23:09:23,632 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd.
datanode3_1  | 2021-08-11 23:09:23,633 [Command processor thread] INFO server.RaftServer: fb8d185f-2f23-4800-ba90-a65832b06bb3: addNew group-ED00911F12B5:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-ED00911F12B5:java.util.concurrent.CompletableFuture@67f18c1a[Not completed]
datanode3_1  | 2021-08-11 23:09:23,642 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3: new RaftServerImpl for group-ED00911F12B5:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-08-11 23:09:23,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-08-11 23:09:23,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-08-11 23:09:23,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-08-11 23:09:23,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-08-11 23:09:23,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-08-11 23:09:23,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-08-11 23:09:23,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-08-11 23:09:23,659 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5: ConfigurationManager, init=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-08-11 23:09:23,660 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-08-11 23:09:23,660 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-08-11 23:09:23,660 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2021-08-11 23:09:23,660 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7d30a22a-435f-40ae-b84a-ed00911f12b5 does not exist. Creating ...
datanode3_1  | 2021-08-11 23:09:23,679 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7d30a22a-435f-40ae-b84a-ed00911f12b5/in_use.lock acquired by nodename 7@9858c43d50b5
datanode3_1  | 2021-08-11 23:09:23,684 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7d30a22a-435f-40ae-b84a-ed00911f12b5 has been successfully formatted.
datanode3_1  | 2021-08-11 23:09:23,719 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-ED00911F12B5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-08-11 23:09:23,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-08-11 23:09:23,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-08-11 23:09:23,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-08-11 23:09:23,721 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-08-11 23:09:23,721 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om3_1        | 2021-08-11 23:09:32,266 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2021-08-11 23:09:32,277 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-08-11 23:09:32,413 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-08-11 23:09:32,477 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2021-08-11 23:09:32,478 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2021-08-11 23:09:32,505 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2021-08-11 23:09:32,513 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-08-11 23:09:32,516 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2021-08-11 23:09:32,520 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-08-11 23:09:32,528 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2021-08-11 23:09:32,529 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.2.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:09Z
recon_1      | STARTUP_MSG:   java = 11.0.10
recon_1      | ************************************************************/
recon_1      | 2021-08-11 23:07:09,502 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2021-08-11 23:07:12,128 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1      | 2021-08-11 23:07:13,439 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2021-08-11 23:07:13,824 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2021-08-11 23:07:14,258 [main] ERROR recon.ReconServer: Error login in as Recon service. 
recon_1      | org.apache.hadoop.security.KerberosAuthException: failure to login: for principal: recon/recon@EXAMPLE.COM from keytab /etc/security/keytabs/recon.keytab javax.security.auth.login.LoginException: Unable to obtain password from user
recon_1      | 
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1986)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytabAndReturnUGI(UserGroupInformation.java:1361)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:1122)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:315)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.loginReconUser(ReconServer.java:218)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.loginReconUserIfSecurityEnabled(ReconServer.java:193)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:101)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:57)
recon_1      | 	at picocli.CommandLine.executeUserObject(CommandLine.java:1933)
recon_1      | 	at picocli.CommandLine.access$1100(CommandLine.java:145)
recon_1      | 	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2332)
recon_1      | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2326)
recon_1      | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2291)
recon_1      | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:2152)
recon_1      | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:2530)
recon_1      | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:2465)
recon_1      | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:96)
recon_1      | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:87)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:73)
recon_1      | Caused by: javax.security.auth.login.LoginException: Unable to obtain password from user
recon_1      | 
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.promptForPass(Krb5LoginModule.java:875)
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:738)
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.login(Krb5LoginModule.java:592)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.invoke(LoginContext.java:726)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext$4.run(LoginContext.java:665)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext$4.run(LoginContext.java:663)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:663)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.login(LoginContext.java:574)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext.login(UserGroupInformation.java:2065)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1975)
recon_1      | 	... 18 more
recon_1      | 2021-08-11 23:07:15,083 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-08-11 23:07:17,969 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
om3_1        | 2021-08-11 23:09:32,515 [Listener at om3/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om3_1        | 2021-08-11 23:09:32,537 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2021-08-11 23:09:32,546 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2021-08-11 23:09:32,547 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2021-08-11 23:09:32,596 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2021-08-11 23:09:32,675 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2021-08-11 23:09:32,712 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2021-08-11 23:09:32,712 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2021-08-11 23:09:32,730 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2021-08-11 23:09:32,739 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2021-08-11 23:09:32,744 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2021-08-11 23:09:32,756 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2021-08-11 23:09:32,768 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2021-08-11 23:09:32,768 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2021-08-11 23:09:33,101 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2021-08-11 23:09:33,163 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2021-08-11 23:09:33,163 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2021-08-11 23:09:33,450 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2021-08-11 23:09:33,456 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2021-08-11 23:09:33,467 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-08-11 23:09:33,469 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2021-08-11 23:09:33,470 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-08-11 23:09:33,474 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2021-08-11 23:09:33,508 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2021-08-11 23:09:33,723 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2021-08-11 23:09:33,731 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$393/0x00000008405b3040@b0e903a] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2021-08-11 23:09:33,732 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2021-08-11 23:09:33,738 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-08-11 23:09:33,740 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2021-08-11 23:09:33,741 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-08-11 23:09:33,759 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2021-08-11 23:09:33,769 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2021-08-11 23:09:33,908 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2021-08-11 23:09:33,909 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2021-08-11 23:09:33,909 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2021-08-11 23:09:33,987 [Listener at om3/9862] INFO util.log: Logging initialized @40691ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2021-08-11 23:09:34,412 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2021-08-11 23:09:34,436 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2021-08-11 23:09:34,440 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2021-08-11 23:09:34,442 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2021-08-11 23:09:34,442 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2021-08-11 23:09:34,450 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2021-08-11 23:09:34,609 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2021-08-11 23:09:34,615 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om3_1        | 2021-08-11 23:09:34,801 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2021-08-11 23:09:34,807 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2021-08-11 23:09:34,819 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2021-08-11 23:09:34,909 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-08-11 23:09:34,924 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@29fae990{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2021-08-11 23:09:34,947 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1483ecad{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2021-08-11 23:09:35,020 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5cb9ef8a{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-2214842533747499412/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2021-08-11 23:09:35,050 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@3087b35f{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2021-08-11 23:09:35,065 [Listener at om1/9862] INFO server.Server: Started @41383ms
om1_1        | 2021-08-11 23:09:35,070 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-08-11 23:09:35,070 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-08-11 23:09:35,072 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2021-08-11 23:09:35,077 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2021-08-11 23:09:35,092 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2021-08-11 23:09:35,174 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2021-08-11 23:09:35,315 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6dace32a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2021-08-11 23:09:38,319 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5160497825ns, electionTimeout:5142ms
om1_1        | 2021-08-11 23:09:38,321 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2021-08-11 23:09:38,322 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2021-08-11 23:09:38,325 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2021-08-11 23:09:38,325 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2021-08-11 23:09:38,359 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-08-11 23:09:40,150 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2021-08-11 23:09:40,162 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2021-08-11 23:09:40,196 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-08-11 23:09:40,424 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2021-08-11 23:09:40,425 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2021-08-11 23:09:40,425 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-08-11 23:09:40,453 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2021-08-11 23:09:40,454 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2021-08-11 23:09:40,454 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2021-08-11 23:09:40,454 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2021-08-11 23:09:40,456 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2021-08-11 23:09:40,460 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2021-08-11 23:09:40,461 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-08-11 23:09:45,515 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 2, (t:0, i:~))
om1_1        | 2021-08-11 23:09:45,516 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: accept ELECTION from om2: our priority 0 <= candidate's priority 0
om1_1        | 2021-08-11 23:09:45,517 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om2
om1_1        | 2021-08-11 23:09:45,517 [grpc-default-executor-1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2021-08-11 23:09:45,517 [grpc-default-executor-1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-08-11 23:09:45,519 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted: {}
om1_1        | java.lang.InterruptedException: sleep interrupted
om1_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om1_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om1_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om1_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om1_1        | 2021-08-11 23:09:45,521 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:OK-t2. Peer's state: om1@group-562213E44849:t2, leader=null, voted=om2, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-08-11 23:09:45,765 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om2 at term 2 for appendEntries, leader elected after 13962ms
om1_1        | 2021-08-11 23:09:45,909 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2021-08-11 23:09:45,945 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-08-11 23:11:02,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:05,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:08,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:11,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:14,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:16,099 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=266,entriesCount=1,lastEntry=(t:2, i:1)
datanode2_1  | 2021-08-11 23:11:16,129 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=267,entriesCount=1,lastEntry=(t:2, i:2)
datanode2_1  | 2021-08-11 23:11:17,502 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=269,entriesCount=1,lastEntry=(t:2, i:3)
datanode2_1  | 2021-08-11 23:11:17,504 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=270,entriesCount=1,lastEntry=(t:2, i:4)
datanode2_1  | 2021-08-11 23:11:17,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:20,943 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:24,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:27,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:30,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:33,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:36,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:42,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:45,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:48,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:51,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:54,735 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:11:57,807 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:00,876 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:03,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:07,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:10,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:13,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:16,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:19,308 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:22,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:25,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:31,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:34,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:37,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:40,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:43,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:46,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:50,031 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:53,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:56,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:12:59,243 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:02,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:05,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:08,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:11,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:14,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:19,807 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=560,entriesCount=1,lastEntry=(t:2, i:5)
datanode2_1  | 2021-08-11 23:13:19,813 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=561,entriesCount=1,lastEntry=(t:2, i:6)
datanode2_1  | 2021-08-11 23:13:19,833 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=563,entriesCount=1,lastEntry=(t:2, i:7)
datanode2_1  | 2021-08-11 23:13:19,848 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=564,entriesCount=1,lastEntry=(t:2, i:8)
datanode2_1  | 2021-08-11 23:13:20,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:23,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:26,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:29,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:09Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-08-11 23:08:25,314 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-08-11 23:08:34,076 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-08-11 23:08:34,595 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-08-11 23:08:34,605 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-08-11 23:08:34,605 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-08-11 23:08:36,553 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2021-08-11 23:08:36,581 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-08-11 23:08:36,679 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-08-11 23:08:39,712 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2021-08-11 23:08:42,955 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2021-08-11 23:08:42,955 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2021-08-11 23:08:42,956 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2021-08-11 23:08:49,642 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2021-08-11 23:08:49,810 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2021-08-11 23:08:49,821 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2021-08-11 23:08:49,839 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2021-08-11 23:08:49,840 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-08-11 23:08:49,844 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-08-11 23:08:49,851 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-08-11 23:08:49,853 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-08-11 23:08:49,864 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:4742394c-da80-4695-95c5-c0a43d189463,clusterId:CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd,subject:om2
om2_1        | 2021-08-11 23:08:50,983 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2021-08-11 23:08:52,797 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd;layoutVersion=0
om2_1        | 2021-08-11 23:08:52,964 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-08-11 23:09:02,503 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.8.9.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.8.9.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:09Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-08-11 23:09:02,558 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-08-11 23:09:10,430 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-08-11 23:09:10,865 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-08-11 23:09:10,869 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-08-11 23:09:10,870 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-08-11 23:09:10,899 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-08-11 23:09:11,072 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om2_1        | 2021-08-11 23:09:12,471 [main] INFO reflections.Reflections: Reflections took 983 ms to scan 1 urls, producing 95 keys and 258 values [using 2 cores]
om2_1        | 2021-08-11 23:09:14,033 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2021-08-11 23:09:14,041 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-08-11 23:09:14,048 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-08-11 23:09:20,667 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2021-08-11 23:09:21,196 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/3023215292325.crt.
om2_1        | 2021-08-11 23:09:21,237 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2021-08-11 23:09:21,260 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2932114727528.crt.
om2_1        | 2021-08-11 23:09:21,465 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-08-11 23:09:22,521 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-08-11 23:09:22,533 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-08-11 23:09:23,887 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2021-08-11 23:09:23,895 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2021-08-11 23:09:24,547 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
datanode3_1  | 2021-08-11 23:09:23,721 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-08-11 23:09:23,721 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-08-11 23:09:23,721 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7d30a22a-435f-40ae-b84a-ed00911f12b5
datanode3_1  | 2021-08-11 23:09:23,722 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-08-11 23:09:23,722 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-08-11 23:09:23,722 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-08-11 23:09:23,722 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-08-11 23:09:23,722 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-08-11 23:09:23,722 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-08-11 23:09:23,722 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-08-11 23:09:23,722 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-08-11 23:09:23,723 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-08-11 23:09:23,724 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:09Z
s3g_1        | STARTUP_MSG:   java = 11.0.10
s3g_1        | ************************************************************/
s3g_1        | 2021-08-11 23:07:10,003 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2021-08-11 23:07:10,140 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2021-08-11 23:07:10,158 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2021-08-11 23:07:10,163 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
s3g_1        | 2021-08-11 23:07:10,387 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2021-08-11 23:07:10,388 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2021-08-11 23:07:10,389 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1        | 2021-08-11 23:07:10,484 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2021-08-11 23:07:10,517 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@58e6d4b8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2021-08-11 23:07:10,518 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64df9a61{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2021-08-11 23:07:16,793 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Aug 11, 2021 11:07:19 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2021-08-11 23:07:19,627 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4a9869a8{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_2_0-SNAPSHOT_jar-_-any-12267847823610285514/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2021-08-11 23:07:19,673 [main] INFO server.AbstractConnector: Started ServerConnector@3d08f3f5{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2021-08-11 23:07:19,673 [main] INFO server.Server: Started @15421ms
s3g_1        | 2021-08-11 23:07:19,675 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2021-08-11 23:14:58,014 [qtp1275028674-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-92698, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:14:58,044 [qtp1275028674-21] INFO endpoint.BucketEndpoint: Location is /bucket-92698
s3g_1        | 2021-08-11 23:15:03,295 [qtp1275028674-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-15985, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:15:03,312 [qtp1275028674-17] INFO endpoint.BucketEndpoint: Location is /bucket-15985
s3g_1        | 2021-08-11 23:15:04,431 [qtp1275028674-19] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2021-08-11 23:15:04,443 [qtp1275028674-19] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2021-08-11 23:15:04,443 [qtp1275028674-19] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2021-08-11 23:07:18,883 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-08-11 23:07:18,939 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2021-08-11 23:07:18,940 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2021-08-11 23:07:20,724 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2021-08-11 23:07:20,724 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2021-08-11 23:07:20,724 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2021-08-11 23:07:20,743 [main] INFO util.log: Logging initialized @15139ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2021-08-11 23:07:20,894 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2021-08-11 23:07:20,913 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2021-08-11 23:07:20,918 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2021-08-11 23:07:20,918 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2021-08-11 23:07:20,918 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2021-08-11 23:07:20,921 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2021-08-11 23:07:21,148 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2021-08-11 23:07:21,644 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2021-08-11 23:07:21,675 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2021-08-11 23:07:21,689 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2021-08-11 23:07:21,738 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2021-08-11 23:07:22,934 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-08-11 23:07:23,342 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-08-11 23:07:23,392 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2021-08-11 23:07:23,394 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2021-08-11 23:07:23,549 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-08-11 23:07:23,801 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
recon_1      | 2021-08-11 23:07:24,011 [main] INFO reflections.Reflections: Reflections took 179 ms to scan 3 urls, producing 104 keys and 214 values 
recon_1      | 2021-08-11 23:07:24,126 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2021-08-11 23:07:24,192 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2021-08-11 23:07:24,212 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2021-08-11 23:07:24,227 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2021-08-11 23:07:24,310 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2021-08-11 23:07:24,347 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2021-08-11 23:07:24,389 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: No pipeline exists in current db
recon_1      | 2021-08-11 23:07:24,440 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2021-08-11 23:07:24,441 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2021-08-11 23:07:24,494 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2021-08-11 23:07:24,565 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2021-08-11 23:07:24,569 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2021-08-11 23:07:24,988 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2021-08-11 23:07:24,996 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
recon_1      | 2021-08-11 23:07:25,051 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2021-08-11 23:07:25,057 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2021-08-11 23:07:25,059 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2021-08-11 23:07:25,102 [Listener at 0.0.0.0/9891] INFO server.session: node0 Stopped scavenging
recon_1      | Problem starting http server
recon_1      | 2021-08-11 23:07:25,169 [shutdown-hook-0] INFO recon.ReconServer: SHUTDOWN_MSG: 
recon_1      | /************************************************************
recon_1      | SHUTDOWN_MSG: Shutting down ReconServer at recon/172.25.0.115
recon_1      | ************************************************************/
datanode2_1  | 2021-08-11 23:13:33,039 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:34,289 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=817,entriesCount=1,lastEntry=(t:2, i:9)
datanode2_1  | 2021-08-11 23:13:34,306 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=818,entriesCount=1,lastEntry=(t:2, i:10)
datanode2_1  | 2021-08-11 23:13:34,317 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=820,entriesCount=1,lastEntry=(t:2, i:11)
datanode2_1  | 2021-08-11 23:13:34,324 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=822,entriesCount=1,lastEntry=(t:2, i:12)
datanode2_1  | 2021-08-11 23:13:36,108 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:39,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:42,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:45,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:48,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:51,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:54,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:13:57,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:00,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:03,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:09,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:12,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:16,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:19,116 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:22,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:25,259 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:28,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:31,407 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:34,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:37,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:40,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:09:46,248 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2021-08-11 23:09:48,985 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2021-08-11 23:09:56,850 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54698
om1_1        | 2021-08-11 23:09:56,888 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:11,015 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54760
om1_1        | 2021-08-11 23:10:11,033 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:12,850 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-08-11 23:10:24,678 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54838
om1_1        | 2021-08-11 23:10:24,702 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:25,268 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54842
om1_1        | 2021-08-11 23:10:25,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:29,943 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54868
om1_1        | 2021-08-11 23:10:29,961 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:30,456 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54874
om1_1        | 2021-08-11 23:10:30,460 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:34,972 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54894
om1_1        | 2021-08-11 23:10:34,995 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:44,652 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54958
om1_1        | 2021-08-11 23:10:44,669 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:49,714 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54986
om1_1        | 2021-08-11 23:10:49,738 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:50,236 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54998
om1_1        | 2021-08-11 23:10:50,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:54,430 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55012
om1_1        | 2021-08-11 23:10:54,447 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:10:58,682 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55034
om1_1        | 2021-08-11 23:10:58,699 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:11,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55104
om1_1        | 2021-08-11 23:11:11,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:11,800 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:61235-source for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-08-11 23:11:14,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55124
om1_1        | 2021-08-11 23:11:14,862 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:15,385 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:61235-target for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-08-11 23:11:18,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55138
om1_1        | 2021-08-11 23:11:18,333 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:21,858 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55158
om1_1        | 2021-08-11 23:11:21,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:30,282 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55192
om2_1        | 2021-08-11 23:09:25,397 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-08-11 23:09:47,059 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5.
datanode1_1  | 2021-08-11 23:09:47,061 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda: new RaftServerImpl for group-8FBFF034B0CD:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-08-11 23:09:47,061 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-08-11 23:09:47,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-08-11 23:09:47,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-08-11 23:09:47,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-08-11 23:09:47,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-08-11 23:09:47,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-08-11 23:09:47,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-08-11 23:09:47,062 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD: ConfigurationManager, init=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-08-11 23:09:47,063 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-08-11 23:09:47,064 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-08-11 23:09:47,064 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2021-08-11 23:09:47,064 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd does not exist. Creating ...
datanode1_1  | 2021-08-11 23:09:47,064 [Command processor thread] INFO server.RaftServer: 97333428-a9dc-49fc-bc54-326166febdda: addNew group-8FBFF034B0CD:[fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-8FBFF034B0CD:java.util.concurrent.CompletableFuture@5d1cadfa[Not completed]
datanode1_1  | 2021-08-11 23:09:47,065 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd/in_use.lock acquired by nodename 8@5f0669529782
scm1.org_1   | 2021-08-11 23:07:23,084 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-08-11 23:07:23,097 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-08-11 23:07:23,159 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-08-11 23:07:23,159 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-08-11 23:07:23,186 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2021-08-11 23:07:23,548 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-08-11 23:07:23,577 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-08-11 23:07:23,579 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-08-11 23:07:23,601 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd
scm1.org_1   | 2021-08-11 23:07:23,602 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-08-11 23:07:23,602 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-08-11 23:07:23,603 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-08-11 23:07:23,604 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm1.org_1   | 2021-08-11 23:07:23,605 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2021-08-11 23:07:23,606 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2021-08-11 23:07:23,607 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2021-08-11 23:07:23,607 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2021-08-11 23:07:23,616 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2021-08-11 23:07:23,618 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2021-08-11 23:07:23,623 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-08-11 23:07:23,623 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-08-11 23:07:23,653 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2021-08-11 23:07:23,655 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-08-11 23:07:23,659 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-08-11 23:07:23,660 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2021-08-11 23:07:23,661 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2021-08-11 23:07:23,661 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-08-11 23:07:23,818 [main] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: start as a follower, conf=-1: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2021-08-11 23:07:23,820 [main] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2021-08-11 23:07:23,821 [main] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: start 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState
scm1.org_1   | 2021-08-11 23:07:23,842 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6C975B8E17FD,id=4742394c-da80-4695-95c5-c0a43d189463
scm1.org_1   | 2021-08-11 23:07:23,855 [main] INFO server.RaftServer: 4742394c-da80-4695-95c5-c0a43d189463: start RPC server
scm1.org_1   | 2021-08-11 23:07:24,075 [main] INFO server.GrpcService: 4742394c-da80-4695-95c5-c0a43d189463: GrpcService started, listening on 9894
scm1.org_1   | 2021-08-11 23:07:24,089 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$334/0x0000000840330840@2f3166a] INFO util.JvmPauseMonitor: JvmPauseMonitor-4742394c-da80-4695-95c5-c0a43d189463: Started
scm1.org_1   | 2021-08-11 23:07:28,892 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO impl.FollowerState: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5070957803ns, electionTimeout:5054ms
scm1.org_1   | 2021-08-11 23:07:28,893 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: shutdown 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState
scm1.org_1   | 2021-08-11 23:07:28,893 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2021-08-11 23:07:28,896 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2021-08-11 23:07:28,896 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: start 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1
scm1.org_1   | 2021-08-11 23:07:28,901 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO impl.LeaderElection: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2021-08-11 23:07:28,902 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO impl.LeaderElection: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2021-08-11 23:07:28,902 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: shutdown 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1
scm1.org_1   | 2021-08-11 23:07:28,902 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2021-08-11 23:07:28,903 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: change Leader from null to 4742394c-da80-4695-95c5-c0a43d189463 at term 1 for becomeLeader, leader elected after 5818ms
scm1.org_1   | 2021-08-11 23:07:28,907 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2021-08-11 23:07:28,910 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-08-11 23:07:28,911 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-08-11 23:07:28,916 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2021-08-11 23:07:28,916 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2021-08-11 23:07:28,917 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2021-08-11 23:07:28,921 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: start 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl
scm1.org_1   | 2021-08-11 23:07:28,938 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2021-08-11 23:07:28,958 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: set configuration 0: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-08-11 23:07:29,001 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_0
scm1.org_1   | 2021-08-11 23:07:30,090 [main] INFO server.RaftServer: 4742394c-da80-4695-95c5-c0a43d189463: close
scm1.org_1   | 2021-08-11 23:07:30,091 [main] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: shutdown
scm1.org_1   | 2021-08-11 23:07:30,091 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6C975B8E17FD,id=4742394c-da80-4695-95c5-c0a43d189463
scm1.org_1   | 2021-08-11 23:07:30,091 [main] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: shutdown 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl
scm1.org_1   | 2021-08-11 23:07:30,096 [main] INFO impl.PendingRequests: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2021-08-11 23:07:30,100 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO impl.StateMachineUpdater: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2021-08-11 23:07:30,100 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO impl.StateMachineUpdater: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2021-08-11 23:07:30,103 [main] INFO impl.StateMachineUpdater: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2021-08-11 23:07:30,104 [main] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: closes. applyIndex: 0
scm1.org_1   | 2021-08-11 23:07:30,105 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2021-08-11 23:07:30,105 [main] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker close()
scm1.org_1   | 2021-08-11 23:07:30,107 [main] INFO server.GrpcService: 4742394c-da80-4695-95c5-c0a43d189463: shutdown server with port 9894 now
scm1.org_1   | 2021-08-11 23:07:30,110 [main] INFO server.GrpcService: 4742394c-da80-4695-95c5-c0a43d189463: shutdown server with port 9894 successfully
scm1.org_1   | 2021-08-11 23:07:30,110 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$334/0x0000000840330840@2f3166a] INFO util.JvmPauseMonitor: JvmPauseMonitor-4742394c-da80-4695-95c5-c0a43d189463: Stopped
scm1.org_1   | 2021-08-11 23:07:30,111 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-08-11 23:07:30,113 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd; layoutVersion=2; scmId=4742394c-da80-4695-95c5-c0a43d189463
scm1.org_1   | 2021-08-11 23:07:30,149 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-08-11 23:07:31,594 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
datanode2_1  | 2021-08-11 23:14:43,691 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:46,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:49,836 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:52,911 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:14:59,055 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:02,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:05,195 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:08,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:11,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:14,411 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:17,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:20,556 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:23,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:26,699 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:29,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:32,844 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:35,917 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:38,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:42,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:48,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:51,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:54,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:15:57,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:00,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:03,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:06,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:08,847 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1131,entriesCount=1,lastEntry=(t:2, i:13)
om1_1        | 2021-08-11 23:11:30,320 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:33,897 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55214
om1_1        | 2021-08-11 23:11:33,971 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:37,573 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55232
om1_1        | 2021-08-11 23:11:37,754 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:41,417 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55270
om1_1        | 2021-08-11 23:11:41,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:45,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55290
om1_1        | 2021-08-11 23:11:45,046 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:48,498 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55312
om1_1        | 2021-08-11 23:11:48,550 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:52,099 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55334
om1_1        | 2021-08-11 23:11:52,129 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:55,754 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55346
om1_1        | 2021-08-11 23:11:55,772 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:11:59,343 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55370
om1_1        | 2021-08-11 23:11:59,362 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:03,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55390
om1_1        | 2021-08-11 23:12:03,048 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:06,587 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55402
om1_1        | 2021-08-11 23:12:06,643 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:10,340 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55444
om1_1        | 2021-08-11 23:12:10,354 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:14,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55456
om1_1        | 2021-08-11 23:12:14,021 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:17,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55478
om1_1        | 2021-08-11 23:12:17,542 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:25,883 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55514
om1_1        | 2021-08-11 23:12:25,899 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:31,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55540
om1_1        | 2021-08-11 23:12:31,748 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:40,365 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55602
om1_1        | 2021-08-11 23:12:40,404 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:45,964 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55632
om1_1        | 2021-08-11 23:12:45,999 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:49,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55654
om1_1        | 2021-08-11 23:12:49,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode1_1  | 2021-08-11 23:09:47,066 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd has been successfully formatted.
datanode1_1  | 2021-08-11 23:09:47,067 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-8FBFF034B0CD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-08-11 23:09:47,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-08-11 23:09:47,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-08-11 23:09:47,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-08-11 23:09:47,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-08-11 23:09:47,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-08-11 23:09:47,071 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-08-11 23:09:47,071 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-08-11 23:09:47,071 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd
datanode1_1  | 2021-08-11 23:09:47,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-08-11 23:09:47,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-08-11 23:09:47,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-08-11 23:09:47,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-08-11 23:09:47,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-08-11 23:09:47,073 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-08-11 23:09:47,073 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-08-11 23:09:47,073 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-08-11 23:09:47,075 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-08-11 23:09:47,075 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-08-11 23:09:47,076 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-08-11 23:09:47,076 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-08-11 23:09:47,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-08-11 23:09:47,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-08-11 23:09:47,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-08-11 23:09:47,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-08-11 23:09:47,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-08-11 23:09:47,084 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-08-11 23:09:47,085 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD: start as a follower, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2021-08-11 23:09:47,085 [pool-23-thread-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-08-11 23:09:47,085 [pool-23-thread-1] INFO impl.RoleInfo: 97333428-a9dc-49fc-bc54-326166febdda: start 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD-FollowerState
datanode1_1  | 2021-08-11 23:09:47,087 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8FBFF034B0CD,id=97333428-a9dc-49fc-bc54-326166febdda
datanode1_1  | 2021-08-11 23:09:47,093 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd
datanode1_1  | 2021-08-11 23:09:47,295 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
om2_1        | 2021-08-11 23:09:25,400 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2021-08-11 23:09:25,531 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2021-08-11 23:09:26,080 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2021-08-11 23:09:26,134 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-08-11 23:09:26,282 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2021-08-11 23:09:26,317 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2021-08-11 23:09:27,023 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2021-08-11 23:09:27,308 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2021-08-11 23:09:27,315 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-08-11 23:09:27,317 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2021-08-11 23:09:27,323 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-08-11 23:09:27,323 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-08-11 23:09:27,324 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2021-08-11 23:09:27,327 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-08-11 23:09:27,337 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2021-08-11 23:09:27,338 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-08-11 23:09:31,571 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2021-08-11 23:09:31,574 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-08-11 23:09:31,577 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-08-11 23:09:31,638 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-08-11 23:09:31,702 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@10ecdd85[Not completed]
om2_1        | 2021-08-11 23:09:31,702 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2021-08-11 23:09:31,881 [pool-24-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2021-08-11 23:09:31,922 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2021-08-11 23:09:31,932 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2021-08-11 23:09:31,950 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2021-08-11 23:09:31,950 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2021-08-11 23:09:31,953 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-08-11 23:09:31,955 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-08-11 23:09:31,955 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2021-08-11 23:09:31,956 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-08-11 23:09:32,103 [pool-24-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2021-08-11 23:09:32,107 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-08-11 23:09:32,113 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2021-08-11 23:09:32,147 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2021-08-11 23:09:32,148 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2021-08-11 23:09:32,153 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2021-08-11 23:09:32,213 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2021-08-11 23:09:32,311 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2021-08-11 23:09:32,334 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2021-08-11 23:09:32,345 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2021-08-11 23:09:32,407 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2021-08-11 23:09:32,412 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-08-11 23:09:32,496 [Listener at om2/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om2_1        | 2021-08-11 23:09:32,536 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-08-11 23:09:32,574 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2021-08-11 23:09:32,592 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2021-08-11 23:09:32,605 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2021-08-11 23:09:32,628 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2021-08-11 23:09:32,633 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2021-08-11 23:09:32,648 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-08-11 23:09:32,651 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2021-08-11 23:09:32,659 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2021-08-11 23:09:32,661 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2021-08-11 23:09:32,671 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2021-08-11 23:09:32,673 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2021-08-11 23:09:32,721 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2021-08-11 23:09:32,727 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2021-08-11 23:09:32,782 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2021-08-11 23:09:32,783 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2021-08-11 23:09:32,830 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2021-08-11 23:09:32,832 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2021-08-11 23:09:32,832 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2021-08-11 23:09:32,845 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2021-08-11 23:09:32,846 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2021-08-11 23:09:32,851 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2021-08-11 23:09:33,011 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2021-08-11 23:09:33,095 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2021-08-11 23:09:33,097 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2021-08-11 23:09:33,335 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2021-08-11 23:09:33,335 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2021-08-11 23:09:33,341 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-08-11 23:09:33,347 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2021-08-11 23:09:33,348 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-08-11 23:09:33,357 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2021-08-11 23:09:33,383 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2021-08-11 23:09:33,569 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2021-08-11 23:09:33,579 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$393/0x00000008405c3040@5abfb698] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2021-08-11 23:09:33,579 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2021-08-11 23:09:33,580 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-08-11 23:09:33,581 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2021-08-11 23:09:33,591 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-08-11 23:09:33,601 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2021-08-11 23:09:33,604 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2021-08-11 23:09:33,802 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2021-08-11 23:09:33,802 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2021-08-11 23:09:33,802 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2021-08-11 23:09:33,895 [Listener at om2/9862] INFO util.log: Logging initialized @39541ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2021-08-11 23:09:34,318 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2021-08-11 23:09:34,344 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2021-08-11 23:09:34,351 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2021-08-11 23:09:34,351 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2021-08-11 23:09:34,351 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2021-08-11 23:09:34,362 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2021-08-11 23:09:34,526 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2021-08-11 23:09:34,527 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om2_1        | 2021-08-11 23:09:34,666 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2021-08-11 23:09:34,671 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2021-08-11 23:09:34,673 [Listener at om2/9862] INFO server.session: node0 Scavenging every 660000ms
om2_1        | 2021-08-11 23:09:34,716 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2021-08-11 23:09:34,722 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@65b9ebee{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2021-08-11 23:09:34,731 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@59b78925{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2021-08-11 23:09:35,089 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-08-11 23:09:35,513 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-08-11 23:09:35,562 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7d6c4c43{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-18088956198199658754/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2021-08-11 23:09:35,631 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@2242dd2b{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2021-08-11 23:09:35,646 [Listener at om3/9862] INFO server.Server: Started @42350ms
om3_1        | 2021-08-11 23:09:35,676 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2021-08-11 23:09:35,677 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2021-08-11 23:09:35,689 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2021-08-11 23:09:35,714 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2021-08-11 23:09:35,697 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2021-08-11 23:09:35,853 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2021-08-11 23:09:35,876 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22e470f4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2021-08-11 23:09:38,496 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5026902907ns, electionTimeout:5009ms
om3_1        | 2021-08-11 23:09:38,498 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-08-11 23:09:38,498 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2021-08-11 23:09:38,501 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2021-08-11 23:09:38,501 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2021-08-11 23:09:38,509 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-08-11 23:09:40,154 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-08-11 23:09:40,162 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2021-08-11 23:09:40,197 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-08-11 23:09:40,422 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-08-11 23:09:40,422 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2021-08-11 23:09:40,422 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-08-11 23:09:40,509 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2021-08-11 23:09:40,510 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2021-08-11 23:09:40,510 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2021-08-11 23:09:40,510 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2021-08-11 23:09:40,511 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2021-08-11 23:09:40,515 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2021-08-11 23:09:40,516 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-08-11 23:09:45,527 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 2, (t:0, i:~))
om3_1        | 2021-08-11 23:09:45,528 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om2: our priority 0 <= candidate's priority 0
om3_1        | 2021-08-11 23:09:45,529 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om2
om3_1        | 2021-08-11 23:09:45,529 [grpc-default-executor-1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-08-11 23:09:45,529 [grpc-default-executor-1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-08-11 23:09:45,530 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted: {}
om3_1        | java.lang.InterruptedException: sleep interrupted
om3_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om3_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om3_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om3_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om3_1        | 2021-08-11 23:09:45,538 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:OK-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om2, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-08-11 23:09:45,817 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om2 at term 2 for appendEntries, leader elected after 13603ms
om3_1        | 2021-08-11 23:09:45,950 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-08-11 23:09:45,968 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2021-08-11 23:09:46,265 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2021-08-11 23:09:49,101 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2021-08-11 23:10:14,059 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-08-11 23:11:11,804 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:61235-source for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-08-11 23:11:15,378 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:61235-target for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-08-11 23:13:34,444 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:61235-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 2021-08-11 23:09:35,129 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@c35b83c{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-2750588403150856448/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2021-08-11 23:09:35,146 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@4f7bb581{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2021-08-11 23:09:35,148 [Listener at om2/9862] INFO server.Server: Started @40794ms
om2_1        | 2021-08-11 23:09:35,151 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2021-08-11 23:09:35,151 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2021-08-11 23:09:35,159 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2021-08-11 23:09:35,162 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-08-11 23:09:35,190 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2021-08-11 23:09:35,436 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1        | 2021-08-11 23:09:35,508 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77070012] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2021-08-11 23:09:38,550 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5202507540ns, electionTimeout:5187ms
om2_1        | 2021-08-11 23:09:38,552 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-08-11 23:09:38,552 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2021-08-11 23:09:38,555 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2021-08-11 23:09:38,561 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2021-08-11 23:09:38,566 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-08-11 23:09:40,405 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-08-11 23:09:40,409 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2021-08-11 23:09:40,420 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-08-11 23:09:40,434 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-08-11 23:09:40,434 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2021-08-11 23:09:40,435 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-08-11 23:09:40,446 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2021-08-11 23:09:40,446 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2021-08-11 23:09:40,447 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2021-08-11 23:09:40,447 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2021-08-11 23:09:40,448 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2021-08-11 23:09:40,448 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2021-08-11 23:09:40,448 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-08-11 23:09:45,506 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057744354ns, electionTimeout:5023ms
om2_1        | 2021-08-11 23:09:45,507 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-08-11 23:09:45,507 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om2_1        | 2021-08-11 23:09:45,507 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2021-08-11 23:09:45,507 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection2
om2_1        | 2021-08-11 23:09:45,509 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-08-11 23:09:45,531 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om2_1        | 2021-08-11 23:09:45,532 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om2<-om1#0:OK-t2
om2_1        | 2021-08-11 23:09:45,532 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om2_1        | 2021-08-11 23:09:45,532 [om2@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection2
om2_1        | 2021-08-11 23:09:45,532 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om2_1        | 2021-08-11 23:09:45,533 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om2 at term 2 for becomeLeader, leader elected after 13216ms
om2_1        | 2021-08-11 23:09:45,543 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om2_1        | 2021-08-11 23:09:45,551 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2021-08-11 23:09:45,551 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om2_1        | 2021-08-11 23:09:45,556 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om2_1        | 2021-08-11 23:09:45,556 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om2_1        | 2021-08-11 23:09:45,557 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1        | 2021-08-11 23:09:45,569 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2021-08-11 23:09:45,570 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-08-11 23:09:45,571 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2021-08-11 23:09:45,579 [om2@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2021-08-11 23:09:45,580 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-08-11 23:09:45,580 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-08-11 23:09:45,588 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2021-08-11 23:09:45,588 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-08-11 23:09:45,590 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2021-08-11 23:09:45,590 [om2@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2021-08-11 23:09:45,591 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-08-11 23:09:45,591 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-08-11 23:09:45,594 [om2@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderStateImpl
om2_1        | 2021-08-11 23:09:45,649 [om2@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2021-08-11 23:09:45,712 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-08-11 23:09:46,126 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2021-08-11 23:09:46,522 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2021-08-11 23:09:57,505 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39946
om2_1        | 2021-08-11 23:09:57,520 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:11,070 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40008
om2_1        | 2021-08-11 23:10:11,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:11,935 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-08-11 23:10:24,741 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40086
om2_1        | 2021-08-11 23:10:24,747 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:25,319 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40090
om2_1        | 2021-08-11 23:10:25,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:29,993 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40116
om2_1        | 2021-08-11 23:10:30,003 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:30,480 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40122
om2_1        | 2021-08-11 23:10:30,489 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:35,032 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40144
om2_1        | 2021-08-11 23:10:35,039 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:44,698 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40206
om2_1        | 2021-08-11 23:10:44,707 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:49,776 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40234
om2_1        | 2021-08-11 23:10:49,786 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:50,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40246
om1_1        | 2021-08-11 23:12:53,393 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55676
om1_1        | 2021-08-11 23:12:53,407 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:12:57,074 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55696
om1_1        | 2021-08-11 23:12:57,099 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:01,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55712
om1_1        | 2021-08-11 23:13:01,092 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:04,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55732
om1_1        | 2021-08-11 23:13:05,038 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:08,869 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55774
om1_1        | 2021-08-11 23:13:08,897 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:12,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55786
om1_1        | 2021-08-11 23:13:12,115 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:15,696 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55810
om1_1        | 2021-08-11 23:13:15,711 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:19,318 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55820
om1_1        | 2021-08-11 23:13:19,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:22,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55842
om1_1        | 2021-08-11 23:13:22,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:26,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55854
om1_1        | 2021-08-11 23:13:26,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:30,330 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55876
om1_1        | 2021-08-11 23:13:30,348 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:33,933 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55896
om1_1        | 2021-08-11 23:13:33,979 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:34,441 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:61235-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:13:37,353 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55912
om1_1        | 2021-08-11 23:13:37,401 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:41,058 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55952
om1_1        | 2021-08-11 23:13:41,073 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:41,634 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:61235-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:13:44,634 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55964
om1_1        | 2021-08-11 23:13:44,666 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:48,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55994
om1_1        | 2021-08-11 23:13:48,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:51,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56018
om1_1        | 2021-08-11 23:13:51,705 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:55,402 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56030
om1_1        | 2021-08-11 23:13:55,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:13:58,860 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56052
om1_1        | 2021-08-11 23:13:58,900 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:02,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56066
om1_1        | 2021-08-11 23:14:02,331 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:05,791 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56086
om1_1        | 2021-08-11 23:14:05,807 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:09,492 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56126
om1_1        | 2021-08-11 23:14:09,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:12,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56138
om1_1        | 2021-08-11 23:14:12,981 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:16,441 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56160
om1_1        | 2021-08-11 23:14:16,456 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:24,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56194
om1_1        | 2021-08-11 23:14:24,783 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:30,236 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56224
om1_1        | 2021-08-11 23:14:30,277 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:33,603 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56244
om1_1        | 2021-08-11 23:14:33,640 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:37,648 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56256
om1_1        | 2021-08-11 23:14:37,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:54,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56504
om1_1        | 2021-08-11 23:14:54,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:14:57,591 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:14:57,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39562
om1_1        | 2021-08-11 23:14:57,610 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:01,031 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56536
om1_1        | 2021-08-11 23:15:01,049 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:03,265 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:13:41,635 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:61235-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:15:54,055 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-18435 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:16:01,830 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:16:44,204 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-39850/39682/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2021-08-11 23:16:44,206 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 39682/multipartKey2 in Volume/Bucket s3v/bucket-39850
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 39682/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:463)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:16:45,253 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-39850/93532/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2021-08-11 23:16:45,254 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:16:45,734 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-39850/93532/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2021-08-11 23:16:45,735 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:16:56,084 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-39850/93532/multipartKey3-a7704d43-a5ee-491b-a176-bcb705bef0f0-106740043265540128-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:16:56,579 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-39850/93532/multipartKey3-a7704d43-a5ee-491b-a176-bcb705bef0f0-106740043265540128-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:16:57,075 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-39850/93532/multipartKey3
om3_1        | 2021-08-11 23:16:57,078 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:411)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2021-08-11 23:07:26,320 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | ************************************************************/
scm2.org_1   | 2021-08-11 23:07:26,333 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2021-08-11 23:07:26,433 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2021-08-11 23:07:26,434 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2021-08-11 23:07:26,465 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2021-08-11 23:07:26,465 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2021-08-11 23:07:26,470 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-08-11 23:07:26,661 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2021-08-11 23:07:26,661 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2021-08-11 23:07:28,900 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-08-11 23:07:30,902 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-08-11 23:07:32,903 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-08-11 23:07:34,915 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-08-11 23:07:36,918 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-08-11 23:07:39,091 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:4742394c-da80-4695-95c5-c0a43d189463 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:196)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:108)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13937)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-08-11 23:07:41,092 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-08-11 23:07:43,094 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-08-11 23:07:45,200 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2021-08-11 23:07:45,685 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2021-08-11 23:07:45,685 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2021-08-11 23:07:45,687 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2021-08-11 23:07:46,256 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2021-08-11 23:07:46,367 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2021-08-11 23:07:46,367 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2021-08-11 23:07:46,377 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:264530c6-4c2c-4bc1-b4ab-46128a8936fc,clusterId:CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd,subject:scm-sub@scm2.org
scm2.org_1   | 2021-08-11 23:07:48,171 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2021-08-11 23:07:48,195 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd, SCMID 264530c6-4c2c-4bc1-b4ab-46128a8936fc
scm2.org_1   | 2021-08-11 23:07:48,195 [main] INFO server.StorageContainerManager: Primary SCM Node ID 4742394c-da80-4695-95c5-c0a43d189463
scm2.org_1   | 2021-08-11 23:07:48,231 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2021-08-11 23:07:50,701 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | ************************************************************/
scm2.org_1   | 2021-08-11 23:07:50,717 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2021-08-11 23:07:50,852 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2021-08-11 23:07:50,852 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2021-08-11 23:07:50,991 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2021-08-11 23:07:50,992 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2021-08-11 23:07:51,060 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-08-11 23:07:51,111 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm2.org_1   | 2021-08-11 23:07:51,467 [main] INFO reflections.Reflections: Reflections took 151 ms to scan 3 urls, producing 104 keys and 214 values 
scm2.org_1   | 2021-08-11 23:07:52,475 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2021-08-11 23:07:52,706 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2958162755516.crt.
scm2.org_1   | 2021-08-11 23:07:52,718 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2021-08-11 23:07:52,725 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2021-08-11 23:07:52,993 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2021-08-11 23:07:52,993 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2021-08-11 23:07:53,069 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-08-11 23:07:53,292 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-08-11 23:07:53,465 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2021-08-11 23:07:53,465 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2021-08-11 23:07:53,589 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:264530c6-4c2c-4bc1-b4ab-46128a8936fc
scm2.org_1   | 2021-08-11 23:07:53,692 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2021-08-11 23:07:53,792 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2021-08-11 23:07:53,793 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-08-11 23:07:53,794 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2021-08-11 23:07:53,794 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-08-11 23:07:53,794 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-08-11 23:07:53,795 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2021-08-11 23:07:53,797 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2021-08-11 23:07:53,797 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2021-08-11 23:17:00,147 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 05864/multipartKey5 in VolumeName/Bucket s3v/bucket-39850
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-39850key: 05864/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-08-11 23:17:00,644 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-39850, Key98200/multipartKey. Exception:{}
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:726)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:618)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:595)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | 2021-08-11 23:16:08,855 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1132,entriesCount=1,lastEntry=(t:2, i:14)
datanode2_1  | 2021-08-11 23:16:08,859 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1133,entriesCount=1,lastEntry=(t:2, i:15)
datanode2_1  | 2021-08-11 23:16:09,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:12,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:15,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:18,747 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1385,entriesCount=1,lastEntry=(t:2, i:16)
datanode2_1  | 2021-08-11 23:16:18,753 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1386,entriesCount=1,lastEntry=(t:2, i:17)
datanode2_1  | 2021-08-11 23:16:18,764 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1387,entriesCount=1,lastEntry=(t:2, i:18)
datanode2_1  | 2021-08-11 23:16:18,771 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1389,entriesCount=1,lastEntry=(t:2, i:19)
datanode2_1  | 2021-08-11 23:16:18,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:21,461 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1642,entriesCount=1,lastEntry=(t:2, i:20)
datanode2_1  | 2021-08-11 23:16:21,471 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1643,entriesCount=1,lastEntry=(t:2, i:21)
datanode2_1  | 2021-08-11 23:16:21,477 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1644,entriesCount=1,lastEntry=(t:2, i:22)
datanode2_1  | 2021-08-11 23:16:21,483 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1645,entriesCount=1,lastEntry=(t:2, i:23)
datanode2_1  | 2021-08-11 23:16:21,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:24,182 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1896,entriesCount=1,lastEntry=(t:2, i:24)
datanode2_1  | 2021-08-11 23:16:24,200 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1897,entriesCount=1,lastEntry=(t:2, i:25)
datanode2_1  | 2021-08-11 23:16:24,206 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1898,entriesCount=1,lastEntry=(t:2, i:26)
datanode2_1  | 2021-08-11 23:16:25,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:27,434 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2148,entriesCount=1,lastEntry=(t:2, i:27)
datanode2_1  | 2021-08-11 23:16:27,474 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2149,entriesCount=1,lastEntry=(t:2, i:28)
datanode2_1  | 2021-08-11 23:16:27,518 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2150,entriesCount=1,lastEntry=(t:2, i:29)
datanode2_1  | 2021-08-11 23:16:27,756 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2172,entriesCount=1,lastEntry=(t:2, i:30)
datanode2_1  | 2021-08-11 23:16:27,921 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2182,entriesCount=1,lastEntry=(t:2, i:31)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-08-11 23:09:47,431 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:218)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:179)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:556)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:181)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:216)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-08-11 23:09:47,436 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd.
datanode1_1  | 2021-08-11 23:09:48,144 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8FBFF034B0CD with new leaderId: fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode1_1  | 2021-08-11 23:09:48,144 [grpc-default-executor-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD: change Leader from null to fb8d185f-2f23-4800-ba90-a65832b06bb3 at term 1 for appendEntries, leader elected after 1076ms
datanode1_1  | 2021-08-11 23:09:48,151 [grpc-default-executor-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode1_1  | 2021-08-11 23:09:48,157 [grpc-default-executor-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD: inconsistency entries. Reply:fb8d185f-2f23-4800-ba90-a65832b06bb3<-97333428-a9dc-49fc-bc54-326166febdda#11:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode1_1  | 2021-08-11 23:09:48,189 [grpc-default-executor-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD: set configuration 0: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2021-08-11 23:09:48,193 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-08-11 23:09:48,278 [97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-8FBFF034B0CD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd/current/log_inprogress_0
datanode1_1  | 2021-08-11 23:09:48,337 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6FA1826E58A5 with new leaderId: 95d91451-f44f-4fa4-a508-c399bd523c99
datanode1_1  | 2021-08-11 23:09:48,337 [grpc-default-executor-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5: change Leader from null to 95d91451-f44f-4fa4-a508-c399bd523c99 at term 2 for appendEntries, leader elected after 2033ms
datanode1_1  | 2021-08-11 23:09:48,337 [grpc-default-executor-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5: Failed appendEntries as previous log entry ((t:2, i:0)) is not found
datanode1_1  | 2021-08-11 23:09:48,337 [grpc-default-executor-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5: inconsistency entries. Reply:95d91451-f44f-4fa4-a508-c399bd523c99<-97333428-a9dc-49fc-bc54-326166febdda#9:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode1_1  | 2021-08-11 23:09:48,345 [grpc-default-executor-1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5: set configuration 0: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2021-08-11 23:09:48,345 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-08-11 23:09:48,347 [97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-6FA1826E58A5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5/current/log_inprogress_0
datanode1_1  | 2021-08-11 23:09:49,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:51,199 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-FollowerState] INFO impl.FollowerState: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5027968001ns, electionTimeout:5006ms
datanode1_1  | 2021-08-11 23:09:51,200 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-FollowerState] INFO impl.RoleInfo: 97333428-a9dc-49fc-bc54-326166febdda: shutdown 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-FollowerState
datanode1_1  | 2021-08-11 23:09:51,200 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-FollowerState] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-08-11 23:09:51,203 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-08-11 23:09:51,203 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-FollowerState] INFO impl.RoleInfo: 97333428-a9dc-49fc-bc54-326166febdda: start 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1
datanode1_1  | 2021-08-11 23:09:51,207 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO impl.LeaderElection: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-08-11 23:09:51,208 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO impl.LeaderElection: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2021-08-11 23:09:51,209 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO impl.RoleInfo: 97333428-a9dc-49fc-bc54-326166febdda: shutdown 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1
datanode1_1  | 2021-08-11 23:09:51,210 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2021-08-11 23:09:51,210 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B867116D2715 with new leaderId: 97333428-a9dc-49fc-bc54-326166febdda
datanode1_1  | 2021-08-11 23:09:51,211 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715: change Leader from null to 97333428-a9dc-49fc-bc54-326166febdda at term 1 for becomeLeader, leader elected after 5432ms
datanode1_1  | 2021-08-11 23:09:51,213 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-08-11 23:09:51,218 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-08-11 23:09:51,219 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2021-08-11 23:09:51,226 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2021-08-11 23:09:51,226 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-08-11 23:09:51,227 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-08-11 23:09:51,235 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO impl.RoleInfo: 97333428-a9dc-49fc-bc54-326166febdda: start 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderStateImpl
datanode1_1  | 2021-08-11 23:09:51,243 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-08-11 23:09:51,245 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/79bd80c8-0720-41ff-85aa-b867116d2715/current/log_inprogress_0
datanode1_1  | 2021-08-11 23:09:51,250 [97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715-LeaderElection1] INFO server.RaftServer$Division: 97333428-a9dc-49fc-bc54-326166febdda@group-B867116D2715: set configuration 0: [97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-08-11 23:09:52,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:55,788 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:09:57,860 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode1_1  | java.net.NoRouteToHostException: No Route to Host from  5f0669529782/172.25.0.102 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:855)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode1_1  | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
datanode1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode1_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode1_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:701)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:822)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1647)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1463)
datanode1_1  | 	... 12 more
datanode1_1  | 2021-08-11 23:10:01,935 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:05,007 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:08,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:11,151 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:14,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:16,722 [ChunkWriter-2-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:3023215292325.
datanode1_1  | 2021-08-11 23:10:17,295 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:20,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:23,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:26,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:29,583 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:32,656 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:35,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:38,796 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:41,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:44,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:51,087 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:10:54,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
scm1.org_1   | 2021-08-11 23:07:31,601 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-08-11 23:07:31,667 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-08-11 23:07:31,672 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-08-11 23:07:31,742 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2021-08-11 23:07:31,742 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-08-11 23:07:31,766 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-08-11 23:07:31,788 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
s3g_1        | 2021-08-11 23:15:04,449 [qtp1275028674-19] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2021-08-11 23:15:04,449 [qtp1275028674-19] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2021-08-11 23:15:04,747 [qtp1275028674-19] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2021-08-11 23:15:18,070 [qtp1275028674-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-84478, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:15:18,084 [qtp1275028674-19] INFO endpoint.BucketEndpoint: Location is /bucket-84478
s3g_1        | 2021-08-11 23:15:18,590 [qtp1275028674-24] INFO rpc.RpcClient: Creating Bucket: s3v/boto-bucket999, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:15:18,616 [qtp1275028674-24] INFO endpoint.BucketEndpoint: Location is /boto-bucket999
s3g_1        | 2021-08-11 23:15:35,264 [qtp1275028674-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-vckgpqxshr, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:15:35,289 [qtp1275028674-20] INFO endpoint.BucketEndpoint: Location is /bucket-vckgpqxshr
s3g_1        | 2021-08-11 23:15:52,562 [qtp1275028674-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-50798, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:15:52,581 [qtp1275028674-23] INFO endpoint.BucketEndpoint: Location is /bucket-50798
s3g_1        | 2021-08-11 23:15:53,065 [qtp1275028674-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-53597, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:15:53,079 [qtp1275028674-24] INFO endpoint.BucketEndpoint: Location is /bucket-53597
s3g_1        | 2021-08-11 23:15:53,560 [qtp1275028674-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-18435, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:15:53,575 [qtp1275028674-24] INFO endpoint.BucketEndpoint: Location is /bucket-18435
s3g_1        | 2021-08-11 23:15:54,040 [qtp1275028674-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-18435, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:15:54,064 [qtp1275028674-23] INFO endpoint.BucketEndpoint: Location is /bucket-18435
s3g_1        | 2021-08-11 23:15:54,573 [qtp1275028674-24] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
s3g_1        | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:464)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:455)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:385)
s3g_1        | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:94)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:239)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm2.org_1   | 2021-08-11 23:07:53,799 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2021-08-11 23:07:54,368 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2021-08-11 23:07:54,369 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2021-08-11 23:07:54,370 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2021-08-11 23:07:54,379 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2021-08-11 23:07:54,396 [main] INFO server.RaftServer: 264530c6-4c2c-4bc1-b4ab-46128a8936fc: addNew group-6C975B8E17FD:[] returns group-6C975B8E17FD:java.util.concurrent.CompletableFuture@177ede17[Not completed]
scm2.org_1   | 2021-08-11 23:07:54,413 [pool-13-thread-1] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc: new RaftServerImpl for group-6C975B8E17FD:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2021-08-11 23:07:54,415 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2021-08-11 23:07:54,416 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2021-08-11 23:07:54,416 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2021-08-11 23:07:54,416 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2021-08-11 23:07:54,416 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2021-08-11 23:07:54,416 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2021-08-11 23:07:54,416 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2021-08-11 23:07:54,420 [pool-13-thread-1] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2021-08-11 23:07:54,420 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2021-08-11 23:07:54,424 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2021-08-11 23:07:54,424 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2021-08-11 23:07:54,425 [pool-13-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd does not exist. Creating ...
scm2.org_1   | 2021-08-11 23:07:54,435 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/in_use.lock acquired by nodename 7@scm2.org
scm2.org_1   | 2021-08-11 23:07:54,452 [pool-13-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd has been successfully formatted.
scm2.org_1   | 2021-08-11 23:07:54,455 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2021-08-11 23:07:54,457 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2021-08-11 23:07:54,463 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2021-08-11 23:07:54,463 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2021-08-11 23:07:54,469 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2021-08-11 23:07:54,474 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm2.org_1   | 2021-08-11 23:07:54,481 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2021-08-11 23:07:54,482 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2021-08-11 23:07:54,485 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd
scm2.org_1   | 2021-08-11 23:07:54,486 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2021-08-11 23:07:54,486 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2021-08-11 23:07:54,487 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm2.org_1   | 2021-08-11 23:07:54,487 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm2.org_1   | 2021-08-11 23:07:54,487 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2021-08-11 23:07:54,488 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2021-08-11 23:07:54,488 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2021-08-11 23:07:54,489 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2021-08-11 23:07:54,495 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2021-08-11 23:07:54,496 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2021-08-11 23:07:54,503 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-08-11 23:07:54,503 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-08-11 23:07:54,507 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2021-08-11 23:07:54,507 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2021-08-11 23:07:54,514 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2021-08-11 23:07:54,514 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2021-08-11 23:07:54,516 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2021-08-11 23:07:54,516 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2021-08-11 23:07:54,547 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2021-08-11 23:07:54,548 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2021-08-11 23:07:54,549 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2021-08-11 23:07:54,842 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm2.org_1   | 2021-08-11 23:07:54,843 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2021-08-11 23:07:54,850 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2021-08-11 23:07:54,853 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2021-08-11 23:07:54,897 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2021-08-11 23:07:54,906 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2021-08-11 23:07:54,915 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
scm2.org_1   | 2021-08-11 23:07:54,962 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2021-08-11 23:07:54,971 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2021-08-11 23:07:54,972 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
datanode3_1  | 2021-08-11 23:09:23,724 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-08-11 23:09:23,725 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-08-11 23:09:23,725 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-08-11 23:09:23,726 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-08-11 23:09:23,726 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-08-11 23:09:23,726 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-08-11 23:09:23,726 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-08-11 23:09:23,726 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-08-11 23:09:23,727 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5: start as a follower, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-08-11 23:09:23,919 [pool-23-thread-1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-08-11 23:09:23,919 [pool-23-thread-1] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-FollowerState
datanode3_1  | 2021-08-11 23:09:23,931 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ED00911F12B5,id=fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode3_1  | 2021-08-11 23:09:23,935 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=7d30a22a-435f-40ae-b84a-ed00911f12b5
datanode3_1  | 2021-08-11 23:09:23,935 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=7d30a22a-435f-40ae-b84a-ed00911f12b5.
datanode3_1  | 2021-08-11 23:09:24,953 [grpc-default-executor-0] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: receive requestVote(ELECTION, 95d91451-f44f-4fa4-a508-c399bd523c99, group-6FA1826E58A5, 1, (t:0, i:0))
datanode3_1  | 2021-08-11 23:09:24,962 [grpc-default-executor-0] INFO impl.VoteContext: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-CANDIDATE: reject ELECTION from 95d91451-f44f-4fa4-a508-c399bd523c99: already has voted for fb8d185f-2f23-4800-ba90-a65832b06bb3 at current term 1
datanode3_1  | 2021-08-11 23:09:25,015 [grpc-default-executor-0] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5 replies to ELECTION vote request: 95d91451-f44f-4fa4-a508-c399bd523c99<-fb8d185f-2f23-4800-ba90-a65832b06bb3#0:FAIL-t1. Peer's state: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5:t1, leader=null, voted=fb8d185f-2f23-4800-ba90-a65832b06bb3, raftlog=fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-08-11 23:09:25,205 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 97333428-a9dc-49fc-bc54-326166febdda: group-6FA1826E58A5 not found.
datanode3_1  | 2021-08-11 23:09:25,286 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1: ELECTION REJECTED received 1 response(s) and 1 exception(s):
datanode3_1  | 2021-08-11 23:09:25,286 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection:   Response 0: fb8d185f-2f23-4800-ba90-a65832b06bb3<-95d91451-f44f-4fa4-a508-c399bd523c99#0:FAIL-t1
datanode3_1  | 2021-08-11 23:09:25,287 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 97333428-a9dc-49fc-bc54-326166febdda: group-6FA1826E58A5 not found.
datanode3_1  | 2021-08-11 23:09:25,287 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1 ELECTION round 0: result REJECTED
datanode3_1  | 2021-08-11 23:09:25,288 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode3_1  | 2021-08-11 23:09:25,288 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: shutdown fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1
datanode3_1  | 2021-08-11 23:09:25,289 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-LeaderElection1] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState
datanode3_1  | 2021-08-11 23:09:25,645 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:26,945 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-FollowerState] INFO impl.FollowerState: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5014798541ns, electionTimeout:5003ms
datanode3_1  | 2021-08-11 23:09:26,945 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-FollowerState] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: shutdown fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-FollowerState
datanode3_1  | 2021-08-11 23:09:26,946 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-FollowerState] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-08-11 23:09:26,946 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-08-11 23:09:26,946 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-FollowerState] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2
datanode3_1  | 2021-08-11 23:09:26,954 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-08-11 23:09:26,997 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 97333428-a9dc-49fc-bc54-326166febdda: group-8FBFF034B0CD not found.
datanode3_1  | 2021-08-11 23:09:27,006 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2: ELECTION PASSED received 1 response(s) and 1 exception(s):
datanode3_1  | 2021-08-11 23:09:27,007 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO impl.LeaderElection:   Response 0: fb8d185f-2f23-4800-ba90-a65832b06bb3<-95d91451-f44f-4fa4-a508-c399bd523c99#0:OK-t1
datanode3_1  | 2021-08-11 23:09:27,007 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 97333428-a9dc-49fc-bc54-326166febdda: group-8FBFF034B0CD not found.
datanode3_1  | 2021-08-11 23:09:27,007 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2 ELECTION round 0: result PASSED
datanode3_1  | 2021-08-11 23:09:27,007 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: shutdown fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2
datanode3_1  | 2021-08-11 23:09:27,007 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2021-08-11 23:09:27,007 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8FBFF034B0CD with new leaderId: fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode3_1  | 2021-08-11 23:09:27,011 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD: change Leader from null to fb8d185f-2f23-4800-ba90-a65832b06bb3 at term 1 for becomeLeader, leader elected after 5122ms
datanode3_1  | 2021-08-11 23:09:27,026 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-08-11 23:09:27,042 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-08-11 23:09:27,044 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2021-08-11 23:09:27,067 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-08-11 23:09:27,070 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-08-11 23:09:27,076 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-08-11 23:09:27,152 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-08-11 23:09:27,156 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-08-11 23:09:27,157 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-08-11 23:09:27,162 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-08-11 23:09:27,172 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-08-11 23:09:27,172 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-08-11 23:09:27,213 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-08-11 23:09:27,213 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-08-11 23:09:27,213 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-08-11 23:09:27,215 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-08-11 23:09:27,215 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-08-11 23:09:27,215 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-08-11 23:09:27,235 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderStateImpl
datanode3_1  | 2021-08-11 23:09:27,312 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-08-11 23:09:27,465 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-LeaderElection2] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD: set configuration 0: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2021-08-11 23:09:27,887 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7b6570e5-884e-4bb2-8002-8fbff034b0cd/current/log_inprogress_0
scm1.org_1   | 2021-08-11 23:07:31,980 [main] INFO reflections.Reflections: Reflections took 100 ms to scan 3 urls, producing 104 keys and 214 values 
scm1.org_1   | 2021-08-11 23:07:32,516 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2021-08-11 23:07:32,614 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2932114727528.crt.
scm1.org_1   | 2021-08-11 23:07:32,618 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2021-08-11 23:07:32,620 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2021-08-11 23:07:32,763 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2021-08-11 23:07:32,763 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2021-08-11 23:07:32,796 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-08-11 23:07:32,959 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-08-11 23:07:33,130 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2021-08-11 23:07:33,130 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2021-08-11 23:07:33,264 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:4742394c-da80-4695-95c5-c0a43d189463
scm1.org_1   | 2021-08-11 23:07:33,339 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2021-08-11 23:07:33,393 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-08-11 23:07:33,394 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-08-11 23:07:33,394 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2021-08-11 23:07:33,394 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-08-11 23:07:33,394 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-08-11 23:07:33,395 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-08-11 23:07:33,396 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-08-11 23:07:33,396 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-08-11 23:07:33,397 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-08-11 23:07:33,974 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-08-11 23:07:33,975 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-08-11 23:07:33,975 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-08-11 23:07:33,985 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-08-11 23:07:33,986 [main] INFO server.RaftServer: 4742394c-da80-4695-95c5-c0a43d189463: found a subdirectory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd
scm1.org_1   | 2021-08-11 23:07:33,990 [main] INFO server.RaftServer: 4742394c-da80-4695-95c5-c0a43d189463: addNew group-6C975B8E17FD:[] returns group-6C975B8E17FD:java.util.concurrent.CompletableFuture@4e4395c[Not completed]
scm1.org_1   | 2021-08-11 23:07:34,008 [pool-13-thread-1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463: new RaftServerImpl for group-6C975B8E17FD:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-08-11 23:07:34,010 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-08-11 23:07:34,010 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2021-08-11 23:07:34,011 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2021-08-11 23:07:34,011 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-08-11 23:07:34,011 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-08-11 23:07:34,011 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2021-08-11 23:07:34,012 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-08-11 23:07:34,016 [pool-13-thread-1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-08-11 23:07:34,016 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-08-11 23:07:34,018 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-08-11 23:07:34,019 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2021-08-11 23:07:34,028 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/in_use.lock acquired by nodename 7@scm1.org
scm1.org_1   | 2021-08-11 23:07:34,033 [pool-13-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=4742394c-da80-4695-95c5-c0a43d189463} from /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/raft-meta
scm1.org_1   | 2021-08-11 23:07:34,057 [pool-13-thread-1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: set configuration 0: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-08-11 23:07:34,057 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-08-11 23:07:34,059 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-08-11 23:07:34,065 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-08-11 23:07:34,065 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-08-11 23:07:34,071 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2021-08-11 23:07:34,076 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-08-11 23:07:34,082 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-08-11 23:07:34,083 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-08-11 23:07:34,086 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd
scm1.org_1   | 2021-08-11 23:07:34,087 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
datanode2_1  | 2021-08-11 23:16:27,952 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2186,entriesCount=1,lastEntry=(t:2, i:32)
datanode2_1  | 2021-08-11 23:16:28,096 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2199,entriesCount=1,lastEntry=(t:2, i:33)
datanode2_1  | 2021-08-11 23:16:28,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:28,200 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2209,entriesCount=1,lastEntry=(t:2, i:34)
datanode2_1  | 2021-08-11 23:16:28,218 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2210,entriesCount=1,lastEntry=(t:2, i:35)
datanode2_1  | 2021-08-11 23:16:31,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:35,983 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2461,entriesCount=1,lastEntry=(t:2, i:36)
datanode2_1  | 2021-08-11 23:16:35,999 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2462,entriesCount=1,lastEntry=(t:2, i:37)
datanode2_1  | 2021-08-11 23:16:36,015 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2463,entriesCount=1,lastEntry=(t:2, i:38)
datanode2_1  | 2021-08-11 23:16:36,030 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2465,entriesCount=1,lastEntry=(t:2, i:39)
datanode2_1  | 2021-08-11 23:16:37,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:39,898 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2705,entriesCount=1,lastEntry=(t:2, i:40)
datanode2_1  | 2021-08-11 23:16:40,043 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2706,entriesCount=1,lastEntry=(t:2, i:41)
datanode2_1  | 2021-08-11 23:16:40,116 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2707,entriesCount=1,lastEntry=(t:2, i:42)
datanode2_1  | 2021-08-11 23:16:40,156 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2711,entriesCount=1,lastEntry=(t:2, i:43)
datanode2_1  | 2021-08-11 23:16:40,318 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2730,entriesCount=1,lastEntry=(t:2, i:44)
datanode2_1  | 2021-08-11 23:16:40,358 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2734,entriesCount=1,lastEntry=(t:2, i:45)
datanode2_1  | 2021-08-11 23:16:40,416 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2739,entriesCount=1,lastEntry=(t:2, i:46)
datanode2_1  | 2021-08-11 23:16:40,421 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2740,entriesCount=1,lastEntry=(t:2, i:47)
datanode2_1  | 2021-08-11 23:16:40,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:43,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:46,572 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:49,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:52,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:55,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:16:58,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:01,933 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:05,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:08,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:11,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:14,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:17,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:20,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:25,112 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3005,entriesCount=1,lastEntry=(t:2, i:48)
datanode2_1  | 2021-08-11 23:17:25,114 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3006,entriesCount=1,lastEntry=(t:2, i:49)
datanode2_1  | 2021-08-11 23:17:25,128 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3007,entriesCount=1,lastEntry=(t:2, i:50)
datanode2_1  | 2021-08-11 23:17:25,278 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3008,entriesCount=1,lastEntry=(t:2, i:51)
datanode2_1  | 2021-08-11 23:17:26,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:29,158 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3257,entriesCount=1,lastEntry=(t:2, i:52)
datanode2_1  | 2021-08-11 23:17:29,178 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3258,entriesCount=1,lastEntry=(t:2, i:53)
datanode2_1  | 2021-08-11 23:17:29,212 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3259,entriesCount=1,lastEntry=(t:2, i:54)
datanode2_1  | 2021-08-11 23:17:29,294 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3260,entriesCount=1,lastEntry=(t:2, i:55)
datanode2_1  | 2021-08-11 23:17:29,304 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3261,entriesCount=1,lastEntry=(t:2, i:56)
datanode2_1  | 2021-08-11 23:17:29,310 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3262,entriesCount=1,lastEntry=(t:2, i:57)
datanode2_1  | 2021-08-11 23:17:29,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:32,655 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:35,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:38,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:41,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:44,943 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:46,416 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3520,entriesCount=1,lastEntry=(t:2, i:58)
datanode2_1  | 2021-08-11 23:17:46,428 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3521,entriesCount=1,lastEntry=(t:2, i:59)
datanode2_1  | 2021-08-11 23:17:46,438 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3522,entriesCount=1,lastEntry=(t:2, i:60)
datanode2_1  | 2021-08-11 23:17:46,513 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3523,entriesCount=1,lastEntry=(t:2, i:61)
datanode2_1  | 2021-08-11 23:17:46,525 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3525,entriesCount=1,lastEntry=(t:2, i:62)
datanode2_1  | 2021-08-11 23:17:48,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:49,719 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3776,entriesCount=1,lastEntry=(t:2, i:63)
datanode2_1  | 2021-08-11 23:17:49,740 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3777,entriesCount=1,lastEntry=(t:2, i:64)
datanode2_1  | 2021-08-11 23:17:49,750 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3778,entriesCount=1,lastEntry=(t:2, i:65)
datanode2_1  | 2021-08-11 23:17:49,869 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3779,entriesCount=1,lastEntry=(t:2, i:66)
datanode2_1  | 2021-08-11 23:17:49,872 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3780,entriesCount=1,lastEntry=(t:2, i:67)
datanode2_1  | 2021-08-11 23:17:49,875 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3781,entriesCount=1,lastEntry=(t:2, i:68)
datanode2_1  | 2021-08-11 23:17:51,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:54,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:17:57,231 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:00,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:01,882 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4034,entriesCount=1,lastEntry=(t:2, i:69)
datanode2_1  | 2021-08-11 23:18:01,913 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4035,entriesCount=1,lastEntry=(t:2, i:70)
datanode2_1  | 2021-08-11 23:18:01,936 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4036,entriesCount=1,lastEntry=(t:2, i:71)
datanode2_1  | 2021-08-11 23:18:01,968 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4037,entriesCount=1,lastEntry=(t:2, i:72)
datanode2_1  | 2021-08-11 23:18:01,987 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4039,entriesCount=1,lastEntry=(t:2, i:73)
datanode2_1  | 2021-08-11 23:18:03,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:06,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:09,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:11,234 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4290,entriesCount=1,lastEntry=(t:2, i:74)
datanode2_1  | 2021-08-11 23:18:11,351 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4291,entriesCount=1,lastEntry=(t:2, i:75)
datanode2_1  | 2021-08-11 23:18:11,372 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4292,entriesCount=1,lastEntry=(t:2, i:76)
datanode2_1  | 2021-08-11 23:18:11,442 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4295,entriesCount=1,lastEntry=(t:2, i:77)
datanode2_1  | 2021-08-11 23:18:11,624 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4300,entriesCount=1,lastEntry=(t:2, i:78)
datanode2_1  | 2021-08-11 23:18:11,680 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4305,entriesCount=1,lastEntry=(t:2, i:79)
datanode2_1  | 2021-08-11 23:18:11,742 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4307,entriesCount=1,lastEntry=(t:2, i:80)
datanode2_1  | 2021-08-11 23:18:11,808 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4314,entriesCount=1,lastEntry=(t:2, i:81)
datanode2_1  | 2021-08-11 23:18:12,187 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4348,entriesCount=1,lastEntry=(t:2, i:82)
datanode2_1  | 2021-08-11 23:18:12,200 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4350,entriesCount=1,lastEntry=(t:2, i:83)
datanode2_1  | 2021-08-11 23:18:12,321 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4353,entriesCount=1,lastEntry=(t:2, i:84)
datanode2_1  | 2021-08-11 23:18:15,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:18,164 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4603,entriesCount=1,lastEntry=(t:2, i:85)
datanode2_1  | 2021-08-11 23:18:18,200 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4604,entriesCount=1,lastEntry=(t:2, i:86)
datanode2_1  | 2021-08-11 23:18:18,206 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4605,entriesCount=1,lastEntry=(t:2, i:87)
datanode2_1  | 2021-08-11 23:18:18,273 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4606,entriesCount=1,lastEntry=(t:2, i:88)
datanode2_1  | 2021-08-11 23:18:18,273 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4607,entriesCount=1,lastEntry=(t:2, i:89)
datanode2_1  | 2021-08-11 23:18:18,732 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:21,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:24,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:26,871 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4859,entriesCount=1,lastEntry=(t:2, i:90)
datanode2_1  | 2021-08-11 23:18:26,946 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4860,entriesCount=1,lastEntry=(t:2, i:91)
datanode2_1  | 2021-08-11 23:18:27,030 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4864,entriesCount=1,lastEntry=(t:2, i:92)
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2021-08-11 23:08:01,124 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm3.org_1   | ************************************************************/
scm3.org_1   | 2021-08-11 23:08:01,149 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2021-08-11 23:08:01,358 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2021-08-11 23:08:01,359 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2021-08-11 23:08:01,433 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2021-08-11 23:08:01,437 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2021-08-11 23:08:01,447 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-08-11 23:08:02,023 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2021-08-11 23:08:02,023 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2021-08-11 23:08:03,053 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2021-08-11 23:08:04,088 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2021-08-11 23:08:04,091 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2021-08-11 23:08:04,093 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2021-08-11 23:08:04,798 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2021-08-11 23:08:04,891 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2021-08-11 23:08:04,891 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2021-08-11 23:08:04,894 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:eaeaf9ca-045e-4787-9b06-868925f829d3,clusterId:CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd,subject:scm-sub@scm3.org
scm3.org_1   | 2021-08-11 23:08:05,746 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2021-08-11 23:08:05,768 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-f360cfa0-cc7c-4d2d-b512-6c975b8e17fd, SCMID eaeaf9ca-045e-4787-9b06-868925f829d3
scm3.org_1   | 2021-08-11 23:08:05,768 [main] INFO server.StorageContainerManager: Primary SCM Node ID 4742394c-da80-4695-95c5-c0a43d189463
scm3.org_1   | 2021-08-11 23:08:05,801 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2021-08-11 23:08:07,167 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:15:54,906 [qtp1275028674-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidBucketName</Code>
s3g_1        |   <Message>The specified bucket is not valid.</Message>
s3g_1        |   <Resource>bucket_1</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:88)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm1.org_1   | 2021-08-11 23:07:34,087 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-08-11 23:07:34,088 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-08-11 23:07:34,088 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm1.org_1   | 2021-08-11 23:07:34,088 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2021-08-11 23:07:34,089 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2021-08-11 23:07:34,089 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2021-08-11 23:07:34,089 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2021-08-11 23:07:34,096 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2021-08-11 23:07:34,096 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2021-08-11 23:07:34,114 [pool-13-thread-1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: set configuration 0: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-08-11 23:07:34,115 [pool-13-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_0
scm1.org_1   | 2021-08-11 23:07:34,117 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2021-08-11 23:07:34,117 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-08-11 23:07:34,165 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2021-08-11 23:07:34,165 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-08-11 23:07:34,166 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-08-11 23:07:34,166 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2021-08-11 23:07:34,167 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2021-08-11 23:07:34,168 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-08-11 23:07:34,193 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2021-08-11 23:07:34,194 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2021-08-11 23:07:34,194 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2021-08-11 23:07:34,397 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm1.org_1   | 2021-08-11 23:07:34,397 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2021-08-11 23:07:34,400 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2021-08-11 23:07:34,402 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2021-08-11 23:07:34,466 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2021-08-11 23:07:34,486 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2021-08-11 23:07:34,504 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
scm1.org_1   | 2021-08-11 23:07:34,553 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2021-08-11 23:07:34,562 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2021-08-11 23:07:34,563 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2021-08-11 23:07:34,595 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2021-08-11 23:07:34,610 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2021-08-11 23:07:34,620 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2021-08-11 23:07:34,621 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-08-11 23:07:34,631 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm1.org_1   | 2021-08-11 23:07:34,632 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2021-08-11 23:07:34,635 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:07:34,637 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2021-08-11 23:07:34,665 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2021-08-11 23:07:34,670 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2021-08-11 23:07:34,685 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 2932114727528 on primary SCM
scm1.org_1   | 2021-08-11 23:07:34,694 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2021-08-11 23:07:34,724 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-08-11 23:07:34,767 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2021-08-11 23:07:35,549 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-08-11 23:07:35,579 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2021-08-11 23:07:35,636 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-08-11 23:07:35,647 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2021-08-11 23:07:35,689 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-08-11 23:07:35,690 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode3_1  | 2021-08-11 23:09:28,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:29,022 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-FollowerState] INFO impl.FollowerState: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5102511599ns, electionTimeout:5087ms
datanode3_1  | 2021-08-11 23:09:29,022 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-FollowerState] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: shutdown fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-FollowerState
datanode3_1  | 2021-08-11 23:09:29,022 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-FollowerState] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-08-11 23:09:29,022 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-08-11 23:09:29,022 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-FollowerState] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3
datanode3_1  | 2021-08-11 23:09:29,030 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-08-11 23:09:29,030 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO impl.LeaderElection: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2021-08-11 23:09:29,030 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: shutdown fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3
datanode3_1  | 2021-08-11 23:09:29,030 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2021-08-11 23:09:29,030 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-ED00911F12B5 with new leaderId: fb8d185f-2f23-4800-ba90-a65832b06bb3
datanode3_1  | 2021-08-11 23:09:29,032 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode3_1  | 2021-08-11 23:09:29,032 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5: change Leader from null to fb8d185f-2f23-4800-ba90-a65832b06bb3 at term 1 for becomeLeader, leader elected after 5310ms
datanode3_1  | 2021-08-11 23:09:29,043 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-08-11 23:09:29,044 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-08-11 23:09:29,045 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2021-08-11 23:09:29,045 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-08-11 23:09:29,046 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-08-11 23:09:29,046 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-08-11 23:09:29,047 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderStateImpl
datanode3_1  | 2021-08-11 23:09:29,048 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-08-11 23:09:29,052 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7d30a22a-435f-40ae-b84a-ed00911f12b5/current/log_inprogress_0
datanode3_1  | 2021-08-11 23:09:29,079 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5-LeaderElection3] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-ED00911F12B5: set configuration 0: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-08-11 23:09:30,390 [grpc-default-executor-0] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: receive requestVote(ELECTION, 95d91451-f44f-4fa4-a508-c399bd523c99, group-6FA1826E58A5, 2, (t:0, i:0))
datanode3_1  | 2021-08-11 23:09:30,390 [grpc-default-executor-0] INFO impl.VoteContext: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FOLLOWER: accept ELECTION from 95d91451-f44f-4fa4-a508-c399bd523c99: our priority 0 <= candidate's priority 1
datanode3_1  | 2021-08-11 23:09:30,390 [grpc-default-executor-0] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:95d91451-f44f-4fa4-a508-c399bd523c99
datanode3_1  | 2021-08-11 23:09:30,390 [grpc-default-executor-0] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: shutdown fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState
datanode3_1  | 2021-08-11 23:09:30,390 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState] INFO impl.FollowerState: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2021-08-11 23:09:30,393 [grpc-default-executor-0] INFO impl.RoleInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3: start fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-FollowerState
datanode3_1  | 2021-08-11 23:09:30,411 [grpc-default-executor-0] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5 replies to ELECTION vote request: 95d91451-f44f-4fa4-a508-c399bd523c99<-fb8d185f-2f23-4800-ba90-a65832b06bb3#0:OK-t2. Peer's state: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5:t2, leader=null, voted=95d91451-f44f-4fa4-a508-c399bd523c99, raftlog=fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-08-11 23:09:30,685 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6FA1826E58A5 with new leaderId: 95d91451-f44f-4fa4-a508-c399bd523c99
datanode3_1  | 2021-08-11 23:09:30,689 [grpc-default-executor-0] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: change Leader from null to 95d91451-f44f-4fa4-a508-c399bd523c99 at term 2 for appendEntries, leader elected after 13772ms
datanode3_1  | 2021-08-11 23:09:30,778 [grpc-default-executor-0] INFO server.RaftServer$Division: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5: set configuration 0: [fb8d185f-2f23-4800-ba90-a65832b06bb3|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 95d91451-f44f-4fa4-a508-c399bd523c99|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 97333428-a9dc-49fc-bc54-326166febdda|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2021-08-11 23:09:30,796 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-08-11 23:09:30,803 [fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-6FA1826E58A5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e8fee977-3a11-4948-b60e-6fa1826e58a5/current/log_inprogress_0
datanode3_1  | 2021-08-11 23:09:31,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:34,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:37,935 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:41,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:44,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:47,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:48,169 [grpc-default-executor-0] INFO leader.FollowerInfo: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2021-08-11 23:09:50,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:53,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:56,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:09:58,436 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode3_1  | java.net.NoRouteToHostException: No Route to Host from  9858c43d50b5/172.25.0.104 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:855)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode3_1  | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
datanode3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode3_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode3_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:701)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:822)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode2_1  | 2021-08-11 23:18:27,071 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4867,entriesCount=1,lastEntry=(t:2, i:93)
datanode2_1  | 2021-08-11 23:18:27,102 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4871,entriesCount=1,lastEntry=(t:2, i:94)
datanode2_1  | 2021-08-11 23:18:27,118 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4873,entriesCount=1,lastEntry=(t:2, i:95)
datanode2_1  | 2021-08-11 23:18:27,137 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4878,entriesCount=1,lastEntry=(t:2, i:96)
datanode2_1  | 2021-08-11 23:18:27,147 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4880,entriesCount=1,lastEntry=(t:2, i:97)
datanode2_1  | 2021-08-11 23:18:27,948 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:31,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:34,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:37,183 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:39,501 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5133,entriesCount=1,lastEntry=(t:2, i:98)
datanode2_1  | 2021-08-11 23:18:39,581 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5134,entriesCount=1,lastEntry=(t:2, i:99)
datanode2_1  | 2021-08-11 23:18:39,640 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5135,entriesCount=1,lastEntry=(t:2, i:100)
datanode2_1  | 2021-08-11 23:18:39,665 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5136,entriesCount=1,lastEntry=(t:2, i:101)
datanode2_1  | 2021-08-11 23:18:39,679 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5137,entriesCount=1,lastEntry=(t:2, i:102)
datanode2_1  | 2021-08-11 23:18:39,715 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5141,entriesCount=1,lastEntry=(t:2, i:103)
datanode2_1  | 2021-08-11 23:18:39,726 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5142,entriesCount=1,lastEntry=(t:2, i:104)
datanode2_1  | 2021-08-11 23:18:39,738 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5144,entriesCount=1,lastEntry=(t:2, i:105)
datanode2_1  | 2021-08-11 23:18:40,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:43,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:44,581 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5397,entriesCount=1,lastEntry=(t:2, i:106)
datanode2_1  | 2021-08-11 23:18:44,705 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5398,entriesCount=1,lastEntry=(t:2, i:107)
datanode2_1  | 2021-08-11 23:18:44,731 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5399,entriesCount=1,lastEntry=(t:2, i:108)
datanode2_1  | 2021-08-11 23:18:44,839 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5409,entriesCount=1,lastEntry=(t:2, i:109)
datanode2_1  | 2021-08-11 23:18:44,843 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5410,entriesCount=1,lastEntry=(t:2, i:110)
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-03f3b68-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/43554e9d5fa1f4aad5bff6e55b2203b3a92550f9 ; compiled by 'runner' on 2021-08-11T22:08Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm3.org_1   | ************************************************************/
scm3.org_1   | 2021-08-11 23:08:07,175 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2021-08-11 23:08:07,281 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2021-08-11 23:08:07,282 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2021-08-11 23:08:07,337 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2021-08-11 23:08:07,337 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2021-08-11 23:08:07,363 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-08-11 23:08:07,385 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm3.org_1   | 2021-08-11 23:08:07,573 [main] INFO reflections.Reflections: Reflections took 97 ms to scan 3 urls, producing 104 keys and 214 values 
scm3.org_1   | 2021-08-11 23:08:08,015 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2021-08-11 23:08:08,311 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2021-08-11 23:08:08,315 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2021-08-11 23:08:08,321 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2976504016675.crt.
scm3.org_1   | 2021-08-11 23:08:08,568 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2021-08-11 23:08:08,569 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2021-08-11 23:08:08,624 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-08-11 23:08:08,919 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-08-11 23:10:50,266 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:54,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40260
om2_1        | 2021-08-11 23:10:54,486 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:10:58,744 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40282
om2_1        | 2021-08-11 23:10:58,751 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:11,250 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40352
om2_1        | 2021-08-11 23:11:11,252 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:11,790 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:61235-source for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-08-11 23:11:14,934 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40374
om2_1        | 2021-08-11 23:11:14,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:15,372 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:61235-target for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-08-11 23:11:18,384 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40386
om2_1        | 2021-08-11 23:11:18,392 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:21,967 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40408
om2_1        | 2021-08-11 23:11:21,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:30,366 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40442
om2_1        | 2021-08-11 23:11:30,374 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:34,142 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40464
om2_1        | 2021-08-11 23:11:34,156 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:37,951 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40498
om2_1        | 2021-08-11 23:11:37,959 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:41,511 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40518
om2_1        | 2021-08-11 23:11:41,519 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:45,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40538
om2_1        | 2021-08-11 23:11:45,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:48,577 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40560
om2_1        | 2021-08-11 23:11:48,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:52,162 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40582
om2_1        | 2021-08-11 23:11:52,167 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:55,824 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40596
om2_1        | 2021-08-11 23:11:55,830 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:11:59,416 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40618
om2_1        | 2021-08-11 23:11:59,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:03,104 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40638
om2_1        | 2021-08-11 23:12:03,107 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:06,681 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40650
om2_1        | 2021-08-11 23:12:06,684 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:10:57,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:00,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:03,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:06,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:09,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:12,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:15,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:18,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:21,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:24,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:27,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:31,023 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:34,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:40,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:43,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:46,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:49,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:52,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:55,599 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:11:58,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:01,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:04,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:07,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:10,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:14,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:17,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:20,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:23,247 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:29,391 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:32,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:35,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:38,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:41,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:44,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:47,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:50,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:53,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:12:57,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:00,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:03,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:06,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:09,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:12,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:18,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:21,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:24,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:27,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:30,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:33,903 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:36,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:40,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:43,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:46,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:49,259 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:12:10,401 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40692
om2_1        | 2021-08-11 23:12:10,432 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:14,075 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40706
om2_1        | 2021-08-11 23:12:14,083 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:17,579 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40726
om2_1        | 2021-08-11 23:12:17,583 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:25,955 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40764
om2_1        | 2021-08-11 23:12:25,963 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:31,802 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40790
om2_1        | 2021-08-11 23:12:31,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:40,443 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40850
om2_1        | 2021-08-11 23:12:40,447 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:46,057 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40890
om2_1        | 2021-08-11 23:12:46,063 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:49,733 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40902
om2_1        | 2021-08-11 23:12:49,739 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:53,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40924
om2_1        | 2021-08-11 23:12:53,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:12:57,143 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40946
om2_1        | 2021-08-11 23:12:57,157 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:01,131 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40960
om2_1        | 2021-08-11 23:13:01,135 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:05,067 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40980
om2_1        | 2021-08-11 23:13:05,073 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:08,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41022
om2_1        | 2021-08-11 23:13:08,944 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:12,176 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41034
om2_1        | 2021-08-11 23:13:12,185 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:15,768 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41058
om2_1        | 2021-08-11 23:13:15,778 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:19,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41070
om2_1        | 2021-08-11 23:13:19,398 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:23,018 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41090
om2_1        | 2021-08-11 23:13:23,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:26,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41102
om2_1        | 2021-08-11 23:13:26,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:30,381 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41124
datanode1_1  | 2021-08-11 23:13:52,335 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:55,407 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:13:58,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:01,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:07,691 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:10,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:13,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:16,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:19,980 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:23,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:26,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:29,199 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:32,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:35,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:38,411 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:41,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:44,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:47,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:50,699 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:56,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:14:59,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:02,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:06,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:09,131 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:12,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:15,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:18,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:21,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1647)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1463)
datanode3_1  | 	... 12 more
datanode3_1  | 2021-08-11 23:10:02,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:05,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:08,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:11,728 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:14,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:16,655 [ChunkWriter-6-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:3023215292325.
datanode3_1  | 2021-08-11 23:10:17,876 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:20,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:24,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:27,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:30,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:33,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:36,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:39,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:42,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:45,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:48,171 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:0)
datanode3_1  | 2021-08-11 23:10:51,660 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:54,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:10:57,804 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:00,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:03,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:07,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:10,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:13,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:16,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:19,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:00,350 [qtp1275028674-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-82600, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:16:00,365 [qtp1275028674-23] INFO endpoint.BucketEndpoint: Location is /bucket-82600
s3g_1        | 2021-08-11 23:16:00,846 [qtp1275028674-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-14807, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:16:00,864 [qtp1275028674-23] INFO endpoint.BucketEndpoint: Location is /bucket-14807
s3g_1        | 2021-08-11 23:16:01,837 [qtp1275028674-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>nosuchbucket</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
datanode3_1  | 2021-08-11 23:11:22,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:25,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:28,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:31,595 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:34,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:37,455 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=278,entriesCount=1,lastEntry=(t:1, i:1)
datanode3_1  | 2021-08-11 23:11:37,496 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=279,entriesCount=1,lastEntry=(t:1, i:2)
datanode3_1  | 2021-08-11 23:11:37,687 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=280,entriesCount=1,lastEntry=(t:1, i:3)
datanode3_1  | 2021-08-11 23:11:37,760 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=284,entriesCount=1,lastEntry=(t:1, i:4)
datanode3_1  | 2021-08-11 23:11:40,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:43,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:46,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:50,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:53,100 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:56,175 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:11:59,247 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:02,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:05,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:08,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:11,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:14,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:17,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:20,748 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:23,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:24,263 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=545,entriesCount=1,lastEntry=(t:1, i:5)
datanode3_1  | 2021-08-11 23:12:24,274 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=546,entriesCount=1,lastEntry=(t:1, i:6)
scm1.org_1   | 2021-08-11 23:07:35,764 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2021-08-11 23:07:35,769 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          0.1
scm1.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.5
scm1.org_1   | Max Size to Move per Iteration                     10737418240B
scm1.org_1   | 
scm1.org_1   | 2021-08-11 23:07:35,769 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-08-11 23:07:35,769 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2021-08-11 23:07:35,772 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2021-08-11 23:07:35,773 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2021-08-11 23:07:35,773 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: start as a follower, conf=0: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-08-11 23:07:35,784 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2021-08-11 23:07:35,785 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: start 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState
scm1.org_1   | 2021-08-11 23:07:35,796 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6C975B8E17FD,id=4742394c-da80-4695-95c5-c0a43d189463
scm1.org_1   | 2021-08-11 23:07:35,803 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 4742394c-da80-4695-95c5-c0a43d189463: start RPC server
scm1.org_1   | 2021-08-11 23:07:35,871 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 4742394c-da80-4695-95c5-c0a43d189463: GrpcService started, listening on 9894
scm1.org_1   | 2021-08-11 23:07:35,885 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-08-11 23:07:35,885 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2021-08-11 23:07:35,889 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2021-08-11 23:07:35,889 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2021-08-11 23:07:35,899 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$424/0x0000000840523040@19b4dd60] INFO util.JvmPauseMonitor: JvmPauseMonitor-4742394c-da80-4695-95c5-c0a43d189463: Started
scm1.org_1   | 2021-08-11 23:07:35,986 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2021-08-11 23:07:35,999 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2021-08-11 23:07:35,999 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2021-08-11 23:07:36,256 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2021-08-11 23:07:36,256 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-08-11 23:07:36,314 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2021-08-11 23:07:36,325 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2021-08-11 23:07:36,325 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2021-08-11 23:07:36,326 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-08-11 23:07:36,326 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2021-08-11 23:07:36,361 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm1.org_1   | 2021-08-11 23:07:36,362 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2021-08-11 23:07:36,367 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-08-11 23:07:36,368 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2021-08-11 23:07:36,368 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2021-08-11 23:07:36,508 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22825762] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2021-08-11 23:07:36,532 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2021-08-11 23:07:36,532 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2021-08-11 23:07:36,536 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2021-08-11 23:07:36,578 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @5946ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2021-08-11 23:07:36,612 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54554
scm1.org_1   | 2021-08-11 23:07:36,679 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:07:36,797 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2021-08-11 23:07:36,818 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2021-08-11 23:07:36,819 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2021-08-11 23:07:36,819 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2021-08-11 23:07:36,820 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2021-08-11 23:07:36,822 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2021-08-11 23:07:36,889 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2021-08-11 23:08:09,176 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2021-08-11 23:08:09,176 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2021-08-11 23:08:09,391 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:eaeaf9ca-045e-4787-9b06-868925f829d3
scm3.org_1   | 2021-08-11 23:08:09,524 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2021-08-11 23:08:09,712 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2021-08-11 23:08:09,713 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-08-11 23:08:09,713 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2021-08-11 23:08:09,714 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-08-11 23:08:09,715 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-08-11 23:08:09,715 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2021-08-11 23:08:09,716 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2021-08-11 23:08:09,717 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2021-08-11 23:08:09,718 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2021-08-11 23:08:11,434 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2021-08-11 23:08:11,436 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2021-08-11 23:08:11,439 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2021-08-11 23:08:11,464 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2021-08-11 23:08:11,488 [main] INFO server.RaftServer: eaeaf9ca-045e-4787-9b06-868925f829d3: addNew group-6C975B8E17FD:[] returns group-6C975B8E17FD:java.util.concurrent.CompletableFuture@17176b18[Not completed]
scm3.org_1   | 2021-08-11 23:08:11,537 [pool-13-thread-1] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3: new RaftServerImpl for group-6C975B8E17FD:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2021-08-11 23:08:11,544 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2021-08-11 23:08:11,544 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2021-08-11 23:08:11,545 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2021-08-11 23:08:11,545 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2021-08-11 23:08:11,545 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2021-08-11 23:08:11,545 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2021-08-11 23:08:11,548 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2021-08-11 23:08:11,561 [pool-13-thread-1] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2021-08-11 23:08:11,561 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2021-08-11 23:08:11,565 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2021-08-11 23:08:11,570 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2021-08-11 23:08:11,571 [pool-13-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd does not exist. Creating ...
scm3.org_1   | 2021-08-11 23:08:11,591 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2021-08-11 23:08:11,634 [pool-13-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd has been successfully formatted.
scm3.org_1   | 2021-08-11 23:08:11,637 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2021-08-11 23:08:11,644 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2021-08-11 23:08:11,661 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2021-08-11 23:08:11,667 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2021-08-11 23:08:11,679 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2021-08-11 23:08:11,694 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm3.org_1   | 2021-08-11 23:08:11,718 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2021-08-11 23:08:11,719 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2021-08-11 23:08:11,729 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd
scm3.org_1   | 2021-08-11 23:08:11,730 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2021-08-11 23:08:11,731 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2021-08-11 23:08:11,732 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm3.org_1   | 2021-08-11 23:08:11,735 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm3.org_1   | 2021-08-11 23:08:11,735 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2021-08-11 23:08:11,737 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2021-08-11 23:08:11,741 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2021-08-11 23:08:11,741 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2021-08-11 23:08:11,758 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2021-08-11 23:08:11,759 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2021-08-11 23:08:11,776 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-08-11 23:07:55,010 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2021-08-11 23:07:55,033 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2021-08-11 23:07:55,046 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2021-08-11 23:07:55,052 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2021-08-11 23:07:55,058 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm2.org_1   | 2021-08-11 23:07:55,064 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2021-08-11 23:07:55,068 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:07:55,071 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2021-08-11 23:07:55,102 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2021-08-11 23:07:55,132 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-08-11 23:07:55,165 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2021-08-11 23:07:56,352 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-08-11 23:07:56,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2021-08-11 23:07:56,377 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-08-11 23:07:56,383 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2021-08-11 23:07:56,506 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-08-11 23:07:56,510 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2021-08-11 23:07:56,684 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2021-08-11 23:07:56,702 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          0.1
scm2.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.5
scm2.org_1   | Max Size to Move per Iteration                     10737418240B
scm2.org_1   | 
scm2.org_1   | 2021-08-11 23:07:56,702 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-08-11 23:07:56,703 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2021-08-11 23:07:56,707 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2021-08-11 23:07:56,709 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2021-08-11 23:07:56,710 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2021-08-11 23:07:56,713 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2021-08-11 23:07:56,714 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6C975B8E17FD,id=264530c6-4c2c-4bc1-b4ab-46128a8936fc
scm2.org_1   | 2021-08-11 23:07:56,735 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 264530c6-4c2c-4bc1-b4ab-46128a8936fc: start RPC server
scm2.org_1   | 2021-08-11 23:07:56,808 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 264530c6-4c2c-4bc1-b4ab-46128a8936fc: GrpcService started, listening on 9894
scm2.org_1   | 2021-08-11 23:07:56,818 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-08-11 23:07:56,818 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-08-11 23:07:56,818 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2021-08-11 23:07:56,819 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$405/0x00000008404f8840@1ced1d14] INFO util.JvmPauseMonitor: JvmPauseMonitor-264530c6-4c2c-4bc1-b4ab-46128a8936fc: Started
scm2.org_1   | 2021-08-11 23:07:59,185 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2021-08-11 23:07:59,185 [grpc-default-executor-0] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: change Leader from null to 4742394c-da80-4695-95c5-c0a43d189463 at term 2 for appendEntries, leader elected after 4730ms
scm2.org_1   | 2021-08-11 23:07:59,187 [grpc-default-executor-0] INFO impl.RoleInfo: 264530c6-4c2c-4bc1-b4ab-46128a8936fc: start 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-FollowerState
scm2.org_1   | 2021-08-11 23:07:59,278 [grpc-default-executor-0] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: set configuration 0: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-08-11 23:07:59,287 [grpc-default-executor-0] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: set configuration 1: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-08-11 23:07:59,291 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2021-08-11 23:07:59,343 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2021-08-11 23:07:59,493 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_0
scm2.org_1   | 2021-08-11 23:07:59,498 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_0 to /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_0-0
scm2.org_1   | 2021-08-11 23:07:59,522 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_1
scm2.org_1   | 2021-08-11 23:07:59,543 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:11,776 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2021-08-11 23:08:11,789 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2021-08-11 23:08:11,797 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2021-08-11 23:08:11,798 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2021-08-11 23:08:11,803 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2021-08-11 23:08:11,804 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
om1_1        | 2021-08-11 23:15:03,266 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39592
om1_1        | 2021-08-11 23:15:03,278 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:03,751 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:03,751 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39600
om1_1        | 2021-08-11 23:15:03,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:08,721 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:08,722 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39636
datanode2_1  | 2021-08-11 23:18:44,849 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5411,entriesCount=1,lastEntry=(t:2, i:111)
datanode2_1  | 2021-08-11 23:18:44,871 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5414,entriesCount=1,lastEntry=(t:2, i:112)
datanode2_1  | 2021-08-11 23:18:46,380 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:49,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:52,527 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:55,608 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:18:58,667 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:00,163 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5670,entriesCount=1,lastEntry=(t:2, i:113)
datanode2_1  | 2021-08-11 23:19:00,164 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5671,entriesCount=1,lastEntry=(t:2, i:114)
datanode2_1  | 2021-08-11 23:19:00,180 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5672,entriesCount=1,lastEntry=(t:2, i:115)
datanode2_1  | 2021-08-11 23:19:00,186 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5673,entriesCount=1,lastEntry=(t:2, i:116)
datanode2_1  | 2021-08-11 23:19:03,814 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5923,entriesCount=1,lastEntry=(t:2, i:117)
om1_1        | 2021-08-11 23:15:08,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:11,839 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:11,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39660
om1_1        | 2021-08-11 23:15:11,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:12,322 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:12,323 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39668
scm1.org_1   | 2021-08-11 23:07:36,890 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
scm1.org_1   | 2021-08-11 23:07:36,986 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2021-08-11 23:07:36,988 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2021-08-11 23:07:36,990 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2021-08-11 23:15:12,335 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:12,788 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode2_1  | 2021-08-11 23:19:03,815 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5924,entriesCount=1,lastEntry=(t:2, i:118)
scm3.org_1   | 2021-08-11 23:08:11,810 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2021-08-11 23:08:11,864 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2021-08-11 23:08:11,865 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2021-08-11 23:08:11,866 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2021-08-11 23:08:12,286 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm3.org_1   | 2021-08-11 23:08:12,286 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2021-08-11 23:08:12,290 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2021-08-11 23:08:12,296 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2021-08-11 23:07:59,544 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
datanode1_1  | 2021-08-11 23:15:24,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:27,566 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:12,789 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39676
om1_1        | 2021-08-11 23:15:12,798 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:15,789 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56656
om1_1        | 2021-08-11 23:15:15,805 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:30,396 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-08-11 23:07:59,546 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2021-08-11 23:07:59,551 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2021-08-11 23:07:59,553 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-08-11 23:07:59,565 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2021-08-11 23:07:59,587 [grpc-default-executor-0] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: set configuration 5: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-08-11 23:07:59,854 [grpc-default-executor-0] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: set configuration 7: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-08-11 23:08:00,095 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-6C975B8E17FD:[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
om1_1        | 2021-08-11 23:15:18,050 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:18,051 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39704
om1_1        | 2021-08-11 23:15:18,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:18,569 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:18,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39712
om1_1        | 2021-08-11 23:15:18,575 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:18,633 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:18,635 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39716
om1_1        | 2021-08-11 23:15:18,641 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:21,336 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:21,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39736
om1_1        | 2021-08-11 23:15:21,383 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:24,046 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:24,047 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39748
scm1.org_1   | 2021-08-11 23:07:37,021 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2021-08-11 23:07:37,025 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57e2d15c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2021-08-11 23:07:37,025 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61868687{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2021-08-11 23:07:37,179 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2021-08-11 23:07:37,189 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5a438c0a{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-4471603717981991030/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2021-08-11 23:07:37,198 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@2456716b{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2021-08-11 23:07:37,199 [Listener at 0.0.0.0/9860] INFO server.Server: Started @6567ms
scm1.org_1   | 2021-08-11 23:07:37,200 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2021-08-11 23:07:37,201 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2021-08-11 23:07:37,202 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2021-08-11 23:07:39,022 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:48346
scm1.org_1   | 2021-08-11 23:07:39,034 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:07:40,860 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO impl.FollowerState: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5075103576ns, electionTimeout:5064ms
scm1.org_1   | 2021-08-11 23:07:40,862 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: shutdown 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState
scm1.org_1   | 2021-08-11 23:07:40,862 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2021-08-11 23:07:40,865 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2021-08-11 23:07:40,865 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-FollowerState] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: start 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1
scm1.org_1   | 2021-08-11 23:07:40,878 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO impl.LeaderElection: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-08-11 23:07:40,879 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO impl.LeaderElection: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2021-08-11 23:07:40,879 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: shutdown 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1
scm1.org_1   | 2021-08-11 23:07:40,880 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2021-08-11 23:07:40,880 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
datanode1_1  | 2021-08-11 23:15:28,213 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$334/0x00000008405a9040@5105b25c] WARN util.JvmPauseMonitor: JvmPauseMonitor-97333428-a9dc-49fc-bc54-326166febdda: Detected pause in JVM or host machine (eg GC): pause of approximately 114848117ns.
datanode1_1  | GC pool 'ParNew' had collection(s): count=1 time=93ms
datanode1_1  | 2021-08-11 23:15:30,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:33,708 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:36,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:39,853 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:08:12,390 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2021-08-11 23:08:12,408 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2021-08-11 23:08:12,454 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
scm3.org_1   | 2021-08-11 23:08:12,528 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
om1_1        | 2021-08-11 23:15:24,058 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:26,765 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:26,766 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39760
om1_1        | 2021-08-11 23:15:26,768 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:15:45,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:49,071 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:52,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:55,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:15:58,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:26,942 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:26,943 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39764
om1_1        | 2021-08-11 23:15:26,963 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:26,971 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm3.org_1   | 2021-08-11 23:08:12,550 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2021-08-11 23:08:12,552 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2021-08-11 23:08:12,625 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2021-08-11 23:08:12,664 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
datanode1_1  | 2021-08-11 23:16:01,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:04,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:07,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:10,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:26,972 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39770
om1_1        | 2021-08-11 23:15:26,985 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:30,880 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:30,880 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39794
scm3.org_1   | 2021-08-11 23:08:12,690 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2021-08-11 23:08:12,696 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2021-08-11 23:08:12,708 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm3.org_1   | 2021-08-11 23:08:12,731 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
datanode1_1  | 2021-08-11 23:16:13,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:30,895 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:07:40,880 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2021-08-11 23:07:40,882 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: change Leader from null to 4742394c-da80-4695-95c5-c0a43d189463 at term 2 for becomeLeader, leader elected after 6822ms
scm1.org_1   | 2021-08-11 23:07:40,887 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2021-08-11 23:07:40,890 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode2_1  | 2021-08-11 23:19:03,818 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5925,entriesCount=1,lastEntry=(t:2, i:119)
datanode2_1  | 2021-08-11 23:19:03,819 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5926,entriesCount=1,lastEntry=(t:2, i:120)
datanode2_1  | 2021-08-11 23:19:04,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:07,395 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6177,entriesCount=1,lastEntry=(t:2, i:121)
datanode2_1  | 2021-08-11 23:19:07,408 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6178,entriesCount=1,lastEntry=(t:2, i:122)
datanode2_1  | 2021-08-11 23:19:07,423 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6180,entriesCount=1,lastEntry=(t:2, i:123)
datanode2_1  | 2021-08-11 23:19:07,450 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6186,entriesCount=1,lastEntry=(t:2, i:124)
datanode2_1  | 2021-08-11 23:19:07,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:10,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:14,030 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:17,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:08:12,739 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:12,743 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2021-08-11 23:08:12,815 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
datanode1_1  | 2021-08-11 23:16:16,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:19,792 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:22,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:25,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:13:34,030 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41148
om2_1        | 2021-08-11 23:13:34,038 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:34,420 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:61235-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm3.org_1   | 2021-08-11 23:08:12,916 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 2021-08-11 23:19:18,391 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6433,entriesCount=1,lastEntry=(t:2, i:125)
datanode2_1  | 2021-08-11 23:19:18,393 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6434,entriesCount=1,lastEntry=(t:2, i:126)
datanode2_1  | 2021-08-11 23:19:18,400 [java.util.concurrent.ThreadPoolExecutor$Worker@50948f34[State = -1, empty queue]] WARN server.GrpcLogAppender: 95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6435,entriesCount=1,lastEntry=(t:2, i:127)
datanode2_1  | 2021-08-11 23:19:20,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:29,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-08-11 23:07:40,891 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-08-11 23:07:40,895 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2021-08-11 23:07:40,895 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2021-08-11 23:19:23,247 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:35,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:13:37,447 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41160
om2_1        | 2021-08-11 23:13:37,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:41,132 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41200
om2_1        | 2021-08-11 23:13:41,140 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:41,625 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:61235-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 2021-08-11 23:15:31,111 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:31,118 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39798
om1_1        | 2021-08-11 23:15:31,128 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:31,260 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:31,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39804
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:15:31,270 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-08-11 23:08:12,982 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2021-08-11 23:08:14,274 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-08-11 23:08:14,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
datanode3_1  | 2021-08-11 23:12:24,291 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=548,entriesCount=1,lastEntry=(t:1, i:7)
datanode3_1  | 2021-08-11 23:12:24,315 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=552,entriesCount=1,lastEntry=(t:1, i:8)
om1_1        | 2021-08-11 23:15:31,320 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:31,321 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39808
datanode2_1  | 2021-08-11 23:19:26,319 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:29,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:32,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:35,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:38,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:41,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:44,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:47,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:53,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:19:57,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:00,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:03,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:06,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:09,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:12,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:15,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:18,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:21,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:24,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:27,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:30,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:33,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:36,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:43,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:46,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-08-11 23:07:40,896 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1        | 2021-08-11 23:13:44,705 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41212
om2_1        | 2021-08-11 23:13:44,714 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:16:38,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:41,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:44,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:47,436 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:31,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:07:40,901 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO impl.RoleInfo: 4742394c-da80-4695-95c5-c0a43d189463: start 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl
scm1.org_1   | 2021-08-11 23:07:40,913 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2021-08-11 23:07:40,917 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_0 to /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_0-0
datanode2_1  | 2021-08-11 23:20:49,259 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:52,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:55,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:20:58,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:29,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:08:14,476 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-08-11 23:08:14,491 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2021-08-11 23:08:14,573 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-08-11 23:08:14,596 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
om2_1        | 2021-08-11 23:13:48,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41242
om2_1        | 2021-08-11 23:13:48,385 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:48,812 [IPC Server handler 26 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket /61235-target/unreadable-link/null
om2_1        | 2021-08-11 23:13:51,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41266
om1_1        | 2021-08-11 23:15:35,046 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode3_1  | 2021-08-11 23:12:33,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:36,108 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:39,179 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:42,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:08:00,099 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2021-08-11 23:08:00,104 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2021-08-11 23:08:00,104 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
om1_1        | 2021-08-11 23:15:35,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39830
om1_1        | 2021-08-11 23:15:35,065 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:35,187 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:35,187 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39834
om1_1        | 2021-08-11 23:15:35,198 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:16:50,512 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:01,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:04,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:07,692 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:10,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-08-11 23:07:40,927 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderElection1] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: set configuration 1: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-08-11 23:07:40,929 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_1
scm1.org_1   | 2021-08-11 23:07:40,934 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2021-08-11 23:07:40,935 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2021-08-11 23:07:40,937 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:14,721 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2021-08-11 23:08:14,732 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
om2_1        | 2021-08-11 23:13:51,754 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:55,462 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41278
om2_1        | 2021-08-11 23:13:55,473 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:13:55,905 [IPC Server handler 7 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket /61235-source/unreadable-bucket/
om2_1        | 2021-08-11 23:13:58,932 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41300
datanode1_1  | 2021-08-11 23:16:53,580 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:56,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:16:59,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:02,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:45,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:48,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:51,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:12:54,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:35,325 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm2.org_1   | 2021-08-11 23:08:00,109 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:08:00,124 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2021-08-11 23:08:00,130 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2021-08-11 23:08:00,464 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2021-08-11 23:08:00,500 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2021-08-11 23:08:00,500 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2021-08-11 23:08:01,281 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2021-08-11 23:08:01,287 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2021-08-11 23:08:01,296 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-08-11 23:07:40,937 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2021-08-11 23:07:40,938 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
datanode1_1  | 2021-08-11 23:17:05,871 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          0.1
om1_1        | 2021-08-11 23:15:35,326 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39838
om1_1        | 2021-08-11 23:15:35,333 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:35,413 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode3_1  | 2021-08-11 23:12:57,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:00,683 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:03,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:06,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
datanode2_1  | 2021-08-11 23:21:13,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:16,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:19,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:23,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:13:58,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:14:02,378 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41314
om2_1        | 2021-08-11 23:14:02,398 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:14:05,856 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41336
om1_1        | 2021-08-11 23:15:35,414 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39842
om1_1        | 2021-08-11 23:15:35,434 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:35,784 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:35,785 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39846
scm3.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.5
scm3.org_1   | Max Size to Move per Iteration                     10737418240B
scm3.org_1   | 
scm3.org_1   | 2021-08-11 23:08:14,733 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-08-11 23:08:14,733 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
datanode1_1  | 2021-08-11 23:17:08,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:12,184 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:15,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:18,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:24,299 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:27,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:30,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:33,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:36,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-08-11 23:07:40,938 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2021-08-11 23:07:40,946 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2021-08-11 23:07:40,951 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-08-11 23:07:46,824 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36292
scm1.org_1   | 2021-08-11 23:07:46,831 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
datanode2_1  | 2021-08-11 23:21:26,127 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:32,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:35,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:08:14,743 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
datanode1_1  | 2021-08-11 23:17:39,663 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:42,733 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:14:05,864 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-08-11 23:13:09,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm1.org_1   | 2021-08-11 23:07:46,954 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 264530c6-4c2c-4bc1-b4ab-46128a8936fc
scm1.org_1   | 2021-08-11 23:07:48,074 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:07:48,074 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2021-08-11 23:07:48,074 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2021-08-11 23:07:48,093 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 1029621.707us
scm1.org_1   | 2021-08-11 23:07:52,636 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54834
scm2.org_1   | 2021-08-11 23:08:01,537 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2021-08-11 23:08:01,538 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2021-08-11 23:08:01,538 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-08-11 23:08:01,539 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2021-08-11 23:08:01,653 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
om1_1        | 2021-08-11 23:15:35,786 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:35,863 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:35,864 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39850
om1_1        | 2021-08-11 23:15:35,866 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:38,589 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:38,590 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39880
datanode3_1  | 2021-08-11 23:13:12,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:19,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:22,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:25,259 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:28,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:31,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:38,411 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:41,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:44,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:46,865 [Thread-664] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-2D8F395979BA->95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5, cid=192, seq=0, Watch-ALL_COMMITTED(130), Message:<EMPTY>, reply=RaftClientReply:client-2D8F395979BA->95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5, cid=192, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 192 and log index 130 is not yet replicated to ALL_COMMITTED, logIndex=130, commits[95d91451-f44f-4fa4-a508-c399bd523c99:c140, fb8d185f-2f23-4800-ba90-a65832b06bb3:c140, 97333428-a9dc-49fc-bc54-326166febdda:c127]
datanode2_1  | 2021-08-11 23:21:47,631 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:08:01,653 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2021-08-11 23:08:01,683 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-08-11 23:08:01,683 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2021-08-11 23:08:01,719 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2021-08-11 23:08:01,801 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-08-11 23:08:01,801 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
om2_1        | 2021-08-11 23:14:09,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41374
om2_1        | 2021-08-11 23:14:09,578 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:14:13,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41388
om2_1        | 2021-08-11 23:14:13,014 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:14:16,489 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41408
scm3.org_1   | 2021-08-11 23:08:14,746 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2021-08-11 23:08:14,752 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2021-08-11 23:08:14,765 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2021-08-11 23:08:14,768 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6C975B8E17FD,id=eaeaf9ca-045e-4787-9b06-868925f829d3
scm3.org_1   | 2021-08-11 23:08:14,787 [Listener at 0.0.0.0/9860] INFO server.RaftServer: eaeaf9ca-045e-4787-9b06-868925f829d3: start RPC server
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm1.org_1   | 2021-08-11 23:07:52,677 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:07:57,237 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:48652
scm1.org_1   | 2021-08-11 23:07:57,266 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:07:57,269 [IPC Server handler 1 on default port 9863] INFO ha.SCMRatisServerImpl: 4742394c-da80-4695-95c5-c0a43d189463: Submitting SetConfiguration request to Ratis server with new SCM peers list: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2021-08-11 23:07:57,276 [IPC Server handler 1 on default port 9863] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: receive setConfiguration SetConfigurationRequest:client-57B57DF880E2->4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD, cid=0, seq=0, RW, null, peers:[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2021-08-11 23:07:57,279 [IPC Server handler 1 on default port 9863] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-57B57DF880E2->4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD, cid=0, seq=0, RW, null, peers:[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0]
datanode2_1  | 2021-08-11 23:21:50,699 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:53,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:56,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:21:59,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:34,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:37,551 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:08:01,801 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2021-08-11 23:08:14,910 [Listener at 0.0.0.0/9860] INFO server.GrpcService: eaeaf9ca-045e-4787-9b06-868925f829d3: GrpcService started, listening on 9894
scm3.org_1   | 2021-08-11 23:08:14,917 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$405/0x00000008404f9440@95958d9] INFO util.JvmPauseMonitor: JvmPauseMonitor-eaeaf9ca-045e-4787-9b06-868925f829d3: Started
scm3.org_1   | 2021-08-11 23:08:14,924 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-08-11 23:08:14,931 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
om1_1        | 2021-08-11 23:15:38,598 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:38,682 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:38,683 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39884
om1_1        | 2021-08-11 23:15:38,687 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:38,731 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode1_1  | 2021-08-11 23:17:45,807 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:48,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:14:16,495 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:14:24,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41442
om2_1        | 2021-08-11 23:14:24,842 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:14:30,312 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41472
datanode3_1  | 2021-08-11 23:13:40,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:43,691 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:46,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:51,951 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:55,019 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:17:58,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
datanode2_1  | 2021-08-11 23:22:02,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:06,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:09,131 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:49,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:38,732 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39888
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm1.org_1   | 2021-08-11 23:07:57,335 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2021-08-11 23:07:57,336 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-08-11 23:07:57,336 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 33554432 (custom)
datanode1_1  | 2021-08-11 23:18:01,164 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:04,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:07,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:13,455 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:16,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:14:30,316 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:14:33,672 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41492
om2_1        | 2021-08-11 23:14:33,678 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:14:37,827 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41524
om2_1        | 2021-08-11 23:14:37,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om1_1        | 2021-08-11 23:15:38,736 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:39,091 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:39,091 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39898
om1_1        | 2021-08-11 23:15:39,095 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:39,213 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode2_1  | 2021-08-11 23:22:12,205 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:15,279 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:21,420 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:24,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-08-11 23:07:58,212 [IPC Server handler 1 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2021-08-11 23:07:58,212 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2021-08-11 23:08:14,935 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2021-08-11 23:08:02,233 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 264530c6-4c2c-4bc1-b4ab-46128a8936fc
scm2.org_1   | 2021-08-11 23:08:02,235 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 2932114727528 on Scm Bootstrap Node 264530c6-4c2c-4bc1-b4ab-46128a8936fc
scm2.org_1   | 2021-08-11 23:08:02,266 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d70dab8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2021-08-11 23:08:21,142 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2021-08-11 23:08:21,146 [grpc-default-executor-0] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: change Leader from null to 4742394c-da80-4695-95c5-c0a43d189463 at term 2 for appendEntries, leader elected after 9505ms
scm3.org_1   | 2021-08-11 23:08:21,214 [grpc-default-executor-0] INFO impl.RoleInfo: eaeaf9ca-045e-4787-9b06-868925f829d3: start eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-FollowerState
om2_1        | 2021-08-11 23:14:54,357 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41752
om2_1        | 2021-08-11 23:14:54,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:07:58,212 [IPC Server handler 1 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-08-11 23:07:58,236 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$424/0x0000000840523040@19b4dd60] WARN util.JvmPauseMonitor: JvmPauseMonitor-4742394c-da80-4695-95c5-c0a43d189463: Detected pause in JVM or host machine (eg GC): pause of approximately 758572852ns.
datanode3_1  | 2021-08-11 23:13:52,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:13:55,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:39,214 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39902
om1_1        | 2021-08-11 23:15:39,217 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:39,254 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:39,254 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39906
om1_1        | 2021-08-11 23:15:39,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:18:19,596 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | GC pool 'ParNew' had collection(s): count=2 time=39ms
scm1.org_1   | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=675ms
scm1.org_1   | 2021-08-11 23:07:59,582 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: set configuration 5: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0], old=[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-08-11 23:07:59,839 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: set configuration 7: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0], old=null
datanode2_1  | 2021-08-11 23:22:27,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:30,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:33,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:36,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:08:02,311 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2021-08-11 23:08:02,311 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2021-08-11 23:08:02,316 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2021-08-11 23:08:02,390 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @13867ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2021-08-11 23:14:57,631 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:14:57,633 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38240
om2_1        | 2021-08-11 23:14:57,635 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:01,083 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41784
om2_1        | 2021-08-11 23:15:01,091 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:18:22,671 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:25,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:28,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:31,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:08:21,946 [grpc-default-executor-0] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: set configuration 0: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | 2021-08-11 23:22:39,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:42,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:08:02,670 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2021-08-11 23:08:02,699 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2021-08-11 23:08:02,700 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
om2_1        | 2021-08-11 23:15:03,284 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode3_1  | 2021-08-11 23:13:59,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:02,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:08,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:11,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:34,955 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:08:21,967 [grpc-default-executor-0] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: set configuration 1: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-08-11 23:08:21,971 [grpc-default-executor-0] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: set configuration 5: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-08-11 23:07:59,983 [IPC Server handler 1 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 264530c6-4c2c-4bc1-b4ab-46128a8936fc.
scm1.org_1   | 2021-08-11 23:08:02,083 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36536
scm1.org_1   | 2021-08-11 23:08:02,093 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:02,875 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:45174
scm1.org_1   | 2021-08-11 23:08:02,934 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:08:05,294 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55022
scm1.org_1   | 2021-08-11 23:08:05,328 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:52752
om1_1        | 2021-08-11 23:15:39,332 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:39,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39910
om1_1        | 2021-08-11 23:15:39,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:42,981 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:42,982 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39936
om1_1        | 2021-08-11 23:15:42,995 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:46,737 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:46,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39970
om1_1        | 2021-08-11 23:15:46,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:50,194 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56944
om1_1        | 2021-08-11 23:15:50,208 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:52,541 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:52,541 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40000
om1_1        | 2021-08-11 23:15:52,545 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-08-11 23:08:21,979 [grpc-default-executor-0] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: set configuration 7: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-08-11 23:08:22,072 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2021-08-11 23:08:22,249 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2021-08-11 23:08:23,062 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_0
scm3.org_1   | 2021-08-11 23:08:23,077 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_0 to /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_0-0
scm3.org_1   | 2021-08-11 23:08:23,159 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_1
scm3.org_1   | 2021-08-11 23:08:23,271 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:23,286 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2021-08-11 23:08:23,287 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2021-08-11 23:08:23,287 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2021-08-11 23:08:23,321 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2021-08-11 23:08:23,751 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-08-11 23:08:23,776 [grpc-default-executor-0] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: set configuration 11: [eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-08-11 23:08:23,787 [grpc-default-executor-0] INFO server.RaftServer$Division: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD: set configuration 13: [eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-08-11 23:08:24,082 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-6C975B8E17FD:[eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-08-11 23:08:24,193 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2021-08-11 23:08:24,462 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$405/0x00000008404f9440@95958d9] WARN util.JvmPauseMonitor: JvmPauseMonitor-eaeaf9ca-045e-4787-9b06-868925f829d3: Detected pause in JVM or host machine (eg GC): pause of approximately 436104614ns. No GCs detected.
scm3.org_1   | 2021-08-11 23:08:24,551 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2021-08-11 23:08:24,551 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2021-08-11 23:08:25,002 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:25,026 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2021-08-11 23:08:25,026 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2021-08-11 23:08:25,254 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:25,493 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2021-08-11 23:08:25,599 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2021-08-11 23:08:25,599 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2021-08-11 23:08:27,733 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2021-08-11 23:08:27,770 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-08-11 23:08:27,818 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2021-08-11 23:08:27,924 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2021-08-11 23:08:27,947 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2021-08-11 23:08:27,973 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-08-11 23:08:27,975 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2021-08-11 23:08:28,650 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm3.org_1   | 2021-08-11 23:08:28,652 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2021-08-11 23:08:28,659 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-08-11 23:08:28,660 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2021-08-11 23:08:28,691 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2021-08-11 23:08:28,938 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-08-11 23:08:28,938 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-08-11 23:08:28,948 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2021-08-11 23:08:30,003 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node eaeaf9ca-045e-4787-9b06-868925f829d3
scm3.org_1   | 2021-08-11 23:08:30,011 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 2932114727528 on Scm Bootstrap Node eaeaf9ca-045e-4787-9b06-868925f829d3
scm3.org_1   | 2021-08-11 23:08:30,128 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40f88929] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2021-08-11 23:08:30,260 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2021-08-11 23:08:30,267 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2021-08-11 23:08:30,276 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2021-08-11 23:08:30,587 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @24492ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2021-08-11 23:08:31,483 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2021-08-11 23:08:31,551 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2021-08-11 23:08:31,580 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2021-08-11 23:08:31,593 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2021-08-11 23:08:31,603 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2021-08-11 23:08:31,609 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2021-08-11 23:08:31,951 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2021-08-11 23:08:31,968 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
scm3.org_1   | 2021-08-11 23:08:32,312 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2021-08-11 23:08:32,314 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2021-08-11 23:08:32,317 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm3.org_1   | 2021-08-11 23:08:32,475 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-08-11 23:08:32,610 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@23c07745{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2021-08-11 23:08:32,614 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@69dc0dd1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2021-08-11 23:08:33,444 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-08-11 23:08:33,582 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1509dade{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-2766737186452650361/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2021-08-11 23:08:33,651 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@21440e36{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2021-08-11 23:08:33,659 [Listener at 0.0.0.0/9860] INFO server.Server: Started @27561ms
scm3.org_1   | 2021-08-11 23:08:33,682 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2021-08-11 23:08:33,682 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2021-08-11 23:08:33,700 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2021-08-11 23:08:36,786 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:41,742 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:42,918 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:08:45,641 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
datanode2_1  | 2021-08-11 23:22:46,004 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:03,285 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38270
om2_1        | 2021-08-11 23:15:03,288 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-08-11 23:08:02,707 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2021-08-11 23:18:38,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:41,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:44,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:47,247 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:50,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:53,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:18:56,459 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:02,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:05,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:08,756 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:11,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:14,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:17,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:21,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:24,107 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 2021-08-11 23:16:07,170 [qtp1275028674-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-57490, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:16:07,184 [qtp1275028674-23] INFO endpoint.BucketEndpoint: Location is /bucket-57490
s3g_1        | 2021-08-11 23:16:08,250 [qtp1275028674-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>ozonenosuchbucketqqweqwe</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
datanode3_1  | 2021-08-11 23:14:14,415 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:17,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:20,556 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:03,771 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:03,771 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38278
datanode2_1  | 2021-08-11 23:22:47,863 [Thread-700] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-FD1A7D298F57->95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5, cid=196, seq=0, Watch-ALL_COMMITTED(135), Message:<EMPTY>, reply=RaftClientReply:client-FD1A7D298F57->95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5, cid=196, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 196 and log index 135 is not yet replicated to ALL_COMMITTED, logIndex=135, commits[95d91451-f44f-4fa4-a508-c399bd523c99:c143, fb8d185f-2f23-4800-ba90-a65832b06bb3:c143, 97333428-a9dc-49fc-bc54-326166febdda:c127]
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm2.org_1   | 2021-08-11 23:08:02,707 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2021-08-11 23:08:02,709 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2021-08-11 23:08:02,852 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2021-08-11 23:08:02,853 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
scm2.org_1   | 2021-08-11 23:08:02,991 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2021-08-11 23:08:05,342 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:08:05,350 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:05,351 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: eaeaf9ca-045e-4787-9b06-868925f829d3
scm1.org_1   | 2021-08-11 23:08:05,656 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:05,677 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 279742.415us
scm1.org_1   | 2021-08-11 23:08:15,593 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55170
om2_1        | 2021-08-11 23:15:03,787 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-08-11 23:14:23,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:26,703 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:29,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:32,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:35,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:49,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:52,143 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:55,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:22:58,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:08,743 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:08,744 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38314
om2_1        | 2021-08-11 23:15:08,750 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:11,855 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:11,856 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38338
scm2.org_1   | 2021-08-11 23:08:02,992 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2021-08-11 23:08:02,994 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm2.org_1   | 2021-08-11 23:08:03,077 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2021-08-11 23:08:03,084 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d1cdebf{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2021-08-11 23:08:03,087 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68553e92{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2021-08-11 23:08:03,315 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2021-08-11 23:08:03,343 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4096a622{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-18064221134555353875/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2021-08-11 23:08:03,363 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4104b585{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2021-08-11 23:08:03,364 [Listener at 0.0.0.0/9860] INFO server.Server: Started @14841ms
scm2.org_1   | 2021-08-11 23:08:03,367 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2021-08-11 23:08:03,367 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2021-08-11 23:08:03,369 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2021-08-11 23:08:05,662 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:08:23,341 [grpc-default-executor-0] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: set configuration 11: [eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-08-11 23:08:23,372 [grpc-default-executor-0] INFO server.RaftServer$Division: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD: set configuration 13: [eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-08-11 23:08:36,809 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:08:41,732 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:08:42,913 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:08:45,620 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:08:51,664 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:15,705 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:08:16,876 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:45360
scm1.org_1   | 2021-08-11 23:08:16,997 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
datanode3_1  | 2021-08-11 23:14:38,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:42,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:45,131 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:01,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:04,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:10,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:13,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:11,867 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:08:17,003 [IPC Server handler 87 on default port 9863] INFO ha.SCMRatisServerImpl: 4742394c-da80-4695-95c5-c0a43d189463: Submitting SetConfiguration request to Ratis server with new SCM peers list: [4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0, eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|priority:0]
datanode3_1  | 2021-08-11 23:14:48,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:14:51,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om1_1        | 2021-08-11 23:15:53,044 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:53,045 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40008
om1_1        | 2021-08-11 23:15:53,046 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-08-11 23:23:16,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:12,339 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:12,340 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38346
om2_1        | 2021-08-11 23:15:12,353 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:19:27,183 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om1_1        | 2021-08-11 23:15:53,539 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm3.org_1   | 2021-08-11 23:08:51,671 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
datanode2_1  | 2021-08-11 23:23:19,788 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:12,804 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:12,805 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38354
om2_1        | 2021-08-11 23:15:12,809 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:15,827 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41904
datanode1_1  | 2021-08-11 23:19:30,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
datanode2_1  | 2021-08-11 23:23:22,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:53,540 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40014
scm1.org_1   | 2021-08-11 23:08:17,006 [IPC Server handler 87 on default port 9863] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: receive setConfiguration SetConfigurationRequest:client-57B57DF880E2->4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD, cid=1, seq=0, RW, null, peers:[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0, eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|priority:0]
datanode3_1  | 2021-08-11 23:14:57,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:00,495 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:03,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:33,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:36,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:08:52,005 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:08:52,304 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:08,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43982
scm2.org_1   | 2021-08-11 23:09:09,017 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:09:09,478 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40298
scm2.org_1   | 2021-08-11 23:09:09,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:09:11,029 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48482
scm2.org_1   | 2021-08-11 23:09:11,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode1_1  | 2021-08-11 23:19:39,467 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:42,546 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:15:53,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:54,025 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm1.org_1   | 2021-08-11 23:08:17,008 [IPC Server handler 87 on default port 9863] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-57B57DF880E2->4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD, cid=1, seq=0, RW, null, peers:[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0, eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2021-08-11 23:08:17,015 [IPC Server handler 87 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2021-08-11 23:08:17,017 [IPC Server handler 87 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-08-11 23:08:17,018 [IPC Server handler 87 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 33554432 (custom)
scm1.org_1   | 2021-08-11 23:08:18,211 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$424/0x0000000840523040@19b4dd60] WARN util.JvmPauseMonitor: JvmPauseMonitor-4742394c-da80-4695-95c5-c0a43d189463: Detected pause in JVM or host machine (eg GC): pause of approximately 373083435ns. No GCs detected.
scm1.org_1   | 2021-08-11 23:08:18,237 [IPC Server handler 87 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2021-08-11 23:08:18,251 [IPC Server handler 87 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
datanode3_1  | 2021-08-11 23:15:06,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:09,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:12,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:15,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:18,716 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=869,entriesCount=1,lastEntry=(t:1, i:9)
om2_1        | 2021-08-11 23:15:15,837 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:19:45,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-08-11 23:08:18,251 [IPC Server handler 87 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-08-11 23:15:18,727 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=870,entriesCount=1,lastEntry=(t:1, i:10)
datanode3_1  | 2021-08-11 23:15:18,745 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=873,entriesCount=1,lastEntry=(t:1, i:11)
om2_1        | 2021-08-11 23:15:18,060 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode2_1  | 2021-08-11 23:23:25,935 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:29,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:32,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:35,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:38,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:41,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:44,367 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:47,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:18,756 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=875,entriesCount=1,lastEntry=(t:1, i:12)
om2_1        | 2021-08-11 23:15:18,061 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38382
om2_1        | 2021-08-11 23:15:18,065 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:08:23,297 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: set configuration 11: [eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|priority:0, 4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0], old=[4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0]
om1_1        | 2021-08-11 23:15:54,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40020
om1_1        | 2021-08-11 23:15:54,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:15:54,058 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-18435 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
datanode3_1  | 2021-08-11 23:15:18,927 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:18,579 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm1.org_1   | 2021-08-11 23:08:23,348 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-LeaderStateImpl] INFO server.RaftServer$Division: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD: set configuration 13: [eaeaf9ca-045e-4787-9b06-868925f829d3|rpc:scm3.org:9894|priority:0, 4742394c-da80-4695-95c5-c0a43d189463|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 264530c6-4c2c-4bc1-b4ab-46128a8936fc|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2021-08-11 23:08:23,423 [IPC Server handler 87 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: eaeaf9ca-045e-4787-9b06-868925f829d3.
datanode1_1  | 2021-08-11 23:19:51,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:54,827 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:19:57,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:00,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:04,047 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:07,115 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:10,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:48,863 [Thread-736] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-DC34FFC80144->95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5, cid=200, seq=0, Watch-ALL_COMMITTED(138), Message:<EMPTY>, reply=RaftClientReply:client-DC34FFC80144->95d91451-f44f-4fa4-a508-c399bd523c99@group-6FA1826E58A5, cid=200, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 200 and log index 138 is not yet replicated to ALL_COMMITTED, logIndex=138, commits[95d91451-f44f-4fa4-a508-c399bd523c99:c147, fb8d185f-2f23-4800-ba90-a65832b06bb3:c147, 97333428-a9dc-49fc-bc54-326166febdda:c127]
datanode2_1  | 2021-08-11 23:23:50,508 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:53,605 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:23:59,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:24:02,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:24:05,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:24:08,945 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:24:12,015 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:24:15,087 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-08-11 23:24:18,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:18,580 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38390
scm1.org_1   | 2021-08-11 23:08:29,737 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:52936
scm1.org_1   | 2021-08-11 23:08:29,760 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om2_1        | 2021-08-11 23:15:18,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:18,645 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:15:54,543 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:15:54,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40028
scm1.org_1   | 2021-08-11 23:08:36,752 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:36,778 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 200433.679us
om2_1        | 2021-08-11 23:15:18,645 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38394
om2_1        | 2021-08-11 23:15:18,651 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:08:39,084 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39388
scm2.org_1   | 2021-08-11 23:09:12,809 [IPC Server handler 65 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/97333428-a9dc-49fc-bc54-326166febdda
datanode1_1  | 2021-08-11 23:20:13,259 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:21,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:25,068 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:28,141 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:31,211 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:34,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:37,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:40,428 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:46,573 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:49,648 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:52,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:55,791 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:15:58,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:01,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:05,003 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:05,564 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1143,entriesCount=1,lastEntry=(t:1, i:13)
datanode3_1  | 2021-08-11 23:16:05,568 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1144,entriesCount=1,lastEntry=(t:1, i:14)
datanode3_1  | 2021-08-11 23:16:05,580 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1145,entriesCount=1,lastEntry=(t:1, i:15)
datanode3_1  | 2021-08-11 23:16:05,587 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1146,entriesCount=1,lastEntry=(t:1, i:16)
datanode3_1  | 2021-08-11 23:16:08,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:11,151 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:14,223 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:21,391 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm1.org_1   | 2021-08-11 23:08:39,154 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-08-11 23:09:12,842 [IPC Server handler 65 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3012461862885, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | 2021-08-11 23:20:16,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:19,404 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:22,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:15:21,391 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38414
om2_1        | 2021-08-11 23:15:21,394 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:24,063 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:24,064 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38426
om2_1        | 2021-08-11 23:15:24,066 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:26,774 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:26,774 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38438
om2_1        | 2021-08-11 23:15:26,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:26,968 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:26,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38444
om2_1        | 2021-08-11 23:15:26,976 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:27,018 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:27,018 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38448
om2_1        | 2021-08-11 23:15:27,041 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:30,901 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:30,902 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38472
om2_1        | 2021-08-11 23:15:30,918 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:31,138 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:31,139 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38476
om2_1        | 2021-08-11 23:15:31,147 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:31,278 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:31,278 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38482
om2_1        | 2021-08-11 23:15:31,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:31,342 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:31,343 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38486
om2_1        | 2021-08-11 23:15:31,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:35,078 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:35,079 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38508
om2_1        | 2021-08-11 23:15:35,106 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:35,207 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm1.org_1   | 2021-08-11 23:08:39,258 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:48128
scm1.org_1   | 2021-08-11 23:08:39,419 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:08:41,004 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41426
scm1.org_1   | 2021-08-11 23:08:41,075 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57044
scm1.org_1   | 2021-08-11 23:08:41,132 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:08:41,235 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:41,249 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 5f0669529782, UUID: 97333428-a9dc-49fc-bc54-326166febdda
scm1.org_1   | 2021-08-11 23:08:41,706 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:41,747 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 123533.159us
scm1.org_1   | 2021-08-11 23:08:42,556 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41410
scm1.org_1   | 2021-08-11 23:08:42,626 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:42,638 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 9858c43d50b5, UUID: fb8d185f-2f23-4800-ba90-a65832b06bb3
scm1.org_1   | 2021-08-11 23:08:42,898 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:42,928 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 125328.507us
scm1.org_1   | 2021-08-11 23:08:45,141 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46858
scm1.org_1   | 2021-08-11 23:08:45,304 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:45,305 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 97f5bd8bbda3, UUID: 95d91451-f44f-4fa4-a508-c399bd523c99
scm1.org_1   | 2021-08-11 23:08:45,607 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:45,617 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 175346.865us
scm1.org_1   | 2021-08-11 23:08:51,009 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55528
scm1.org_1   | 2021-08-11 23:08:51,043 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:51,051 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: fca8fea2-a566-47c5-94a7-9f82479f20cb
scm1.org_1   | 2021-08-11 23:08:51,125 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55274
scm1.org_1   | 2021-08-11 23:08:51,253 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:43488
scm1.org_1   | 2021-08-11 23:08:51,299 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:51,320 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 60f93a69-291e-4949-9f44-b89eee94ddda
scm1.org_1   | 2021-08-11 23:08:51,496 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57086
scm1.org_1   | 2021-08-11 23:08:51,545 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:51,548 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:08:51,644 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:51,693 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 308268.805us
scm1.org_1   | 2021-08-11 23:08:51,763 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:39440
scm1.org_1   | 2021-08-11 23:08:51,880 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:51,896 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 12c7a2f8-4911-4780-a790-1dc8e0c98705
scm1.org_1   | 2021-08-11 23:08:51,988 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:52,023 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 142431.96us
scm1.org_1   | 2021-08-11 23:08:52,274 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:08:52,327 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 148334.128us
scm1.org_1   | 2021-08-11 23:08:52,836 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41452
scm1.org_1   | 2021-08-11 23:08:52,891 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:08:55,324 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46904
scm1.org_1   | 2021-08-11 23:08:55,334 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:09:08,923 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45288
scm1.org_1   | 2021-08-11 23:09:09,030 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:09:09,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57304
scm1.org_1   | 2021-08-11 23:09:09,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:09:11,021 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35650
scm1.org_1   | 2021-08-11 23:09:11,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:09:13,029 [IPC Server handler 27 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/97333428-a9dc-49fc-bc54-326166febdda
scm1.org_1   | 2021-08-11 23:09:13,080 [IPC Server handler 27 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3012461862885, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-08-11 23:09:13,147 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-08-11 23:09:13,177 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=79bd80c8-0720-41ff-85aa-b867116d2715 to datanode:97333428-a9dc-49fc-bc54-326166febdda
scm1.org_1   | 2021-08-11 23:09:13,251 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2021-08-11 23:09:13,251 [IPC Server handler 80 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/95d91451-f44f-4fa4-a508-c399bd523c99
scm1.org_1   | 2021-08-11 23:09:13,471 [IPC Server handler 29 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/fb8d185f-2f23-4800-ba90-a65832b06bb3
scm1.org_1   | 2021-08-11 23:09:13,387 [IPC Server handler 80 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3016481445845, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-08-11 23:09:13,515 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-08-11 23:09:13,475 [IPC Server handler 29 on default port 9861] INFO node.SCMNodeManager: Registered Data node : fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3013808804155, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-08-11 23:09:13,591 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-08-11 23:09:13,593 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2021-08-11 23:09:13,669 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2021-08-11 23:09:13,670 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2021-08-11 23:09:12,936 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-08-11 23:09:12,951 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2021-08-11 23:09:13,199 [IPC Server handler 58 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/95d91451-f44f-4fa4-a508-c399bd523c99
scm2.org_1   | 2021-08-11 23:09:13,215 [IPC Server handler 58 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3016481445845, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-08-11 23:09:13,216 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-08-11 23:09:13,223 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2021-08-11 23:09:13,445 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/fb8d185f-2f23-4800-ba90-a65832b06bb3
scm2.org_1   | 2021-08-11 23:09:13,446 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3013808804155, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-08-11 23:09:13,446 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-08-11 23:09:13,448 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2021-08-11 23:09:13,448 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2021-08-11 23:09:13,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2021-08-11 23:09:13,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
datanode1_1  | 2021-08-11 23:20:25,547 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:28,623 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:31,695 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:09:13,465 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2021-08-11 23:09:13,466 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
om1_1        | 2021-08-11 23:15:54,553 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1        | 2021-08-11 23:15:58,092 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57010
om1_1        | 2021-08-11 23:15:58,106 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:00,327 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:00,328 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40058
om1_1        | 2021-08-11 23:16:00,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:00,820 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:00,821 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40066
om1_1        | 2021-08-11 23:16:00,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode1_1  | 2021-08-11 23:20:34,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:40,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:43,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:47,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:50,129 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:53,195 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:56,271 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:20:59,339 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:02,411 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:05,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:08,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:11,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:14,699 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:17,775 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:20,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:23,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:30,064 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:33,134 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:36,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:39,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:16:01,309 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:01,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40072
om1_1        | 2021-08-11 23:16:01,312 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:01,792 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:01,793 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40080
om1_1        | 2021-08-11 23:16:01,798 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:01,833 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 2021-08-11 23:16:17,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:20,364 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:23,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:26,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:29,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:31,652 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1404,entriesCount=1,lastEntry=(t:1, i:17)
datanode3_1  | 2021-08-11 23:16:31,669 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1405,entriesCount=1,lastEntry=(t:1, i:18)
datanode3_1  | 2021-08-11 23:16:31,776 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1406,entriesCount=1,lastEntry=(t:1, i:19)
datanode3_1  | 2021-08-11 23:16:31,776 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1407,entriesCount=1,lastEntry=(t:1, i:20)
datanode3_1  | 2021-08-11 23:16:31,950 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1418,entriesCount=1,lastEntry=(t:1, i:21)
datanode3_1  | 2021-08-11 23:16:32,114 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1431,entriesCount=1,lastEntry=(t:1, i:22)
datanode3_1  | 2021-08-11 23:16:32,116 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1433,entriesCount=1,lastEntry=(t:1, i:23)
datanode3_1  | 2021-08-11 23:16:32,128 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1435,entriesCount=1,lastEntry=(t:1, i:24)
scm2.org_1   | 2021-08-11 23:09:13,966 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 79bd80c8-0720-41ff-85aa-b867116d2715, Nodes: 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:13.170Z[UTC]].
scm2.org_1   | 2021-08-11 23:09:13,975 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:14,128 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]].
scm2.org_1   | 2021-08-11 23:09:14,128 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:14,303 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c604f00f-ba94-42dc-a421-13e7f8d4be22, Nodes: 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.169Z[UTC]].
scm2.org_1   | 2021-08-11 23:09:14,308 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:14,344 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolling segment log-1_34 to index:34
scm2.org_1   | 2021-08-11 23:09:14,350 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_1 to /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_1-34
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm3.org_1   | 2021-08-11 23:08:52,012 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
datanode1_1  | 2021-08-11 23:21:42,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:45,423 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:48,491 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:51,563 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:09:14,355 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_35
scm2.org_1   | 2021-08-11 23:09:14,408 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7b6570e5-884e-4bb2-8002-8fbff034b0cd, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.294Z[UTC]].
datanode3_1  | 2021-08-11 23:16:32,391 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1459,entriesCount=1,lastEntry=(t:1, i:25)
datanode3_1  | 2021-08-11 23:16:32,433 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1466,entriesCount=1,lastEntry=(t:1, i:26)
datanode3_1  | 2021-08-11 23:16:35,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:38,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:41,867 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:43,739 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1720,entriesCount=1,lastEntry=(t:1, i:27)
datanode3_1  | 2021-08-11 23:16:43,853 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1721,entriesCount=1,lastEntry=(t:1, i:28)
om2_1        | 2021-08-11 23:15:35,208 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38512
om2_1        | 2021-08-11 23:15:35,216 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:35,338 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:35,339 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38516
om2_1        | 2021-08-11 23:15:35,346 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:35,747 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:35,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38520
om2_1        | 2021-08-11 23:15:35,749 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:35,793 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:35,794 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38524
om2_1        | 2021-08-11 23:15:35,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:35,870 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:35,870 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38528
om2_1        | 2021-08-11 23:15:35,871 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:38,613 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:38,613 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38558
om2_1        | 2021-08-11 23:15:38,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:38,692 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:38,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38562
om2_1        | 2021-08-11 23:15:38,695 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:38,742 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:38,743 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38566
om2_1        | 2021-08-11 23:15:38,744 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:39,101 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:39,102 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38576
om2_1        | 2021-08-11 23:15:39,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:39,221 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:39,221 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38580
om2_1        | 2021-08-11 23:15:39,223 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:39,264 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:39,264 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38584
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm3.org_1   | 2021-08-11 23:08:52,313 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:09,028 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45202
scm3.org_1   | 2021-08-11 23:09:09,059 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:09:09,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55570
scm3.org_1   | 2021-08-11 23:09:09,511 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:09:09,855 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$405/0x00000008404f9440@95958d9] WARN util.JvmPauseMonitor: JvmPauseMonitor-eaeaf9ca-045e-4787-9b06-868925f829d3: Detected pause in JVM or host machine (eg GC): pause of approximately 167837232ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=172ms
scm3.org_1   | 2021-08-11 23:09:11,015 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48930
scm3.org_1   | 2021-08-11 23:09:11,091 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:09:12,807 [IPC Server handler 33 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/97333428-a9dc-49fc-bc54-326166febdda
scm3.org_1   | 2021-08-11 23:09:12,856 [IPC Server handler 33 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3012461862885, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-08-11 23:09:12,993 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-08-11 23:09:13,007 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2021-08-11 23:09:13,199 [IPC Server handler 80 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/95d91451-f44f-4fa4-a508-c399bd523c99
scm3.org_1   | 2021-08-11 23:09:13,211 [IPC Server handler 80 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3016481445845, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-08-11 23:09:13,216 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-08-11 23:09:13,238 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2021-08-11 23:09:13,447 [IPC Server handler 26 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/fb8d185f-2f23-4800-ba90-a65832b06bb3
scm3.org_1   | 2021-08-11 23:09:13,448 [IPC Server handler 26 on default port 9861] INFO node.SCMNodeManager: Registered Data node : fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3013808804155, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-08-11 23:09:13,448 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-08-11 23:09:13,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2021-08-11 23:09:13,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2021-08-11 23:09:13,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2021-08-11 23:09:13,450 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-08-11 23:09:13,450 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2021-08-11 23:09:13,451 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-08-11 23:09:14,298 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 79bd80c8-0720-41ff-85aa-b867116d2715, Nodes: 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:13.170Z[UTC]].
scm3.org_1   | 2021-08-11 23:09:14,345 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:14,349 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]].
scm3.org_1   | 2021-08-11 23:09:14,374 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:14,370 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolling segment log-1_34 to index:34
scm3.org_1   | 2021-08-11 23:09:14,408 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_1 to /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_1-34
scm3.org_1   | 2021-08-11 23:09:14,424 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c604f00f-ba94-42dc-a421-13e7f8d4be22, Nodes: 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.169Z[UTC]].
scm3.org_1   | 2021-08-11 23:09:14,425 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:14,428 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_35
scm3.org_1   | 2021-08-11 23:09:14,453 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7b6570e5-884e-4bb2-8002-8fbff034b0cd, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.294Z[UTC]].
scm3.org_1   | 2021-08-11 23:09:14,505 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:14,538 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7d30a22a-435f-40ae-b84a-ed00911f12b5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.431Z[UTC]].
scm3.org_1   | 2021-08-11 23:09:14,546 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:16:04,986 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57062
om1_1        | 2021-08-11 23:16:05,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-08-11 23:09:14,408 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:14,492 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7d30a22a-435f-40ae-b84a-ed00911f12b5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.431Z[UTC]].
scm2.org_1   | 2021-08-11 23:09:14,493 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:21,944 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c604f00f-ba94-42dc-a421-13e7f8d4be22, Nodes: 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:14.169Z[UTC]] moved to OPEN state
scm2.org_1   | 2021-08-11 23:09:22,110 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@359997df, cost 159335.264us
scm2.org_1   | 2021-08-11 23:09:22,120 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
datanode1_1  | 2021-08-11 23:21:54,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:21:57,711 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:00,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:03,855 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:16:07,153 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:07,154 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40110
om1_1        | 2021-08-11 23:16:07,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:07,770 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:07,771 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40136
om1_1        | 2021-08-11 23:16:07,772 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:08,228 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:08,229 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40144
om1_1        | 2021-08-11 23:16:08,231 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
datanode3_1  | 2021-08-11 23:16:43,947 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1722,entriesCount=1,lastEntry=(t:1, i:29)
datanode3_1  | 2021-08-11 23:16:43,987 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1723,entriesCount=1,lastEntry=(t:1, i:30)
datanode3_1  | 2021-08-11 23:16:44,025 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1724,entriesCount=1,lastEntry=(t:1, i:31)
datanode1_1  | 2021-08-11 23:22:06,927 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:09:22,187 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-08-11 23:09:23,819 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:23,976 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-08-11 23:09:36,587 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:44,651 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44178
scm2.org_1   | 2021-08-11 23:09:44,680 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:09:44,965 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48670
scm2.org_1   | 2021-08-11 23:09:44,978 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:09:44,979 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-08-11 23:09:45,338 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40502
scm2.org_1   | 2021-08-11 23:09:45,341 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:09:45,345 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-08-11 23:09:45,826 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 79bd80c8-0720-41ff-85aa-b867116d2715, Nodes: 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:97333428-a9dc-49fc-bc54-326166febdda, CreationTimestamp2021-08-11T23:09:13.170Z[UTC]] moved to OPEN state
scm2.org_1   | 2021-08-11 23:09:45,827 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@359997df, cost 779.922us
scm2.org_1   | 2021-08-11 23:09:45,880 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-08-11 23:09:46,339 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
datanode1_1  | 2021-08-11 23:22:09,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:13,067 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:44,112 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1731,entriesCount=1,lastEntry=(t:1, i:32)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
datanode1_1  | 2021-08-11 23:22:19,215 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:22,287 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:25,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:44,141 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1733,entriesCount=1,lastEntry=(t:1, i:33)
datanode3_1  | 2021-08-11 23:16:44,157 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1734,entriesCount=1,lastEntry=(t:1, i:34)
datanode3_1  | 2021-08-11 23:16:44,943 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:48,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:51,084 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:54,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:16:57,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:00,303 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:03,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:06,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:09,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:12,587 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:15,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:18,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:21,708 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2000,entriesCount=1,lastEntry=(t:1, i:35)
datanode3_1  | 2021-08-11 23:17:21,738 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2001,entriesCount=1,lastEntry=(t:1, i:36)
om1_1        | 2021-08-11 23:16:11,303 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57128
om1_1        | 2021-08-11 23:16:11,328 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:13,786 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode1_1  | 2021-08-11 23:22:28,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:31,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:16:13,787 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40176
om1_1        | 2021-08-11 23:16:13,797 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:14,289 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:14,289 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40184
om1_1        | 2021-08-11 23:16:14,295 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:17,540 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57166
om1_1        | 2021-08-11 23:16:17,555 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:19,861 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode1_1  | 2021-08-11 23:22:34,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:37,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:40,715 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:43,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:46,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:49,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm2.org_1   | 2021-08-11 23:09:46,358 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2021-08-11 23:09:46,358 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2021-08-11 23:09:46,358 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode1_1  | 2021-08-11 23:22:53,007 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:56,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:22:59,148 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:02,220 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:08,363 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:11,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:14,511 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:17,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:20,652 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:23,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:26,799 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:29,873 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:32,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:36,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:39,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:42,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:45,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:48,301 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:51,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:23:57,519 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:24:00,589 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:24:03,660 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:24:06,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:24:09,807 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:24:12,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:24:15,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-08-11 23:24:19,032 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:16:19,861 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40214
om1_1        | 2021-08-11 23:16:19,862 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:20,348 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:20,348 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40220
om1_1        | 2021-08-11 23:16:20,356 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:20,913 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:20,914 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40228
om1_1        | 2021-08-11 23:16:20,918 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:21,505 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:21,506 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40234
om1_1        | 2021-08-11 23:16:21,512 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:24,924 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:24,925 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40258
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:08,251 [qtp1275028674-24] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:131)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:68)
datanode3_1  | 2021-08-11 23:17:21,764 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2002,entriesCount=1,lastEntry=(t:1, i:37)
datanode3_1  | 2021-08-11 23:17:21,836 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2003,entriesCount=1,lastEntry=(t:1, i:38)
datanode3_1  | 2021-08-11 23:17:21,870 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2006,entriesCount=1,lastEntry=(t:1, i:39)
datanode3_1  | 2021-08-11 23:17:21,876 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2007,entriesCount=1,lastEntry=(t:1, i:40)
datanode3_1  | 2021-08-11 23:17:24,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:27,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:09:46,358 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2021-08-11 23:09:46,358 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-08-11 23:09:46,358 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2021-08-11 23:09:59,076 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40582
scm2.org_1   | 2021-08-11 23:09:59,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:10:00,477 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48762
scm2.org_1   | 2021-08-11 23:10:00,564 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:10:12,780 [264530c6-4c2c-4bc1-b4ab-46128a8936fc@group-6C975B8E17FD-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm2.org_1   | 2021-08-11 23:10:14,671 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44344
scm2.org_1   | 2021-08-11 23:10:14,682 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:10:16,716 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48846
scm2.org_1   | 2021-08-11 23:10:16,808 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-08-11 23:15:39,265 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:39,341 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:39,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38588
om2_1        | 2021-08-11 23:15:39,346 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:43,002 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:43,003 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38614
om2_1        | 2021-08-11 23:15:43,011 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:09:13,670 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2021-08-11 23:09:13,670 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-08-11 23:09:13,670 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2021-08-11 23:09:13,670 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:295)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
datanode3_1  | 2021-08-11 23:17:31,026 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:32,461 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2261,entriesCount=1,lastEntry=(t:1, i:41)
datanode3_1  | 2021-08-11 23:17:32,461 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2262,entriesCount=1,lastEntry=(t:1, i:42)
datanode3_1  | 2021-08-11 23:17:32,474 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2263,entriesCount=1,lastEntry=(t:1, i:43)
scm1.org_1   | 2021-08-11 23:09:13,806 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 79bd80c8-0720-41ff-85aa-b867116d2715, Nodes: 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:13.170Z[UTC]].
scm1.org_1   | 2021-08-11 23:09:13,851 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:13,851 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 153390.848us
scm1.org_1   | 2021-08-11 23:09:13,939 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5 to datanode:fb8d185f-2f23-4800-ba90-a65832b06bb3
scm1.org_1   | 2021-08-11 23:09:13,943 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5 to datanode:95d91451-f44f-4fa4-a508-c399bd523c99
scm1.org_1   | 2021-08-11 23:09:13,943 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5 to datanode:97333428-a9dc-49fc-bc54-326166febdda
scm1.org_1   | 2021-08-11 23:09:14,081 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]].
scm1.org_1   | 2021-08-11 23:09:14,098 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:14,106 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 161262.567us
scm1.org_1   | 2021-08-11 23:09:14,169 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c604f00f-ba94-42dc-a421-13e7f8d4be22 to datanode:95d91451-f44f-4fa4-a508-c399bd523c99
scm1.org_1   | 2021-08-11 23:09:14,252 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c604f00f-ba94-42dc-a421-13e7f8d4be22, Nodes: 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.169Z[UTC]].
scm1.org_1   | 2021-08-11 23:09:14,264 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:14,275 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 104183.549us
scm1.org_1   | 2021-08-11 23:09:14,294 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd to datanode:fb8d185f-2f23-4800-ba90-a65832b06bb3
scm1.org_1   | 2021-08-11 23:09:14,294 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd to datanode:95d91451-f44f-4fa4-a508-c399bd523c99
scm1.org_1   | 2021-08-11 23:09:14,295 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd to datanode:97333428-a9dc-49fc-bc54-326166febdda
scm1.org_1   | 2021-08-11 23:09:14,308 [RatisPipelineUtilsThread - 0] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolling segment log-1_34 to index:34
scm1.org_1   | 2021-08-11 23:09:14,323 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_1 to /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_1-34
om2_1        | 2021-08-11 23:15:46,746 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm3.org_1   | 2021-08-11 23:09:21,939 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c604f00f-ba94-42dc-a421-13e7f8d4be22, Nodes: 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:14.169Z[UTC]] moved to OPEN state
scm3.org_1   | 2021-08-11 23:09:22,076 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:22,283 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@7b17af63, cost 341561.566us
datanode3_1  | 2021-08-11 23:17:32,480 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2265,entriesCount=1,lastEntry=(t:1, i:44)
om1_1        | 2021-08-11 23:16:24,932 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:28,274 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:28,275 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40282
om1_1        | 2021-08-11 23:16:28,276 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:28,871 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:28,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40288
om1_1        | 2021-08-11 23:16:28,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:32,363 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:32,364 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40306
om1_1        | 2021-08-11 23:16:32,365 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:35,521 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:35,522 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40326
om1_1        | 2021-08-11 23:16:35,529 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:36,051 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:36,051 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40334
om1_1        | 2021-08-11 23:16:36,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:37,082 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:37,082 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40346
om1_1        | 2021-08-11 23:16:37,084 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:37,652 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:37,652 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40372
om1_1        | 2021-08-11 23:16:37,678 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:40,992 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:40,992 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40394
om1_1        | 2021-08-11 23:16:40,999 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:44,164 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:44,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40408
om1_1        | 2021-08-11 23:16:44,172 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:44,216 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-39850/39682/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2021-08-11 23:16:44,216 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 39682/multipartKey2 in Volume/Bucket s3v/bucket-39850
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 39682/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:463)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:16:44,688 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:44,689 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40416
om1_1        | 2021-08-11 23:16:44,691 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:45,222 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:45,223 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40424
om1_1        | 2021-08-11 23:16:45,226 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:45,258 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-39850/93532/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2021-08-11 23:16:45,260 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:16:45,703 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:45,704 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40430
om1_1        | 2021-08-11 23:16:45,706 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:45,730 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-39850/93532/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2021-08-11 23:16:45,730 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3
om2_1        | 2021-08-11 23:15:46,747 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38648
om2_1        | 2021-08-11 23:15:46,748 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:50,242 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42192
om2_1        | 2021-08-11 23:15:50,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:52,549 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:52,551 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38678
om2_1        | 2021-08-11 23:15:52,552 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:53,053 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:53,057 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38686
om2_1        | 2021-08-11 23:15:53,060 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:53,548 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:53,548 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38692
om2_1        | 2021-08-11 23:15:53,549 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:54,033 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:54,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38698
scm2.org_1   | 2021-08-11 23:10:17,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40680
scm2.org_1   | 2021-08-11 23:10:17,253 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:10:37,687 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40778
scm2.org_1   | 2021-08-11 23:10:37,703 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48964
scm2.org_1   | 2021-08-11 23:10:37,775 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44482
scm2.org_1   | 2021-08-11 23:10:37,788 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:10:37,809 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:10:37,835 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:11:07,760 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40942
scm2.org_1   | 2021-08-11 23:11:07,786 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49122
scm2.org_1   | 2021-08-11 23:11:07,851 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:11:07,876 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:09:22,313 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-08-11 23:09:23,805 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:23,949 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode3_1  | 2021-08-11 23:17:34,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:37,163 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:37,942 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2516,entriesCount=1,lastEntry=(t:1, i:45)
datanode3_1  | 2021-08-11 23:17:37,947 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2517,entriesCount=1,lastEntry=(t:1, i:46)
scm3.org_1   | 2021-08-11 23:09:36,582 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:44,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45398
datanode3_1  | 2021-08-11 23:17:37,947 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2518,entriesCount=1,lastEntry=(t:1, i:47)
datanode3_1  | 2021-08-11 23:17:40,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:41,115 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2768,entriesCount=1,lastEntry=(t:1, i:48)
datanode3_1  | 2021-08-11 23:17:41,120 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2769,entriesCount=1,lastEntry=(t:1, i:49)
datanode3_1  | 2021-08-11 23:17:41,130 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2770,entriesCount=1,lastEntry=(t:1, i:50)
datanode3_1  | 2021-08-11 23:17:41,137 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2771,entriesCount=1,lastEntry=(t:1, i:51)
datanode3_1  | 2021-08-11 23:17:43,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:09:44,619 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:09:44,928 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49118
scm3.org_1   | 2021-08-11 23:09:44,936 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:09:44,938 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-08-11 23:09:45,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55766
scm3.org_1   | 2021-08-11 23:09:45,292 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:09:45,324 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-08-11 23:09:45,826 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 79bd80c8-0720-41ff-85aa-b867116d2715, Nodes: 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:97333428-a9dc-49fc-bc54-326166febdda, CreationTimestamp2021-08-11T23:09:13.170Z[UTC]] moved to OPEN state
scm3.org_1   | 2021-08-11 23:09:45,827 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@7b17af63, cost 1186.732us
scm3.org_1   | 2021-08-11 23:09:45,914 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:46,312 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]] moved to OPEN state
scm3.org_1   | 2021-08-11 23:09:46,313 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@7b17af63, cost 793.021us
scm3.org_1   | 2021-08-11 23:09:46,317 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-08-11 23:09:46,346 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:47,098 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
scm3.org_1   | 2021-08-11 23:09:47,148 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2021-08-11 23:09:47,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2021-08-11 23:09:47,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2021-08-11 23:09:47,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2021-08-11 23:09:47,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-08-11 23:09:47,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2021-08-11 23:09:59,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55844
om2_1        | 2021-08-11 23:15:54,035 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:54,047 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-18435 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:193)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:15:54,558 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:15:54,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38706
om2_1        | 2021-08-11 23:15:54,565 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:15:58,140 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42258
om2_1        | 2021-08-11 23:15:58,141 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:00,339 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:00,340 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38736
om2_1        | 2021-08-11 23:16:00,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:00,839 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:00,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38744
om2_1        | 2021-08-11 23:16:00,842 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:01,316 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:01,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38750
om2_1        | 2021-08-11 23:16:01,320 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:01,808 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:01,809 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38758
om2_1        | 2021-08-11 23:16:01,810 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:01,827 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm1.org_1   | 2021-08-11 23:09:14,338 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f360cfa0-cc7c-4d2d-b512-6c975b8e17fd/current/log_inprogress_35
scm1.org_1   | 2021-08-11 23:09:14,388 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7b6570e5-884e-4bb2-8002-8fbff034b0cd, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.294Z[UTC]].
scm2.org_1   | 2021-08-11 23:11:07,957 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44640
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
datanode3_1  | 2021-08-11 23:17:46,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:49,452 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:52,523 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:52,990 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3024,entriesCount=1,lastEntry=(t:1, i:52)
datanode3_1  | 2021-08-11 23:17:52,997 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3025,entriesCount=1,lastEntry=(t:1, i:53)
datanode3_1  | 2021-08-11 23:17:52,999 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3026,entriesCount=1,lastEntry=(t:1, i:54)
datanode3_1  | 2021-08-11 23:17:53,014 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3027,entriesCount=1,lastEntry=(t:1, i:55)
datanode3_1  | 2021-08-11 23:17:55,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:17:58,671 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:01,739 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:04,811 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm2.org_1   | 2021-08-11 23:11:07,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:11:37,615 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41106
scm2.org_1   | 2021-08-11 23:11:37,628 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49294
scm2.org_1   | 2021-08-11 23:11:37,666 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:11:37,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:11:37,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44802
scm2.org_1   | 2021-08-11 23:11:37,874 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:12:07,609 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41280
scm2.org_1   | 2021-08-11 23:12:07,652 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49460
scm2.org_1   | 2021-08-11 23:12:07,662 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:12:07,674 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:12:07,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44980
scm2.org_1   | 2021-08-11 23:12:07,738 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:12:37,726 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41442
scm2.org_1   | 2021-08-11 23:12:37,729 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:12:37,749 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49626
scm2.org_1   | 2021-08-11 23:12:37,752 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45136
scm2.org_1   | 2021-08-11 23:12:37,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:12:37,764 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:12:55,059 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2021-08-11 23:13:07,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41616
scm2.org_1   | 2021-08-11 23:13:07,611 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:13:07,665 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49802
scm2.org_1   | 2021-08-11 23:13:07,667 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45308
scm2.org_1   | 2021-08-11 23:13:07,699 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:13:07,712 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:13:37,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41790
scm2.org_1   | 2021-08-11 23:13:37,607 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:13:37,651 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49978
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm1.org_1   | 2021-08-11 23:09:14,394 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:14,404 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 105542.987us
scm1.org_1   | 2021-08-11 23:09:14,427 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=7b6570e5-884e-4bb2-8002-8fbff034b0cd contains same datanodes as previous pipelines: PipelineID=e8fee977-3a11-4948-b60e-6fa1826e58a5 nodeIds: fb8d185f-2f23-4800-ba90-a65832b06bb3, 95d91451-f44f-4fa4-a508-c399bd523c99, 97333428-a9dc-49fc-bc54-326166febdda
scm1.org_1   | 2021-08-11 23:09:14,432 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7d30a22a-435f-40ae-b84a-ed00911f12b5 to datanode:fb8d185f-2f23-4800-ba90-a65832b06bb3
scm1.org_1   | 2021-08-11 23:09:14,467 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7d30a22a-435f-40ae-b84a-ed00911f12b5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-08-11T23:09:14.431Z[UTC]].
scm1.org_1   | 2021-08-11 23:09:14,481 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:14,483 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 47824.753us
scm1.org_1   | 2021-08-11 23:09:17,180 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39518
scm1.org_1   | 2021-08-11 23:09:17,295 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
datanode3_1  | 2021-08-11 23:18:05,118 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3281,entriesCount=1,lastEntry=(t:1, i:56)
datanode3_1  | 2021-08-11 23:18:05,119 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3282,entriesCount=1,lastEntry=(t:1, i:57)
datanode3_1  | 2021-08-11 23:18:05,122 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3283,entriesCount=1,lastEntry=(t:1, i:58)
datanode3_1  | 2021-08-11 23:18:07,883 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:11,501 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3536,entriesCount=1,lastEntry=(t:1, i:59)
datanode3_1  | 2021-08-11 23:18:11,764 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3537,entriesCount=1,lastEntry=(t:1, i:60)
datanode3_1  | 2021-08-11 23:18:11,880 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3538,entriesCount=1,lastEntry=(t:1, i:61)
datanode3_1  | 2021-08-11 23:18:12,353 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3539,entriesCount=1,lastEntry=(t:1, i:62)
datanode3_1  | 2021-08-11 23:18:12,359 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3540,entriesCount=1,lastEntry=(t:1, i:63)
datanode3_1  | 2021-08-11 23:18:12,383 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3541,entriesCount=1,lastEntry=(t:1, i:64)
datanode3_1  | 2021-08-11 23:18:14,027 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:17,099 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:20,171 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:22,114 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3794,entriesCount=1,lastEntry=(t:1, i:65)
datanode3_1  | 2021-08-11 23:18:22,166 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3795,entriesCount=1,lastEntry=(t:1, i:66)
datanode3_1  | 2021-08-11 23:18:22,188 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3796,entriesCount=1,lastEntry=(t:1, i:67)
datanode3_1  | 2021-08-11 23:18:22,230 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3797,entriesCount=1,lastEntry=(t:1, i:68)
datanode3_1  | 2021-08-11 23:18:22,263 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3800,entriesCount=1,lastEntry=(t:1, i:69)
datanode3_1  | 2021-08-11 23:18:23,243 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:26,315 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:29,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:31,071 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4053,entriesCount=1,lastEntry=(t:1, i:70)
datanode3_1  | 2021-08-11 23:18:31,196 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4054,entriesCount=1,lastEntry=(t:1, i:71)
datanode3_1  | 2021-08-11 23:18:31,203 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4055,entriesCount=1,lastEntry=(t:1, i:72)
datanode3_1  | 2021-08-11 23:18:31,269 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4059,entriesCount=1,lastEntry=(t:1, i:73)
datanode3_1  | 2021-08-11 23:18:31,274 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4060,entriesCount=1,lastEntry=(t:1, i:74)
datanode3_1  | 2021-08-11 23:18:31,312 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4063,entriesCount=1,lastEntry=(t:1, i:75)
datanode3_1  | 2021-08-11 23:18:31,334 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4066,entriesCount=1,lastEntry=(t:1, i:76)
datanode3_1  | 2021-08-11 23:18:31,353 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4070,entriesCount=1,lastEntry=(t:1, i:77)
datanode3_1  | 2021-08-11 23:18:32,463 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:34,592 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4321,entriesCount=1,lastEntry=(t:1, i:78)
datanode3_1  | 2021-08-11 23:18:34,593 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4322,entriesCount=1,lastEntry=(t:1, i:79)
datanode3_1  | 2021-08-11 23:18:34,597 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4323,entriesCount=1,lastEntry=(t:1, i:80)
datanode3_1  | 2021-08-11 23:18:34,598 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4324,entriesCount=1,lastEntry=(t:1, i:81)
datanode3_1  | 2021-08-11 23:18:35,531 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:38,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:41,675 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:44,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:47,819 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:48,039 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4579,entriesCount=1,lastEntry=(t:1, i:82)
datanode3_1  | 2021-08-11 23:18:48,039 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4580,entriesCount=1,lastEntry=(t:1, i:83)
datanode3_1  | 2021-08-11 23:18:48,051 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4581,entriesCount=1,lastEntry=(t:1, i:84)
datanode3_1  | 2021-08-11 23:18:48,051 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4582,entriesCount=1,lastEntry=(t:1, i:85)
datanode3_1  | 2021-08-11 23:18:50,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:53,963 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:18:57,035 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:03,183 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:06,251 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:09,323 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:12,395 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:15,471 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:18,543 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:21,611 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:23,014 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4845,entriesCount=1,lastEntry=(t:1, i:86)
datanode3_1  | 2021-08-11 23:19:23,021 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4846,entriesCount=1,lastEntry=(t:1, i:87)
datanode3_1  | 2021-08-11 23:19:23,026 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4847,entriesCount=1,lastEntry=(t:1, i:88)
scm1.org_1   | 2021-08-11 23:09:17,847 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:48258
scm1.org_1   | 2021-08-11 23:09:17,884 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41554
scm1.org_1   | 2021-08-11 23:09:17,972 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:09:17,974 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:09:21,922 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c604f00f-ba94-42dc-a421-13e7f8d4be22, Nodes: 95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:14.169Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-08-11 23:09:22,041 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:22,078 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 151726.951us
scm1.org_1   | 2021-08-11 23:09:22,198 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:13,820 [qtp1275028674-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-54059, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:16:13,833 [qtp1275028674-23] INFO endpoint.BucketEndpoint: Location is /bucket-54059
scm3.org_1   | 2021-08-11 23:09:59,112 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:10:00,496 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49210
scm3.org_1   | 2021-08-11 23:10:00,551 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:10:12,756 [eaeaf9ca-045e-4787-9b06-868925f829d3@group-6C975B8E17FD-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm3.org_1   | 2021-08-11 23:10:14,633 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45564
scm3.org_1   | 2021-08-11 23:10:14,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:09:22,221 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-08-11 23:09:23,735 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7d30a22a-435f-40ae-b84a-ed00911f12b5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:fb8d185f-2f23-4800-ba90-a65832b06bb3, CreationTimestamp2021-08-11T23:09:14.431Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-08-11 23:09:23,770 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:23,776 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 41076.348us
scm1.org_1   | 2021-08-11 23:09:23,785 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-08-11 23:09:24,935 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55408
scm1.org_1   | 2021-08-11 23:09:25,126 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-08-11 23:10:16,719 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49294
scm3.org_1   | 2021-08-11 23:10:16,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:10:17,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55944
scm3.org_1   | 2021-08-11 23:10:17,241 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:10:37,626 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45696
scm3.org_1   | 2021-08-11 23:10:37,659 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:10:37,735 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56048
scm3.org_1   | 2021-08-11 23:10:37,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49412
scm3.org_1   | 2021-08-11 23:10:37,808 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:10:37,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:11:07,869 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56206
scm3.org_1   | 2021-08-11 23:11:07,884 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49574
scm3.org_1   | 2021-08-11 23:11:07,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45864
scm3.org_1   | 2021-08-11 23:11:07,922 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:11:07,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:11:08,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:11:37,629 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56370
scm3.org_1   | 2021-08-11 23:11:37,675 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:11:37,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46022
scm3.org_1   | 2021-08-11 23:11:37,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49742
scm3.org_1   | 2021-08-11 23:11:37,709 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:11:37,852 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:09:26,773 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:39590
scm1.org_1   | 2021-08-11 23:09:26,780 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:09:26,926 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:43644
scm1.org_1   | 2021-08-11 23:09:26,938 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:09:27,567 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55690
scm1.org_1   | 2021-08-11 23:09:27,579 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:09:36,569 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:36,574 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 36292.097us
scm1.org_1   | 2021-08-11 23:09:38,062 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55480
scm1.org_1   | 2021-08-11 23:09:38,083 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:09:44,642 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45484
scm1.org_1   | 2021-08-11 23:09:44,667 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55518
scm1.org_1   | 2021-08-11 23:09:44,672 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:13:37,666 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:13:37,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45486
scm2.org_1   | 2021-08-11 23:13:37,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:14:07,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41968
scm2.org_1   | 2021-08-11 23:14:07,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:14:07,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45668
scm2.org_1   | 2021-08-11 23:14:07,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:14:07,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50146
om2_1        | 2021-08-11 23:16:05,053 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42312
om2_1        | 2021-08-11 23:16:05,058 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:07,160 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:07,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38788
scm2.org_1   | 2021-08-11 23:14:07,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:14:37,712 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42130
scm2.org_1   | 2021-08-11 23:14:37,728 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45828
scm2.org_1   | 2021-08-11 23:14:37,731 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50320
scm2.org_1   | 2021-08-11 23:14:37,736 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:14:37,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:14:37,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:15:07,660 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46142
scm2.org_1   | 2021-08-11 23:15:07,666 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42450
scm2.org_1   | 2021-08-11 23:15:07,690 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:15:07,701 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50636
scm2.org_1   | 2021-08-11 23:15:07,709 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:15:07,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:15:37,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42696
scm2.org_1   | 2021-08-11 23:15:37,741 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46390
scm2.org_1   | 2021-08-11 23:15:37,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:15:37,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50884
scm2.org_1   | 2021-08-11 23:15:37,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:15:37,807 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:16:07,652 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51138
scm2.org_1   | 2021-08-11 23:16:07,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42952
scm2.org_1   | 2021-08-11 23:16:07,685 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:16:07,716 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46644
scm2.org_1   | 2021-08-11 23:16:07,716 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:16:07,758 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:16:37,716 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51374
scm2.org_1   | 2021-08-11 23:16:37,729 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43186
scm2.org_1   | 2021-08-11 23:16:37,737 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46880
scm2.org_1   | 2021-08-11 23:16:37,756 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:16:37,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:16:37,841 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:17:07,641 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43458
scm2.org_1   | 2021-08-11 23:17:07,652 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:17:07,670 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51644
scm2.org_1   | 2021-08-11 23:17:07,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47152
scm2.org_1   | 2021-08-11 23:17:07,709 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:17:07,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:17:37,719 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47440
scm2.org_1   | 2021-08-11 23:17:37,726 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43746
scm2.org_1   | 2021-08-11 23:17:37,751 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51934
scm2.org_1   | 2021-08-11 23:17:37,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:17:37,778 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:17:37,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:17:55,059 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm2.org_1   | 2021-08-11 23:18:07,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44034
scm2.org_1   | 2021-08-11 23:18:07,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47726
scm2.org_1   | 2021-08-11 23:18:07,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:18:07,768 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52218
scm2.org_1   | 2021-08-11 23:18:07,779 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:18:07,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:18:37,660 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52498
scm2.org_1   | 2021-08-11 23:18:37,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44310
scm2.org_1   | 2021-08-11 23:18:37,692 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:18:37,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48004
scm2.org_1   | 2021-08-11 23:18:37,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:18:37,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:19:07,794 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48164
scm2.org_1   | 2021-08-11 23:19:07,800 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52646
scm2.org_1   | 2021-08-11 23:19:07,803 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44466
scm2.org_1   | 2021-08-11 23:19:07,811 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:19:07,819 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:19:07,837 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:19:37,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52772
scm2.org_1   | 2021-08-11 23:19:37,729 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:19:37,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44586
scm2.org_1   | 2021-08-11 23:19:37,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:19:37,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48282
scm2.org_1   | 2021-08-11 23:19:37,794 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:20:07,662 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52912
scm2.org_1   | 2021-08-11 23:20:07,663 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44724
scm2.org_1   | 2021-08-11 23:20:07,671 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48418
scm2.org_1   | 2021-08-11 23:20:07,707 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:20:07,718 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:20:07,735 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:20:37,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44848
scm2.org_1   | 2021-08-11 23:20:37,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48540
scm2.org_1   | 2021-08-11 23:20:37,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53034
scm2.org_1   | 2021-08-11 23:20:37,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:20:37,762 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:20:37,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:21:07,619 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44980
scm2.org_1   | 2021-08-11 23:21:07,638 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:21:07,670 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53160
scm2.org_1   | 2021-08-11 23:21:07,698 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48680
scm2.org_1   | 2021-08-11 23:21:07,708 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:21:07,736 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:21:37,702 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48794
scm2.org_1   | 2021-08-11 23:21:37,719 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53286
scm2.org_1   | 2021-08-11 23:21:37,723 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:21:37,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45100
scm2.org_1   | 2021-08-11 23:21:37,747 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:09:44,693 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:09:44,899 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35832
scm1.org_1   | 2021-08-11 23:09:44,903 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:09:44,906 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-08-11 23:09:45,254 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57502
scm1.org_1   | 2021-08-11 23:09:45,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:09:45,263 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-08-11 23:09:45,854 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 79bd80c8-0720-41ff-85aa-b867116d2715, Nodes: 97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:97333428-a9dc-49fc-bc54-326166febdda, CreationTimestamp2021-08-11T23:09:13.170Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-08-11 23:09:45,868 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:45,871 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 17215.667us
scm1.org_1   | 2021-08-11 23:09:45,874 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-08-11 23:09:46,315 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-08-11 23:09:46,328 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2021-08-11 23:09:46,330 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 15033.307us
scm1.org_1   | 2021-08-11 23:09:46,333 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
om2_1        | 2021-08-11 23:16:07,165 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:07,776 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:07,776 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38814
om2_1        | 2021-08-11 23:16:07,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:08,235 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:08,236 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38822
om2_1        | 2021-08-11 23:16:08,243 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:11,365 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42376
om2_1        | 2021-08-11 23:16:11,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:13,802 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm3.org_1   | 2021-08-11 23:12:07,606 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56548
scm3.org_1   | 2021-08-11 23:12:07,671 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:12:07,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49914
scm3.org_1   | 2021-08-11 23:12:07,696 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46204
scm3.org_1   | 2021-08-11 23:12:07,703 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-08-11 23:16:13,802 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38854
om2_1        | 2021-08-11 23:16:13,811 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:14,303 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:14,304 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38862
om2_1        | 2021-08-11 23:16:14,305 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:17,591 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42414
om2_1        | 2021-08-11 23:16:17,599 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:19,873 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:19,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38892
om2_1        | 2021-08-11 23:16:19,875 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:20,360 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm3.org_1   | 2021-08-11 23:12:07,740 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:12:37,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46356
scm3.org_1   | 2021-08-11 23:12:37,709 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56706
scm3.org_1   | 2021-08-11 23:12:37,712 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50074
scm3.org_1   | 2021-08-11 23:12:37,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:12:37,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:12:37,743 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:13:07,627 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56880
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
s3g_1        | 2021-08-11 23:16:19,880 [qtp1275028674-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-39850, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:16:19,898 [qtp1275028674-23] INFO endpoint.BucketEndpoint: Location is /bucket-39850
s3g_1        | 2021-08-11 23:16:44,210 [qtp1275028674-19] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-39850, , key: 39682/multipartKey2
s3g_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 39682/multipartKey2. Entity too small.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:986)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1096)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:725)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:532)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm1.org_1   | 2021-08-11 23:09:46,333 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2021-08-11 23:09:46,333 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:16:46,256 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:46,257 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40454
om1_1        | 2021-08-11 23:16:46,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:49,568 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:49,569 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40468
om1_1        | 2021-08-11 23:16:49,570 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:52,894 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:52,894 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40492
om1_1        | 2021-08-11 23:16:52,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:56,051 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:56,051 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40506
om1_1        | 2021-08-11 23:16:56,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:56,086 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-39850/93532/multipartKey3-a7704d43-a5ee-491b-a176-bcb705bef0f0-106740043265540128-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:16:56,527 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:56,528 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40512
om1_1        | 2021-08-11 23:16:56,541 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:56,578 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
scm1.org_1   | 2021-08-11 23:09:46,333 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2021-08-11 23:09:46,333 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-08-11 23:09:46,334 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2021-08-11 23:09:46,334 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2021-08-11 23:09:47,070 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7b6570e5-884e-4bb2-8002-8fbff034b0cd, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:fb8d185f-2f23-4800-ba90-a65832b06bb3, CreationTimestamp2021-08-11T23:09:14.294Z[UTC]] moved to OPEN state
scm1.org_1   | 2021-08-11 23:09:47,092 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 21534.983us
scm1.org_1   | 2021-08-11 23:09:51,877 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55578
scm1.org_1   | 2021-08-11 23:09:51,900 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:09:59,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57582
scm1.org_1   | 2021-08-11 23:09:59,122 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:10:00,487 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35930
scm1.org_1   | 2021-08-11 23:10:00,517 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:10:12,409 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:48562
scm1.org_1   | 2021-08-11 23:10:12,432 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:10:12,533 [IPC Server handler 77 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 88912.428us
scm1.org_1   | 2021-08-11 23:10:12,533 [IPC Server handler 77 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2021-08-11 23:10:12,636 [IPC Server handler 77 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 87429.39us
scm1.org_1   | 2021-08-11 23:10:12,733 [4742394c-da80-4695-95c5-c0a43d189463@group-6C975B8E17FD-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm1.org_1   | 2021-08-11 23:10:12,759 [IPC Server handler 77 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 61863.52us
scm1.org_1   | 2021-08-11 23:10:12,825 [IPC Server handler 77 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 56499.98us
scm1.org_1   | 2021-08-11 23:10:12,826 [IPC Server handler 77 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 107544261427200000 to 107544261427201000.
scm1.org_1   | 2021-08-11 23:10:14,600 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45650
scm1.org_1   | 2021-08-11 23:10:14,607 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:10:16,273 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47300
scm1.org_1   | 2021-08-11 23:10:16,288 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:10:16,717 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36008
scm1.org_1   | 2021-08-11 23:10:16,720 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41866
scm1.org_1   | 2021-08-11 23:10:16,732 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:10:16,778 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57512
scm1.org_1   | 2021-08-11 23:10:16,786 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:10:16,828 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-08-11 23:10:17,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57680
scm1.org_1   | 2021-08-11 23:10:17,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:10:25,352 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:48640
scm1.org_1   | 2021-08-11 23:10:25,361 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:10:25,383 [IPC Server handler 43 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 19920.213us
scm1.org_1   | 2021-08-11 23:10:35,638 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:48694
scm1.org_1   | 2021-08-11 23:10:35,644 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:10:36,553 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 15214.286us
scm1.org_1   | 2021-08-11 23:10:37,641 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57784
scm1.org_1   | 2021-08-11 23:10:37,681 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45782
scm1.org_1   | 2021-08-11 23:10:37,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36132
scm1.org_1   | 2021-08-11 23:10:37,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:10:37,799 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:10:37,854 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:10:59,209 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:49728
scm1.org_1   | 2021-08-11 23:10:59,213 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:11:07,757 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57942
scm1.org_1   | 2021-08-11 23:11:07,763 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36286
scm1.org_1   | 2021-08-11 23:11:07,792 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45942
scm1.org_1   | 2021-08-11 23:11:07,807 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:11:07,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:11:07,862 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:11:22,517 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:48960
scm1.org_1   | 2021-08-11 23:11:22,529 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:11:33,824 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:49010
scm1.org_1   | 2021-08-11 23:11:33,829 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:11:33,885 [IPC Server handler 7 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 37465.185us
scm1.org_1   | 2021-08-11 23:11:33,886 [IPC Server handler 7 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2021-08-11 23:11:33,909 [IPC Server handler 7 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 17662.717us
scm1.org_1   | 2021-08-11 23:11:36,548 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 10075.037us
scm1.org_1   | 2021-08-11 23:11:37,662 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46108
scm1.org_1   | 2021-08-11 23:11:37,677 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58112
scm1.org_1   | 2021-08-11 23:11:37,718 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:11:37,718 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:11:37,722 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36456
scm1.org_1   | 2021-08-11 23:11:37,738 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:12:07,626 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58282
scm1.org_1   | 2021-08-11 23:12:07,675 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:12:07,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36624
scm1.org_1   | 2021-08-11 23:12:07,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46286
scm1.org_1   | 2021-08-11 23:12:07,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:13:07,647 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50248
scm3.org_1   | 2021-08-11 23:13:07,668 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46540
scm3.org_1   | 2021-08-11 23:13:07,675 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:13:07,703 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:13:07,717 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:13:12,709 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm3.org_1   | 2021-08-11 23:13:37,614 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57058
scm3.org_1   | 2021-08-11 23:13:37,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:13:37,639 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50424
scm3.org_1   | 2021-08-11 23:13:37,668 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:13:37,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46706
om2_1        | 2021-08-11 23:16:20,360 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38898
om2_1        | 2021-08-11 23:16:20,367 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:20,924 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:20,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38906
om2_1        | 2021-08-11 23:16:20,927 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:21,516 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:21,516 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38912
om2_1        | 2021-08-11 23:16:21,517 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-08-11 23:19:23,039 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4849,entriesCount=1,lastEntry=(t:1, i:89)
datanode3_1  | 2021-08-11 23:19:24,687 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:27,755 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:28,596 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5101,entriesCount=1,lastEntry=(t:1, i:90)
datanode3_1  | 2021-08-11 23:19:28,602 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5102,entriesCount=1,lastEntry=(t:1, i:91)
datanode3_1  | 2021-08-11 23:19:28,602 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5103,entriesCount=1,lastEntry=(t:1, i:92)
datanode3_1  | 2021-08-11 23:19:28,603 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5104,entriesCount=1,lastEntry=(t:1, i:93)
om2_1        | 2021-08-11 23:16:24,937 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:24,937 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38936
om2_1        | 2021-08-11 23:16:24,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:28,281 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:44,224 [qtp1275028674-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>EntityTooSmall</Code>
s3g_1        |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
s3g_1        |   <Resource>39682/multipartKey2</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:102)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
datanode3_1  | 2021-08-11 23:19:30,831 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:33,899 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:36,971 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:40,043 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:43,119 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:43,525 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5358,entriesCount=1,lastEntry=(t:1, i:94)
scm3.org_1   | 2021-08-11 23:13:37,699 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:14:07,662 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57232
scm3.org_1   | 2021-08-11 23:14:07,666 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:14:07,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50598
scm3.org_1   | 2021-08-11 23:14:07,718 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46886
scm3.org_1   | 2021-08-11 23:14:07,735 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:14:07,745 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:14:37,663 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47048
scm3.org_1   | 2021-08-11 23:14:37,687 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:14:37,697 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57400
scm3.org_1   | 2021-08-11 23:14:37,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50768
scm3.org_1   | 2021-08-11 23:14:37,718 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:14:37,755 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:15:07,632 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57714
scm3.org_1   | 2021-08-11 23:15:07,654 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47366
scm3.org_1   | 2021-08-11 23:15:07,662 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:15:07,674 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:15:07,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51082
scm3.org_1   | 2021-08-11 23:15:07,694 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:15:37,710 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47614
scm3.org_1   | 2021-08-11 23:15:37,752 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57964
scm3.org_1   | 2021-08-11 23:15:37,758 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51330
scm3.org_1   | 2021-08-11 23:15:37,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:15:37,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:15:37,815 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:16:07,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58216
scm3.org_1   | 2021-08-11 23:16:07,664 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:16:07,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47864
scm3.org_1   | 2021-08-11 23:16:07,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51584
scm3.org_1   | 2021-08-11 23:16:07,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-08-11 23:16:28,281 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38960
om2_1        | 2021-08-11 23:16:28,282 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:28,883 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:28,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38966
om2_1        | 2021-08-11 23:16:28,885 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:32,370 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:32,371 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:38984
om2_1        | 2021-08-11 23:16:32,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:35,538 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:35,539 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39004
om2_1        | 2021-08-11 23:16:35,543 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:36,056 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:36,057 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39012
om2_1        | 2021-08-11 23:16:36,058 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:37,089 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:37,089 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39024
om2_1        | 2021-08-11 23:16:37,090 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:37,694 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:37,695 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39050
om2_1        | 2021-08-11 23:16:37,696 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:41,004 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode3_1  | 2021-08-11 23:19:43,525 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5359,entriesCount=1,lastEntry=(t:1, i:95)
datanode3_1  | 2021-08-11 23:19:43,536 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5360,entriesCount=1,lastEntry=(t:1, i:96)
datanode3_1  | 2021-08-11 23:19:43,538 [java.util.concurrent.ThreadPoolExecutor$Worker@6762abea[State = -1, empty queue]] WARN server.GrpcLogAppender: fb8d185f-2f23-4800-ba90-a65832b06bb3@group-8FBFF034B0CD->97333428-a9dc-49fc-bc54-326166febdda-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5361,entriesCount=1,lastEntry=(t:1, i:97)
datanode3_1  | 2021-08-11 23:19:46,187 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:52,331 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:55,403 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:19:58,475 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:01,551 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:04,619 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:07,696 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:10,763 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:13,835 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:16,907 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:19,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-39850/93532/multipartKey3-a7704d43-a5ee-491b-a176-bcb705bef0f0-106740043265540128-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:16:57,029 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:57,029 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40520
om1_1        | 2021-08-11 23:16:57,032 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:57,063 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-39850/93532/multipartKey3
om1_1        | 2021-08-11 23:16:57,064 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3 because parts are in Invalid order.
datanode3_1  | 2021-08-11 23:20:23,051 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:26,123 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:29,195 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:32,267 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:35,343 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:41,483 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:44,555 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:47,627 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:50,700 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:53,771 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:56,843 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:20:59,915 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:02,987 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:06,059 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:09,131 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:12,203 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:15,275 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:18,347 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:21,419 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:24,492 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:30,635 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:33,707 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:36,779 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:39,851 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:42,923 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:45,995 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:49,072 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:52,139 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:55,215 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:21:58,283 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:01,355 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:04,427 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:07,499 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:10,571 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:13,643 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:19,787 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:22,859 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:25,931 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:16:41,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39072
om2_1        | 2021-08-11 23:16:41,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:44,176 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:44,176 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39086
om2_1        | 2021-08-11 23:16:44,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:44,207 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-39850/39682/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2021-08-11 23:16:44,208 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 39682/multipartKey2 in Volume/Bucket s3v/bucket-39850
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 39682/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:463)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:16:44,700 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:44,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39094
om2_1        | 2021-08-11 23:16:44,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:45,231 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:45,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39102
om2_1        | 2021-08-11 23:16:45,236 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:45,251 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-39850/93532/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2021-08-11 23:16:45,252 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:16:45,710 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:45,710 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39108
om2_1        | 2021-08-11 23:16:45,711 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:45,728 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-39850/93532/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2021-08-11 23:16:45,732 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:173)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:16:46,262 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:46,262 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39132
om2_1        | 2021-08-11 23:16:46,267 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:49,573 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:49,573 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39146
om2_1        | 2021-08-11 23:16:49,574 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:52,908 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm3.org_1   | 2021-08-11 23:16:07,747 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:16:37,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48104
scm3.org_1   | 2021-08-11 23:16:37,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58454
scm3.org_1   | 2021-08-11 23:16:37,702 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51822
scm3.org_1   | 2021-08-11 23:16:37,731 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:16:37,762 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:16:37,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:17:07,606 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58722
scm3.org_1   | 2021-08-11 23:17:07,642 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:17:07,659 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52092
scm3.org_1   | 2021-08-11 23:17:07,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48376
scm3.org_1   | 2021-08-11 23:17:07,698 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:17:07,705 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:17:37,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48658
scm3.org_1   | 2021-08-11 23:17:37,731 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59010
scm3.org_1   | 2021-08-11 23:17:37,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52382
scm3.org_1   | 2021-08-11 23:17:37,784 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:17:37,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:17:37,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:18:07,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59298
scm3.org_1   | 2021-08-11 23:18:07,702 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52670
scm3.org_1   | 2021-08-11 23:18:07,716 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:18:07,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:18:07,757 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48946
scm3.org_1   | 2021-08-11 23:18:07,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:18:12,709 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm3.org_1   | 2021-08-11 23:18:37,620 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59578
scm3.org_1   | 2021-08-11 23:18:37,653 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52946
scm3.org_1   | 2021-08-11 23:18:37,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49228
scm3.org_1   | 2021-08-11 23:18:37,668 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:18:37,735 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:411)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:16:57,515 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:57,516 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40528
om1_1        | 2021-08-11 23:16:57,524 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:58,031 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:58,031 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40542
om1_1        | 2021-08-11 23:16:58,033 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:59,055 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:59,055 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40556
om1_1        | 2021-08-11 23:16:59,062 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:16:59,626 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:16:59,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40562
om1_1        | 2021-08-11 23:16:59,628 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:00,114 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:00,114 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40570
om1_1        | 2021-08-11 23:17:00,116 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:00,147 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 05864/multipartKey5 in VolumeName/Bucket s3v/bucket-39850
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-39850key: 05864/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode3_1  | 2021-08-11 23:22:29,007 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:22:32,075 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 2021-08-11 23:18:37,778 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
datanode3_1  | 2021-08-11 23:22:35,147 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-08-11 23:16:52,909 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39170
om1_1        | 2021-08-11 23:17:00,605 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm2.org_1   | 2021-08-11 23:21:37,771 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:22:07,625 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45244
scm2.org_1   | 2021-08-11 23:22:07,647 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53428
scm2.org_1   | 2021-08-11 23:22:07,671 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48946
scm2.org_1   | 2021-08-11 23:22:07,687 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:12:07,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:12:18,152 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:49278
scm1.org_1   | 2021-08-11 23:12:18,157 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:12:26,519 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50218
scm1.org_1   | 2021-08-11 23:12:26,522 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-08-11 23:22:07,691 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:22:07,726 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:22:37,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45362
scm2.org_1   | 2021-08-11 23:22:37,735 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53546
scm2.org_1   | 2021-08-11 23:22:37,738 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:22:37,752 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49054
scm2.org_1   | 2021-08-11 23:22:37,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:22:37,774 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:12:32,324 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:49340
scm1.org_1   | 2021-08-11 23:12:32,330 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:12:34,632 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2021-08-11 23:12:36,548 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 10326.826us
scm1.org_1   | 2021-08-11 23:12:37,777 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46442
scm1.org_1   | 2021-08-11 23:12:37,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36794
scm1.org_1   | 2021-08-11 23:12:37,788 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:12:37,790 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58442
scm1.org_1   | 2021-08-11 23:12:37,794 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:12:37,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:12:40,854 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50298
scm1.org_1   | 2021-08-11 23:12:40,863 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-08-11 23:22:55,060 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2021-08-11 23:23:07,620 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45508
scm2.org_1   | 2021-08-11 23:23:07,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:23:07,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53688
scm2.org_1   | 2021-08-11 23:23:07,670 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:23:07,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49206
om1_1        | 2021-08-11 23:17:00,606 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40578
om1_1        | 2021-08-11 23:17:00,609 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:00,632 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-39850, Key98200/multipartKey. Exception:{}
scm1.org_1   | 2021-08-11 23:13:07,649 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58622
scm1.org_1   | 2021-08-11 23:13:07,689 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:13:07,733 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36962
scm1.org_1   | 2021-08-11 23:13:07,734 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46624
scm2.org_1   | 2021-08-11 23:23:07,754 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:726)
scm2.org_1   | 2021-08-11 23:23:37,625 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45624
scm2.org_1   | 2021-08-11 23:23:37,648 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53812
scm3.org_1   | 2021-08-11 23:19:07,752 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53098
scm3.org_1   | 2021-08-11 23:19:07,764 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:13:07,739 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:23:37,662 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49320
scm2.org_1   | 2021-08-11 23:23:37,670 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:23:37,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:23:37,699 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:24:07,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45924
scm2.org_1   | 2021-08-11 23:24:07,692 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:24:07,696 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54104
scm3.org_1   | 2021-08-11 23:19:07,792 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49388
scm3.org_1   | 2021-08-11 23:19:07,799 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59734
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:618)
scm3.org_1   | 2021-08-11 23:19:07,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:19:07,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-08-11 23:24:07,707 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode3_1  | 2021-08-11 23:22:38,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm3.org_1   | 2021-08-11 23:19:37,679 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59854
scm3.org_1   | 2021-08-11 23:19:37,709 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53224
scm3.org_1   | 2021-08-11 23:19:37,750 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:19:37,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:19:37,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49502
scm3.org_1   | 2021-08-11 23:19:37,784 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:20:07,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49642
scm3.org_1   | 2021-08-11 23:20:07,687 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59988
scm3.org_1   | 2021-08-11 23:20:07,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53360
scm1.org_1   | 2021-08-11 23:13:07,747 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:13:33,799 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:49692
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:595)
scm1.org_1   | 2021-08-11 23:13:33,812 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2021-08-11 23:20:07,706 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:20:07,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode3_1  | 2021-08-11 23:22:41,291 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
datanode3_1  | 2021-08-11 23:22:44,367 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:20:07,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:20:37,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60110
scm3.org_1   | 2021-08-11 23:20:37,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49764
scm3.org_1   | 2021-08-11 23:20:37,725 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53482
scm3.org_1   | 2021-08-11 23:20:37,748 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:20:37,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:20:37,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode3_1  | 2021-08-11 23:22:47,435 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:21:07,618 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60244
scm3.org_1   | 2021-08-11 23:21:07,635 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:21:07,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53606
scm3.org_1   | 2021-08-11 23:21:07,697 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49900
scm3.org_1   | 2021-08-11 23:21:07,717 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:21:07,726 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:21:37,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60364
datanode3_1  | 2021-08-11 23:22:50,507 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:21:37,698 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50012
scm3.org_1   | 2021-08-11 23:21:37,742 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:13:33,835 [IPC Server handler 19 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 21535.241us
scm1.org_1   | 2021-08-11 23:13:36,559 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 18218.671us
scm1.org_1   | 2021-08-11 23:13:37,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58792
scm1.org_1   | 2021-08-11 23:13:37,626 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:13:37,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37142
datanode3_1  | 2021-08-11 23:22:53,579 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-08-11 23:17:01,087 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:01,088 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40584
datanode3_1  | 2021-08-11 23:22:56,651 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:17:01,090 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:01,691 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:01,692 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40590
om1_1        | 2021-08-11 23:17:01,693 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-08-11 23:24:07,730 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49622
scm2.org_1   | 2021-08-11 23:24:07,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode3_1  | 2021-08-11 23:22:59,723 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm3.org_1   | 2021-08-11 23:21:37,749 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:13:37,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46792
om1_1        | 2021-08-11 23:17:05,008 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
datanode3_1  | 2021-08-11 23:23:02,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:08,939 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:21:37,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53732
om2_1        | 2021-08-11 23:16:52,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:56,057 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:56,057 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39184
om2_1        | 2021-08-11 23:16:56,058 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:56,075 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-39850/93532/multipartKey3-a7704d43-a5ee-491b-a176-bcb705bef0f0-106740043265540128-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:16:56,546 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:56,547 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39190
om2_1        | 2021-08-11 23:16:56,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:13:37,729 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:13:37,749 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:14:07,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46976
scm1.org_1   | 2021-08-11 23:14:07,773 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58968
scm1.org_1   | 2021-08-11 23:14:07,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:14:07,792 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37310
scm3.org_1   | 2021-08-11 23:21:37,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode3_1  | 2021-08-11 23:23:12,011 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:15,083 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-08-11 23:14:07,799 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:14:07,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:14:17,026 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:49960
scm1.org_1   | 2021-08-11 23:14:17,034 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2021-08-11 23:17:05,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40614
om1_1        | 2021-08-11 23:17:05,019 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:08,258 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:08,258 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40646
scm1.org_1   | 2021-08-11 23:14:25,263 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50888
scm1.org_1   | 2021-08-11 23:14:25,272 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:14:36,556 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 17835.841us
scm1.org_1   | 2021-08-11 23:14:37,596 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59136
scm1.org_1   | 2021-08-11 23:14:37,601 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-08-11 23:17:08,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:08,846 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:08,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40652
om1_1        | 2021-08-11 23:17:08,848 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:09,388 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:09,388 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40660
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
scm1.org_1   | 2021-08-11 23:14:37,633 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47134
scm1.org_1   | 2021-08-11 23:14:37,656 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
datanode3_1  | 2021-08-11 23:23:18,155 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:21,227 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-08-11 23:14:37,668 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37482
om1_1        | 2021-08-11 23:17:09,389 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-08-11 23:23:24,303 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm1.org_1   | 2021-08-11 23:14:37,722 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:15:03,837 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50360
scm1.org_1   | 2021-08-11 23:15:03,839 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:15:07,737 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59450
scm1.org_1   | 2021-08-11 23:15:07,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37800
scm1.org_1   | 2021-08-11 23:15:07,743 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47450
scm1.org_1   | 2021-08-11 23:15:07,745 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:15:07,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:15:07,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:15:36,545 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 6809.822us
scm1.org_1   | 2021-08-11 23:15:37,693 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59698
scm1.org_1   | 2021-08-11 23:15:37,708 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47698
scm1.org_1   | 2021-08-11 23:15:37,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:15:37,751 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38048
scm1.org_1   | 2021-08-11 23:15:37,774 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:15:37,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:15:38,899 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51544
scm1.org_1   | 2021-08-11 23:15:38,905 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:16:07,661 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38302
scm1.org_1   | 2021-08-11 23:16:07,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59952
scm1.org_1   | 2021-08-11 23:16:07,697 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1        | 2021-08-11 23:17:09,889 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:09,889 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40668
om1_1        | 2021-08-11 23:17:09,892 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:10,649 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:10,650 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40684
om1_1        | 2021-08-11 23:17:10,651 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:10,736 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:10,736 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40688
om1_1        | 2021-08-11 23:17:10,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:10,830 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:10,830 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40694
om1_1        | 2021-08-11 23:17:10,831 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:10,882 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:10,882 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40700
om1_1        | 2021-08-11 23:17:10,919 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:14,937 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:14,937 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40718
om1_1        | 2021-08-11 23:17:14,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:15,458 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:15,459 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40726
datanode3_1  | 2021-08-11 23:23:27,371 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:30,443 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:33,519 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:36,591 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:39,659 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:42,731 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:45,803 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:48,875 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:45,258 [qtp1275028674-19] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-39850, , key: 93532/multipartKey3
datanode3_1  | 2021-08-11 23:23:51,947 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:23:58,091 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:24:01,168 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:24:04,239 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-08-11 23:22:07,621 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60512
scm3.org_1   | 2021-08-11 23:22:07,678 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:22:07,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53876
scm3.org_1   | 2021-08-11 23:22:07,699 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50160
scm3.org_1   | 2021-08-11 23:22:07,702 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:22:07,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:22:37,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60626
scm3.org_1   | 2021-08-11 23:22:37,723 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:22:37,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53994
scm3.org_1   | 2021-08-11 23:22:37,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50284
scm3.org_1   | 2021-08-11 23:22:37,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:22:37,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:23:07,618 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60772
scm3.org_1   | 2021-08-11 23:23:07,628 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:23:07,653 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54136
scm3.org_1   | 2021-08-11 23:23:07,662 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:23:07,726 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50426
scm3.org_1   | 2021-08-11 23:23:07,739 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:23:12,710 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm3.org_1   | 2021-08-11 23:23:37,615 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60892
scm3.org_1   | 2021-08-11 23:23:37,648 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54260
scm3.org_1   | 2021-08-11 23:23:37,652 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:23:37,679 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50540
scm3.org_1   | 2021-08-11 23:23:37,685 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:23:37,701 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:24:07,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32956
scm3.org_1   | 2021-08-11 23:24:07,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54552
scm3.org_1   | 2021-08-11 23:24:07,692 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:24:07,707 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-08-11 23:24:07,735 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50846
scm3.org_1   | 2021-08-11 23:24:07,771 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-08-11 23:16:56,574 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-39850/93532/multipartKey3-a7704d43-a5ee-491b-a176-bcb705bef0f0-106740043265540128-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:445)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:16:57,036 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:57,037 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39198
om2_1        | 2021-08-11 23:16:57,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:57,062 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-39850/93532/multipartKey3
om2_1        | 2021-08-11 23:16:57,067 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 93532/multipartKey3 in Volume/Bucket s3v/bucket-39850
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3 because parts are in Invalid order.
datanode3_1  | 2021-08-11 23:24:07,307 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:24:10,379 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:24:13,451 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:24:16,528 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-08-11 23:24:19,599 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-08-11 23:17:15,463 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:15,496 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:15,497 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40734
om1_1        | 2021-08-11 23:17:15,500 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:15,509 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:15,509 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40738
scm1.org_1   | 2021-08-11 23:16:07,727 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47956
scm1.org_1   | 2021-08-11 23:16:07,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:16:07,754 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:16:21,560 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50994
scm1.org_1   | 2021-08-11 23:16:21,565 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:16:33,802 [IPC Server handler 92 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 15692.766us
scm1.org_1   | 2021-08-11 23:16:36,295 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51990
scm1.org_1   | 2021-08-11 23:16:36,302 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:16:36,554 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 11301.191us
scm1.org_1   | 2021-08-11 23:16:37,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38536
scm1.org_1   | 2021-08-11 23:16:37,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60188
scm1.org_1   | 2021-08-11 23:16:37,744 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48188
scm1.org_1   | 2021-08-11 23:16:37,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:16:37,806 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:16:37,843 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:16:58,328 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52198
scm1.org_1   | 2021-08-11 23:16:58,333 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:17:07,606 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60464
scm1.org_1   | 2021-08-11 23:17:07,676 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:17:07,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48460
scm1.org_1   | 2021-08-11 23:17:07,687 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38812
scm1.org_1   | 2021-08-11 23:17:07,713 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:17:07,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:17:15,713 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52400
scm1.org_1   | 2021-08-11 23:17:15,721 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:17:33,800 [IPC Server handler 58 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 9860.057us
scm1.org_1   | 2021-08-11 23:17:34,635 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 2 containers.
scm1.org_1   | 2021-08-11 23:17:36,550 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 7265.816us
scm1.org_1   | 2021-08-11 23:17:37,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39096
scm1.org_1   | 2021-08-11 23:17:37,798 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60746
scm1.org_1   | 2021-08-11 23:17:37,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48748
scm1.org_1   | 2021-08-11 23:17:37,806 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:17:37,819 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:17:37,827 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:18:00,071 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51888
scm1.org_1   | 2021-08-11 23:18:00,077 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:18:03,676 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52808
scm1.org_1   | 2021-08-11 23:18:03,679 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:18:07,448 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:53936
scm1.org_1   | 2021-08-11 23:18:07,472 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:18:07,492 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:60234
scm1.org_1   | 2021-08-11 23:18:07,502 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:18:07,628 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49038
scm1.org_1   | 2021-08-11 23:18:07,650 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39382
scm1.org_1   | 2021-08-11 23:18:07,654 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:18:07,670 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32802
scm1.org_1   | 2021-08-11 23:18:07,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:18:07,713 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:18:18,338 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52058
scm1.org_1   | 2021-08-11 23:18:18,341 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:18:33,809 [IPC Server handler 45 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 22357.539us
scm1.org_1   | 2021-08-11 23:18:36,576 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 31410.076us
scm1.org_1   | 2021-08-11 23:18:37,717 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33080
scm1.org_1   | 2021-08-11 23:18:37,743 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:18:37,760 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39660
scm1.org_1   | 2021-08-11 23:18:37,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:18:37,785 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49312
scm1.org_1   | 2021-08-11 23:18:37,796 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:19:07,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39810
scm1.org_1   | 2021-08-11 23:19:07,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33236
scm1.org_1   | 2021-08-11 23:19:07,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:19:07,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49478
scm1.org_1   | 2021-08-11 23:19:07,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:19:07,818 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:19:36,554 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 10526.052us
scm1.org_1   | 2021-08-11 23:19:37,709 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33356
scm1.org_1   | 2021-08-11 23:19:37,718 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39936
scm1.org_1   | 2021-08-11 23:19:37,742 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:19:37,742 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:19:37,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49588
scm1.org_1   | 2021-08-11 23:19:37,785 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:19:47,470 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52576
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:411)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 2021-08-11 23:17:15,515 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:15,516 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40742
om1_1        | 2021-08-11 23:17:15,519 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:15,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:17,049 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:17,049 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40768
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
om1_1        | 2021-08-11 23:17:17,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:17,944 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:986)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1096)
om1_1        | 2021-08-11 23:17:17,944 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40776
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:725)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:532)
om1_1        | 2021-08-11 23:17:17,945 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:21,244 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:21,245 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40794
om1_1        | 2021-08-11 23:17:21,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:21,758 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:21,759 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40800
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-08-11 23:19:47,477 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:20:07,606 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33498
om2_1        | 2021-08-11 23:16:57,528 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:57,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39206
om2_1        | 2021-08-11 23:16:57,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:20:07,652 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40074
scm1.org_1   | 2021-08-11 23:20:07,666 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:20:07,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49726
om1_1        | 2021-08-11 23:17:21,760 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:25,300 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:25,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40824
scm1.org_1   | 2021-08-11 23:20:07,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-08-11 23:17:25,301 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm1.org_1   | 2021-08-11 23:20:07,699 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-08-11 23:17:25,789 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm1.org_1   | 2021-08-11 23:20:36,550 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 6115.684us
om1_1        | 2021-08-11 23:17:25,790 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40830
om2_1        | 2021-08-11 23:16:58,040 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:58,040 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39220
om2_1        | 2021-08-11 23:16:58,042 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om2_1        | 2021-08-11 23:16:59,067 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:59,068 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39234
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om2_1        | 2021-08-11 23:16:59,069 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:16:59,631 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:16:59,632 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39240
om2_1        | 2021-08-11 23:16:59,633 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:25,791 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:26,670 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:00,120 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:00,120 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39248
om2_1        | 2021-08-11 23:17:00,121 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:26,671 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40840
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om1_1        | 2021-08-11 23:17:26,673 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om1_1        | 2021-08-11 23:17:30,125 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om2_1        | 2021-08-11 23:17:00,143 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 05864/multipartKey5 in VolumeName/Bucket s3v/bucket-39850
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-39850key: 05864/multipartKey5
om1_1        | 2021-08-11 23:17:30,126 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40862
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:17:00,613 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om2_1        | 2021-08-11 23:17:00,613 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39256
om2_1        | 2021-08-11 23:17:00,614 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:00,628 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-39850, Key98200/multipartKey. Exception:{}
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:726)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:618)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:595)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:246)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 2021-08-11 23:17:30,130 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
scm1.org_1   | 2021-08-11 23:20:37,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33618
om1_1        | 2021-08-11 23:17:30,643 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm1.org_1   | 2021-08-11 23:20:37,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49848
scm1.org_1   | 2021-08-11 23:20:37,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40196
scm1.org_1   | 2021-08-11 23:20:37,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:20:37,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:20:37,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:20:47,839 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52836
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2021-08-11 23:17:30,643 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40870
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm1.org_1   | 2021-08-11 23:20:47,842 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:21:07,620 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33748
scm1.org_1   | 2021-08-11 23:21:07,648 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:21:07,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40324
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-08-11 23:17:01,094 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:01,094 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39262
om2_1        | 2021-08-11 23:17:01,095 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:01,699 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:30,654 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:21:07,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49986
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om2_1        | 2021-08-11 23:17:01,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39268
om2_1        | 2021-08-11 23:17:01,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:21:07,718 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:21:07,740 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om1_1        | 2021-08-11 23:17:34,384 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:34,385 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40896
om1_1        | 2021-08-11 23:17:34,393 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:37,634 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:37,636 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40930
om1_1        | 2021-08-11 23:17:37,639 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:38,302 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:38,303 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40936
om1_1        | 2021-08-11 23:17:38,307 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:39,324 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:05,022 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om2_1        | 2021-08-11 23:17:05,023 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39292
om2_1        | 2021-08-11 23:17:05,027 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:08,262 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:08,263 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39324
om2_1        | 2021-08-11 23:17:08,264 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:21:36,557 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 12959.671us
scm1.org_1   | 2021-08-11 23:21:37,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33868
scm1.org_1   | 2021-08-11 23:21:37,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50108
scm1.org_1   | 2021-08-11 23:21:37,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40444
scm1.org_1   | 2021-08-11 23:21:37,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-08-11 23:17:39,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40948
om1_1        | 2021-08-11 23:17:39,326 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:42,717 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:42,717 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40970
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm1.org_1   | 2021-08-11 23:21:37,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-08-11 23:17:08,851 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:08,852 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39330
om2_1        | 2021-08-11 23:17:08,853 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-08-11 23:21:37,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:21:48,397 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53092
scm1.org_1   | 2021-08-11 23:21:48,403 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2021-08-11 23:17:42,719 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:43,232 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:43,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40978
om1_1        | 2021-08-11 23:17:43,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
om2_1        | 2021-08-11 23:17:09,393 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:09,393 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39338
om2_1        | 2021-08-11 23:17:09,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:43,743 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:43,743 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40986
scm1.org_1   | 2021-08-11 23:21:48,431 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53990
scm1.org_1   | 2021-08-11 23:21:48,444 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:21:48,448 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:55084
scm1.org_1   | 2021-08-11 23:21:48,461 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
om2_1        | 2021-08-11 23:17:09,896 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:09,897 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39346
om2_1        | 2021-08-11 23:17:09,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:10,654 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:43,755 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:44,276 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:44,277 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40992
om1_1        | 2021-08-11 23:17:44,289 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:47,903 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm1.org_1   | 2021-08-11 23:21:48,467 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:33150
scm1.org_1   | 2021-08-11 23:21:48,502 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2021-08-11 23:17:10,655 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39362
om2_1        | 2021-08-11 23:17:10,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:10,745 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm1.org_1   | 2021-08-11 23:22:07,624 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34014
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
om1_1        | 2021-08-11 23:17:47,903 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41026
scm1.org_1   | 2021-08-11 23:22:07,664 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40596
scm1.org_1   | 2021-08-11 23:22:07,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50246
om1_1        | 2021-08-11 23:17:47,904 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:51,080 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:10,746 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39366
om2_1        | 2021-08-11 23:17:10,748 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:10,836 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm1.org_1   | 2021-08-11 23:22:07,683 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:22:07,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:22:07,729 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:22:34,635 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2021-08-11 23:22:36,551 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 7171.291us
om1_1        | 2021-08-11 23:17:51,081 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41042
om1_1        | 2021-08-11 23:17:51,082 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:51,557 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:51,557 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41050
om2_1        | 2021-08-11 23:17:10,836 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39372
om2_1        | 2021-08-11 23:17:10,844 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:10,925 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:10,926 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39378
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:45,259 [qtp1275028674-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
scm1.org_1   | 2021-08-11 23:22:37,696 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34130
scm1.org_1   | 2021-08-11 23:22:37,727 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:22:37,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50362
scm1.org_1   | 2021-08-11 23:22:37,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40708
scm1.org_1   | 2021-08-11 23:22:37,761 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-08-11 23:17:51,560 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:52,417 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:52,418 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41070
om1_1        | 2021-08-11 23:17:52,420 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:10,937 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:14,942 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:52,940 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        |   <Resource>93532/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm1.org_1   | 2021-08-11 23:22:37,765 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:22:48,366 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53356
scm1.org_1   | 2021-08-11 23:22:48,368 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:22:48,414 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:33410
scm1.org_1   | 2021-08-11 23:22:48,415 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54256
om2_1        | 2021-08-11 23:17:14,943 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39396
om2_1        | 2021-08-11 23:17:14,944 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:15,466 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:15,467 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39404
om2_1        | 2021-08-11 23:17:15,467 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:52,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41078
om1_1        | 2021-08-11 23:17:52,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:53,456 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:53,456 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41084
om1_1        | 2021-08-11 23:17:53,458 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:56,825 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58058
om1_1        | 2021-08-11 23:17:56,848 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
scm1.org_1   | 2021-08-11 23:22:48,420 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2021-08-11 23:17:15,507 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:15,507 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39416
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm1.org_1   | 2021-08-11 23:22:48,424 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:55350
scm1.org_1   | 2021-08-11 23:22:48,431 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:22:48,441 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:23:07,618 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34276
om2_1        | 2021-08-11 23:17:15,519 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:15,530 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:15,530 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39420
om2_1        | 2021-08-11 23:17:15,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:15,540 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:59,093 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:59,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41116
om1_1        | 2021-08-11 23:17:59,094 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:17:59,556 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:17:59,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41122
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2021-08-11 23:23:07,641 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:23:07,654 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40850
scm1.org_1   | 2021-08-11 23:23:07,663 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:23:07,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50518
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om2_1        | 2021-08-11 23:17:15,541 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39422
om2_1        | 2021-08-11 23:17:15,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:17,059 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:17,060 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39446
om1_1        | 2021-08-11 23:17:59,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2021-08-11 23:23:07,755 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-08-11 23:18:00,044 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:00,044 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41128
om1_1        | 2021-08-11 23:18:00,047 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:03,172 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm1.org_1   | 2021-08-11 23:23:36,552 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1a2d12aa, cost 7298.589us
om2_1        | 2021-08-11 23:17:17,063 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:17,949 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:17,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39454
om2_1        | 2021-08-11 23:17:17,956 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm1.org_1   | 2021-08-11 23:23:37,617 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34394
scm1.org_1   | 2021-08-11 23:23:37,654 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40974
scm1.org_1   | 2021-08-11 23:23:37,671 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-08-11 23:18:03,173 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41144
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm1.org_1   | 2021-08-11 23:23:37,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50626
scm1.org_1   | 2021-08-11 23:23:37,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:23:37,702 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-08-11 23:17:21,250 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:03,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:03,650 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:03,650 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41152
om1_1        | 2021-08-11 23:18:03,653 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:21,251 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39472
om2_1        | 2021-08-11 23:17:21,251 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm1.org_1   | 2021-08-11 23:23:51,698 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53642
scm1.org_1   | 2021-08-11 23:23:51,702 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-08-11 23:23:56,640 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54584
scm1.org_1   | 2021-08-11 23:23:56,643 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-08-11 23:24:07,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41266
om2_1        | 2021-08-11 23:17:21,766 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:21,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39478
om2_1        | 2021-08-11 23:17:21,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:25,304 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:25,304 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39502
om1_1        | 2021-08-11 23:18:06,788 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:06,788 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41178
om1_1        | 2021-08-11 23:18:06,789 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:07,248 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:07,249 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41184
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm1.org_1   | 2021-08-11 23:24:07,699 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34692
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om2_1        | 2021-08-11 23:17:25,308 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:25,793 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:25,794 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39508
om2_1        | 2021-08-11 23:17:25,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:07,257 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:10,433 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:10,433 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41236
om1_1        | 2021-08-11 23:18:10,434 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:10,904 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
scm1.org_1   | 2021-08-11 23:24:07,703 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:24:07,714 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-08-11 23:24:07,730 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50930
scm1.org_1   | 2021-08-11 23:24:07,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om2_1        | 2021-08-11 23:17:26,677 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:26,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39518
om2_1        | 2021-08-11 23:17:26,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:10,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41242
om1_1        | 2021-08-11 23:18:10,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:11,371 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:11,373 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41248
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om2_1        | 2021-08-11 23:17:30,133 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:30,133 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39540
om2_1        | 2021-08-11 23:17:30,138 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:30,658 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:11,374 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:11,837 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:11,837 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41256
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om2_1        | 2021-08-11 23:17:30,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39548
om2_1        | 2021-08-11 23:17:30,663 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:34,396 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:11,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:12,316 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:12,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41262
om2_1        | 2021-08-11 23:17:34,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39574
om2_1        | 2021-08-11 23:17:34,398 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:37,643 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:37,643 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39608
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1        | 2021-08-11 23:18:12,328 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:15,424 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58234
om1_1        | 2021-08-11 23:18:15,444 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:37,649 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:38,310 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:38,310 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39614
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om1_1        | 2021-08-11 23:18:17,812 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:17,815 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41292
om1_1        | 2021-08-11 23:18:17,826 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:38,311 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:39,344 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:39,344 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39626
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 2021-08-11 23:18:18,309 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:18,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41298
om1_1        | 2021-08-11 23:18:18,310 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
om2_1        | 2021-08-11 23:17:39,349 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:42,722 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:42,722 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39648
om2_1        | 2021-08-11 23:17:42,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om1_1        | 2021-08-11 23:18:19,094 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:19,095 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41310
om1_1        | 2021-08-11 23:18:19,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:19,648 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:19,649 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41318
om2_1        | 2021-08-11 23:17:43,242 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:43,243 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39656
om2_1        | 2021-08-11 23:17:43,243 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
om1_1        | 2021-08-11 23:18:19,658 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:20,254 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:43,766 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om2_1        | 2021-08-11 23:17:43,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39664
om2_1        | 2021-08-11 23:17:43,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:44,292 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:44,292 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39670
om1_1        | 2021-08-11 23:18:20,255 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41326
om1_1        | 2021-08-11 23:18:20,256 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:20,775 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:20,775 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41332
om1_1        | 2021-08-11 23:18:20,776 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:21,445 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:21,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41338
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om2_1        | 2021-08-11 23:17:44,298 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:47,907 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:47,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39704
om2_1        | 2021-08-11 23:17:47,908 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:51,089 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om1_1        | 2021-08-11 23:18:21,447 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:22,309 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:22,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41346
om1_1        | 2021-08-11 23:18:22,310 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
om2_1        | 2021-08-11 23:17:51,089 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39722
om2_1        | 2021-08-11 23:17:51,091 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:51,562 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:51,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39728
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
om1_1        | 2021-08-11 23:18:22,916 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:22,917 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41362
om1_1        | 2021-08-11 23:18:22,918 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:26,129 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:26,129 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41376
om1_1        | 2021-08-11 23:18:26,141 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om2_1        | 2021-08-11 23:17:51,567 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:52,423 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:52,424 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39748
om2_1        | 2021-08-11 23:17:52,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:52,947 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om1_1        | 2021-08-11 23:18:26,840 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:26,841 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41384
om1_1        | 2021-08-11 23:18:26,843 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:27,358 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:27,358 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41390
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
om2_1        | 2021-08-11 23:17:52,947 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39756
om2_1        | 2021-08-11 23:17:52,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:53,460 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:53,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39762
om1_1        | 2021-08-11 23:18:27,364 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:27,921 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:27,921 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41396
om1_1        | 2021-08-11 23:18:27,922 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:28,510 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
om2_1        | 2021-08-11 23:17:53,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:56,888 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43306
om2_1        | 2021-08-11 23:17:56,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:59,097 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:45,737 [qtp1275028674-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-39850, , key: 93532/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
om1_1        | 2021-08-11 23:18:28,512 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41412
om1_1        | 2021-08-11 23:18:28,513 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:59,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39794
om2_1        | 2021-08-11 23:17:59,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:17:59,560 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:17:59,561 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39800
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:986)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1096)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:725)
om1_1        | 2021-08-11 23:18:31,662 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:31,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41426
om1_1        | 2021-08-11 23:18:31,663 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:32,298 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:32,298 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41434
om2_1        | 2021-08-11 23:17:59,562 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:00,051 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:00,051 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39806
om2_1        | 2021-08-11 23:18:00,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:532)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om1_1        | 2021-08-11 23:18:32,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:32,871 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:32,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41442
om2_1        | 2021-08-11 23:18:03,180 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:03,181 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39822
om2_1        | 2021-08-11 23:18:03,182 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:03,656 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:03,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39830
om2_1        | 2021-08-11 23:18:03,660 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:06,792 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om1_1        | 2021-08-11 23:18:32,873 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:33,460 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:33,460 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41448
om1_1        | 2021-08-11 23:18:33,465 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:34,156 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:34,156 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41456
om1_1        | 2021-08-11 23:18:34,160 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:06,792 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39856
om2_1        | 2021-08-11 23:18:06,793 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:07,260 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:07,260 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39862
om2_1        | 2021-08-11 23:18:07,267 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om1_1        | 2021-08-11 23:18:39,937 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58460
om1_1        | 2021-08-11 23:18:39,968 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:42,858 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:42,859 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41518
om1_1        | 2021-08-11 23:18:42,861 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:10,437 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:10,437 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39914
om2_1        | 2021-08-11 23:18:10,438 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:10,908 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:10,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39920
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om1_1        | 2021-08-11 23:18:43,428 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:18:43,428 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41524
om1_1        | 2021-08-11 23:18:43,429 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:18:46,602 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:10,909 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:11,378 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:11,378 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39926
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om1_1        | 2021-08-11 23:18:46,603 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41560
om1_1        | 2021-08-11 23:18:46,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om2_1        | 2021-08-11 23:18:11,379 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:11,844 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:11,854 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39934
om2_1        | 2021-08-11 23:18:11,855 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:19:47,429 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:19:47,430 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41816
om1_1        | 2021-08-11 23:19:47,431 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:12,332 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:12,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39940
om2_1        | 2021-08-11 23:18:12,341 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:15,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43482
om2_1        | 2021-08-11 23:18:15,475 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:17,830 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:17,831 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39970
om1_1        | 2021-08-11 23:20:47,766 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:20:47,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42076
om1_1        | 2021-08-11 23:20:47,768 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:21:48,220 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:21:48,221 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42332
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 2021-08-11 23:21:48,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:22:48,315 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om2_1        | 2021-08-11 23:18:17,835 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:22:48,315 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42596
om1_1        | 2021-08-11 23:22:48,316 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:18,313 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 2021-08-11 23:23:47,971 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59812
om1_1        | 2021-08-11 23:23:48,004 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:23:51,103 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:23:51,104 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42874
om1_1        | 2021-08-11 23:23:51,104 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:23:51,608 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:18,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39976
om2_1        | 2021-08-11 23:18:18,313 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:19,102 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:19,102 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39988
om2_1        | 2021-08-11 23:18:19,104 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
om2_1        | 2021-08-11 23:18:19,662 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:19,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39996
om2_1        | 2021-08-11 23:18:19,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:20,260 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:20,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40004
om2_1        | 2021-08-11 23:18:20,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:20,780 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:20,780 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40010
om1_1        | 2021-08-11 23:23:51,609 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42882
om1_1        | 2021-08-11 23:23:51,609 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:23:54,851 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:23:54,851 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42908
om1_1        | 2021-08-11 23:23:54,852 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:23:55,343 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om1_1        | 2021-08-11 23:23:55,343 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42914
om1_1        | 2021-08-11 23:23:55,345 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:20,781 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:21,451 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:21,452 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40016
om2_1        | 2021-08-11 23:18:21,460 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:22,314 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om1_1        | 2021-08-11 23:23:55,921 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:23:55,922 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42922
om1_1        | 2021-08-11 23:23:55,922 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:23:56,600 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:23:56,601 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42928
om1_1        | 2021-08-11 23:23:56,606 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:22,314 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40024
om2_1        | 2021-08-11 23:18:22,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om1_1        | 2021-08-11 23:23:57,236 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:23:57,237 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42938
om1_1        | 2021-08-11 23:23:57,237 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:23:57,763 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:23:57,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42948
om1_1        | 2021-08-11 23:23:57,772 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:22,921 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:22,921 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40040
om2_1        | 2021-08-11 23:18:22,922 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:26,144 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:26,145 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40054
om2_1        | 2021-08-11 23:18:26,145 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om1_1        | 2021-08-11 23:23:58,413 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:23:58,414 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42958
om1_1        | 2021-08-11 23:23:58,414 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:23:59,020 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:23:59,020 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42966
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
om2_1        | 2021-08-11 23:18:26,845 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:26,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40062
om2_1        | 2021-08-11 23:18:26,850 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:27,367 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:27,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40068
om1_1        | 2021-08-11 23:23:59,021 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:23:59,571 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
om1_1        | 2021-08-11 23:23:59,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42972
om1_1        | 2021-08-11 23:23:59,575 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:27,372 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:27,925 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:27,926 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40074
om2_1        | 2021-08-11 23:18:27,933 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:28,516 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:28,516 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40090
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:45,739 [qtp1275028674-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
om1_1        | 2021-08-11 23:24:00,167 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:00,168 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42982
om1_1        | 2021-08-11 23:24:00,170 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:00,959 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:00,960 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43000
om1_1        | 2021-08-11 23:24:00,962 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:28,518 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:31,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:31,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40104
om2_1        | 2021-08-11 23:18:31,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:32,302 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>93532/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
om1_1        | 2021-08-11 23:24:01,500 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:01,501 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43010
om1_1        | 2021-08-11 23:24:01,502 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:02,088 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:02,089 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43018
om2_1        | 2021-08-11 23:18:32,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40112
om2_1        | 2021-08-11 23:18:32,311 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:32,876 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:32,877 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40120
om2_1        | 2021-08-11 23:18:32,877 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:33,470 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:02,093 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:02,700 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:02,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43026
om1_1        | 2021-08-11 23:24:02,701 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:03,312 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:03,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43036
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om2_1        | 2021-08-11 23:18:33,470 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40126
om2_1        | 2021-08-11 23:18:33,478 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:34,163 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:34,164 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40134
om2_1        | 2021-08-11 23:18:34,169 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:40,017 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43708
om2_1        | 2021-08-11 23:18:40,027 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:42,864 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:42,864 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40196
om2_1        | 2021-08-11 23:18:42,872 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:43,432 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:43,433 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40202
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om1_1        | 2021-08-11 23:24:03,316 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:03,935 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:03,935 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43046
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om1_1        | 2021-08-11 23:24:03,936 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:04,528 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:04,528 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43056
om1_1        | 2021-08-11 23:24:04,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:05,014 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om2_1        | 2021-08-11 23:18:43,433 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:18:46,607 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:18:46,607 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40238
om2_1        | 2021-08-11 23:18:46,610 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:19:47,434 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:19:47,435 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40494
om1_1        | 2021-08-11 23:24:05,014 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43062
om1_1        | 2021-08-11 23:24:05,017 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:05,523 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:05,524 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43068
om1_1        | 2021-08-11 23:24:05,524 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:11,082 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60074
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
om2_1        | 2021-08-11 23:19:47,436 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:20:47,770 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:11,114 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-08-11 23:24:14,713 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om1_1        | 2021-08-11 23:24:14,713 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43134
om2_1        | 2021-08-11 23:20:47,771 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40754
om2_1        | 2021-08-11 23:20:47,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:21:46,729 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:21:46,729 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40994
om1_1        | 2021-08-11 23:24:14,718 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om2_1        | 2021-08-11 23:21:46,731 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:21:48,227 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:21:48,228 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41010
om2_1        | 2021-08-11 23:21:48,229 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:22:47,591 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:22:47,591 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41260
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om2_1        | 2021-08-11 23:22:47,597 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:22:48,320 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:22:48,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41274
om2_1        | 2021-08-11 23:22:48,321 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:48,026 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:48,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41528
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om2_1        | 2021-08-11 23:23:48,029 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:48,089 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45062
om2_1        | 2021-08-11 23:23:48,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:51,107 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:51,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41552
om2_1        | 2021-08-11 23:23:51,108 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:51,612 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:51,612 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41560
om2_1        | 2021-08-11 23:23:51,613 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:54,854 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:54,855 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41586
om2_1        | 2021-08-11 23:23:54,855 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:55,351 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:55,352 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41592
om2_1        | 2021-08-11 23:23:55,357 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:55,931 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om2_1        | 2021-08-11 23:23:55,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41600
om2_1        | 2021-08-11 23:23:55,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:56,610 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:56,610 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41606
om2_1        | 2021-08-11 23:23:56,617 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:57,240 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:57,241 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41616
om2_1        | 2021-08-11 23:23:57,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om2_1        | 2021-08-11 23:23:57,775 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:57,776 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41626
om2_1        | 2021-08-11 23:23:57,776 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:58,418 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:58,418 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41636
om2_1        | 2021-08-11 23:23:58,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:59,023 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:59,024 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41644
om2_1        | 2021-08-11 23:23:59,024 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:23:59,578 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:23:59,578 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41650
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:56,090 [qtp1275028674-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-39850, , key: 93532/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-39850/93532/multipartKey3-a7704d43-a5ee-491b-a176-bcb705bef0f0-106740043265540128-1
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:986)
om2_1        | 2021-08-11 23:23:59,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:00,175 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:00,176 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41660
om2_1        | 2021-08-11 23:24:00,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:00,965 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:00,965 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41678
om2_1        | 2021-08-11 23:24:00,966 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:01,505 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:01,505 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41688
om2_1        | 2021-08-11 23:24:01,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:02,096 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:02,096 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41696
om2_1        | 2021-08-11 23:24:02,097 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1096)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:725)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:532)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om2_1        | 2021-08-11 23:24:02,704 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:02,704 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41704
om2_1        | 2021-08-11 23:24:02,705 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:03,319 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:03,319 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41714
om2_1        | 2021-08-11 23:24:03,320 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:03,939 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:03,941 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41724
om2_1        | 2021-08-11 23:24:03,946 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om2_1        | 2021-08-11 23:24:04,534 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:04,534 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41734
om2_1        | 2021-08-11 23:24:04,535 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:05,022 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:05,023 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41740
om2_1        | 2021-08-11 23:24:05,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:05,527 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:05,527 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41746
om2_1        | 2021-08-11 23:24:05,528 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:11,213 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45322
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
om2_1        | 2021-08-11 23:24:11,227 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-08-11 23:24:14,723 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 400d1e2794477ee4b60a7f4ce5feccb5b27872784b42e1268784385ecc3ea9f3
om2_1        | 2021-08-11 23:24:14,723 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41812
om2_1        | 2021-08-11 23:24:14,727 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:56,091 [qtp1275028674-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>93532/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:56,581 [qtp1275028674-19] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-39850, , key: 93532/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-39850/93532/multipartKey3-a7704d43-a5ee-491b-a176-bcb705bef0f0-106740043265540128-2
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:986)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1096)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:725)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:532)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:56,583 [qtp1275028674-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>93532/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:57,072 [qtp1275028674-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-39850, , key: 93532/multipartKey3
s3g_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-39850 key: 93532/multipartKey3 because parts are in Invalid order.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:613)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:986)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1096)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:725)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:532)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:16:57,074 [qtp1275028674-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPartOrder</Code>
s3g_1        |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
s3g_1        |   <Resource>93532/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:97)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:17:00,153 [qtp1275028674-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:17:00,635 [qtp1275028674-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:17:43,289 [qtp1275028674-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-39850/95013/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:17:43,803 [qtp1275028674-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-39850/95013/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:17:59,107 [qtp1275028674-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-21068, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:17:59,115 [qtp1275028674-20] INFO endpoint.BucketEndpoint: Location is /bucket-21068
s3g_1        | 2021-08-11 23:17:59,565 [qtp1275028674-21] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-56981, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:17:59,577 [qtp1275028674-21] INFO endpoint.BucketEndpoint: Location is /destbucket-56981
s3g_1        | 2021-08-11 23:18:10,914 [qtp1275028674-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:18:11,384 [qtp1275028674-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:18:12,348 [qtp1275028674-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchKey</Code>
s3g_1        |   <Message>The specified key does not exist</Message>
s3g_1        |   <Resource>nonnonexistentkey</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:18:17,841 [qtp1275028674-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-87217, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:18:17,852 [qtp1275028674-21] INFO endpoint.BucketEndpoint: Location is /bucket-87217
s3g_1        | 2021-08-11 23:18:34,174 [qtp1275028674-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>bucket-87217-nosuchbucket</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:18:42,878 [qtp1275028674-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-63172, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:18:42,894 [qtp1275028674-21] INFO endpoint.BucketEndpoint: Location is /bucket-63172
s3g_1        | 2021-08-11 23:21:46,710 [qtp1275028674-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #192 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:529)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:543)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:130)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:226)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #192 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-08-11 23:21:46,718 [qtp1275028674-20] INFO scm.XceiverClientRatis: Could not commit index 130 on pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]] to all the nodes. Server 97333428-a9dc-49fc-bc54-326166febdda has failed. Committed by majority.
s3g_1        | 2021-08-11 23:21:46,718 [qtp1275028674-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 107544261427200049 bcsId: 130 on Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]]. Failed nodes: [97333428-a9dc-49fc-bc54-326166febdda{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-08-11 23:22:47,576 [qtp1275028674-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #196 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:529)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:543)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:130)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:226)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #196 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-08-11 23:22:47,585 [qtp1275028674-22] INFO scm.XceiverClientRatis: Could not commit index 135 on pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]] to all the nodes. Server 97333428-a9dc-49fc-bc54-326166febdda has failed. Committed by majority.
s3g_1        | 2021-08-11 23:22:47,585 [qtp1275028674-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 107544261427200050 bcsId: 135 on Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]]. Failed nodes: [97333428-a9dc-49fc-bc54-326166febdda{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-08-11 23:23:47,998 [qtp1275028674-19] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #200 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:529)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:543)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:130)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:503)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:477)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:530)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:226)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #200 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2021-08-11 23:23:48,008 [qtp1275028674-19] INFO scm.XceiverClientRatis: Could not commit index 138 on pipeline Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]] to all the nodes. Server 97333428-a9dc-49fc-bc54-326166febdda has failed. Committed by majority.
s3g_1        | 2021-08-11 23:23:48,008 [qtp1275028674-19] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 107544261427200051 bcsId: 138 on Pipeline[ Id: e8fee977-3a11-4948-b60e-6fa1826e58a5, Nodes: fb8d185f-2f23-4800-ba90-a65832b06bb3{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}95d91451-f44f-4fa4-a508-c399bd523c99{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97333428-a9dc-49fc-bc54-326166febdda{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:95d91451-f44f-4fa4-a508-c399bd523c99, CreationTimestamp2021-08-11T23:09:13.939Z[UTC]]. Failed nodes: [97333428-a9dc-49fc-bc54-326166febdda{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2021-08-11 23:23:51,111 [qtp1275028674-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-24269, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:23:51,124 [qtp1275028674-17] INFO endpoint.BucketEndpoint: Location is /bucket-24269
s3g_1        | 2021-08-11 23:23:59,035 [qtp1275028674-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=10000-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:24:04,542 [qtp1275028674-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-0</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:24:05,041 [qtp1275028674-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-1</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:24:05,548 [qtp1275028674-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1668)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-08-11 23:24:14,736 [qtp1275028674-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-65039, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-08-11 23:24:14,743 [qtp1275028674-17] INFO endpoint.BucketEndpoint: Location is /bucket-65039
