Attaching to ozonesecure-ha_om1_1, ozonesecure-ha_s3g_1, ozonesecure-ha_om3_1, ozonesecure-ha_om2_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_kms_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_kdc_1, ozonesecure-ha_recon_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_datanode2_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2021-11-25 07:50:46,545 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = bf0b5f0c901d/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2021-11-25 07:50:46,387 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 2c7bc09527e7/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
datanode2_1  | STARTUP_MSG:   java = 11.0.10
datanode2_1  | ************************************************************/
datanode2_1  | 2021-11-25 07:50:46,523 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2021-11-25 07:50:49,069 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2021-11-25 07:50:50,200 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2021-11-25 07:50:51,768 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2021-11-25 07:50:51,770 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2021-11-25 07:50:53,191 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2c7bc09527e7 ip:172.25.0.103
datanode2_1  | 2021-11-25 07:50:58,124 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-11-25 07:50:59,748 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2021-11-25 07:50:59,766 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2021-11-25 07:51:02,911 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2021-11-25 07:51:02,929 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2021-11-25 07:51:02,932 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2021-11-25 07:51:02,935 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2021-11-25 07:51:13,607 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2021-11-25 07:51:13,853 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:2c7bc09527e7
datanode2_1  | 2021-11-25 07:51:13,853 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2021-11-25 07:51:13,982 [main] ERROR client.DNCertificateClient: Invalid domain 2c7bc09527e7
datanode2_1  | 2021-11-25 07:51:13,983 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@2c7bc09527e7
datanode2_1  | 2021-11-25 07:51:21,588 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2021-11-25 07:51:21,675 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/8112927771086.crt.
datanode2_1  | 2021-11-25 07:51:21,705 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2021-11-25 07:51:21,765 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-7981323859056.crt.
datanode2_1  | 2021-11-25 07:51:21,765 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2021-11-25 07:51:22,018 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode2_1  | 2021-11-25 07:51:23,787 [main] INFO reflections.Reflections: Reflections took 1271 ms to scan 2 urls, producing 85 keys and 173 values 
datanode2_1  | 2021-11-25 07:51:24,702 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2021-11-25 07:51:26,759 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2021-11-25 07:51:26,867 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2021-11-25 07:51:26,950 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2021-11-25 07:51:26,952 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2021-11-25 07:51:27,377 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2021-11-25 07:51:27,529 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-11-25 07:51:27,540 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2021-11-25 07:51:27,541 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2021-11-25 07:51:27,542 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2021-11-25 07:51:27,543 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
datanode1_1  | STARTUP_MSG:   java = 11.0.10
datanode1_1  | ************************************************************/
datanode1_1  | 2021-11-25 07:50:46,635 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2021-11-25 07:50:49,089 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2021-11-25 07:50:50,320 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2021-11-25 07:50:51,959 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2021-11-25 07:50:51,968 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2021-11-25 07:50:53,510 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:bf0b5f0c901d ip:172.25.0.102
datanode1_1  | 2021-11-25 07:50:59,090 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-11-25 07:51:00,851 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2021-11-25 07:51:00,866 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2021-11-25 07:51:03,939 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2021-11-25 07:51:03,942 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2021-11-25 07:51:03,960 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2021-11-25 07:51:03,963 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2021-11-25 07:51:09,366 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2021-11-25 07:51:09,481 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:bf0b5f0c901d
datanode1_1  | 2021-11-25 07:51:09,514 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2021-11-25 07:51:09,548 [main] ERROR client.DNCertificateClient: Invalid domain bf0b5f0c901d
datanode1_1  | 2021-11-25 07:51:09,562 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@bf0b5f0c901d
datanode1_1  | 2021-11-25 07:51:19,397 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2021-11-25 07:51:19,511 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/8109713599631.crt.
datanode1_1  | 2021-11-25 07:51:19,569 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2021-11-25 07:51:19,600 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-7981323859056.crt.
datanode1_1  | 2021-11-25 07:51:19,610 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2021-11-25 07:51:19,840 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode1_1  | 2021-11-25 07:51:21,400 [main] INFO reflections.Reflections: Reflections took 1144 ms to scan 2 urls, producing 85 keys and 173 values 
datanode1_1  | 2021-11-25 07:51:22,391 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2021-11-25 07:51:24,247 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2021-11-25 07:51:24,415 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2021-11-25 07:51:24,479 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2021-11-25 07:51:24,486 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2021-11-25 07:51:24,923 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2021-11-25 07:51:25,258 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-11-25 07:51:25,288 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2021-11-25 07:51:25,303 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2021-11-25 07:51:25,304 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2021-11-25 07:51:25,304 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2021-11-25 07:51:25,795 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2021-11-25 07:51:25,813 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2021-11-25 07:51:35,647 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-11-25 07:51:36,622 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2021-11-25 07:51:37,959 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2021-11-25 07:51:37,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2021-11-25 07:51:37,999 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2021-11-25 07:51:38,010 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2021-11-25 07:51:38,015 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-11-25 07:51:38,023 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2021-11-25 07:51:38,044 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-11-25 07:51:47,634 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2021-11-25 07:51:47,748 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-11-25 07:51:47,751 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-11-25 07:51:47,873 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-11-25 07:51:51,504 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2021-11-25 07:51:27,779 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2021-11-25 07:51:27,805 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2021-11-25 07:51:38,175 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-11-25 07:51:38,909 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2021-11-25 07:51:40,374 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2021-11-25 07:51:40,415 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2021-11-25 07:51:40,465 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2021-11-25 07:51:40,477 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2021-11-25 07:51:40,511 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-11-25 07:51:40,512 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2021-11-25 07:51:40,525 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-11-25 07:51:49,564 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2021-11-25 07:51:49,572 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-11-25 07:51:49,587 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-11-25 07:51:49,691 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-11-25 07:51:53,188 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2021-11-25 07:51:53,188 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2021-11-25 07:51:53,201 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2021-11-25 07:51:53,577 [main] INFO util.log: Logging initialized @79035ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2021-11-25 07:51:54,733 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2021-11-25 07:51:54,796 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2021-11-25 07:51:54,830 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2021-11-25 07:51:54,830 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2021-11-25 07:51:54,830 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2021-11-25 07:51:54,851 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2021-11-25 07:51:55,278 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2021-11-25 07:51:55,304 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode2_1  | 2021-11-25 07:51:55,771 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2021-11-25 07:51:55,811 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2021-11-25 07:51:55,826 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2021-11-25 07:51:56,118 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-11-25 07:51:56,149 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@e196238{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2021-11-25 07:51:56,162 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6c2063e0{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2021-11-25 07:51:57,150 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-11-25 07:51:57,251 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4ab959e8{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-12047329997216167141/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2021-11-25 07:51:57,322 [main] INFO server.AbstractConnector: Started ServerConnector@43600de0{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2021-11-25 07:51:57,322 [main] INFO server.Server: Started @82781ms
datanode2_1  | 2021-11-25 07:51:57,341 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2021-11-25 07:51:57,346 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2021-11-25 07:51:57,350 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2021-11-25 07:51:57,377 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2021-11-25 07:51:57,522 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73f9afd8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2021-11-25 07:51:58,241 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2021-11-25 07:52:01,402 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2021-11-25 07:52:01,423 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2021-11-25 07:52:01,742 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode2_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode1_1  | 2021-11-25 07:51:51,510 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2021-11-25 07:51:51,510 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2021-11-25 07:51:51,792 [main] INFO util.log: Logging initialized @77770ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2021-11-25 07:51:52,765 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2021-11-25 07:51:52,828 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2021-11-25 07:51:52,851 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2021-11-25 07:51:52,859 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2021-11-25 07:51:52,859 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2021-11-25 07:51:52,875 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2021-11-25 07:51:53,206 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2021-11-25 07:51:53,208 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode1_1  | 2021-11-25 07:51:53,435 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2021-11-25 07:51:53,439 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2021-11-25 07:51:53,458 [main] INFO server.session: node0 Scavenging every 660000ms
datanode1_1  | 2021-11-25 07:51:53,572 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-11-25 07:51:53,614 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@20c55658{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2021-11-25 07:51:53,616 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44f5259a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2021-11-25 07:51:54,722 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-11-25 07:51:54,857 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@52d68eb9{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-16992076364672816928/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2021-11-25 07:51:54,961 [main] INFO server.AbstractConnector: Started ServerConnector@2dedde74{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2021-11-25 07:51:54,963 [main] INFO server.Server: Started @80941ms
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:633)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:280)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:468)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	... 1 more
datanode2_1  | 2021-11-25 07:52:02,677 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 0950a55d-429f-4438-94ab-c48b091ad805
datanode2_1  | 2021-11-25 07:52:02,948 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 0950a55d-429f-4438-94ab-c48b091ad805: start RPC server
datanode2_1  | 2021-11-25 07:52:02,963 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 0950a55d-429f-4438-94ab-c48b091ad805: GrpcService started, listening on 9856
datanode2_1  | 2021-11-25 07:52:02,988 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 0950a55d-429f-4438-94ab-c48b091ad805: GrpcService started, listening on 9857
datanode2_1  | 2021-11-25 07:52:02,994 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 0950a55d-429f-4438-94ab-c48b091ad805: GrpcService started, listening on 9858
datanode2_1  | 2021-11-25 07:52:03,004 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0950a55d-429f-4438-94ab-c48b091ad805 is started using port 9858 for RATIS
datanode2_1  | 2021-11-25 07:52:03,004 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0950a55d-429f-4438-94ab-c48b091ad805 is started using port 9857 for RATIS_ADMIN
kdc_1        | Nov 25 07:48:14 kdc krb5kdc[7](info): Loaded
kdc_1        | Nov 25 07:48:14 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Nov 25 07:48:14 kdc krb5kdc[7](info): setting up network...
kdc_1        | Nov 25 07:48:14 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Nov 25 07:48:14 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Nov 25 07:48:14 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Nov 25 07:48:14 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Nov 25 07:48:23 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1637826503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:48:36 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1637826516, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:48:50 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1637826530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:49:16 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1637826556, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:49:21 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1637826561, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:49:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1637826530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:49:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1637826556, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:49:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1637826503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:49:36 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1637826576, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:49:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1637826576, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:49:50 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1637826590, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:49:52 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1637826592, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:50:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1637826590, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:50:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1637826592, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:50:07 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1637826607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:50:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1637826607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:50:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1637826611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode1_1  | 2021-11-25 07:51:54,976 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2021-11-25 07:51:54,976 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2021-11-25 07:51:54,978 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2021-11-25 07:51:55,023 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2021-11-25 07:51:55,540 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@416a0426] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2021-11-25 07:51:56,155 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2021-11-25 07:52:01,239 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2021-11-25 07:52:01,271 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2021-11-25 07:52:02,855 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 20a284f6-c8a8-496d-9157-8df5a2a17913
datanode1_1  | 2021-11-25 07:52:03,315 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 20a284f6-c8a8-496d-9157-8df5a2a17913: start RPC server
datanode1_1  | 2021-11-25 07:52:03,330 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 20a284f6-c8a8-496d-9157-8df5a2a17913: GrpcService started, listening on 9856
datanode1_1  | 2021-11-25 07:52:03,347 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 20a284f6-c8a8-496d-9157-8df5a2a17913: GrpcService started, listening on 9857
datanode1_1  | 2021-11-25 07:52:03,360 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 20a284f6-c8a8-496d-9157-8df5a2a17913: GrpcService started, listening on 9858
datanode1_1  | 2021-11-25 07:52:03,389 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 20a284f6-c8a8-496d-9157-8df5a2a17913 is started using port 9858 for RATIS
datanode1_1  | 2021-11-25 07:52:03,394 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 20a284f6-c8a8-496d-9157-8df5a2a17913 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2021-11-25 07:52:03,390 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$339/0x00000008405d8c40@25a1d3ab] INFO util.JvmPauseMonitor: JvmPauseMonitor-20a284f6-c8a8-496d-9157-8df5a2a17913: Started
datanode1_1  | 2021-11-25 07:52:03,396 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 20a284f6-c8a8-496d-9157-8df5a2a17913 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2021-11-25 07:52:03,457 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-11-25 07:52:03,457 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-11-25 07:52:03,023 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0950a55d-429f-4438-94ab-c48b091ad805 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2021-11-25 07:52:03,063 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$339/0x00000008405d8c40@700aad6e] INFO util.JvmPauseMonitor: JvmPauseMonitor-0950a55d-429f-4438-94ab-c48b091ad805: Started
datanode2_1  | 2021-11-25 07:52:03,167 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-11-25 07:52:03,167 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
kdc_1        | Nov 25 07:50:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1637826611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:50:23 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1637826623, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:50:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1637826628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:50:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1637826623, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:50:58 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1637826658, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:50:59 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1637826659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:51:00 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1637826660, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:51:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1637826628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:51:05 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1637826665, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:51:06 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1637826666, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:51:06 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1637826666, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:51:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1637826665, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:51:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1637826666, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:51:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1637826666, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:51:14 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1637826674, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:51:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1637826660, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2021-11-25 07:50:45,548 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = f7a87fafecdb/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
kdc_1        | Nov 25 07:51:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1637826658, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:51:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1637826659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:51:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1637826660, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Nov 25 07:51:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1637826658, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Nov 25 07:52:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1637826659, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Nov 25 07:52:01 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1637826721, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:52:02 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1637826722, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:52:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1637826674, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:52:02 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1637826722, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:52:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1637826721, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:52:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1637826722, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:52:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1637826722, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Nov 25 07:52:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1637826732, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Nov 25 07:52:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1637826530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Nov 25 07:52:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1637826732, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
datanode3_1  | STARTUP_MSG:   java = 11.0.10
datanode3_1  | ************************************************************/
datanode3_1  | 2021-11-25 07:50:45,719 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2021-11-25 07:50:48,516 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2021-11-25 07:50:49,680 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2021-11-25 07:50:51,254 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2021-11-25 07:50:51,266 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2021-11-25 07:50:52,724 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f7a87fafecdb ip:172.25.0.104
datanode3_1  | 2021-11-25 07:50:57,470 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-11-25 07:50:59,176 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2021-11-25 07:50:59,176 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2021-11-25 07:51:02,501 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2021-11-25 07:51:02,532 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2021-11-25 07:51:02,538 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2021-11-25 07:51:02,547 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2021-11-25 07:51:11,776 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2021-11-25 07:51:11,900 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:f7a87fafecdb
datanode3_1  | 2021-11-25 07:51:11,910 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2021-11-25 07:51:11,946 [main] ERROR client.DNCertificateClient: Invalid domain f7a87fafecdb
datanode3_1  | 2021-11-25 07:51:11,952 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@f7a87fafecdb
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode3_1  | 2021-11-25 07:51:19,908 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2021-11-25 07:51:20,041 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/8111158445552.crt.
datanode3_1  | 2021-11-25 07:51:20,139 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2021-11-25 07:51:20,182 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-7981323859056.crt.
datanode3_1  | 2021-11-25 07:51:20,198 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2021-11-25 07:51:20,348 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode3_1  | 2021-11-25 07:51:21,751 [main] INFO reflections.Reflections: Reflections took 1093 ms to scan 2 urls, producing 85 keys and 173 values 
datanode3_1  | 2021-11-25 07:51:22,624 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2021-11-25 07:51:24,488 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2021-11-25 07:51:24,588 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2021-11-25 07:51:24,596 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2021-11-25 07:48:31,000 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:23Z
recon_1      | STARTUP_MSG:   java = 11.0.10
recon_1      | ************************************************************/
recon_1      | 2021-11-25 07:48:31,185 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2021-11-25 07:48:41,960 [main] INFO reflections.Reflections: Reflections took 704 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1      | 2021-11-25 07:48:48,565 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2021-11-25 07:48:49,152 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2021-11-25 07:48:50,456 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2021-11-25 07:48:50,462 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2021-11-25 07:48:51,360 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-11-25 07:48:55,233 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2021-11-25 07:48:56,639 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-11-25 07:48:56,724 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2021-11-25 07:48:56,725 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2021-11-25 07:49:01,241 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2021-11-25 07:49:01,250 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2021-11-25 07:49:01,251 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2021-11-25 07:49:01,275 [main] INFO util.log: Logging initialized @41364ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2021-11-25 07:49:01,739 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2021-11-25 07:49:01,777 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2021-11-25 07:49:01,790 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2021-11-25 07:49:01,802 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2021-11-25 07:49:01,803 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2021-11-25 07:49:01,820 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2021-11-25 07:49:02,268 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2021-11-25 07:49:03,398 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2021-11-25 07:49:03,419 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2021-11-25 07:49:03,433 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2021-11-25 07:49:03,579 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2021-11-25 07:49:05,766 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-11-25 07:49:06,524 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-11-25 07:49:06,676 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2021-11-25 07:49:06,678 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2021-11-25 07:49:06,946 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-11-25 07:49:07,331 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-11-25 07:50:48,703 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:23Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-11-25 07:50:48,808 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-11-25 07:51:03,611 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-11-25 07:51:05,019 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-11-25 07:51:05,020 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-11-25 07:51:05,020 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-11-25 07:51:08,095 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2021-11-25 07:51:08,098 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-11-25 07:51:08,240 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-11-25 07:51:14,139 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2021-11-25 07:51:19,700 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2021-11-25 07:51:19,717 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2021-11-25 07:51:19,719 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2021-11-25 07:51:24,290 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2021-11-25 07:51:24,902 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2021-11-25 07:51:24,906 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2021-11-25 07:51:24,917 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2021-11-25 07:51:24,920 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-11-25 07:51:24,928 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-11-25 07:51:24,934 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-11-25 07:51:24,937 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-11-25 07:51:24,955 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:d1137d26-6502-410a-9479-0d2074af0cec,clusterId:CID-2f16d919-03be-44c6-8b84-cfad39a678e5,subject:om3
om3_1        | 2021-11-25 07:51:26,393 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2021-11-25 07:51:29,585 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-2f16d919-03be-44c6-8b84-cfad39a678e5;layoutVersion=0
om3_1        | 2021-11-25 07:51:29,959 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-11-25 07:51:43,926 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2021-11-25 07:48:37,333 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2021-11-25 07:48:37,341 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2021-11-25 07:48:38,437 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2021-11-25 07:48:38,437 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2021-11-25 07:48:38,454 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2021-11-25 07:48:39,059 [main] INFO util.log: Logging initialized @19316ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2021-11-25 07:48:40,779 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2021-11-25 07:48:40,902 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2021-11-25 07:48:40,930 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2021-11-25 07:48:40,930 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2021-11-25 07:48:40,930 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2021-11-25 07:48:41,222 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2021-11-25 07:48:42,063 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:23Z
s3g_1        | STARTUP_MSG:   java = 11.0.10
s3g_1        | ************************************************************/
s3g_1        | 2021-11-25 07:48:42,175 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2021-11-25 07:48:42,617 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2021-11-25 07:48:42,720 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2021-11-25 07:48:42,763 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
s3g_1        | 2021-11-25 07:48:43,456 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2021-11-25 07:48:43,456 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2021-11-25 07:48:43,495 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1        | 2021-11-25 07:48:44,006 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2021-11-25 07:48:44,109 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a66a204{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2021-11-25 07:48:44,130 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2c7d121c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2021-11-25 07:48:56,704 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Nov 25, 2021 7:49:01 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2021-11-25 07:49:01,153 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@790654d5{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-10906114927736834607/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2021-11-25 07:49:01,225 [main] INFO server.AbstractConnector: Started ServerConnector@452ba1db{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2021-11-25 07:49:01,225 [main] INFO server.Server: Started @41483ms
s3g_1        | 2021-11-25 07:49:01,236 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
datanode3_1  | 2021-11-25 07:51:24,603 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2021-11-25 07:51:24,919 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2021-11-25 07:51:25,152 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-11-25 07:51:25,198 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2021-11-25 07:51:25,206 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2021-11-25 07:51:25,208 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2021-11-25 07:51:25,210 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2021-11-25 07:51:25,546 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2021-11-25 07:51:25,563 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2021-11-25 07:51:35,864 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-11-25 07:51:36,788 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2021-11-25 07:51:37,934 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2021-11-25 07:51:37,940 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2021-11-25 07:51:37,945 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2021-11-25 07:51:37,982 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2021-11-25 07:51:37,985 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-11-25 07:51:37,998 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2021-11-25 07:51:38,016 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-11-25 07:51:48,510 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2021-11-25 07:51:48,527 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-11-25 07:51:48,536 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-11-25 07:51:48,637 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-11-25 07:51:51,530 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2021-11-25 07:51:51,534 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2021-11-25 07:51:51,534 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2021-11-25 07:51:51,882 [main] INFO util.log: Logging initialized @78245ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2021-11-25 07:51:52,815 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2021-11-25 07:51:52,857 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2021-11-25 07:51:52,875 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2021-11-25 07:51:52,880 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2021-11-25 07:51:52,898 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2021-11-25 07:51:52,976 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2021-11-25 07:51:53,337 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2021-11-25 07:51:53,343 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
datanode3_1  | 2021-11-25 07:51:53,793 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2021-11-25 07:51:53,795 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2021-11-25 07:51:53,815 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2021-11-25 07:51:54,060 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-11-25 07:51:54,079 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@37bac0f4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2021-11-25 07:51:54,083 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@63f819a6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2021-11-25 07:51:55,256 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-11-25 07:51:55,432 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@13ac1657{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1658169282636259751/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2021-11-25 07:51:55,569 [main] INFO server.AbstractConnector: Started ServerConnector@125ed27{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2021-11-25 07:51:55,581 [main] INFO server.Server: Started @81945ms
datanode3_1  | 2021-11-25 07:51:55,601 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2021-11-25 07:51:55,601 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2021-11-25 07:51:55,604 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
recon_1      | 2021-11-25 07:49:07,484 [main] INFO reflections.Reflections: Reflections took 136 ms to scan 3 urls, producing 103 keys and 217 values 
recon_1      | 2021-11-25 07:49:07,627 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2021-11-25 07:49:07,741 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2021-11-25 07:49:07,777 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2021-11-25 07:49:07,825 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2021-11-25 07:49:07,947 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2021-11-25 07:49:08,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2021-11-25 07:49:08,196 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2021-11-25 07:49:08,451 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2021-11-25 07:49:08,451 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2021-11-25 07:49:08,680 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2021-11-25 07:49:08,742 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2021-11-25 07:49:08,742 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2021-11-25 07:49:09,468 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2021-11-25 07:49:09,470 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
recon_1      | 2021-11-25 07:49:09,526 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2021-11-25 07:49:09,526 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2021-11-25 07:49:09,531 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2021-11-25 07:49:09,569 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2021-11-25 07:49:09,590 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@673a9db4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2021-11-25 07:49:09,591 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5649f55{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2021-11-25 07:49:10,623 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2021-11-25 07:49:10,629 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2021-11-25 07:49:15,267 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5640a424{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-16005403745028998524/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2021-11-25 07:49:15,295 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@2cebf82f{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2021-11-25 07:49:15,295 [Listener at 0.0.0.0/9891] INFO server.Server: Started @55384ms
recon_1      | 2021-11-25 07:49:15,315 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2021-11-25 07:49:15,315 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2021-11-25 07:49:15,317 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2021-11-25 07:49:15,317 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2021-11-25 07:49:15,341 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2021-11-25 07:49:15,363 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2021-11-25 07:49:15,364 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2021-11-25 07:49:15,364 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-11-25 07:49:15,365 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2021-11-25 07:49:15,383 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2021-11-25 07:49:17,870 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:19,872 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:21,874 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-11-25 07:50:48,906 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:23Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-11-25 07:50:49,058 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-11-25 07:51:03,766 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-11-25 07:51:04,810 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-11-25 07:51:04,811 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-11-25 07:51:04,811 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-11-25 07:51:07,977 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2021-11-25 07:51:07,977 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-11-25 07:51:08,051 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-11-25 07:51:12,917 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2021-11-25 07:51:19,062 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2021-11-25 07:51:19,062 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2021-11-25 07:51:19,064 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2021-11-25 07:51:24,714 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2021-11-25 07:51:25,030 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2021-11-25 07:51:25,030 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2021-11-25 07:51:25,039 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2021-11-25 07:51:25,061 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-11-25 07:51:25,079 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-11-25 07:51:25,079 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-11-25 07:51:25,087 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-11-25 07:51:25,111 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:d1137d26-6502-410a-9479-0d2074af0cec,clusterId:CID-2f16d919-03be-44c6-8b84-cfad39a678e5,subject:om1
om1_1        | 2021-11-25 07:51:26,813 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2021-11-25 07:51:30,177 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-2f16d919-03be-44c6-8b84-cfad39a678e5;layoutVersion=0
om1_1        | 2021-11-25 07:51:30,468 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-11-25 07:51:44,388 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:23Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-11-25 07:51:44,047 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-11-25 07:51:55,463 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-11-25 07:51:56,164 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-11-25 07:51:56,173 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-11-25 07:51:56,175 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-11-25 07:51:56,307 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-11-25 07:51:56,693 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om3_1        | 2021-11-25 07:51:59,250 [main] INFO reflections.Reflections: Reflections took 1944 ms to scan 1 urls, producing 96 keys and 261 values [using 2 cores]
om3_1        | 2021-11-25 07:52:02,474 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2021-11-25 07:52:02,475 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-11-25 07:52:02,475 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-11-25 07:52:12,024 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2021-11-25 07:52:12,982 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/8121234991285.crt.
om3_1        | 2021-11-25 07:52:13,030 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2021-11-25 07:52:13,042 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-7981323859056.crt.
om3_1        | 2021-11-25 07:52:13,288 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-11-25 07:52:14,307 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-11-25 07:52:14,332 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-11-25 07:52:16,216 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2021-11-25 07:52:16,217 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2021-11-25 07:52:16,942 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2021-11-25 07:52:17,775 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-11-25 07:52:17,778 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2021-11-25 07:52:17,864 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2021-11-25 07:52:18,802 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2021-11-25 07:52:18,915 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-11-25 07:52:19,221 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2021-11-25 07:52:19,326 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2021-11-25 07:52:20,644 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2021-11-25 07:52:21,114 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2021-11-25 07:52:21,127 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-11-25 07:52:21,134 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2021-11-25 07:52:21,136 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-11-25 07:52:21,137 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-11-25 07:52:21,137 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2021-11-25 07:52:21,168 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-11-25 07:52:21,178 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2021-11-25 07:52:21,180 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-11-25 07:52:26,483 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2021-11-25 07:52:26,497 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-11-25 07:52:26,531 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-11-25 07:52:26,698 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-11-25 07:52:26,754 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@7be3baf2[Not completed]
om3_1        | 2021-11-25 07:52:26,758 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2021-11-25 07:52:26,894 [pool-24-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2021-11-25 07:52:27,004 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2021-11-25 07:52:27,018 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2021-11-25 07:52:27,019 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2021-11-25 07:52:27,019 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-11-25 07:52:27,019 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-11-25 07:52:27,020 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2021-11-25 07:52:27,021 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-11-25 07:52:27,081 [pool-24-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2021-11-25 07:52:27,122 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-11-25 07:52:27,192 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2021-11-25 07:52:27,236 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2021-11-25 07:52:27,245 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2021-11-25 07:52:27,247 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2021-11-25 07:52:27,346 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om3
om3_1        | 2021-11-25 07:52:27,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2021-11-25 07:52:27,758 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2021-11-25 07:52:27,771 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2021-11-25 07:52:27,792 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2021-11-25 07:52:27,907 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2021-11-25 07:52:27,914 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-11-25 07:52:28,127 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-11-25 07:52:28,143 [Listener at om3/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om3_1        | 2021-11-25 07:52:28,194 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2021-11-25 07:52:28,206 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2021-11-25 07:52:28,277 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-11-25 07:50:48,801 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:23Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-11-25 07:50:48,916 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-11-25 07:51:02,379 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-11-25 07:51:03,824 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-11-25 07:51:03,829 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-11-25 07:51:03,829 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-11-25 07:51:07,019 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2021-11-25 07:51:07,029 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-11-25 07:51:07,169 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-11-25 07:51:12,677 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2021-11-25 07:51:18,220 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2021-11-25 07:51:18,229 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2021-11-25 07:51:18,242 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2021-11-25 07:51:24,235 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2021-11-25 07:51:24,955 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2021-11-25 07:51:24,973 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2021-11-25 07:51:25,019 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2021-11-25 07:51:25,031 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-11-25 07:51:25,041 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-11-25 07:51:25,043 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-11-25 07:51:25,043 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-11-25 07:51:25,056 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:d1137d26-6502-410a-9479-0d2074af0cec,clusterId:CID-2f16d919-03be-44c6-8b84-cfad39a678e5,subject:om2
om2_1        | 2021-11-25 07:51:26,646 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2021-11-25 07:51:29,805 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-2f16d919-03be-44c6-8b84-cfad39a678e5;layoutVersion=0
om2_1        | 2021-11-25 07:51:30,020 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
recon_1      | 2021-11-25 07:49:23,876 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:25,880 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:28,730 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:d1137d26-6502-410a-9479-0d2074af0cec is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:245)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:164)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:56079)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:30,732 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:32,734 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:34,938 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2021-11-25 07:49:34,940 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2021-11-25 07:49:34,940 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2021-11-25 07:49:35,006 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2021-11-25 07:49:34,958 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2021-11-25 07:49:35,507 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2021-11-25 07:49:35,508 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2021-11-25 07:49:35,642 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2021-11-25 07:49:35,643 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2021-11-25 07:49:35,818 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2021-11-25 07:49:35,843 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2021-11-25 07:49:36,008 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2021-11-25 07:49:36,035 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 131 milliseconds.
recon_1      | 2021-11-25 07:49:36,215 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 505 milliseconds to process 0 existing database records.
recon_1      | 2021-11-25 07:49:36,231 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:36,245 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:36,375 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 160 milliseconds for processing 0 containers.
recon_1      | 2021-11-25 07:49:38,247 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:38,249 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
datanode3_1  | 2021-11-25 07:51:55,632 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2021-11-25 07:51:55,954 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@400ca30d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2021-11-25 07:51:56,513 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2021-11-25 07:52:01,316 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2021-11-25 07:52:01,325 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2021-11-25 07:52:02,483 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ece86bc6-b07b-4fda-a4d6-106fafa8b49c
datanode3_1  | 2021-11-25 07:52:02,857 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: ece86bc6-b07b-4fda-a4d6-106fafa8b49c: start RPC server
datanode3_1  | 2021-11-25 07:52:02,916 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: ece86bc6-b07b-4fda-a4d6-106fafa8b49c: GrpcService started, listening on 9856
datanode3_1  | 2021-11-25 07:52:02,921 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: ece86bc6-b07b-4fda-a4d6-106fafa8b49c: GrpcService started, listening on 9857
datanode3_1  | 2021-11-25 07:52:02,924 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: ece86bc6-b07b-4fda-a4d6-106fafa8b49c: GrpcService started, listening on 9858
datanode3_1  | 2021-11-25 07:52:02,957 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ece86bc6-b07b-4fda-a4d6-106fafa8b49c is started using port 9858 for RATIS
datanode3_1  | 2021-11-25 07:52:02,982 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ece86bc6-b07b-4fda-a4d6-106fafa8b49c is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2021-11-25 07:52:02,983 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ece86bc6-b07b-4fda-a4d6-106fafa8b49c is started using port 9856 for RATIS_SERVER
datanode3_1  | 2021-11-25 07:52:03,008 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$336/0x00000008405d8040@6ff4d875] INFO util.JvmPauseMonitor: JvmPauseMonitor-ece86bc6-b07b-4fda-a4d6-106fafa8b49c: Started
datanode3_1  | 2021-11-25 07:52:03,122 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-11-25 07:52:03,122 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-11-25 07:48:50,903 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
scm1.org_1   | 2021-11-25 07:48:51,027 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-11-25 07:48:51,884 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-11-25 07:48:52,375 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-11-25 07:48:52,386 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-11-25 07:48:52,873 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2021-11-25 07:48:52,887 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-11-25 07:48:52,992 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2021-11-25 07:48:57,331 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2021-11-25 07:48:57,350 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2021-11-25 07:48:57,378 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2021-11-25 07:49:00,813 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2021-11-25 07:49:07,523 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-11-25 07:49:07,523 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-11-25 07:49:07,856 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-11-25 07:49:07,856 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-11-25 07:49:07,857 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:d1137d26-6502-410a-9479-0d2074af0cec,clusterId:CID-2f16d919-03be-44c6-8b84-cfad39a678e5,subject:scm-sub@scm1.org
scm1.org_1   | 2021-11-25 07:49:08,120 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2021-11-25 07:49:08,425 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2021-11-25 07:49:08,628 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-11-25 07:49:08,629 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-11-25 07:49:08,634 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2021-11-25 07:49:08,635 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-11-25 07:49:08,635 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-11-25 07:49:08,638 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-11-25 07:49:08,645 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-11-25 07:49:08,662 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-11-25 07:49:08,664 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-11-25 07:49:09,346 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-11-25 07:49:09,348 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-11-25 07:49:09,348 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-11-25 07:49:09,395 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-11-25 07:49:09,430 [main] INFO server.RaftServer: d1137d26-6502-410a-9479-0d2074af0cec: addNew group-CFAD39A678E5:[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|priority:0] returns group-CFAD39A678E5:java.util.concurrent.CompletableFuture@177515d1[Not completed]
scm1.org_1   | 2021-11-25 07:49:09,532 [pool-2-thread-1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec: new RaftServerImpl for group-CFAD39A678E5:[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-11-25 07:49:09,563 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-11-25 07:49:09,563 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2021-11-25 07:49:09,564 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2021-11-25 07:49:09,564 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-11-25 07:49:09,564 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-11-25 07:49:09,564 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2021-11-25 07:50:06,202 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm3.org_1   | ************************************************************/
scm3.org_1   | 2021-11-25 07:50:06,225 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2021-11-25 07:50:06,637 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2021-11-25 07:50:06,642 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2021-11-25 07:50:06,823 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2021-11-25 07:50:06,823 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2021-11-25 07:50:06,849 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-11-25 07:50:07,661 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2021-11-25 07:50:07,661 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2021-11-25 07:50:08,266 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2021-11-25 07:50:09,145 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2021-11-25 07:50:09,145 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2021-11-25 07:50:09,155 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2021-11-25 07:50:12,772 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2021-11-25 07:50:12,922 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2021-11-25 07:50:12,922 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2021-11-25 07:50:12,933 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:e39fb3e9-4060-458c-ab31-c74db05e820c,clusterId:CID-2f16d919-03be-44c6-8b84-cfad39a678e5,subject:scm-sub@scm3.org
scm3.org_1   | 2021-11-25 07:50:15,325 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2021-11-25 07:50:15,376 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-2f16d919-03be-44c6-8b84-cfad39a678e5, SCMID e39fb3e9-4060-458c-ab31-c74db05e820c
scm3.org_1   | 2021-11-25 07:50:15,376 [main] INFO server.StorageContainerManager: Primary SCM Node ID d1137d26-6502-410a-9479-0d2074af0cec
scm3.org_1   | 2021-11-25 07:50:15,422 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2021-11-25 07:50:19,655 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:23Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-11-25 07:51:44,499 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-11-25 07:51:56,943 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-11-25 07:51:57,474 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-11-25 07:51:57,477 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-11-25 07:51:57,486 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-11-25 07:51:57,570 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-11-25 07:51:57,885 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om1_1        | 2021-11-25 07:52:01,494 [main] INFO reflections.Reflections: Reflections took 2343 ms to scan 1 urls, producing 96 keys and 261 values [using 2 cores]
om1_1        | 2021-11-25 07:52:04,072 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2021-11-25 07:52:04,094 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-11-25 07:52:04,097 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-11-25 07:52:13,003 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2021-11-25 07:52:13,736 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2021-11-25 07:52:13,756 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/8122318757614.crt.
om1_1        | 2021-11-25 07:52:13,786 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-7981323859056.crt.
om1_1        | 2021-11-25 07:52:14,002 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-11-25 07:52:15,164 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-11-25 07:52:15,170 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-11-25 07:52:16,654 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2021-11-25 07:52:16,655 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2021-11-25 07:52:17,299 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2021-11-25 07:52:17,948 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-11-25 07:52:17,953 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2021-11-25 07:52:18,061 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2021-11-25 07:52:19,341 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2021-11-25 07:52:19,472 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-11-25 07:52:19,868 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2021-11-25 07:52:19,965 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2021-11-25 07:52:21,675 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2021-11-25 07:52:22,072 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2021-11-25 07:52:22,074 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-11-25 07:52:22,079 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2021-11-25 07:52:22,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-11-25 07:52:22,094 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-11-25 07:52:22,095 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2021-11-25 07:52:22,106 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-11-25 07:52:22,111 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2021-11-25 07:52:22,124 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-11-25 07:52:25,960 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2021-11-25 07:52:25,972 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-11-25 07:52:25,977 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-11-25 07:52:26,098 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-11-25 07:52:26,182 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@36cd58e7[Not completed]
om1_1        | 2021-11-25 07:52:26,186 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2021-11-25 07:52:26,454 [pool-24-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2021-11-25 07:52:26,539 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2021-11-25 07:49:15,435 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | ************************************************************/
scm2.org_1   | 2021-11-25 07:49:15,475 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2021-11-25 07:49:15,924 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2021-11-25 07:49:15,924 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2021-11-25 07:49:16,066 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2021-11-25 07:49:16,070 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2021-11-25 07:49:16,088 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-11-25 07:49:16,420 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2021-11-25 07:49:16,420 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2021-11-25 07:49:18,875 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-11-25 07:49:20,877 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-11-25 07:49:22,879 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-11-25 07:49:24,882 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-11-25 07:49:26,887 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-11-25 07:49:29,157 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:d1137d26-6502-410a-9479-0d2074af0cec is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:245)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:108)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13937)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om3_1        | 2021-11-25 07:52:28,278 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-11-25 07:52:28,278 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2021-11-25 07:52:28,280 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-11-25 07:52:28,300 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2021-11-25 07:52:28,306 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2021-11-25 07:52:28,327 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2021-11-25 07:52:28,339 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2021-11-25 07:52:28,339 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2021-11-25 07:52:28,446 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2021-11-25 07:52:28,455 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2021-11-25 07:52:28,528 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2021-11-25 07:52:28,534 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2021-11-25 07:52:28,584 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2021-11-25 07:52:28,590 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2021-11-25 07:52:28,594 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2021-11-25 07:52:28,606 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2021-11-25 07:52:28,612 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2021-11-25 07:52:28,627 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2021-11-25 07:52:29,019 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2021-11-25 07:52:29,294 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2021-11-25 07:52:29,295 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2021-11-25 07:52:29,608 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2021-11-25 07:52:29,615 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2021-11-25 07:52:29,621 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-11-25 07:52:29,638 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2021-11-25 07:52:29,649 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-11-25 07:52:29,667 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2021-11-25 07:52:29,751 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2021-11-25 07:52:30,081 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2021-11-25 07:52:30,098 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$395/0x00000008405c3440@5233b7ad] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2021-11-25 07:52:30,103 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2021-11-25 07:52:30,107 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2021-11-25 07:49:09,567 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-11-25 07:49:09,573 [pool-2-thread-1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: ConfigurationManager, init=-1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-11-25 07:49:09,573 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-11-25 07:49:09,591 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-11-25 07:49:09,592 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2021-11-25 07:49:09,604 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5 does not exist. Creating ...
scm1.org_1   | 2021-11-25 07:49:09,642 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/in_use.lock acquired by nodename 14@scm1.org
scm1.org_1   | 2021-11-25 07:49:09,658 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5 has been successfully formatted.
scm1.org_1   | 2021-11-25 07:49:09,668 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-11-25 07:49:09,677 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-11-25 07:49:09,702 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-11-25 07:49:09,703 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-11-25 07:49:09,752 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2021-11-25 07:49:10,035 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2021-11-25 07:49:10,052 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-11-25 07:49:10,053 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-11-25 07:49:10,075 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5
scm1.org_1   | 2021-11-25 07:49:10,075 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-11-25 07:49:10,076 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-11-25 07:49:10,077 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2021-11-25 07:49:10,077 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2021-11-25 07:49:10,078 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2021-11-25 07:49:10,079 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2021-11-25 07:49:10,080 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2021-11-25 07:49:10,080 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2021-11-25 07:49:10,109 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2021-11-25 07:49:10,118 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2021-11-25 07:49:10,125 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-11-25 07:49:10,125 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-11-25 07:49:10,168 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2021-11-25 07:49:10,170 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-11-25 07:49:10,172 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-11-25 07:49:10,173 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2021-11-25 07:49:10,177 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2021-11-25 07:49:10,179 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-11-25 07:49:10,298 [main] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: start as a follower, conf=-1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2021-11-25 07:49:10,304 [main] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2021-11-25 07:49:10,307 [main] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: start d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState
scm1.org_1   | 2021-11-25 07:49:10,341 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFAD39A678E5,id=d1137d26-6502-410a-9479-0d2074af0cec
scm1.org_1   | 2021-11-25 07:49:10,354 [main] INFO server.RaftServer: d1137d26-6502-410a-9479-0d2074af0cec: start RPC server
scm1.org_1   | 2021-11-25 07:49:10,606 [main] INFO server.GrpcService: d1137d26-6502-410a-9479-0d2074af0cec: GrpcService started, listening on 9894
scm1.org_1   | 2021-11-25 07:49:10,621 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$335/0x0000000840330840@1b7332a7] INFO util.JvmPauseMonitor: JvmPauseMonitor-d1137d26-6502-410a-9479-0d2074af0cec: Started
scm1.org_1   | 2021-11-25 07:49:15,507 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO impl.FollowerState: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5199695355ns, electionTimeout:5179ms
scm1.org_1   | 2021-11-25 07:49:15,508 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: shutdown d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState
scm1.org_1   | 2021-11-25 07:49:15,509 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2021-11-25 07:49:15,513 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2021-11-25 07:49:15,523 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: start d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1
scm1.org_1   | 2021-11-25 07:49:15,545 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO impl.LeaderElection: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2021-11-25 07:49:15,548 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO impl.LeaderElection: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2021-11-25 07:49:15,549 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: shutdown d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1
scm1.org_1   | 2021-11-25 07:49:15,550 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2021-11-25 07:49:15,551 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: change Leader from null to d1137d26-6502-410a-9479-0d2074af0cec at term 1 for becomeLeader, leader elected after 5883ms
om1_1        | 2021-11-25 07:52:26,543 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2021-11-25 07:52:26,544 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2021-11-25 07:52:26,549 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-11-25 07:52:26,549 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-11-25 07:52:26,550 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2021-11-25 07:52:26,554 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-11-25 07:52:26,745 [pool-24-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2021-11-25 07:52:26,749 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-11-25 07:52:26,764 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-11-25 07:52:26,842 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2021-11-25 07:52:26,889 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2021-11-25 07:52:26,906 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2021-11-25 07:52:26,923 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2021-11-25 07:52:27,058 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2021-11-25 07:52:27,265 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2021-11-25 07:52:27,278 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2021-11-25 07:52:27,300 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-11-25 07:52:27,370 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2021-11-25 07:52:27,374 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-11-25 07:52:27,554 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-11-25 07:52:27,697 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2021-11-25 07:52:27,700 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2021-11-25 07:52:27,721 [Listener at om1/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om1_1        | 2021-11-25 07:52:27,780 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2021-11-25 07:52:27,793 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-11-25 07:52:27,797 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2021-11-25 07:52:27,811 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-11-25 07:52:27,825 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
recon_1      | 2021-11-25 07:49:38,250 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:40,252 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:40,254 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:40,261 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:42,266 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:42,273 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:42,277 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:44,280 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:44,281 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:44,288 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:46,302 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:46,309 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:46,313 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:48,315 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:48,316 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:48,317 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-11-25 07:51:44,435 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:23Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-11-25 07:51:44,556 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-11-25 07:51:56,379 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-11-25 07:51:56,963 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-11-25 07:51:56,963 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-11-25 07:51:56,966 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-11-25 07:51:57,107 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-11-25 07:51:57,420 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om2_1        | 2021-11-25 07:52:00,802 [main] INFO reflections.Reflections: Reflections took 2245 ms to scan 1 urls, producing 96 keys and 261 values [using 2 cores]
om2_1        | 2021-11-25 07:52:03,307 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2021-11-25 07:52:03,309 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-11-25 07:52:03,310 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-11-25 07:52:12,801 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2021-11-25 07:52:13,570 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/8121775853936.crt.
om2_1        | 2021-11-25 07:52:13,613 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2021-11-25 07:52:13,636 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-7981323859056.crt.
om2_1        | 2021-11-25 07:52:13,817 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-11-25 07:52:14,828 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-11-25 07:52:14,861 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-11-25 07:52:16,646 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2021-11-25 07:52:16,647 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2021-11-25 07:52:17,364 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om2_1        | 2021-11-25 07:52:18,079 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-11-25 07:52:30,125 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2021-11-25 07:52:30,132 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-11-25 07:52:30,155 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2021-11-25 07:52:30,156 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2021-11-25 07:52:30,411 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2021-11-25 07:52:30,416 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2021-11-25 07:52:30,417 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2021-11-25 07:52:30,593 [Listener at om3/9862] INFO util.log: Logging initialized @59047ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2021-11-25 07:52:31,323 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2021-11-25 07:52:31,330 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2021-11-25 07:52:31,332 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2021-11-25 07:52:31,332 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2021-11-25 07:52:31,332 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2021-11-25 07:52:31,338 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2021-11-25 07:52:31,471 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2021-11-25 07:52:31,491 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om3_1        | 2021-11-25 07:52:31,898 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2021-11-25 07:52:31,910 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2021-11-25 07:52:31,930 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
om3_1        | 2021-11-25 07:52:32,077 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-11-25 07:52:32,099 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@507c33cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2021-11-25 07:52:32,120 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1fdc2d45{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2021-11-25 07:52:32,625 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-11-25 07:49:31,159 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-11-25 07:49:33,166 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-11-25 07:49:35,615 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2021-11-25 07:49:37,490 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2021-11-25 07:49:37,498 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm3.org_1   | ************************************************************/
scm3.org_1   | 2021-11-25 07:50:19,691 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2021-11-25 07:50:19,955 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2021-11-25 07:50:19,956 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2021-11-25 07:50:20,167 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2021-11-25 07:50:20,168 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2021-11-25 07:50:20,308 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-11-25 07:50:20,392 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm3.org_1   | 2021-11-25 07:50:21,387 [main] INFO reflections.Reflections: Reflections took 438 ms to scan 3 urls, producing 103 keys and 217 values 
scm3.org_1   | 2021-11-25 07:50:23,244 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2021-11-25 07:50:23,535 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/8047253457661.crt.
scm3.org_1   | 2021-11-25 07:50:23,540 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2021-11-25 07:50:23,565 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2021-11-25 07:50:24,006 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2021-11-25 07:50:24,006 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2021-11-25 07:50:24,113 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-11-25 07:50:24,379 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-11-25 07:50:24,713 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2021-11-25 07:50:24,714 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2021-11-25 07:50:24,905 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2021-11-25 07:49:37,502 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2021-11-25 07:49:38,974 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2021-11-25 07:49:39,064 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2021-11-25 07:49:39,065 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2021-11-25 07:49:39,073 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:95e9e3e6-77c8-42b6-8332-7b517674b4f8,clusterId:CID-2f16d919-03be-44c6-8b84-cfad39a678e5,subject:scm-sub@scm2.org
scm2.org_1   | 2021-11-25 07:49:43,180 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2021-11-25 07:49:43,248 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-2f16d919-03be-44c6-8b84-cfad39a678e5, SCMID 95e9e3e6-77c8-42b6-8332-7b517674b4f8
scm2.org_1   | 2021-11-25 07:49:43,248 [main] INFO server.StorageContainerManager: Primary SCM Node ID d1137d26-6502-410a-9479-0d2074af0cec
scm2.org_1   | 2021-11-25 07:49:43,291 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2021-11-25 07:49:47,652 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | 2021-11-25 07:52:18,084 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2021-11-25 07:52:18,262 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2021-11-25 07:52:19,633 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2021-11-25 07:52:19,782 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-11-25 07:52:20,039 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2021-11-25 07:52:20,111 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2021-11-25 07:52:21,580 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2021-11-25 07:52:22,283 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2021-11-25 07:52:22,294 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-11-25 07:52:22,296 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2021-11-25 07:52:22,303 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-11-25 07:52:22,306 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-11-25 07:52:22,321 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2021-11-25 07:52:22,329 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-11-25 07:52:22,351 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2021-11-25 07:52:22,354 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-11-25 07:52:26,672 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2021-11-25 07:52:26,680 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-11-25 07:52:26,698 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-11-25 07:52:26,895 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-11-25 07:52:26,973 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@e471cef[Not completed]
om2_1        | 2021-11-25 07:52:26,973 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2021-11-25 07:52:27,157 [pool-24-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2021-11-25 07:52:27,213 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2021-11-25 07:52:27,231 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2021-11-25 07:52:27,232 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2021-11-25 07:52:27,234 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-11-25 07:52:27,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-11-25 07:52:27,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2021-11-25 07:52:27,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-11-25 07:52:27,323 [pool-24-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2021-11-25 07:52:27,324 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-11-25 07:52:27,360 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2021-11-25 07:52:27,371 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2021-11-25 07:52:27,376 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2021-11-25 07:52:27,525 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2021-11-25 07:52:27,596 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | ************************************************************/
scm2.org_1   | 2021-11-25 07:49:47,685 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2021-11-25 07:49:47,920 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2021-11-25 07:49:47,920 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2021-11-25 07:49:48,110 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2021-11-25 07:49:48,118 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2021-11-25 07:49:48,262 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-11-25 07:49:48,472 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm2.org_1   | 2021-11-25 07:49:49,074 [main] INFO reflections.Reflections: Reflections took 255 ms to scan 3 urls, producing 103 keys and 217 values 
scm2.org_1   | 2021-11-25 07:49:50,128 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2021-11-25 07:49:50,325 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/8013676818917.crt.
scm2.org_1   | 2021-11-25 07:49:50,329 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2021-11-25 07:49:50,336 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2021-11-25 07:49:50,582 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2021-11-25 07:49:50,583 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2021-11-25 07:49:50,686 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-11-25 07:49:51,058 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-11-25 07:49:51,574 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2021-11-25 07:49:51,574 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2021-11-25 07:49:51,885 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2021-11-25 07:49:52,035 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:95e9e3e6-77c8-42b6-8332-7b517674b4f8
scm2.org_1   | 2021-11-25 07:49:52,335 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2021-11-25 07:49:52,539 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2021-11-25 07:49:52,541 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-11-25 07:49:52,542 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2021-11-25 07:49:52,547 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-11-25 07:49:52,547 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2021-11-25 07:49:52,557 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2021-11-25 07:49:52,569 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2021-11-25 07:49:52,571 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2021-11-25 07:49:52,572 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2021-11-25 07:49:54,074 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2021-11-25 07:49:54,080 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2021-11-25 07:49:54,080 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2021-11-25 07:49:54,146 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2021-11-25 07:49:54,190 [main] INFO server.RaftServer: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: addNew group-CFAD39A678E5:[] returns group-CFAD39A678E5:java.util.concurrent.CompletableFuture@4357524b[Not completed]
scm2.org_1   | 2021-11-25 07:49:54,272 [pool-14-thread-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: new RaftServerImpl for group-CFAD39A678E5:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2021-11-25 07:49:54,276 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2021-11-25 07:49:54,277 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2021-11-25 07:49:54,278 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2021-11-25 07:52:32,686 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@71897380{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-2650471662944299107/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2021-11-25 07:52:32,716 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@df80af2{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2021-11-25 07:52:32,726 [Listener at om3/9862] INFO server.Server: Started @61180ms
om3_1        | 2021-11-25 07:52:32,740 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2021-11-25 07:52:32,740 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2021-11-25 07:52:32,745 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2021-11-25 07:52:32,776 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2021-11-25 07:52:32,745 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2021-11-25 07:52:32,932 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2021-11-25 07:52:32,991 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3669d7ac] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2021-11-25 07:52:34,831 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5183800078ns, electionTimeout:5164ms
om3_1        | 2021-11-25 07:52:34,834 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-11-25 07:52:34,835 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2021-11-25 07:52:34,844 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2021-11-25 07:52:34,864 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2021-11-25 07:52:34,894 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-11-25 07:52:35,759 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$395/0x00000008405c3440@5233b7ad] WARN util.JvmPauseMonitor: JvmPauseMonitor-om3: Detected pause in JVM or host machine (eg GC): pause of approximately 115897974ns.
om3_1        | GC pool 'ParNew' had collection(s): count=1 time=102ms
om3_1        | 2021-11-25 07:52:38,825 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-11-25 07:52:38,827 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2021-11-25 07:52:38,854 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-11-25 07:52:39,602 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.879442401s. [buffered_nanos=2457040085, remote_addr=om1/172.25.0.111:9872]
om3_1        | 2021-11-25 07:52:39,616 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 1 response(s) and 1 exception(s):
om3_1        | 2021-11-25 07:52:39,616 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om2#0:FAIL-t1
om3_1        | 2021-11-25 07:52:39,639 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.879442401s. [buffered_nanos=2457040085, remote_addr=om1/172.25.0.111:9872]
om3_1        | 2021-11-25 07:52:39,641 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2021-11-25 07:52:39,648 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2021-11-25 07:52:39,649 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2021-11-25 07:52:39,650 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-11-25 07:52:39,757 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-11-25 07:52:39,757 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2021-11-25 07:52:39,758 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-11-25 07:52:39,956 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om3_1        | 2021-11-25 07:52:39,964 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1        | 2021-11-25 07:52:39,966 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om3_1        | 2021-11-25 07:52:39,971 [grpc-default-executor-0] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-11-25 07:52:39,973 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted: {}
om3_1        | java.lang.InterruptedException: sleep interrupted
om3_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om3_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om3_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om3_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om3_1        | 2021-11-25 07:52:39,990 [grpc-default-executor-0] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-11-25 07:52:40,027 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:OK-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om1, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
recon_1      | 2021-11-25 07:49:50,319 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:50,320 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:50,321 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:52,322 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:52,323 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:52,324 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:54,326 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:54,330 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:54,331 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:56,335 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:56,337 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:56,344 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:49:58,346 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:58,348 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:49:58,373 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:00,381 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:00,385 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:00,387 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:02,390 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
om1_1        | 2021-11-25 07:52:27,830 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2021-11-25 07:52:27,851 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2021-11-25 07:52:27,863 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2021-11-25 07:52:27,870 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2021-11-25 07:52:27,952 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2021-11-25 07:52:27,974 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2021-11-25 07:52:28,065 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2021-11-25 07:52:28,074 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2021-11-25 07:52:28,119 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2021-11-25 07:52:28,171 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2021-11-25 07:52:28,192 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2021-11-25 07:52:28,211 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2021-11-25 07:52:28,230 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2021-11-25 07:52:28,230 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2021-11-25 07:52:28,635 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2021-11-25 07:52:28,726 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2021-11-25 07:52:28,726 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2021-11-25 07:52:29,171 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2021-11-25 07:52:29,177 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2021-11-25 07:52:29,184 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-11-25 07:52:29,207 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2021-11-25 07:52:29,210 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-11-25 07:52:29,231 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2021-11-25 07:52:29,318 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2021-11-25 07:52:29,626 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2021-11-25 07:52:29,639 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$395/0x00000008405c3040@21ad0060] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2021-11-25 07:52:29,640 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2021-11-25 07:52:29,640 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-11-25 07:52:29,642 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2021-11-25 07:52:29,653 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-11-25 07:52:29,675 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2021-11-25 07:52:29,692 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2021-11-25 07:52:29,938 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2021-11-25 07:52:29,941 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2021-11-25 07:52:29,941 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
scm3.org_1   | 2021-11-25 07:50:25,015 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:e39fb3e9-4060-458c-ab31-c74db05e820c
scm3.org_1   | 2021-11-25 07:50:25,208 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2021-11-25 07:50:25,370 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2021-11-25 07:50:25,372 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-11-25 07:50:25,374 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2021-11-25 07:50:25,376 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-11-25 07:50:25,376 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2021-11-25 07:50:25,379 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2021-11-25 07:50:25,383 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2021-11-25 07:50:25,387 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2021-11-25 07:50:25,388 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2021-11-25 07:50:26,862 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2021-11-25 07:50:26,865 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2021-11-25 07:50:26,866 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2021-11-25 07:50:26,889 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2021-11-25 07:50:26,902 [main] INFO server.RaftServer: e39fb3e9-4060-458c-ab31-c74db05e820c: addNew group-CFAD39A678E5:[] returns group-CFAD39A678E5:java.util.concurrent.CompletableFuture@26874f2c[Not completed]
scm3.org_1   | 2021-11-25 07:50:26,965 [pool-14-thread-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c: new RaftServerImpl for group-CFAD39A678E5:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2021-11-25 07:50:26,973 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2021-11-25 07:50:26,974 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2021-11-25 07:50:26,993 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2021-11-25 07:50:26,994 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2021-11-25 07:50:26,996 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2021-11-25 07:50:26,998 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2021-11-25 07:50:26,999 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2021-11-25 07:50:27,025 [pool-14-thread-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2021-11-25 07:50:27,030 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2021-11-25 07:50:27,041 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2021-11-25 07:50:27,048 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2021-11-25 07:50:27,059 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5 does not exist. Creating ...
scm3.org_1   | 2021-11-25 07:50:27,118 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/in_use.lock acquired by nodename 9@scm3.org
scm3.org_1   | 2021-11-25 07:50:27,158 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5 has been successfully formatted.
scm3.org_1   | 2021-11-25 07:50:27,167 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2021-11-25 07:50:27,177 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2021-11-25 07:50:27,225 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2021-11-25 07:50:27,225 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2021-11-25 07:50:27,267 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2021-11-25 07:50:27,307 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2021-11-25 07:50:27,307 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2021-11-25 07:50:27,316 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5
scm3.org_1   | 2021-11-25 07:50:27,319 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2021-11-25 07:50:27,320 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2021-11-25 07:50:27,321 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2021-11-25 07:50:27,326 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2021-11-25 07:50:27,327 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2021-11-25 07:50:27,330 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2021-11-25 07:50:27,330 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2021-11-25 07:50:27,331 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2021-11-25 07:50:27,354 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2021-11-25 07:50:27,360 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2021-11-25 07:50:27,377 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2021-11-25 07:50:27,377 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2021-11-25 07:50:27,401 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2021-11-25 07:50:27,401 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2021-11-25 07:50:27,403 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2021-11-25 07:50:27,405 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2021-11-25 07:50:27,411 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2021-11-25 07:50:27,412 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2021-11-25 07:50:27,517 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2021-11-25 07:50:27,518 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2021-11-25 07:50:27,518 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2021-11-25 07:50:28,242 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm3.org_1   | 2021-11-25 07:50:28,242 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2021-11-25 07:50:28,252 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2021-11-25 07:50:28,265 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2021-11-25 07:50:28,485 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2021-11-25 07:50:28,506 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2021-11-25 07:50:28,520 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2021-11-25 07:50:28,625 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2021-11-25 07:50:28,644 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2021-11-25 07:50:28,645 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2021-11-25 07:50:28,738 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2021-11-25 07:50:28,865 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2021-11-25 07:50:28,926 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2021-11-25 07:50:28,931 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2021-11-25 07:50:28,963 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm3.org_1   | 2021-11-25 07:50:29,009 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2021-11-25 07:50:29,018 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:50:29,027 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2021-11-25 07:50:29,110 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2021-11-25 07:50:29,167 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-11-25 07:50:29,330 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2021-11-25 07:50:31,633 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-11-25 07:50:31,645 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2021-11-25 07:50:31,864 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-11-25 07:50:31,920 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2021-11-25 07:50:32,035 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-11-25 07:50:32,037 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2021-11-25 07:50:32,297 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2021-11-25 07:50:32,319 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          0.1
scm3.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.2
scm3.org_1   | Max Size to Move per Iteration                     30GB
scm3.org_1   | Max Size Entering Target per Iteration             1GB
scm3.org_1   | Max Size Leaving Source per Iteration              1GB
scm3.org_1   | 
scm3.org_1   | 2021-11-25 07:50:32,319 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-11-25 07:50:32,320 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2021-11-25 07:50:32,353 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2021-11-25 07:50:32,356 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2021-11-25 07:50:32,364 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2021-11-25 07:50:32,374 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2021-11-25 07:50:32,378 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFAD39A678E5,id=e39fb3e9-4060-458c-ab31-c74db05e820c
scm3.org_1   | 2021-11-25 07:50:32,421 [Listener at 0.0.0.0/9860] INFO server.RaftServer: e39fb3e9-4060-458c-ab31-c74db05e820c: start RPC server
scm3.org_1   | 2021-11-25 07:50:32,563 [Listener at 0.0.0.0/9860] INFO server.GrpcService: e39fb3e9-4060-458c-ab31-c74db05e820c: GrpcService started, listening on 9894
scm3.org_1   | 2021-11-25 07:50:32,589 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/0x000000084052f040@44b82007] INFO util.JvmPauseMonitor: JvmPauseMonitor-e39fb3e9-4060-458c-ab31-c74db05e820c: Started
om2_1        | 2021-11-25 07:52:27,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2021-11-25 07:52:27,779 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2021-11-25 07:52:27,797 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2021-11-25 07:52:27,812 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2021-11-25 07:52:27,962 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2021-11-25 07:52:27,962 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-11-25 07:52:28,146 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-11-25 07:52:28,224 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2021-11-25 07:52:28,224 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2021-11-25 07:52:28,270 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2021-11-25 07:52:28,278 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2021-11-25 07:52:28,279 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2021-11-25 07:52:28,280 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-11-25 07:52:28,295 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2021-11-25 07:52:28,296 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2021-11-25 07:52:28,299 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2021-11-25 07:52:28,297 [Listener at om2/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om2_1        | 2021-11-25 07:52:28,312 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2021-11-25 07:52:28,313 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2021-11-25 07:52:28,382 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2021-11-25 07:52:28,383 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2021-11-25 07:52:28,426 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2021-11-25 07:52:28,428 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2021-11-25 07:52:28,468 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2021-11-25 07:52:28,483 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2021-11-25 07:52:28,495 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2021-11-25 07:52:28,507 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2021-11-25 07:52:28,531 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2021-11-25 07:52:28,536 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2021-11-25 07:52:28,996 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2021-11-25 07:52:29,134 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2021-11-25 07:52:29,143 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2021-11-25 07:52:29,636 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2021-11-25 07:52:29,636 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2021-11-25 07:52:29,660 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-11-25 07:52:29,692 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2021-11-25 07:52:29,708 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-11-25 07:52:29,717 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2021-11-25 07:52:29,773 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2021-11-25 07:52:30,142 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2021-11-25 07:52:30,154 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$395/0x00000008405bb440@5a69f1ef] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2021-11-25 07:52:30,156 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2021-11-25 07:52:30,156 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-11-25 07:52:30,183 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2021-11-25 07:52:30,183 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-11-25 07:52:30,197 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2021-11-25 07:52:30,203 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2021-11-25 07:52:30,460 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2021-11-25 07:52:30,460 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2021-11-25 07:52:30,461 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2021-11-25 07:52:30,602 [Listener at om2/9862] INFO util.log: Logging initialized @59040ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2021-11-25 07:52:31,462 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2021-11-25 07:52:31,493 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2021-11-25 07:52:31,509 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2021-11-25 07:52:31,509 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2021-11-25 07:52:31,509 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2021-11-25 07:52:31,512 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2021-11-25 07:52:31,760 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
scm2.org_1   | 2021-11-25 07:49:54,278 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2021-11-25 07:49:54,278 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-11-25 07:49:15,558 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2021-11-25 07:49:15,607 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-11-25 07:49:15,629 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-11-25 07:49:15,647 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2021-11-25 07:49:15,648 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2021-11-25 07:49:15,665 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2021-11-25 07:49:15,684 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-11-25 07:49:15,702 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2021-11-25 07:49:15,713 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: start d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl
scm1.org_1   | 2021-11-25 07:49:15,817 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2021-11-25 07:49:16,047 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: set configuration 0: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-11-25 07:49:16,088 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/current/log_inprogress_0
scm1.org_1   | 2021-11-25 07:49:16,623 [main] INFO server.RaftServer: d1137d26-6502-410a-9479-0d2074af0cec: close
scm1.org_1   | 2021-11-25 07:49:16,624 [main] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: shutdown
scm1.org_1   | 2021-11-25 07:49:16,625 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFAD39A678E5,id=d1137d26-6502-410a-9479-0d2074af0cec
scm1.org_1   | 2021-11-25 07:49:16,625 [main] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: shutdown d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl
scm1.org_1   | 2021-11-25 07:49:16,645 [main] INFO impl.PendingRequests: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2021-11-25 07:49:16,649 [main] INFO impl.StateMachineUpdater: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2021-11-25 07:49:16,650 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO impl.StateMachineUpdater: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2021-11-25 07:49:16,654 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO impl.StateMachineUpdater: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2021-11-25 07:49:16,670 [main] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: closes. applyIndex: 0
scm1.org_1   | 2021-11-25 07:49:16,673 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2021-11-25 07:49:16,675 [main] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker close()
recon_1      | 2021-11-25 07:50:02,391 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:02,393 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:04,401 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:04,402 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:04,403 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:06,408 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:06,418 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:06,420 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:08,424 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:08,425 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:08,426 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:10,433 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:10,435 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:10,462 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:12,468 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:12,468 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:12,469 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:14,471 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:14,473 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:14,474 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:16,476 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:16,480 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:16,481 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:18,483 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
om1_1        | 2021-11-25 07:52:30,111 [Listener at om1/9862] INFO util.log: Logging initialized @58267ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2021-11-25 07:52:30,748 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2021-11-25 07:52:30,777 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2021-11-25 07:52:30,805 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2021-11-25 07:52:30,805 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2021-11-25 07:52:30,806 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2021-11-25 07:52:30,809 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2021-11-25 07:52:31,098 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2021-11-25 07:52:31,119 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om1_1        | 2021-11-25 07:52:31,332 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2021-11-25 07:52:31,334 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2021-11-25 07:49:54,282 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2021-11-25 07:49:54,283 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2021-11-25 07:49:54,299 [pool-14-thread-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2021-11-25 07:49:54,299 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2021-11-25 07:49:54,309 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2021-11-25 07:49:54,314 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2021-11-25 07:49:54,316 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5 does not exist. Creating ...
scm2.org_1   | 2021-11-25 07:49:54,345 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/in_use.lock acquired by nodename 11@scm2.org
scm2.org_1   | 2021-11-25 07:49:54,379 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5 has been successfully formatted.
scm2.org_1   | 2021-11-25 07:49:54,387 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2021-11-25 07:49:54,389 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2021-11-25 07:49:54,412 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2021-11-25 07:49:54,418 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2021-11-25 07:49:54,459 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2021-11-25 07:49:54,477 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2021-11-25 07:49:54,482 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2021-11-25 07:49:54,493 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5
scm2.org_1   | 2021-11-25 07:49:54,498 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2021-11-25 07:49:54,500 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2021-11-25 07:49:54,507 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2021-11-25 07:49:54,507 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2021-11-25 07:49:54,508 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2021-11-25 07:49:54,509 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2021-11-25 07:49:54,510 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2021-11-25 07:49:54,514 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2021-11-25 07:49:54,555 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2021-11-25 07:49:54,556 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2021-11-25 07:49:54,583 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-11-25 07:49:54,583 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2021-11-25 07:49:54,605 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2021-11-25 07:49:54,626 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2021-11-25 07:49:54,626 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2021-11-25 07:49:54,627 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2021-11-25 07:49:54,629 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2021-11-25 07:49:54,633 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2021-11-25 07:49:54,767 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2021-11-25 07:49:54,767 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2021-11-25 07:49:54,774 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2021-11-25 07:49:55,496 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
om3_1        | 2021-11-25 07:52:41,130 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 13359ms
om3_1        | 2021-11-25 07:52:41,380 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-11-25 07:52:41,406 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2021-11-25 07:52:41,670 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2021-11-25 07:52:42,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37315
om3_1        | 2021-11-25 07:52:42,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-11-25 07:52:44,354 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
scm1.org_1   | 2021-11-25 07:49:16,677 [main] INFO server.GrpcService: d1137d26-6502-410a-9479-0d2074af0cec: shutdown server with port 9894 now
scm1.org_1   | 2021-11-25 07:49:16,687 [main] INFO server.GrpcService: d1137d26-6502-410a-9479-0d2074af0cec: shutdown server with port 9894 successfully
scm1.org_1   | 2021-11-25 07:49:16,688 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$335/0x0000000840330840@1b7332a7] INFO util.JvmPauseMonitor: JvmPauseMonitor-d1137d26-6502-410a-9479-0d2074af0cec: Stopped
scm1.org_1   | 2021-11-25 07:49:16,688 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-11-25 07:49:16,699 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-2f16d919-03be-44c6-8b84-cfad39a678e5; layoutVersion=2; scmId=d1137d26-6502-410a-9479-0d2074af0cec
scm1.org_1   | 2021-11-25 07:49:16,808 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-11-25 07:49:19,171 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
recon_1      | 2021-11-25 07:50:18,484 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:18,485 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:20,487 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:20,488 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:20,491 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:22,496 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:22,497 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:22,511 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:24,516 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:24,518 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:24,526 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:26,538 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:26,557 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:26,559 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2021-11-25 07:52:31,336 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2021-11-25 07:52:31,425 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-11-25 07:52:31,439 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4e2bed0f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2021-11-25 07:52:31,441 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1aacde34{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2021-11-25 07:52:32,105 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-11-25 07:52:32,207 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6740b169{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-3018561853112724599/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2021-11-25 07:52:32,273 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@737652a9{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2021-11-25 07:52:32,281 [Listener at om1/9862] INFO server.Server: Started @60438ms
om1_1        | 2021-11-25 07:52:32,294 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-11-25 07:52:32,294 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-11-25 07:52:32,297 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2021-11-25 07:52:32,304 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2021-11-25 07:52:32,326 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2021-11-25 07:52:32,789 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2021-11-25 07:52:32,851 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@460818c1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2021-11-25 07:52:33,244 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42307
om1_1        | 2021-11-25 07:52:33,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-11-25 07:52:34,351 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5141403625ns, electionTimeout:5088ms
recon_1      | 2021-11-25 07:50:28,560 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:28,561 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:28,562 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:30,566 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:30,568 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:30,569 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:32,579 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:32,581 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:32,582 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:34,583 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:34,585 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:34,620 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:36,626 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:36,627 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:36,652 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:38,654 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm2.org_1   | 2021-11-25 07:49:55,496 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2021-11-25 07:49:55,531 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2021-11-25 07:49:55,534 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2021-11-25 07:49:55,779 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2021-11-25 07:49:55,831 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2021-11-25 07:49:55,882 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2021-11-25 07:49:56,022 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2021-11-25 07:49:56,051 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2021-11-25 07:49:56,058 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2021-11-25 07:49:56,234 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2021-11-25 07:49:56,311 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2021-11-25 07:49:56,376 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2021-11-25 07:49:56,380 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2021-11-25 07:49:56,407 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm2.org_1   | 2021-11-25 07:49:56,419 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2021-11-25 07:49:56,434 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:49:56,450 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2021-11-25 07:49:56,525 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2021-11-25 07:49:56,653 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-11-25 07:49:56,793 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2021-11-25 07:49:59,198 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-11-25 07:49:59,202 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2021-11-25 07:49:59,488 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-11-25 07:49:59,498 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2021-11-25 07:49:59,557 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2021-11-25 07:49:59,574 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2021-11-25 07:49:59,759 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2021-11-25 07:49:59,863 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          0.1
scm2.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.2
scm2.org_1   | Max Size to Move per Iteration                     30GB
scm2.org_1   | Max Size Entering Target per Iteration             1GB
scm2.org_1   | Max Size Leaving Source per Iteration              1GB
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | 2021-11-25 07:50:32,603 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-11-25 07:50:32,610 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-11-25 07:50:32,614 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
om1_1        | 2021-11-25 07:52:34,356 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f78085143548604b64ca9a407ca2d4a34f0e9d8c ; compiled by 'runner' on 2021-11-25T07:22Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
scm1.org_1   | 2021-11-25 07:49:19,182 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-11-25 07:49:19,323 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-11-25 07:49:19,323 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-11-25 07:49:19,421 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2021-11-25 07:49:19,421 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-11-25 07:49:19,491 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-11-25 07:49:19,532 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm1.org_1   | 2021-11-25 07:49:19,885 [main] INFO reflections.Reflections: Reflections took 215 ms to scan 3 urls, producing 103 keys and 217 values 
scm1.org_1   | 2021-11-25 07:49:20,779 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2021-11-25 07:49:20,974 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/7981323859056.crt.
scm1.org_1   | 2021-11-25 07:49:20,977 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2021-11-25 07:49:20,982 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2021-11-25 07:49:21,190 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2021-11-25 07:49:21,191 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2021-11-25 07:49:21,233 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-11-25 07:50:35,390 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/0x000000084052f040@44b82007] WARN util.JvmPauseMonitor: JvmPauseMonitor-e39fb3e9-4060-458c-ab31-c74db05e820c: Detected pause in JVM or host machine (eg GC): pause of approximately 164375418ns. No GCs detected.
scm3.org_1   | 2021-11-25 07:50:41,479 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:41,574 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2021-11-25 07:50:41,582 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: change Leader from null to d1137d26-6502-410a-9479-0d2074af0cec at term 2 for installSnapshot, leader elected after 14407ms
scm3.org_1   | 2021-11-25 07:50:41,604 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Received notification to install snapshot at index 10
scm3.org_1   | 2021-11-25 07:50:42,044 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 10.
scm3.org_1   | 2021-11-25 07:50:42,088 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:42,122 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm3.org_1   | 2021-11-25 07:50:45,411 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
om1_1        | 2021-11-25 07:52:34,379 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2021-11-25 07:52:34,404 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2021-11-25 07:52:34,407 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2021-11-25 07:52:34,470 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-11-25 07:52:39,698 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2021-11-25 07:52:39,735 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2021-11-25 07:52:39,821 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION TIMEOUT received 0 response(s) and 0 exception(s):
om1_1        | 2021-11-25 07:52:39,821 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result TIMEOUT
om1_1        | 2021-11-25 07:52:39,865 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-11-25 07:52:39,871 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 1: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-11-25 07:52:39,980 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2021-11-25 07:52:39,986 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t2
om1_1        | 2021-11-25 07:52:39,987 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 1: result PASSED
om1_1        | 2021-11-25 07:52:39,989 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2021-11-25 07:52:39,993 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om1_1        | 2021-11-25 07:52:39,996 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om1 at term 2 for becomeLeader, leader elected after 12718ms
om1_1        | 2021-11-25 07:52:40,023 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2021-11-25 07:52:40,097 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2021-11-25 07:52:40,098 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-11-25 07:52:40,137 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1        | 2021-11-25 07:52:40,137 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1        | 2021-11-25 07:52:40,140 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2021-11-25 07:52:40,193 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2021-11-25 07:52:40,215 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1        | 2021-11-25 07:52:40,283 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2021-11-25 07:52:40,294 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-11-25 07:52:40,322 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2021-11-25 07:52:40,334 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2021-11-25 07:52:40,335 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-11-25 07:52:40,335 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-11-25 07:52:40,344 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2021-11-25 07:52:40,344 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-11-25 07:52:40,345 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2021-11-25 07:52:40,357 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2021-11-25 07:52:40,358 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-11-25 07:52:40,362 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-11-25 07:49:21,459 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-11-25 07:49:21,694 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
om2_1        | 2021-11-25 07:52:31,780 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
om2_1        | 2021-11-25 07:52:32,112 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2021-11-25 07:52:32,112 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2021-11-25 07:52:32,133 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2021-11-25 07:52:32,363 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2021-11-25 07:52:32,379 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@611c9d31{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2021-11-25 07:52:32,380 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@29478556{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2021-11-25 07:52:32,867 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2021-11-25 07:52:32,967 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@dcdf733{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-14998060131928085485/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2021-11-25 07:52:32,999 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@7a9df9b2{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
recon_1      | 2021-11-25 07:50:38,655 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:38,656 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:40,658 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:40,659 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:40,660 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:42,661 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:42,664 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:42,666 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:44,675 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:44,679 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:44,679 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:46,681 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:46,683 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:46,684 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:48,689 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:48,702 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:48,724 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:50,726 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:50,727 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:50,728 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:52,729 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:52,730 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:52,731 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:54,735 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:54,737 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:45,550 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:45,585 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t0,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:45,772 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:45,993 [grpc-default-executor-0] INFO impl.RoleInfo: e39fb3e9-4060-458c-ab31-c74db05e820c: start e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-FollowerState
scm3.org_1   | 2021-11-25 07:50:46,032 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,038 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:46,069 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:46,076 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:46,080 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:46,081 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:46,112 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,234 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:46,237 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:46,288 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,289 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
om2_1        | 2021-11-25 07:52:32,999 [Listener at om2/9862] INFO server.Server: Started @61437ms
om2_1        | 2021-11-25 07:52:33,012 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2021-11-25 07:52:33,013 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2021-11-25 07:52:33,029 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2021-11-25 07:52:33,033 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-11-25 07:52:33,076 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2021-11-25 07:52:33,402 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1        | 2021-11-25 07:52:33,457 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3713ebe9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2021-11-25 07:52:34,754 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5046747056ns, electionTimeout:5044ms
om2_1        | 2021-11-25 07:52:34,756 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-11-25 07:52:34,757 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2021-11-25 07:52:34,779 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2021-11-25 07:52:34,781 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2021-11-25 07:52:34,796 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-11-25 07:52:38,936 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-11-25 07:52:38,945 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2021-11-25 07:52:38,956 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-11-25 07:52:39,080 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38441
om2_1        | 2021-11-25 07:52:39,119 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-11-25 07:52:39,624 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.716774942s. [buffered_nanos=2429787122, remote_addr=om1/172.25.0.111:9872]
om2_1        | 2021-11-25 07:52:39,626 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 1 response(s) and 1 exception(s):
om2_1        | 2021-11-25 07:52:39,628 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om3#0:FAIL-t1
om2_1        | 2021-11-25 07:52:39,629 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.716774942s. [buffered_nanos=2429787122, remote_addr=om1/172.25.0.111:9872]
om2_1        | 2021-11-25 07:52:39,639 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2021-11-25 07:52:39,653 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2021-11-25 07:52:39,665 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
scm1.org_1   | 2021-11-25 07:49:21,695 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2021-11-25 07:49:21,867 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2021-11-25 07:49:21,942 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:d1137d26-6502-410a-9479-0d2074af0cec
scm1.org_1   | 2021-11-25 07:49:22,056 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2021-11-25 07:49:22,180 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-11-25 07:49:22,181 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-11-25 07:49:22,182 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2021-11-25 07:49:22,183 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-11-25 07:49:22,184 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-11-25 07:49:22,185 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-11-25 07:49:22,188 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-11-25 07:49:22,191 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-11-25 07:49:22,192 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-11-25 07:49:23,026 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-11-25 07:49:23,028 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-11-25 07:49:23,028 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-11-25 07:49:23,041 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-11-25 07:49:23,043 [main] INFO server.RaftServer: d1137d26-6502-410a-9479-0d2074af0cec: found a subdirectory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5
scm1.org_1   | 2021-11-25 07:49:23,048 [main] INFO server.RaftServer: d1137d26-6502-410a-9479-0d2074af0cec: addNew group-CFAD39A678E5:[] returns group-CFAD39A678E5:java.util.concurrent.CompletableFuture@26874f2c[Not completed]
scm1.org_1   | 2021-11-25 07:49:23,079 [pool-14-thread-1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec: new RaftServerImpl for group-CFAD39A678E5:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-11-25 07:49:23,084 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-11-25 07:49:23,084 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2021-11-25 07:49:23,085 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2021-11-25 07:49:23,085 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-11-25 07:49:23,085 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-11-25 07:49:23,085 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2021-11-25 07:49:23,086 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-11-25 07:49:23,092 [pool-14-thread-1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-11-25 07:49:23,093 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-11-25 07:49:23,097 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-11-25 07:49:23,098 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2021-11-25 07:49:23,119 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/in_use.lock acquired by nodename 7@scm1.org
scm1.org_1   | 2021-11-25 07:49:23,126 [pool-14-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=d1137d26-6502-410a-9479-0d2074af0cec} from /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/current/raft-meta
scm1.org_1   | 2021-11-25 07:49:23,164 [pool-14-thread-1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: set configuration 0: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-11-25 07:49:23,166 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-11-25 07:49:23,168 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-11-25 07:49:23,182 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-11-25 07:49:23,182 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-11-25 07:49:23,207 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2021-11-25 07:49:23,218 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-11-25 07:49:23,218 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-11-25 07:49:23,225 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5
recon_1      | 2021-11-25 07:50:54,737 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:56,740 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:56,741 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:56,743 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:50:58,820 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:58,843 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:50:58,846 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:00,855 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:00,999 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:01,001 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 128 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:03,019 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 129 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:03,021 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 130 failover attempts. Trying to failover immediately.
om1_1        | 2021-11-25 07:52:40,412 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderStateImpl
om1_1        | 2021-11-25 07:52:40,579 [om1@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2021-11-25 07:52:40,741 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2021-11-25 07:52:41,343 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2021-11-25 07:52:41,858 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2021-11-25 07:52:45,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37527
om1_1        | 2021-11-25 07:52:45,593 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 
scm2.org_1   | 2021-11-25 07:49:59,864 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-11-25 07:49:59,864 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2021-11-25 07:49:59,882 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2021-11-25 07:49:59,895 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2021-11-25 07:49:59,896 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: start with initializing state, conf=-1: [], old=null
recon_1      | 2021-11-25 07:51:03,029 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 131 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:05,031 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 132 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:05,032 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 133 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:05,032 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 134 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:07,036 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 135 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:07,037 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 136 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:07,039 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 137 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:09,041 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 138 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:09,042 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 139 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:09,042 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 140 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:11,044 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 141 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:11,046 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 142 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:11,047 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 143 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:13,054 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 144 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:13,063 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 145 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:13,083 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 146 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:15,089 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 147 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:15,091 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 148 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:15,093 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 149 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:17,108 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 150 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:17,115 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 151 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:17,116 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 152 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:19,118 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 153 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:19,120 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 154 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:19,123 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 155 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:21,129 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 156 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-11-25 07:49:59,909 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2021-11-25 07:49:59,914 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFAD39A678E5,id=95e9e3e6-77c8-42b6-8332-7b517674b4f8
scm2.org_1   | 2021-11-25 07:49:59,946 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: start RPC server
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:46,290 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:46,297 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:46,301 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,386 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:46,393 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:46,396 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,406 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:46,410 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:00,209 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: GrpcService started, listening on 9894
scm2.org_1   | 2021-11-25 07:50:00,305 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/0x000000084052f040@1ed0128b] INFO util.JvmPauseMonitor: JvmPauseMonitor-95e9e3e6-77c8-42b6-8332-7b517674b4f8: Started
scm2.org_1   | 2021-11-25 07:50:00,355 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-11-25 07:50:00,378 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-11-25 07:50:00,379 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2021-11-25 07:50:03,625 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:03,670 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2021-11-25 07:50:03,670 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: change Leader from null to d1137d26-6502-410a-9479-0d2074af0cec at term 2 for installSnapshot, leader elected after 9284ms
scm2.org_1   | 2021-11-25 07:50:03,677 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Received notification to install snapshot at index 4
scm2.org_1   | 2021-11-25 07:50:03,797 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 4.
scm2.org_1   | 2021-11-25 07:50:03,802 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:03,805 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm2.org_1   | 2021-11-25 07:50:05,353 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:05,371 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:05,372 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t0,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:05,410 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,554 [grpc-default-executor-0] INFO impl.RoleInfo: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: start 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-FollowerState
scm2.org_1   | 2021-11-25 07:50:05,555 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:05,558 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:05,629 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,635 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
om2_1        | 2021-11-25 07:52:39,666 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-11-25 07:52:39,730 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
scm1.org_1   | 2021-11-25 07:49:23,226 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-11-25 07:49:23,227 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-11-25 07:49:23,228 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2021-11-25 07:49:23,229 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2021-11-25 07:49:23,230 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2021-11-25 07:49:23,231 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2021-11-25 07:49:23,232 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2021-11-25 07:49:23,232 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2021-11-25 07:49:23,243 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2021-11-25 07:50:46,411 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:46,426 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,495 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:46,502 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:46,590 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,591 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:46,592 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:46,592 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
recon_1      | 2021-11-25 07:51:21,131 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 157 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-11-25 07:50:46,618 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,656 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:46,665 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:46,696 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,707 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
recon_1      | 2021-11-25 07:51:21,132 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 158 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | 2021-11-25 07:52:39,735 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: reject ELECTION from om1: already has voted for om2 at current term 1
recon_1      | 2021-11-25 07:51:23,135 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 159 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:23,162 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 160 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:23,167 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 161 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:25,187 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 162 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:25,188 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 163 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:25,191 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 164 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | 2021-11-25 07:52:39,735 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-11-25 07:52:39,930 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2021-11-25 07:52:39,937 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1        | 2021-11-25 07:52:39,937 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om2_1        | 2021-11-25 07:52:39,938 [grpc-default-executor-1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-11-25 07:52:39,939 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted: {}
om2_1        | java.lang.InterruptedException: sleep interrupted
om2_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om2_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om2_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
scm1.org_1   | 2021-11-25 07:49:23,244 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2021-11-25 07:49:23,272 [pool-14-thread-1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: set configuration 0: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-11-25 07:49:23,273 [pool-14-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/current/log_inprogress_0
scm1.org_1   | 2021-11-25 07:49:23,276 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:49:23,276 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-11-25 07:49:23,355 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2021-11-25 07:49:23,356 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-11-25 07:49:23,358 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-11-25 07:49:23,361 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2021-11-25 07:49:23,363 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2021-11-25 07:49:23,363 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-11-25 07:49:23,427 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2021-11-25 07:49:23,428 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2021-11-25 07:49:23,428 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2021-11-25 07:49:23,791 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm1.org_1   | 2021-11-25 07:49:23,792 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2021-11-25 07:49:23,797 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2021-11-25 07:49:23,802 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2021-11-25 07:49:23,907 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2021-11-25 07:49:23,921 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2021-11-25 07:51:27,209 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 165 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:27,211 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 166 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:27,213 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 167 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:29,215 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 168 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:29,217 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 169 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:29,218 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 170 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:31,221 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 171 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:31,223 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 172 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:31,224 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 173 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:33,227 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 174 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:33,228 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 175 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:33,231 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 176 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:35,246 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 177 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:35,285 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 178 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:35,297 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 179 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:37,303 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 180 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:37,307 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 181 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:37,310 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 182 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:39,313 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 183 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:39,316 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 184 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:39,317 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 185 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:41,318 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 186 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:41,320 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 187 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:41,320 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 188 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:43,323 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 189 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:43,326 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 190 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:43,327 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 191 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:45,329 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 192 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:45,330 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 193 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:45,333 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 194 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:47,334 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 195 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:47,336 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 196 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:47,336 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 197 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:49,339 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 198 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:49,340 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 199 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:49,341 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 200 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:51,342 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 201 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:51,344 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 202 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:51,345 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 203 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:53,346 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 204 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:53,347 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 205 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:53,348 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 206 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:55,355 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 207 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:55,362 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 208 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:55,362 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 209 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:57,364 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 210 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:57,365 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 211 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:57,366 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 212 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:51:58,029 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45468
scm1.org_1   | 2021-11-25 07:49:23,932 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:46,710 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:46,710 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:46,724 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
om2_1        | 2021-11-25 07:52:39,944 [grpc-default-executor-1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-11-25 07:52:39,962 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:OK-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om1, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-11-25 07:52:41,195 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 13398ms
om2_1        | 2021-11-25 07:52:41,399 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-11-25 07:52:41,497 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2021-11-25 07:52:42,252 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2021-11-25 07:52:45,131 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
scm3.org_1   | 2021-11-25 07:50:46,801 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:05,638 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:05,639 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:05,661 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,676 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:05,676 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:05,715 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,718 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:05,719 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:05,719 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:05,728 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,750 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:05,750 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:05,758 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,759 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:05,766 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:05,767 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:05,768 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,796 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:05,797 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:05,825 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,826 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
recon_1      | 2021-11-25 07:51:58,086 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-11-25 07:51:58,786 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54962
recon_1      | 2021-11-25 07:51:58,841 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-11-25 07:51:59,389 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 213 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:59,396 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 214 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:51:59,409 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 215 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:00,542 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54278
recon_1      | 2021-11-25 07:52:00,597 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-11-25 07:52:01,414 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 216 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:01,421 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 217 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:01,424 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 218 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:02,891 [IPC Server handler 1 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0950a55d-429f-4438-94ab-c48b091ad805
recon_1      | 2021-11-25 07:52:02,936 [IPC Server handler 1 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [], networkLocation: /default-rack, certSerialId: 8112927771086, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-11-25 07:52:03,182 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 0950a55d-429f-4438-94ab-c48b091ad805 to Node DB.
recon_1      | 2021-11-25 07:52:03,289 [IPC Server handler 58 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ece86bc6-b07b-4fda-a4d6-106fafa8b49c
recon_1      | 2021-11-25 07:52:03,299 [IPC Server handler 58 on default port 9891] INFO node.SCMNodeManager: Registered Data node : ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8111158445552, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-11-25 07:52:03,290 [IPC Server handler 55 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/20a284f6-c8a8-496d-9157-8df5a2a17913
recon_1      | 2021-11-25 07:52:03,301 [IPC Server handler 55 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886], networkLocation: /default-rack, certSerialId: 8109713599631, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2021-11-25 07:52:03,323 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node ece86bc6-b07b-4fda-a4d6-106fafa8b49c to Node DB.
recon_1      | 2021-11-25 07:52:03,332 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 20a284f6-c8a8-496d-9157-8df5a2a17913 to Node DB.
recon_1      | 2021-11-25 07:52:03,437 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 219 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:03,440 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 220 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:03,456 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 221 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:03,900 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2021-11-25 07:52:04,006 [IPC Server handler 4 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2021-11-25 07:52:04,313 [IPC Server handler 58 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2021-11-25 07:52:05,458 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 222 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:05,459 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 223 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:05,479 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 224 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:07,508 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 225 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:07,512 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 226 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:07,516 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 227 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:09,520 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 228 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:09,523 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 229 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:09,526 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 230 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:11,527 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 231 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:11,529 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 232 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:11,563 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 233 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:13,567 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 234 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:13,573 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 235 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:13,589 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 236 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:15,592 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 237 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:15,595 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 238 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:15,596 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 239 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:17,597 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 240 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:17,600 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 241 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:17,606 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 242 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:19,608 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 243 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:19,612 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 244 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:19,613 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 245 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | 2021-11-25 07:49:23,985 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2021-11-25 07:49:23,992 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2021-11-25 07:49:23,992 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2021-11-25 07:49:24,042 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2021-11-25 07:49:24,073 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2021-11-25 07:49:24,109 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2021-11-25 07:49:24,136 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-11-25 07:49:24,146 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 4 milliseconds for processing 0 containers.
scm1.org_1   | 2021-11-25 07:49:24,158 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2021-11-25 07:49:24,164 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:49:24,168 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2021-11-25 07:49:24,218 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2021-11-25 07:49:24,225 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2021-11-25 07:49:24,226 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 7981323859056 on primary SCM
scm1.org_1   | 2021-11-25 07:49:24,231 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2021-11-25 07:49:24,296 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-11-25 07:49:24,343 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2021-11-25 07:49:25,556 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-11-25 07:49:25,570 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2021-11-25 07:49:25,662 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-11-25 07:49:25,671 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2021-11-25 07:49:25,712 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-11-25 07:49:25,713 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2021-11-25 07:49:25,862 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2021-11-25 07:49:25,890 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          0.1
scm1.org_1   | Max Datanodes to Involve per Iteration(ratio)      0.2
scm1.org_1   | Max Size to Move per Iteration                     30GB
scm1.org_1   | Max Size Entering Target per Iteration             1GB
scm1.org_1   | Max Size Leaving Source per Iteration              1GB
scm1.org_1   | 
scm1.org_1   | 2021-11-25 07:49:25,890 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-11-25 07:49:25,890 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2021-11-25 07:49:25,895 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2021-11-25 07:49:25,896 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2021-11-25 07:49:25,897 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: start as a follower, conf=0: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-11-25 07:49:25,912 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2021-11-25 07:49:25,913 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: start d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState
scm1.org_1   | 2021-11-25 07:49:25,919 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFAD39A678E5,id=d1137d26-6502-410a-9479-0d2074af0cec
scm1.org_1   | 2021-11-25 07:49:25,930 [Listener at 0.0.0.0/9860] INFO server.RaftServer: d1137d26-6502-410a-9479-0d2074af0cec: start RPC server
scm1.org_1   | 2021-11-25 07:49:26,026 [Listener at 0.0.0.0/9860] INFO server.GrpcService: d1137d26-6502-410a-9479-0d2074af0cec: GrpcService started, listening on 9894
scm1.org_1   | 2021-11-25 07:49:26,033 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-11-25 07:50:46,810 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:46,811 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:46,811 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:46,812 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:46,833 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:46,834 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:46,910 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:46,918 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:46,927 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:47,005 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:47,014 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:47,015 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:47,074 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:47,131 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:47,132 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#7:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:47,155 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:47,158 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm1.org_1   | 2021-11-25 07:49:26,033 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2021-11-25 07:49:26,034 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$430/0x0000000840521040@1acd2a14] INFO util.JvmPauseMonitor: JvmPauseMonitor-d1137d26-6502-410a-9479-0d2074af0cec: Started
scm1.org_1   | 2021-11-25 07:49:26,040 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2021-11-25 07:49:26,040 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2021-11-25 07:49:26,338 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2021-11-25 07:49:26,376 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2021-11-25 07:49:26,376 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2021-11-25 07:49:26,827 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2021-11-25 07:49:26,849 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-11-25 07:49:26,851 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2021-11-25 07:49:26,893 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2021-11-25 07:49:26,894 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2021-11-25 07:49:26,896 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-11-25 07:49:26,896 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2021-11-25 07:49:26,926 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm1.org_1   | 2021-11-25 07:49:26,926 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2021-11-25 07:49:26,927 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-11-25 07:49:26,928 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2021-11-25 07:49:26,934 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2021-11-25 07:49:27,059 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@79194b1c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2021-11-25 07:49:27,090 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2021-11-25 07:49:27,090 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2021-11-25 07:49:27,095 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2021-11-25 07:49:27,144 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @9719ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2021-11-25 07:49:27,318 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2021-11-25 07:49:27,326 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2021-11-25 07:49:27,328 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2021-11-25 07:49:27,328 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2021-11-25 07:49:27,329 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2021-11-25 07:49:27,345 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2021-11-25 07:49:27,393 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
recon_1      | 2021-11-25 07:52:21,614 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 246 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-11-25 07:50:05,827 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:05,831 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:05,832 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,931 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:05,936 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:05,954 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:05,959 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:05,961 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:05,962 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:05,969 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,024 [grpc-default-executor-0] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1637826603805.tar.gz
scm2.org_1   | 2021-11-25 07:50:06,062 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:06,062 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:06,069 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,070 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:06,070 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:06,071 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:06,073 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,082 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1637826603805
scm2.org_1   | 2021-11-25 07:50:06,086 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1637826603805
scm2.org_1   | 2021-11-25 07:50:06,255 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:06,257 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:06,264 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,268 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:06,277 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:06,282 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:06,283 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,311 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:06,311 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#7:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:47,166 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:47,167 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:47,182 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:47,439 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:47,442 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#8:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:47,530 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:47,530 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:47,537 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
recon_1      | 2021-11-25 07:52:21,615 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 247 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:21,616 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 248 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:23,618 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 249 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:23,618 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 250 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:23,621 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 251 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:25,622 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 252 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:25,624 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 253 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:25,629 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 254 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2021-11-25 07:52:33,948 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54354
recon_1      | 2021-11-25 07:52:33,960 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45554
recon_1      | 2021-11-25 07:52:34,001 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-11-25 07:52:34,008 [IPC Server handler 84 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2021-11-25 07:52:34,030 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-11-25 07:52:34,049 [IPC Server handler 5 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2021-11-25 07:52:34,432 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55062
recon_1      | 2021-11-25 07:52:34,522 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2021-11-25 07:52:34,523 [IPC Server handler 82 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2021-11-25 07:52:38,544 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 255 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-11-25 07:50:47,537 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:47,538 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:47,804 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:47,805 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#9:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:47,904 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:47,913 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:47,917 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:47,925 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:47,957 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,060 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:48,066 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#10:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:48,071 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,073 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:48,077 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:48,078 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:48,126 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,217 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:48,218 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#11:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:48,236 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,237 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:48,238 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:48,242 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:06,316 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,317 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:06,318 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:06,321 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:06,322 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,350 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:06,350 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#8:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:06,371 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,382 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm1.org_1   | 2021-11-25 07:49:27,395 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
scm1.org_1   | 2021-11-25 07:49:27,440 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2021-11-25 07:49:27,441 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2021-11-25 07:49:27,443 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2021-11-25 07:49:27,468 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2021-11-25 07:49:27,477 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b88a2e2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2021-11-25 07:49:27,479 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2fb3c930{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2021-11-25 07:49:27,612 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2021-11-25 07:49:27,637 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@259647f2{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-4058844993136124309/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2021-11-25 07:49:27,653 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@6eaa8abf{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2021-11-25 07:49:27,654 [Listener at 0.0.0.0/9860] INFO server.Server: Started @10233ms
scm1.org_1   | 2021-11-25 07:49:27,663 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2021-11-25 07:49:27,664 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2021-11-25 07:49:27,666 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2021-11-25 07:49:28,296 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39473
scm1.org_1   | 2021-11-25 07:49:28,339 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-11-25 07:49:29,041 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36972
scm1.org_1   | 2021-11-25 07:49:29,060 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:49:30,966 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO impl.FollowerState: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5053848748ns, electionTimeout:5044ms
scm1.org_1   | 2021-11-25 07:49:30,968 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: shutdown d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState
scm1.org_1   | 2021-11-25 07:49:30,970 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2021-11-25 07:49:30,975 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2021-11-25 07:49:30,975 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-FollowerState] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: start d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1
scm1.org_1   | 2021-11-25 07:49:31,033 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO impl.LeaderElection: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-11-25 07:49:31,036 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO impl.LeaderElection: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2021-11-25 07:49:31,037 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: shutdown d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1
scm1.org_1   | 2021-11-25 07:49:31,038 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2021-11-25 07:49:31,039 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2021-11-25 07:49:31,039 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2021-11-25 07:49:31,045 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: change Leader from null to d1137d26-6502-410a-9479-0d2074af0cec at term 2 for becomeLeader, leader elected after 7873ms
scm1.org_1   | 2021-11-25 07:49:31,060 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2021-11-25 07:49:31,077 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-11-25 07:49:31,089 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-11-25 07:49:31,098 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2021-11-25 07:49:31,099 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1      | 2021-11-25 07:52:42,523 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
scm2.org_1   | 2021-11-25 07:50:06,383 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:06,383 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:06,390 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,421 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:06,422 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,428 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#9:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:06,433 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:06,434 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:06,435 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 256 failover attempts. Trying to failover immediately.
recon_1      | 2021-11-25 07:52:43,429 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2021-11-25 07:49:31,100 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2021-11-25 07:49:31,108 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-11-25 07:49:31,111 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2021-11-25 07:49:31,118 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO impl.RoleInfo: d1137d26-6502-410a-9479-0d2074af0cec: start d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl
scm1.org_1   | 2021-11-25 07:49:31,128 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2021-11-25 07:49:31,135 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/current/log_inprogress_0 to /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/current/log_0-0
scm1.org_1   | 2021-11-25 07:49:31,162 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/current/log_inprogress_1
scm1.org_1   | 2021-11-25 07:49:31,165 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderElection1] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-11-25 07:49:31,181 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2021-11-25 07:49:31,187 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2021-11-25 07:49:31,203 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:49:31,205 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2021-11-25 07:49:31,210 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2021-11-25 07:49:31,213 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2021-11-25 07:49:31,227 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2021-11-25 07:49:31,239 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2021-11-25 07:49:31,822 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57772
scm1.org_1   | 2021-11-25 07:49:31,839 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-11-25 07:49:39,727 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36256
scm1.org_1   | 2021-11-25 07:49:39,738 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:49:40,128 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 95e9e3e6-77c8-42b6-8332-7b517674b4f8
scm1.org_1   | 2021-11-25 07:49:42,848 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:49:42,848 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2021-11-25 07:49:42,848 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2021-11-25 07:49:42,876 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 2297816.411us
scm1.org_1   | 2021-11-25 07:49:47,411 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58014
scm1.org_1   | 2021-11-25 07:49:47,475 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-11-25 07:50:01,489 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37474
scm1.org_1   | 2021-11-25 07:50:01,542 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:50:01,545 [IPC Server handler 21 on default port 9863] INFO ha.SCMRatisServerImpl: d1137d26-6502-410a-9479-0d2074af0cec: Submitting SetConfiguration request to Ratis server with new SCM peers list: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2021-11-25 07:50:01,554 [IPC Server handler 21 on default port 9863] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: receive setConfiguration SetConfigurationRequest:client-359BB2B85C33->d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5, cid=0, seq=0, RW, null, peers:[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2021-11-25 07:50:01,554 [IPC Server handler 21 on default port 9863] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-359BB2B85C33->d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5, cid=0, seq=0, RW, null, peers:[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2021-11-25 07:50:01,591 [IPC Server handler 21 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2021-11-25 07:50:01,592 [IPC Server handler 21 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-11-25 07:50:01,592 [IPC Server handler 21 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm2.org_1   | 2021-11-25 07:50:06,437 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,459 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#4
scm2.org_1   | 2021-11-25 07:50:06,461 [pool-16-thread-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: StateMachine successfully installed snapshot index 4. Reloading the StateMachine.
scm2.org_1   | 2021-11-25 07:50:06,462 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2021-11-25 07:50:06,462 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2021-11-25 07:50:06,464 [pool-16-thread-1] INFO raftlog.RaftLog: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 4
scm2.org_1   | 2021-11-25 07:50:06,478 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,477 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:06,488 [grpc-default-executor-1] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#10:FAIL-t2,INCONSISTENCY,nextIndex=5,followerCommit=-1
scm2.org_1   | 2021-11-25 07:50:06,488 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:06,489 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:06,490 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:06,503 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,516 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:06,518 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#11:FAIL-t2,INCONSISTENCY,nextIndex=5,followerCommit=4
scm2.org_1   | 2021-11-25 07:50:06,531 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,531 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:06,532 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:06,532 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm2.org_1   | 2021-11-25 07:50:06,535 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,566 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: Failed appendEntries as snapshot (4) installation is in progress
scm2.org_1   | 2021-11-25 07:50:06,566 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#12:FAIL-t2,INCONSISTENCY,nextIndex=5,followerCommit=4
scm2.org_1   | 2021-11-25 07:50:06,589 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,590 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 4
scm2.org_1   | 2021-11-25 07:50:06,590 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm3.org_1   | 2021-11-25 07:50:48,244 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,380 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:48,390 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#12:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:48,401 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,402 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:48,405 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:48,406 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:48,408 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,431 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:48,432 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#13:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:48,441 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,442 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:48,443 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:48,443 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:48,446 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 257 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | 2021-11-25 07:50:01,629 [IPC Server handler 21 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2021-11-25 07:50:01,643 [IPC Server handler 21 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-11-25 07:50:01,644 [IPC Server handler 21 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-11-25 07:50:01,726 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:01,838 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,066 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58268
scm1.org_1   | 2021-11-25 07:50:05,156 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-11-25 07:50:05,275 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2021-11-25 07:50:05,396 [grpc-default-executor-0] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1637826605276 in 119 milliseconds
scm1.org_1   | 2021-11-25 07:50:05,392 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received the first reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t0,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:05,421 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:05,587 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,588 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,622 [grpc-default-executor-1] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:05,655 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:05,658 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:05,667 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,667 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,744 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:05,745 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:05,746 [grpc-default-executor-1] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:05,746 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,746 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,776 [grpc-default-executor-1] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:05,790 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:05,790 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:05,795 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,801 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,848 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:05,889 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:05,889 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:05,890 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,891 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:05,936 [grpc-default-executor-0] INFO ha.SCMGrpcOutputStream: Sent 7512 bytes for cluster CID-2f16d919-03be-44c6-8b84-cfad39a678e5
scm1.org_1   | 2021-11-25 07:50:05,951 [grpc-default-executor-0] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 553 milliseconds
scm1.org_1   | 2021-11-25 07:50:05,955 [grpc-default-executor-0] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1637826605276
scm1.org_1   | 2021-11-25 07:50:06,019 [grpc-default-executor-1] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:06,046 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:06,046 [grpc-default-executor-1] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:06,047 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,048 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,145 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:06,149 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:06,154 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:06,171 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,173 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,266 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:06,289 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:06,292 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:06,301 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,306 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,331 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:06,338 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:06,339 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:06,340 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm2.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:06,591 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 1: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:06,591 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=4
scm2.org_1   | 2021-11-25 07:50:06,593 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 95e9e3e6-77c8-42b6-8332-7b517674b4f8: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2021-11-25 07:50:06,726 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#4
scm2.org_1   | 2021-11-25 07:50:06,759 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 4
scm2.org_1   | 2021-11-25 07:50:06,759 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-11-25 07:50:06,761 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-11-25 07:50:06,943 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
scm2.org_1   | 2021-11-25 07:50:06,951 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2021-11-25 07:50:06,961 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 4
scm2.org_1   | 2021-11-25 07:50:06,968 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO impl.StateMachineUpdater: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2021-11-25 07:50:06,968 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO impl.StateMachineUpdater: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2021-11-25 07:50:08,873 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 5: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-11-25 07:50:08,884 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLogWorker: Starting segment from index:5
scm2.org_1   | 2021-11-25 07:50:09,291 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/current/log_inprogress_5
scm2.org_1   | 2021-11-25 07:50:09,381 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:50:48,538 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:48,552 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#14:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:48,562 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,579 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:48,582 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:48,583 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:48,600 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,658 [grpc-default-executor-1] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1637826642123.tar.gz
scm3.org_1   | 2021-11-25 07:50:48,809 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:48,821 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#15:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:48,825 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,828 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm2.org_1   | 2021-11-25 07:50:09,383 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2021-11-25 07:50:09,390 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2021-11-25 07:50:09,391 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2021-11-25 07:50:09,404 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:50:09,504 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-11-25 07:50:09,534 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2021-11-25 07:50:09,671 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-CFAD39A678E5:[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-11-25 07:50:09,738 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2021-11-25 07:50:10,071 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2021-11-25 07:50:10,071 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2021-11-25 07:50:10,931 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2021-11-25 07:50:11,047 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2021-11-25 07:50:11,048 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2021-11-25 07:50:12,306 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2021-11-25 07:50:12,322 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-11-25 07:50:12,322 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2021-11-25 07:50:12,752 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2021-11-25 07:50:12,753 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2021-11-25 07:50:12,766 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-11-25 07:50:12,767 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2021-11-25 07:50:13,029 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm2.org_1   | 2021-11-25 07:50:13,030 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2021-11-25 07:50:13,031 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-11-25 07:50:13,031 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2021-11-25 07:50:13,032 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2021-11-25 07:50:13,200 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-11-25 07:50:13,208 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2021-11-25 07:50:13,208 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2021-11-25 07:50:13,953 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@34c31a34] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2021-11-25 07:50:14,041 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2021-11-25 07:50:14,042 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2021-11-25 07:50:14,059 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2021-11-25 07:50:14,209 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @30158ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2021-11-25 07:50:14,722 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2021-11-25 07:50:14,745 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2021-11-25 07:50:14,747 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2021-11-25 07:50:14,758 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2021-11-25 07:50:14,758 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2021-11-25 07:50:14,762 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2021-11-25 07:50:14,933 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2021-11-25 07:50:14,942 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
scm2.org_1   | 2021-11-25 07:50:15,164 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2021-11-25 07:50:15,164 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2021-11-25 07:50:15,211 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm2.org_1   | 2021-11-25 07:50:15,379 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:50:48,838 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:48,854 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:48,867 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,976 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:48,976 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:48,977 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#16:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:48,977 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:48,977 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:48,994 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:48,995 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,029 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1637826642123
scm3.org_1   | 2021-11-25 07:50:49,034 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1637826642123
scm3.org_1   | 2021-11-25 07:50:49,076 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:49,084 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#17:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:49,084 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,099 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm1.org_1   | 2021-11-25 07:50:06,341 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,390 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:06,407 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:06,410 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:06,411 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,412 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,441 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:06,455 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:06,459 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:06,469 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,470 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,492 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 0 -> 5
scm1.org_1   | 2021-11-25 07:50:06,508 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:06,509 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:06,522 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 5 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,522 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,524 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 5 -> 5
scm1.org_1   | 2021-11-25 07:50:06,560 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:06,562 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:06,569 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateUnconditionally 5 -> 5
scm1.org_1   | 2021-11-25 07:50:06,574 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: followerNextIndex = 5 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,574 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->95e9e3e6-77c8-42b6-8332-7b517674b4f8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2021-11-25 07:50:06,601 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-95e9e3e6-77c8-42b6-8332-7b517674b4f8#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=4
scm1.org_1   | 2021-11-25 07:50:06,602 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8-InstallSnapshotResponseHandler: Follower installed snapshot at index 4
scm1.org_1   | 2021-11-25 07:50:06,602 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: snapshotIndex: setUnconditionally 0 -> 4
scm1.org_1   | 2021-11-25 07:50:06,602 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: matchIndex: setUnconditionally 0 -> 4
scm1.org_1   | 2021-11-25 07:50:06,602 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: setUnconditionally 5 -> 5
scm1.org_1   | 2021-11-25 07:50:06,602 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8 acknowledged installing snapshot
scm1.org_1   | 2021-11-25 07:50:06,603 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->95e9e3e6-77c8-42b6-8332-7b517674b4f8: nextIndex: updateToMax old=5, new=5, updated? false
scm1.org_1   | 2021-11-25 07:50:08,192 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:49776
scm1.org_1   | 2021-11-25 07:50:08,222 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:50:08,858 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: set configuration 5: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0], old=[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-11-25 07:50:09,369 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2021-11-25 07:50:09,554 [IPC Server handler 21 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 95e9e3e6-77c8-42b6-8332-7b517674b4f8.
scm1.org_1   | 2021-11-25 07:50:13,514 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36744
scm1.org_1   | 2021-11-25 07:50:13,572 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:50:13,900 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:48124
scm1.org_1   | 2021-11-25 07:50:13,913 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:50:13,915 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: e39fb3e9-4060-458c-ab31-c74db05e820c
scm1.org_1   | 2021-11-25 07:50:14,957 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:50:14,991 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 938749.837us
scm1.org_1   | 2021-11-25 07:50:23,134 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58518
scm1.org_1   | 2021-11-25 07:50:23,207 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-11-25 07:50:36,759 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:50132
scm1.org_1   | 2021-11-25 07:50:37,043 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:50:37,045 [IPC Server handler 12 on default port 9863] INFO ha.SCMRatisServerImpl: d1137d26-6502-410a-9479-0d2074af0cec: Submitting SetConfiguration request to Ratis server with new SCM peers list: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2021-11-25 07:50:37,045 [IPC Server handler 12 on default port 9863] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: receive setConfiguration SetConfigurationRequest:client-359BB2B85C33->d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5, cid=1, seq=0, RW, null, peers:[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2021-11-25 07:50:37,045 [IPC Server handler 12 on default port 9863] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-359BB2B85C33->d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5, cid=1, seq=0, RW, null, peers:[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2021-11-25 07:50:37,045 [IPC Server handler 12 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2021-11-25 07:50:37,045 [IPC Server handler 12 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-11-25 07:50:37,045 [IPC Server handler 12 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2021-11-25 07:50:37,052 [IPC Server handler 12 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2021-11-25 07:50:37,053 [IPC Server handler 12 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-11-25 07:50:37,053 [IPC Server handler 12 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-11-25 07:50:37,161 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:37,212 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:45,839 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received the first reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t0,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:45,854 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:45,893 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:45,903 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,128 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:46,129 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:46,214 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm3.org_1   |     address: "scm1.org:9894"
scm2.org_1   | 2021-11-25 07:50:15,381 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2021-11-25 07:50:15,381 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2021-11-25 07:50:15,443 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2021-11-25 07:50:15,457 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2daf2351{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2021-11-25 07:50:15,475 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@29922188{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2021-11-25 07:50:15,934 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2021-11-25 07:50:15,983 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6eb506d0{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-104080515669258311/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2021-11-25 07:50:16,021 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@370e5bb9{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2021-11-25 07:50:16,021 [Listener at 0.0.0.0/9860] INFO server.Server: Started @31971ms
scm2.org_1   | 2021-11-25 07:50:16,026 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2021-11-25 07:50:16,028 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2021-11-25 07:50:16,035 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2021-11-25 07:50:51,491 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 11: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-11-25 07:50:51,580 [grpc-default-executor-0] INFO server.RaftServer$Division: 95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5: set configuration 13: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-11-25 07:51:17,408 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:51:18,320 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:51:20,074 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:51:21,222 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/0x000000084052f040@1ed0128b] WARN util.JvmPauseMonitor: JvmPauseMonitor-95e9e3e6-77c8-42b6-8332-7b517674b4f8: Detected pause in JVM or host machine (eg GC): pause of approximately 147497225ns.
scm2.org_1   | GC pool 'ParNew' had collection(s): count=1 time=124ms
scm2.org_1   | 2021-11-25 07:51:28,443 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:51:28,984 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:51:29,401 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:51:58,357 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36914
scm2.org_1   | 2021-11-25 07:51:58,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-11-25 07:51:58,847 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48140
scm2.org_1   | 2021-11-25 07:51:58,915 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-11-25 07:52:00,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44540
scm2.org_1   | 2021-11-25 07:52:00,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-11-25 07:52:01,103 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/0x000000084052f040@1ed0128b] WARN util.JvmPauseMonitor: JvmPauseMonitor-95e9e3e6-77c8-42b6-8332-7b517674b4f8: Detected pause in JVM or host machine (eg GC): pause of approximately 248414753ns.
scm2.org_1   | GC pool 'ParNew' had collection(s): count=1 time=133ms
scm2.org_1   | 2021-11-25 07:52:04,151 [IPC Server handler 46 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0950a55d-429f-4438-94ab-c48b091ad805
scm2.org_1   | 2021-11-25 07:52:04,186 [IPC Server handler 18 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/20a284f6-c8a8-496d-9157-8df5a2a17913
scm2.org_1   | 2021-11-25 07:52:04,250 [IPC Server handler 72 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ece86bc6-b07b-4fda-a4d6-106fafa8b49c
scm2.org_1   | 2021-11-25 07:52:04,251 [IPC Server handler 72 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8111158445552, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-11-25 07:52:04,257 [IPC Server handler 18 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8109713599631, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-11-25 07:52:04,237 [IPC Server handler 46 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8112927771086, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-11-25 07:52:04,322 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2021-11-25 07:52:04,402 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2021-11-25 07:52:04,406 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2021-11-25 07:52:04,406 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2021-11-25 07:52:04,424 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2021-11-25 07:52:04,424 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-11-25 07:52:04,516 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2021-11-25 07:52:04,424 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-11-25 07:52:04,518 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-11-25 07:52:04,522 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-11-25 07:52:04,524 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-11-25 07:52:06,263 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a58ff28e-e672-4a6e-b65c-6c91577ea767, Nodes: ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:04.381Z[UTC]].
scm2.org_1   | 2021-11-25 07:52:06,265 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:52:06,325 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 920724e0-2396-4120-9852-100cc9d9f034, Nodes: 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:05.895Z[UTC]].
scm2.org_1   | 2021-11-25 07:52:06,336 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:52:06,362 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6a1182b-7d4f-4a64-ae52-9ddd9117c2fb, Nodes: 20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.222Z[UTC]].
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm1.org_1   | 2021-11-25 07:50:46,216 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,243 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:46,276 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:46,308 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:46,310 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:46,315 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,349 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,414 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:46,452 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:46,452 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:46,464 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,470 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,539 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:46,630 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:46,630 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:46,632 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,640 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,685 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:46,743 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:46,751 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:46,753 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,770 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,851 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:46,859 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:46,870 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:46,874 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,878 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:46,974 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:47,099 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:47,113 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:47,118 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:47,122 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:47,147 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:47,187 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:47,199 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:47,246 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:47,402 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:47,529 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:47,559 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:47,565 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:47,580 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:47,586 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,017 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:48,020 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:48,019 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:48,029 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm2.org_1   | 2021-11-25 07:52:06,365 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:52:06,557 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 65c842b6-e24f-41e4-aa24-d7c3b8105647, Nodes: ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.360Z[UTC]].
scm2.org_1   | 2021-11-25 07:52:06,564 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:52:06,697 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 2f49bc21-d6f0-4805-9d81-f57ca044c536, Nodes: 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.571Z[UTC]].
scm2.org_1   | 2021-11-25 07:52:06,715 [95e9e3e6-77c8-42b6-8332-7b517674b4f8@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-11-25 07:52:33,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36996
scm2.org_1   | 2021-11-25 07:52:34,002 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44620
scm2.org_1   | 2021-11-25 07:52:34,006 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-11-25 07:52:34,033 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-11-25 07:52:34,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48236
scm2.org_1   | 2021-11-25 07:52:34,542 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:49,103 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:49,103 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:49,114 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,184 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,184 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:49,185 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:49,186 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:49,186 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,185 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:49,194 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#18:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:49,320 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm1.org_1   | 2021-11-25 07:50:48,030 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,083 [grpc-default-executor-2] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2021-11-25 07:50:48,117 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:48,135 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:48,142 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:48,149 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,170 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,291 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:48,308 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:48,314 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:48,320 [grpc-default-executor-2] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1637826648116 in 204 milliseconds
scm1.org_1   | 2021-11-25 07:50:48,346 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,347 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,406 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:48,419 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:48,419 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:48,420 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,427 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,442 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:48,468 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:48,470 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:48,474 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,474 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,599 [grpc-default-executor-2] INFO ha.SCMGrpcOutputStream: Sent 8708 bytes for cluster CID-2f16d919-03be-44c6-8b84-cfad39a678e5
scm1.org_1   | 2021-11-25 07:50:48,603 [grpc-default-executor-2] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 280 milliseconds
scm1.org_1   | 2021-11-25 07:50:48,622 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:48,626 [grpc-default-executor-2] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1637826648116
scm1.org_1   | 2021-11-25 07:50:48,662 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:48,662 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:48,663 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,670 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,888 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:48,898 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:48,898 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:48,901 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:48,909 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,003 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:49,049 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:49,055 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:49,056 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,060 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,110 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:49,120 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:49,120 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:49,136 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,145 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,321 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#19:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:49,324 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,333 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:49,334 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:49,334 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:49,337 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,469 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:49,470 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#20:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:49,472 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,479 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:49,480 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:49,482 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:49,250 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:49,485 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,557 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:49,563 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#21:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:49,569 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,581 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm1.org_1   | 2021-11-25 07:50:49,251 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm1.org_1   | 2021-11-25 07:50:49,270 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm1.org_1   | 2021-11-25 07:50:49,276 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:49,581 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:49,582 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:49,582 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,679 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#10
scm3.org_1   | 2021-11-25 07:50:49,699 [pool-16-thread-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: StateMachine successfully installed snapshot index 10. Reloading the StateMachine.
scm3.org_1   | 2021-11-25 07:50:49,702 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2021-11-25 07:50:49,731 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,719 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:49,743 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#22:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:49,744 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm1.org_1   | 2021-11-25 07:50:49,293 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,331 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:49,375 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:49,383 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:49,390 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,414 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,484 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:49,511 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:49,512 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:49,514 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,523 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,608 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:49,661 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:49,670 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:49,680 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,684 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,767 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2021-11-25 07:50:49,767 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:49,772 [grpc-default-executor-0] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:49,777 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,794 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,905 [grpc-default-executor-0] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 0 -> 11
scm1.org_1   | 2021-11-25 07:50:49,914 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2021-11-25 07:50:49,925 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2021-11-25 07:50:49,937 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: followerNextIndex = 11 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,949 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-GrpcLogAppender: send d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2021-11-25 07:50:49,970 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateUnconditionally 11 -> 11
scm1.org_1   | 2021-11-25 07:50:50,001 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: received a reply d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=10
scm1.org_1   | 2021-11-25 07:50:50,013 [grpc-default-executor-2] INFO server.GrpcLogAppender: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c-InstallSnapshotResponseHandler: Follower installed snapshot at index 10
scm1.org_1   | 2021-11-25 07:50:50,013 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: snapshotIndex: setUnconditionally 0 -> 10
scm1.org_1   | 2021-11-25 07:50:50,017 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: matchIndex: setUnconditionally 0 -> 10
scm1.org_1   | 2021-11-25 07:50:50,020 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: setUnconditionally 11 -> 11
scm1.org_1   | 2021-11-25 07:50:50,020 [grpc-default-executor-2] INFO leader.FollowerInfo: Follower d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c acknowledged installing snapshot
scm1.org_1   | 2021-11-25 07:50:50,112 [grpc-default-executor-2] INFO leader.FollowerInfo: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5->e39fb3e9-4060-458c-ab31-c74db05e820c: nextIndex: updateToMax old=11, new=11, updated? false
scm1.org_1   | 2021-11-25 07:50:51,451 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: set configuration 11: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0], old=[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2021-11-25 07:50:51,558 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-LeaderStateImpl] INFO server.RaftServer$Division: d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5: set configuration 13: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2021-11-25 07:50:51,769 [IPC Server handler 12 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: e39fb3e9-4060-458c-ab31-c74db05e820c.
scm1.org_1   | 2021-11-25 07:51:00,279 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:48440
scm1.org_1   | 2021-11-25 07:51:00,323 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:49,748 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:49,749 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:49,754 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,777 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2021-11-25 07:50:49,801 [pool-16-thread-1] INFO raftlog.RaftLog: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 10
scm3.org_1   | 2021-11-25 07:50:49,854 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,830 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:49,865 [grpc-default-executor-0] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#23:FAIL-t2,INCONSISTENCY,nextIndex=11,followerCommit=-1
scm3.org_1   | 2021-11-25 07:50:49,865 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:49,870 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:49,871 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2021-11-25 07:50:49,875 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,933 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2021-11-25 07:50:49,947 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: inconsistency entries. Reply:d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#24:FAIL-t2,INCONSISTENCY,nextIndex=11,followerCommit=10
scm3.org_1   | 2021-11-25 07:50:49,980 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: receive installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:49,989 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 10
scm3.org_1   | 2021-11-25 07:50:49,989 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "d1137d26-6502-410a-9479-0d2074af0cec"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm1.org_1   | 2021-11-25 07:51:05,559 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58724
scm1.org_1   | 2021-11-25 07:51:05,809 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-11-25 07:51:12,099 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:57968
scm1.org_1   | 2021-11-25 07:51:12,248 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40430
scm1.org_1   | 2021-11-25 07:51:12,253 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:51:12,408 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:51:12,847 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:54882
scm1.org_1   | 2021-11-25 07:51:13,234 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:51:16,142 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56710
scm1.org_1   | 2021-11-25 07:51:16,265 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:16,266 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn bf0b5f0c901d, UUID: 20a284f6-c8a8-496d-9157-8df5a2a17913
scm1.org_1   | 2021-11-25 07:51:17,398 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:51:17,426 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 761748.497us
scm1.org_1   | 2021-11-25 07:51:17,562 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39138
scm1.org_1   | 2021-11-25 07:51:17,725 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:17,736 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn f7a87fafecdb, UUID: ece86bc6-b07b-4fda-a4d6-106fafa8b49c
scm1.org_1   | 2021-11-25 07:51:18,267 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:51:18,310 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 181210.072us
scm1.org_1   | 2021-11-25 07:51:19,393 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35520
scm1.org_1   | 2021-11-25 07:51:19,602 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:19,607 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 2c7bc09527e7, UUID: 0950a55d-429f-4438-94ab-c48b091ad805
scm1.org_1   | 2021-11-25 07:51:19,963 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:51:19,978 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 179682.65us
scm1.org_1   | 2021-11-25 07:51:27,461 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40200
scm1.org_1   | 2021-11-25 07:51:27,504 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:27,519 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: b3f678a8-7358-4f7c-bed1-dc360a4070ec
scm1.org_1   | 2021-11-25 07:51:27,998 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53914
scm1.org_1   | 2021-11-25 07:51:28,020 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:28,042 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: f61bd027-db9f-4e8f-9ee5-a58464150e69
scm1.org_1   | 2021-11-25 07:51:28,346 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41370
scm1.org_1   | 2021-11-25 07:51:28,415 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:51:28,461 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 254469.558us
scm1.org_1   | 2021-11-25 07:51:28,462 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:28,761 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 8ac462b1-8fae-41d0-a101-55c774a0d753
scm1.org_1   | 2021-11-25 07:51:28,948 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:51:28,990 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 115838.374us
scm1.org_1   | 2021-11-25 07:51:29,383 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:51:29,415 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 168036.183us
scm1.org_1   | 2021-11-25 07:51:34,498 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39186
scm1.org_1   | 2021-11-25 07:51:34,526 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:34,934 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56762
scm1.org_1   | 2021-11-25 07:51:34,985 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:37,160 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35570
scm1.org_1   | 2021-11-25 07:51:37,261 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:51:57,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48442
scm3.org_1   |   peers {
scm3.org_1   |     id: "95e9e3e6-77c8-42b6-8332-7b517674b4f8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2021-11-25 07:50:49,990 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 7: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:49,990 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: reply installSnapshot: d1137d26-6502-410a-9479-0d2074af0cec<-e39fb3e9-4060-458c-ab31-c74db05e820c#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=10
scm3.org_1   | 2021-11-25 07:50:49,991 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: e39fb3e9-4060-458c-ab31-c74db05e820c: Completed INSTALL_SNAPSHOT, lastRequest: d1137d26-6502-410a-9479-0d2074af0cec->e39fb3e9-4060-458c-ab31-c74db05e820c#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2021-11-25 07:50:50,456 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#10
scm3.org_1   | 2021-11-25 07:50:50,496 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 10
scm3.org_1   | 2021-11-25 07:50:50,510 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-11-25 07:50:50,521 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2021-11-25 07:50:51,011 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
scm3.org_1   | 2021-11-25 07:50:51,065 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2021-11-25 07:50:51,078 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 10
scm3.org_1   | 2021-11-25 07:50:51,158 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO impl.StateMachineUpdater: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2021-11-25 07:50:51,160 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO impl.StateMachineUpdater: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2021-11-25 07:50:51,537 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 11: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-11-25 07:50:51,617 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLogWorker: Starting segment from index:11
scm3.org_1   | 2021-11-25 07:50:51,931 [grpc-default-executor-1] INFO server.RaftServer$Division: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5: set configuration 13: [d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-11-25 07:50:52,225 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-CFAD39A678E5:[d1137d26-6502-410a-9479-0d2074af0cec|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, e39fb3e9-4060-458c-ab31-c74db05e820c|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 95e9e3e6-77c8-42b6-8332-7b517674b4f8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2021-11-25 07:50:52,261 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2021-11-25 07:50:52,274 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2021-11-25 07:50:52,280 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2021-11-25 07:50:53,359 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/2f16d919-03be-44c6-8b84-cfad39a678e5/current/log_inprogress_11
scm3.org_1   | 2021-11-25 07:50:53,622 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:50:53,627 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2021-11-25 07:50:53,655 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2021-11-25 07:50:53,659 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2021-11-25 07:50:53,924 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2021-11-25 07:50:54,072 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2021-11-25 07:50:54,074 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2021-11-25 07:50:56,269 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2021-11-25 07:50:56,290 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-11-25 07:50:56,749 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2021-11-25 07:50:57,223 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2021-11-25 07:50:57,223 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-11-25 07:50:57,958 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2021-11-25 07:50:57,963 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2021-11-25 07:50:58,010 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-11-25 07:50:58,013 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2021-11-25 07:50:58,708 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm3.org_1   | 2021-11-25 07:50:58,709 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2021-11-25 07:50:58,710 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2021-11-25 07:50:58,719 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2021-11-25 07:50:58,730 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2021-11-25 07:50:59,348 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-11-25 07:50:59,385 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2021-11-25 07:50:59,385 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm1.org_1   | 2021-11-25 07:51:57,995 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-11-25 07:51:58,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40516
scm1.org_1   | 2021-11-25 07:51:58,950 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-11-25 07:52:00,280 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47204
scm1.org_1   | 2021-11-25 07:52:00,446 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-11-25 07:52:03,172 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58840
scm1.org_1   | 2021-11-25 07:52:03,418 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-11-25 07:52:04,251 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ece86bc6-b07b-4fda-a4d6-106fafa8b49c
scm1.org_1   | 2021-11-25 07:52:04,270 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8111158445552, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-11-25 07:52:04,301 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-11-25 07:52:04,455 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2021-11-25 07:52:04,879 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$430/0x0000000840521040@1acd2a14] WARN util.JvmPauseMonitor: JvmPauseMonitor-d1137d26-6502-410a-9479-0d2074af0cec: Detected pause in JVM or host machine (eg GC): pause of approximately 224358317ns.
scm1.org_1   | GC pool 'ParNew' had collection(s): count=1 time=315ms
scm1.org_1   | 2021-11-25 07:52:04,974 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a58ff28e-e672-4a6e-b65c-6c91577ea767 to datanode:ece86bc6-b07b-4fda-a4d6-106fafa8b49c
scm1.org_1   | 2021-11-25 07:52:04,314 [IPC Server handler 16 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0950a55d-429f-4438-94ab-c48b091ad805
scm1.org_1   | 2021-11-25 07:52:05,042 [IPC Server handler 29 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/20a284f6-c8a8-496d-9157-8df5a2a17913
scm1.org_1   | 2021-11-25 07:52:05,202 [IPC Server handler 29 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8109713599631, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-11-25 07:52:05,209 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-11-25 07:52:05,002 [IPC Server handler 16 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8112927771086, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-11-25 07:52:05,258 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-11-25 07:52:05,377 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2021-11-25 07:52:05,509 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2021-11-25 07:52:05,518 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2021-11-25 07:52:05,518 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2021-11-25 07:52:05,519 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-11-25 07:52:05,519 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2021-11-25 07:52:05,519 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2021-11-25 07:52:05,795 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a58ff28e-e672-4a6e-b65c-6c91577ea767, Nodes: ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:04.381Z[UTC]].
scm1.org_1   | 2021-11-25 07:52:05,798 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:52:05,802 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 237539.485us
scm1.org_1   | 2021-11-25 07:52:05,909 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=920724e0-2396-4120-9852-100cc9d9f034 to datanode:0950a55d-429f-4438-94ab-c48b091ad805
scm1.org_1   | 2021-11-25 07:52:05,911 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=920724e0-2396-4120-9852-100cc9d9f034 to datanode:ece86bc6-b07b-4fda-a4d6-106fafa8b49c
scm3.org_1   | 2021-11-25 07:51:01,062 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4ec25389] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2021-11-25 07:51:01,272 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2021-11-25 07:51:01,272 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2021-11-25 07:51:01,287 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2021-11-25 07:51:01,643 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @45375ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2021-11-25 07:51:03,255 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2021-11-25 07:51:03,335 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2021-11-25 07:51:03,339 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2021-11-25 07:51:03,350 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2021-11-25 07:51:03,357 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2021-11-25 07:51:03,390 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2021-11-25 07:51:03,786 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2021-11-25 07:51:03,800 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.10+9-LTS
scm3.org_1   | 2021-11-25 07:51:04,166 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2021-11-25 07:51:04,166 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2021-11-25 07:51:04,168 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2021-11-25 07:51:04,400 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-11-25 07:51:04,421 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7072606{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2021-11-25 07:51:04,436 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@758e8b8d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2021-11-25 07:51:05,726 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2021-11-25 07:51:06,062 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@11fd6f02{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-17247426054200015588/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2021-11-25 07:51:06,168 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@18b12df9{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2021-11-25 07:51:06,178 [Listener at 0.0.0.0/9860] INFO server.Server: Started @49910ms
scm3.org_1   | 2021-11-25 07:51:06,213 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2021-11-25 07:51:06,244 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2021-11-25 07:51:06,255 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2021-11-25 07:51:17,937 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:51:17,965 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2021-11-25 07:51:17,965 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2021-11-25 07:51:18,368 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:51:19,985 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:51:28,449 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:52:05,918 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=920724e0-2396-4120-9852-100cc9d9f034 to datanode:20a284f6-c8a8-496d-9157-8df5a2a17913
scm1.org_1   | 2021-11-25 07:52:06,025 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 920724e0-2396-4120-9852-100cc9d9f034, Nodes: 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:05.895Z[UTC]].
scm1.org_1   | 2021-11-25 07:52:06,039 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:52:06,159 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 237022.577us
scm1.org_1   | 2021-11-25 07:52:06,222 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a6a1182b-7d4f-4a64-ae52-9ddd9117c2fb to datanode:20a284f6-c8a8-496d-9157-8df5a2a17913
scm1.org_1   | 2021-11-25 07:52:06,311 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6a1182b-7d4f-4a64-ae52-9ddd9117c2fb, Nodes: 20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.222Z[UTC]].
scm1.org_1   | 2021-11-25 07:52:06,332 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:52:06,345 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 93499.353us
scm1.org_1   | 2021-11-25 07:52:06,360 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=65c842b6-e24f-41e4-aa24-d7c3b8105647 to datanode:ece86bc6-b07b-4fda-a4d6-106fafa8b49c
scm1.org_1   | 2021-11-25 07:52:06,362 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=65c842b6-e24f-41e4-aa24-d7c3b8105647 to datanode:0950a55d-429f-4438-94ab-c48b091ad805
scm1.org_1   | 2021-11-25 07:52:06,365 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=65c842b6-e24f-41e4-aa24-d7c3b8105647 to datanode:20a284f6-c8a8-496d-9157-8df5a2a17913
scm1.org_1   | 2021-11-25 07:52:06,506 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 65c842b6-e24f-41e4-aa24-d7c3b8105647, Nodes: ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.360Z[UTC]].
scm1.org_1   | 2021-11-25 07:52:06,517 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:52:06,522 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 157095.706us
scm1.org_1   | 2021-11-25 07:52:06,566 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=65c842b6-e24f-41e4-aa24-d7c3b8105647 contains same datanodes as previous pipelines: PipelineID=920724e0-2396-4120-9852-100cc9d9f034 nodeIds: ece86bc6-b07b-4fda-a4d6-106fafa8b49c, 0950a55d-429f-4438-94ab-c48b091ad805, 20a284f6-c8a8-496d-9157-8df5a2a17913
scm1.org_1   | 2021-11-25 07:52:06,571 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2f49bc21-d6f0-4805-9d81-f57ca044c536 to datanode:0950a55d-429f-4438-94ab-c48b091ad805
scm1.org_1   | 2021-11-25 07:52:06,625 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 2f49bc21-d6f0-4805-9d81-f57ca044c536, Nodes: 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.571Z[UTC]].
scm1.org_1   | 2021-11-25 07:52:06,642 [d1137d26-6502-410a-9479-0d2074af0cec@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-11-25 07:52:06,643 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@54198221, cost 67117.7us
scm1.org_1   | 2021-11-25 07:52:08,597 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55004
scm1.org_1   | 2021-11-25 07:52:08,706 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:52:09,094 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:58096
scm1.org_1   | 2021-11-25 07:52:09,142 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:52:09,308 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40558
scm1.org_1   | 2021-11-25 07:52:09,405 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-11-25 07:52:20,191 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40314
scm3.org_1   | 2021-11-25 07:51:28,972 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:51:29,399 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:51:58,127 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57680
scm3.org_1   | 2021-11-25 07:51:58,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-11-25 07:51:58,725 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60976
scm3.org_1   | 2021-11-25 07:51:58,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-11-25 07:52:00,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51306
scm3.org_1   | 2021-11-25 07:52:00,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-11-25 07:52:03,989 [IPC Server handler 39 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0950a55d-429f-4438-94ab-c48b091ad805
scm3.org_1   | 2021-11-25 07:52:04,030 [IPC Server handler 29 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/20a284f6-c8a8-496d-9157-8df5a2a17913
scm3.org_1   | 2021-11-25 07:52:04,222 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ece86bc6-b07b-4fda-a4d6-106fafa8b49c
scm3.org_1   | 2021-11-25 07:52:04,222 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8111158445552, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-11-25 07:52:04,281 [IPC Server handler 39 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8112927771086, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2021-11-25 07:52:20,233 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:52:20,988 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41482
scm1.org_1   | 2021-11-25 07:52:21,001 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:52:21,078 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54030
scm1.org_1   | 2021-11-25 07:52:21,099 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-11-25 07:52:33,969 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48536
scm1.org_1   | 2021-11-25 07:52:34,131 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-11-25 07:52:34,178 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47284
scm1.org_1   | 2021-11-25 07:52:34,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-11-25 07:52:34,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40612
scm1.org_1   | 2021-11-25 07:52:34,531 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-11-25 07:52:40,670 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58954
scm1.org_1   | 2021-11-25 07:52:40,731 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-11-25 07:52:04,172 [IPC Server handler 29 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8109713599631, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-11-25 07:52:04,306 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2021-11-25 07:52:04,993 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$414/0x000000084052f040@44b82007] WARN util.JvmPauseMonitor: JvmPauseMonitor-e39fb3e9-4060-458c-ab31-c74db05e820c: Detected pause in JVM or host machine (eg GC): pause of approximately 338675851ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=244ms
scm3.org_1   | 2021-11-25 07:52:05,084 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2021-11-25 07:52:04,993 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-11-25 07:52:05,220 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-11-25 07:52:05,221 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-11-25 07:52:05,245 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2021-11-25 07:52:05,250 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2021-11-25 07:52:05,250 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2021-11-25 07:52:05,251 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-11-25 07:52:05,251 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2021-11-25 07:52:05,251 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-11-25 07:52:05,897 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a58ff28e-e672-4a6e-b65c-6c91577ea767, Nodes: ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:04.381Z[UTC]].
scm3.org_1   | 2021-11-25 07:52:05,911 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:52:06,113 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 920724e0-2396-4120-9852-100cc9d9f034, Nodes: 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:05.895Z[UTC]].
scm3.org_1   | 2021-11-25 07:52:06,136 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:52:06,380 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6a1182b-7d4f-4a64-ae52-9ddd9117c2fb, Nodes: 20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.222Z[UTC]].
scm3.org_1   | 2021-11-25 07:52:06,382 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:52:06,541 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 65c842b6-e24f-41e4-aa24-d7c3b8105647, Nodes: ece86bc6-b07b-4fda-a4d6-106fafa8b49c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}20a284f6-c8a8-496d-9157-8df5a2a17913{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.360Z[UTC]].
scm3.org_1   | 2021-11-25 07:52:06,542 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:52:06,676 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 2f49bc21-d6f0-4805-9d81-f57ca044c536, Nodes: 0950a55d-429f-4438-94ab-c48b091ad805{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-11-25T07:52:06.571Z[UTC]].
scm3.org_1   | 2021-11-25 07:52:06,677 [e39fb3e9-4060-458c-ab31-c74db05e820c@group-CFAD39A678E5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-11-25 07:52:33,771 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57770
scm3.org_1   | 2021-11-25 07:52:33,985 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-11-25 07:52:34,052 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51382
scm3.org_1   | 2021-11-25 07:52:34,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-11-25 07:52:34,426 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32836
scm3.org_1   | 2021-11-25 07:52:34,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
