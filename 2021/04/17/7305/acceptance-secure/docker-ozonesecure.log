Attaching to ozonesecure_datanode_3, ozonesecure_datanode_2, ozonesecure_datanode_1, ozonesecure_scm_1, ozonesecure_recon_1, ozonesecure_s3g_1, ozonesecure_om_1, ozonesecure_kms_1, ozonesecure_kdc_1
datanode_1  | Sleeping for 5 seconds
datanode_1  | Setting up kerberos!!
datanode_1  | KDC ISSUER_SERVER => kdc:8081
datanode_1  | Sleeping for 5 seconds
datanode_1  | Got 200, KDC service ready!!
datanode_1  | Download dn/22b4ef3d5c71@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_1  | --2021-04-17 01:02:03--  http://kdc:8081/keytab/22b4ef3d5c71/dn
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 158 [application/octet-stream]
datanode_1  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_1  | 
datanode_1  |      0K                                                       100% 3.86M=0s
datanode_1  | 
datanode_1  | 2021-04-17 01:02:03 (3.86 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 04/17/21 01:02:03 dn/22b4ef3d5c71@EXAMPLE.COM
datanode_1  |    2 04/17/21 01:02:03 dn/22b4ef3d5c71@EXAMPLE.COM
datanode_1  | Download HTTP/22b4ef3d5c71@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_1  | --2021-04-17 01:02:03--  http://kdc:8081/keytab/22b4ef3d5c71/HTTP
datanode_1  | Resolving kdc (kdc)... 172.18.0.2
datanode_1  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 162 [application/octet-stream]
datanode_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_1  | 
datanode_1  |      0K                                                       100% 6.03M=0s
datanode_1  | 
datanode_1  | 2021-04-17 01:02:03 (6.03 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 04/17/21 01:02:03 HTTP/22b4ef3d5c71@EXAMPLE.COM
datanode_1  |    2 04/17/21 01:02:03 HTTP/22b4ef3d5c71@EXAMPLE.COM
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2021-04-17 01:02:12,820 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 22b4ef3d5c71/172.18.0.6
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:50Z
datanode_1  | STARTUP_MSG:   java = 11.0.10
datanode_1  | ************************************************************/
datanode_1  | 2021-04-17 01:02:12,935 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2021-04-17 01:02:16,484 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2021-04-17 01:02:17,145 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2021-04-17 01:02:18,143 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2021-04-17 01:02:18,143 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2021-04-17 01:02:18,355 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:22b4ef3d5c71 ip:172.18.0.6
datanode_1  | 2021-04-17 01:02:21,498 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_1  | 2021-04-17 01:02:22,702 [main] INFO security.UserGroupInformation: Login successful for user dn/22b4ef3d5c71@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_1  | 2021-04-17 01:02:22,702 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_1  | 2021-04-17 01:02:22,707 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_1  | 2021-04-17 01:02:22,707 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_1  | 2021-04-17 01:02:22,712 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_1  | 2021-04-17 01:02:22,730 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_1  | 2021-04-17 01:02:24,398 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_1  | 2021-04-17 01:02:24,513 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.6,host:22b4ef3d5c71
datanode_1  | 2021-04-17 01:02:24,535 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_1  | 2021-04-17 01:02:24,540 [main] ERROR client.DNCertificateClient: Invalid domain 22b4ef3d5c71
datanode_1  | 2021-04-17 01:02:24,554 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@22b4ef3d5c71
datanode_1  | 2021-04-17 01:02:28,406 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 22b4ef3d5c71/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:30,408 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 22b4ef3d5c71/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:32,410 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 22b4ef3d5c71/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:34,411 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 22b4ef3d5c71/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:36,413 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 22b4ef3d5c71/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:38,415 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 22b4ef3d5c71/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:40,416 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 22b4ef3d5c71/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:42,419 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 22b4ef3d5c71/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:47,249 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
datanode_1  | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
datanode_1  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
datanode_1  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_1  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode_1  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:49,254 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
datanode_1  | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
datanode_1  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
datanode_1  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_1  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode_1  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2021-04-17 01:02:53,094 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode_1  | 2021-04-17 01:02:53,164 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-540203851203.crt.
datanode_1  | 2021-04-17 01:02:53,186 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/552803055385.crt.
datanode_1  | 2021-04-17 01:02:53,196 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode_1  | 2021-04-17 01:02:53,205 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_1  | 2021-04-17 01:02:54,068 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2021-04-17 01:02:54,084 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2021-04-17 01:02:54,110 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2021-04-17 01:02:54,128 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2021-04-17 01:02:54,285 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2021-04-17 01:02:54,394 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode_1  | 2021-04-17 01:02:54,433 [Thread-16] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_1  | 2021-04-17 01:02:54,434 [Thread-16] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1  | 2021-04-17 01:02:54,434 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1  | 2021-04-17 01:02:58,106 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2021-04-17 01:02:58,359 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_1  | 2021-04-17 01:02:58,737 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_1  | 2021-04-17 01:02:58,748 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_1  | 2021-04-17 01:02:58,752 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_1  | 2021-04-17 01:02:58,776 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2021-04-17 01:02:58,777 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2021-04-17 01:02:58,777 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2021-04-17 01:02:58,778 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2021-04-17 01:03:02,835 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_1  | 2021-04-17 01:03:02,850 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2021-04-17 01:03:02,851 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2021-04-17 01:03:02,886 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2021-04-17 01:03:02,908 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2021-04-17 01:03:04,126 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2021-04-17 01:03:04,126 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_1  | 2021-04-17 01:03:04,126 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_1  | 2021-04-17 01:03:04,210 [main] INFO util.log: Logging initialized @59365ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2021-04-17 01:03:04,624 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2021-04-17 01:03:04,652 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2021-04-17 01:03:04,654 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_1  | 2021-04-17 01:03:04,656 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | 2021-04-17 01:03:04,660 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | 2021-04-17 01:03:04,662 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_1  | 2021-04-17 01:03:04,796 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2021-04-17 01:03:04,804 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode_1  | 2021-04-17 01:03:04,969 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2021-04-17 01:03:04,969 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2021-04-17 01:03:04,971 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2021-04-17 01:03:05,025 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/22b4ef3d5c71@EXAMPLE.COM
datanode_1  | 2021-04-17 01:03:05,037 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4505015b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2021-04-17 01:03:05,038 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@75d0cac6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2021-04-17 01:03:05,402 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/22b4ef3d5c71@EXAMPLE.COM
datanode_1  | 2021-04-17 01:03:05,453 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@c7b100b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-12236405775800360793/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2021-04-17 01:03:05,491 [main] INFO server.AbstractConnector: Started ServerConnector@5d24703e{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_1  | 2021-04-17 01:03:05,491 [main] INFO server.Server: Started @60646ms
datanode_1  | 2021-04-17 01:03:05,518 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2021-04-17 01:03:05,518 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2021-04-17 01:03:05,520 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2021-04-17 01:03:05,645 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5256e6c2] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2021-04-17 01:03:05,908 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.5:9891
datanode_1  | 2021-04-17 01:03:08,867 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2021-04-17 01:03:08,869 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2021-04-17 01:03:09,033 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 129c26c3-a794-4177-9973-54b2e59dd63f
datanode_1  | 2021-04-17 01:03:09,134 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO server.RaftServer: 129c26c3-a794-4177-9973-54b2e59dd63f: start RPC server
datanode_1  | 2021-04-17 01:03:09,141 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO server.GrpcService: 129c26c3-a794-4177-9973-54b2e59dd63f: GrpcService started, listening on 9856
datanode_1  | 2021-04-17 01:03:09,150 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO server.GrpcService: 129c26c3-a794-4177-9973-54b2e59dd63f: GrpcService started, listening on 9857
datanode_1  | 2021-04-17 01:03:09,150 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO server.GrpcService: 129c26c3-a794-4177-9973-54b2e59dd63f: GrpcService started, listening on 9858
datanode_1  | 2021-04-17 01:03:09,159 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 129c26c3-a794-4177-9973-54b2e59dd63f is started using port 9858 for RATIS
datanode_1  | 2021-04-17 01:03:09,159 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 129c26c3-a794-4177-9973-54b2e59dd63f is started using port 9857 for RATIS_ADMIN
datanode_1  | 2021-04-17 01:03:09,159 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 129c26c3-a794-4177-9973-54b2e59dd63f is started using port 9856 for RATIS_SERVER
datanode_1  | 2021-04-17 01:03:09,160 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$317/0x0000000840546c40@546b27da] INFO util.JvmPauseMonitor: JvmPauseMonitor-129c26c3-a794-4177-9973-54b2e59dd63f: Started
datanode_1  | 2021-04-17 01:03:12,681 [Command processor thread] INFO server.RaftServer: 129c26c3-a794-4177-9973-54b2e59dd63f: addNew group-AA2C80C06E39:[129c26c3-a794-4177-9973-54b2e59dd63f|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] returns group-AA2C80C06E39:java.util.concurrent.CompletableFuture@45f5bacc[Not completed]
datanode_1  | 2021-04-17 01:03:12,781 [pool-20-thread-1] INFO server.RaftServer$Division: 129c26c3-a794-4177-9973-54b2e59dd63f: new RaftServerImpl for group-AA2C80C06E39:[129c26c3-a794-4177-9973-54b2e59dd63f|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_1  | 2021-04-17 01:03:12,789 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2021-04-17 01:03:12,793 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2021-04-17 01:03:12,793 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2021-04-17 01:03:12,794 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2021-04-17 01:03:12,794 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2021-04-17 01:03:12,796 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1  | 2021-04-17 01:03:12,797 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2021-04-17 01:03:12,803 [pool-20-thread-1] INFO server.RaftServer$Division: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39: ConfigurationManager, init=-1: [129c26c3-a794-4177-9973-54b2e59dd63f|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_1  | 2021-04-17 01:03:12,812 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2021-04-17 01:03:12,824 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2021-04-17 01:03:12,825 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fa3cfe8a-2730-45c8-bb06-aa2c80c06e39 does not exist. Creating ...
datanode_1  | 2021-04-17 01:03:12,853 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fa3cfe8a-2730-45c8-bb06-aa2c80c06e39/in_use.lock acquired by nodename 7@22b4ef3d5c71
datanode_1  | 2021-04-17 01:03:12,878 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fa3cfe8a-2730-45c8-bb06-aa2c80c06e39 has been successfully formatted.
datanode_1  | 2021-04-17 01:03:12,903 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-AA2C80C06E39: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2021-04-17 01:03:12,906 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2021-04-17 01:03:12,913 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2021-04-17 01:03:12,930 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2021-04-17 01:03:12,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2021-04-17 01:03:12,963 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39
datanode_1  | 2021-04-17 01:03:13,030 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2021-04-17 01:03:13,107 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2021-04-17 01:03:13,107 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 2021-04-17 01:03:13,124 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fa3cfe8a-2730-45c8-bb06-aa2c80c06e39
datanode_1  | 2021-04-17 01:03:13,128 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2021-04-17 01:03:13,128 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2021-04-17 01:03:13,131 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2021-04-17 01:03:13,132 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2021-04-17 01:03:13,133 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2021-04-17 01:03:13,145 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2021-04-17 01:03:13,145 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2021-04-17 01:03:13,148 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2021-04-17 01:03:13,183 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2021-04-17 01:03:13,201 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2021-04-17 01:03:13,237 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2021-04-17 01:03:13,237 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2021-04-17 01:03:13,248 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2021-04-17 01:03:13,252 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2021-04-17 01:03:13,253 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2021-04-17 01:03:13,254 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2021-04-17 01:03:13,257 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2021-04-17 01:03:13,260 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 2021-04-17 01:03:13,352 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39
datanode_1  | 2021-04-17 01:03:13,355 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39
datanode_1  | 2021-04-17 01:03:13,386 [pool-20-thread-1] INFO server.RaftServer$Division: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39: start as a follower, conf=-1: [129c26c3-a794-4177-9973-54b2e59dd63f|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_1  | 2021-04-17 01:03:13,477 [pool-20-thread-1] INFO server.RaftServer$Division: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2021-04-17 01:03:13,478 [pool-20-thread-1] INFO impl.RoleInfo: 129c26c3-a794-4177-9973-54b2e59dd63f: start 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-FollowerState
datanode_1  | 2021-04-17 01:03:13,532 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AA2C80C06E39,id=129c26c3-a794-4177-9973-54b2e59dd63f
datanode_1  | 2021-04-17 01:03:13,533 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39
datanode_1  | 2021-04-17 01:03:13,587 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=fa3cfe8a-2730-45c8-bb06-aa2c80c06e39
datanode_1  | 2021-04-17 01:03:13,617 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=fa3cfe8a-2730-45c8-bb06-aa2c80c06e39.
datanode_1  | 2021-04-17 01:03:18,669 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-FollowerState] INFO impl.FollowerState: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5190902215ns, electionTimeout:5188ms
datanode_1  | 2021-04-17 01:03:18,670 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-FollowerState] INFO impl.RoleInfo: 129c26c3-a794-4177-9973-54b2e59dd63f: shutdown 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-FollowerState
datanode_1  | 2021-04-17 01:03:18,671 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-FollowerState] INFO server.RaftServer$Division: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2021-04-17 01:03:18,674 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2  | Sleeping for 5 seconds
datanode_2  | Setting up kerberos!!
datanode_2  | KDC ISSUER_SERVER => kdc:8081
datanode_2  | Sleeping for 5 seconds
datanode_2  | Got 200, KDC service ready!!
datanode_2  | Download dn/95170cd1a491@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | --2021-04-17 01:01:58--  http://kdc:8081/keytab/95170cd1a491/dn
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 158 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 21.5M=0s
datanode_2  | 
datanode_2  | 2021-04-17 01:01:58 (21.5 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 04/17/21 01:01:58 dn/95170cd1a491@EXAMPLE.COM
datanode_2  |    2 04/17/21 01:01:58 dn/95170cd1a491@EXAMPLE.COM
datanode_2  | Download HTTP/95170cd1a491@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_2  | --2021-04-17 01:01:58--  http://kdc:8081/keytab/95170cd1a491/HTTP
datanode_2  | Resolving kdc (kdc)... 172.18.0.2
datanode_2  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 162 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 26.6M=0s
datanode_2  | 
datanode_2  | 2021-04-17 01:01:58 (26.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 04/17/21 01:01:58 HTTP/95170cd1a491@EXAMPLE.COM
datanode_2  |    2 04/17/21 01:01:58 HTTP/95170cd1a491@EXAMPLE.COM
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2021-04-17 01:01:59,465 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 95170cd1a491/172.18.0.7
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:50Z
datanode_2  | STARTUP_MSG:   java = 11.0.10
datanode_2  | ************************************************************/
datanode_2  | 2021-04-17 01:01:59,481 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2021-04-17 01:02:01,243 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2021-04-17 01:02:01,694 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2021-04-17 01:02:02,340 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2021-04-17 01:02:02,340 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2021-04-17 01:02:02,530 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:95170cd1a491 ip:172.18.0.7
datanode_2  | 2021-04-17 01:02:06,390 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_2  | 2021-04-17 01:02:07,817 [main] INFO security.UserGroupInformation: Login successful for user dn/95170cd1a491@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_2  | 2021-04-17 01:02:07,840 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_2  | 2021-04-17 01:02:07,840 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_2  | 2021-04-17 01:02:07,841 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_2  | 2021-04-17 01:02:07,850 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_2  | 2021-04-17 01:02:07,855 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_2  | 2021-04-17 01:02:11,381 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_2  | 2021-04-17 01:02:11,430 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.7,host:95170cd1a491
datanode_2  | 2021-04-17 01:02:11,438 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_2  | 2021-04-17 01:02:11,445 [main] ERROR client.DNCertificateClient: Invalid domain 95170cd1a491
datanode_2  | 2021-04-17 01:02:11,455 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@95170cd1a491
datanode_2  | 2021-04-17 01:02:16,538 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:18,546 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:20,553 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:22,555 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:24,560 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:26,568 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | Sleeping for 5 seconds
datanode_3  | Setting up kerberos!!
datanode_3  | KDC ISSUER_SERVER => kdc:8081
datanode_3  | Sleeping for 5 seconds
datanode_3  | Got 200, KDC service ready!!
datanode_3  | Download dn/e1ee43307ac4@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_3  | --2021-04-17 01:02:01--  http://kdc:8081/keytab/e1ee43307ac4/dn
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 158 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_3  | 
datanode_3  |      0K                                                       100% 21.2M=0s
datanode_3  | 
datanode_3  | 2021-04-17 01:02:01 (21.2 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 04/17/21 01:02:01 dn/e1ee43307ac4@EXAMPLE.COM
datanode_3  |    2 04/17/21 01:02:01 dn/e1ee43307ac4@EXAMPLE.COM
datanode_3  | Download HTTP/e1ee43307ac4@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_3  | --2021-04-17 01:02:01--  http://kdc:8081/keytab/e1ee43307ac4/HTTP
datanode_3  | Resolving kdc (kdc)... 172.18.0.2
datanode_3  | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 162 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_3  | 
datanode_3  |      0K                                                       100% 29.2M=0s
datanode_3  | 
datanode_3  | 2021-04-17 01:02:01 (29.2 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 04/17/21 01:02:01 HTTP/e1ee43307ac4@EXAMPLE.COM
datanode_3  |    2 04/17/21 01:02:01 HTTP/e1ee43307ac4@EXAMPLE.COM
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2021-04-17 01:02:10,636 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = e1ee43307ac4/172.18.0.10
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_2  | 2021-04-17 01:02:28,571 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:30,573 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:32,585 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:34,588 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:36,590 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:38,592 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:40,594 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:42,597 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 95170cd1a491/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2021-04-17 01:02:47,193 [main] ERROR ozone.HddsDatanodeService: Error while storing SCM signed certificate.
datanode_2  | org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
datanode_2  | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
datanode_2  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
datanode_2  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_2  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode_2  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode_2  | 
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2  | 	at com.sun.proxy.$Proxy18.submitRequest(Unknown Source)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_2  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
datanode_2  | 	at com.sun.proxy.$Proxy18.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.submitRequest(SCMSecurityProtocolClientSideTranslatorPB.java:104)
datanode_2  | 	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.getDataNodeCertificateChain(SCMSecurityProtocolClientSideTranslatorPB.java:263)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.getSCMSignedCert(HddsDatanodeService.java:349)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.initializeCertificateClient(HddsDatanodeService.java:320)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.start(HddsDatanodeService.java:248)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.start(HddsDatanodeService.java:192)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.call(HddsDatanodeService.java:166)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.call(HddsDatanodeService.java:84)
datanode_2  | 	at picocli.CommandLine.executeUserObject(CommandLine.java:1933)
datanode_2  | 	at picocli.CommandLine.access$1100(CommandLine.java:145)
datanode_2  | 	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2332)
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:50Z
datanode_3  | STARTUP_MSG:   java = 11.0.10
datanode_3  | ************************************************************/
datanode_3  | 2021-04-17 01:02:10,767 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2021-04-17 01:02:13,865 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2021-04-17 01:02:14,654 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2021-04-17 01:02:15,730 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2021-04-17 01:02:15,731 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2021-04-17 01:02:15,982 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e1ee43307ac4 ip:172.18.0.10
datanode_3  | 2021-04-17 01:02:19,500 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_3  | 2021-04-17 01:02:20,850 [main] INFO security.UserGroupInformation: Login successful for user dn/e1ee43307ac4@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_3  | 2021-04-17 01:02:20,861 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_3  | 2021-04-17 01:02:20,864 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_3  | 2021-04-17 01:02:20,864 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_3  | 2021-04-17 01:02:20,864 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_3  | 2021-04-17 01:02:20,869 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_3  | 2021-04-17 01:02:22,972 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_3  | 2021-04-17 01:02:23,072 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.10,host:e1ee43307ac4
datanode_3  | 2021-04-17 01:02:23,072 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_3  | 2021-04-17 01:02:23,075 [main] ERROR client.DNCertificateClient: Invalid domain e1ee43307ac4
datanode_3  | 2021-04-17 01:02:23,111 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@e1ee43307ac4
datanode_3  | 2021-04-17 01:02:26,889 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:28,891 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:30,892 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:32,894 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:34,895 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:36,898 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:38,900 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:40,902 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:42,904 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From e1ee43307ac4/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:47,205 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
datanode_3  | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
datanode_3  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
datanode_3  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_3  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode_3  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode_3  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:49,208 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
datanode_3  | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
datanode_3  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
datanode_3  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_3  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode_3  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode_3  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2021-04-17 01:02:53,163 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode_3  | 2021-04-17 01:02:53,221 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-540203851203.crt.
datanode_3  | 2021-04-17 01:02:53,225 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode_3  | 2021-04-17 01:02:53,250 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/553573924627.crt.
datanode_3  | 2021-04-17 01:02:53,260 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_3  | 2021-04-17 01:02:54,147 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2021-04-17 01:02:54,152 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2021-04-17 01:02:54,155 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2021-04-17 01:02:54,184 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2021-04-17 01:02:54,413 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2021-04-17 01:02:54,605 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode_3  | 2021-04-17 01:02:54,608 [Thread-17] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_3  | 2021-04-17 01:02:54,612 [Thread-17] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3  | 2021-04-17 01:02:54,613 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_3  | 2021-04-17 01:02:57,964 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2021-04-17 01:02:58,227 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_3  | 2021-04-17 01:02:58,544 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_3  | 2021-04-17 01:02:58,545 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_3  | 2021-04-17 01:02:58,545 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_3  | 2021-04-17 01:02:58,546 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2021-04-17 01:02:58,556 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2021-04-17 01:02:58,557 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2021-04-17 01:02:58,558 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2021-04-17 01:03:02,668 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_3  | 2021-04-17 01:03:02,677 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2021-04-17 01:03:02,679 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2021-04-17 01:03:02,726 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2021-04-17 01:03:02,733 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2021-04-17 01:03:04,402 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2021-04-17 01:03:04,402 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 2021-04-17 01:03:04,403 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_3  | 2021-04-17 01:03:04,572 [main] INFO util.log: Logging initialized @62728ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2021-04-17 01:03:05,013 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2021-04-17 01:03:05,035 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2021-04-17 01:03:05,041 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_1  | 2021-04-17 01:03:18,674 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-FollowerState] INFO impl.RoleInfo: 129c26c3-a794-4177-9973-54b2e59dd63f: start 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1
datanode_1  | 2021-04-17 01:03:18,681 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO impl.LeaderElection: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [129c26c3-a794-4177-9973-54b2e59dd63f|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|priority:1], old=null
datanode_1  | 2021-04-17 01:03:18,681 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO impl.LeaderElection: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_1  | 2021-04-17 01:03:18,681 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO impl.RoleInfo: 129c26c3-a794-4177-9973-54b2e59dd63f: shutdown 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1
datanode_1  | 2021-04-17 01:03:18,682 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServer$Division: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2021-04-17 01:03:18,683 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AA2C80C06E39 with new leaderId: 129c26c3-a794-4177-9973-54b2e59dd63f
datanode_1  | 2021-04-17 01:03:18,691 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServer$Division: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39: change Leader from null to 129c26c3-a794-4177-9973-54b2e59dd63f at term 1 for becomeLeader, leader elected after 5778ms
datanode_1  | 2021-04-17 01:03:18,699 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2021-04-17 01:03:18,700 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39
datanode_1  | 2021-04-17 01:03:18,706 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2021-04-17 01:03:18,707 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2021-04-17 01:03:18,715 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2021-04-17 01:03:18,715 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2021-04-17 01:03:18,716 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2021-04-17 01:03:18,729 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO impl.RoleInfo: 129c26c3-a794-4177-9973-54b2e59dd63f: start 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderStateImpl
datanode_1  | 2021-04-17 01:03:18,755 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2021-04-17 01:03:18,844 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-LeaderElection1] INFO server.RaftServer$Division: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39: set configuration 0: [129c26c3-a794-4177-9973-54b2e59dd63f|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:|priority:1], old=null
datanode_1  | 2021-04-17 01:03:18,903 [129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 129c26c3-a794-4177-9973-54b2e59dd63f@group-AA2C80C06E39-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fa3cfe8a-2730-45c8-bb06-aa2c80c06e39/current/log_inprogress_0
datanode_3  | 2021-04-17 01:03:05,045 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2021-04-17 01:03:05,046 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 2021-04-17 01:03:05,056 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_3  | 2021-04-17 01:03:05,187 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2021-04-17 01:03:05,199 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode_3  | 2021-04-17 01:03:05,356 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2021-04-17 01:03:05,356 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2021-04-17 01:03:05,357 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 2021-04-17 01:03:05,449 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/e1ee43307ac4@EXAMPLE.COM
datanode_3  | 2021-04-17 01:03:05,459 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@567baa55{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2021-04-17 01:03:05,460 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ab717f3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2021-04-17 01:03:05,749 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/e1ee43307ac4@EXAMPLE.COM
datanode_3  | 2021-04-17 01:03:05,811 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6aed4a23{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-13621454095910949870/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2021-04-17 01:03:05,849 [main] INFO server.AbstractConnector: Started ServerConnector@231c521e{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_3  | 2021-04-17 01:03:05,851 [main] INFO server.Server: Started @64008ms
datanode_3  | 2021-04-17 01:03:05,864 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2021-04-17 01:03:05,864 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2021-04-17 01:03:05,866 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2021-04-17 01:03:06,069 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@49eee358] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2021-04-17 01:03:06,233 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.5:9891
datanode_3  | 2021-04-17 01:03:08,872 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2021-04-17 01:03:08,874 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2021-04-17 01:03:09,063 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 6a2218ae-2ed2-4a70-82aa-b47f176c4c61
datanode_3  | 2021-04-17 01:03:09,144 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO server.RaftServer: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: start RPC server
datanode_3  | 2021-04-17 01:03:09,146 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO server.GrpcService: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: GrpcService started, listening on 9856
datanode_3  | 2021-04-17 01:03:09,147 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO server.GrpcService: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: GrpcService started, listening on 9857
datanode_3  | 2021-04-17 01:03:09,160 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO server.GrpcService: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: GrpcService started, listening on 9858
datanode_3  | 2021-04-17 01:03:09,172 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 6a2218ae-2ed2-4a70-82aa-b47f176c4c61 is started using port 9858 for RATIS
datanode_3  | 2021-04-17 01:03:09,173 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 6a2218ae-2ed2-4a70-82aa-b47f176c4c61 is started using port 9857 for RATIS_ADMIN
datanode_3  | 2021-04-17 01:03:09,173 [EndpointStateMachine task thread for scm/172.18.0.8:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 6a2218ae-2ed2-4a70-82aa-b47f176c4c61 is started using port 9856 for RATIS_SERVER
datanode_3  | 2021-04-17 01:03:09,196 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$317/0x0000000840546c40@74e4b339] INFO util.JvmPauseMonitor: JvmPauseMonitor-6a2218ae-2ed2-4a70-82aa-b47f176c4c61: Started
datanode_3  | 2021-04-17 01:03:13,160 [Command processor thread] INFO server.RaftServer: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: addNew group-297E31173CBF:[6a2218ae-2ed2-4a70-82aa-b47f176c4c61|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|priority:1] returns group-297E31173CBF:java.util.concurrent.CompletableFuture@608fb42f[Not completed]
datanode_3  | 2021-04-17 01:03:13,274 [pool-20-thread-1] INFO server.RaftServer$Division: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: new RaftServerImpl for group-297E31173CBF:[6a2218ae-2ed2-4a70-82aa-b47f176c4c61|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_3  | 2021-04-17 01:03:13,278 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2021-04-17 01:03:13,296 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2021-04-17 01:03:13,297 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2021-04-17 01:03:13,297 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2021-04-17 01:03:13,297 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2021-04-17 01:03:13,298 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2  | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2326)
datanode_2  | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2291)
datanode_2  | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:2152)
datanode_2  | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:2530)
datanode_2  | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:2465)
datanode_2  | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:96)
datanode_2  | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:87)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.main(HddsDatanodeService.java:149)
datanode_2  | 2021-04-17 01:02:47,199 [main] ERROR ozone.HddsDatanodeService: Exception in HddsDatanodeService.
datanode_2  | java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
datanode_2  | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
datanode_2  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
datanode_2  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_2  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode_2  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode_2  | 
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.getSCMSignedCert(HddsDatanodeService.java:379)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.initializeCertificateClient(HddsDatanodeService.java:320)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.start(HddsDatanodeService.java:248)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.start(HddsDatanodeService.java:192)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.call(HddsDatanodeService.java:166)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.call(HddsDatanodeService.java:84)
datanode_2  | 	at picocli.CommandLine.executeUserObject(CommandLine.java:1933)
datanode_2  | 	at picocli.CommandLine.access$1100(CommandLine.java:145)
datanode_2  | 	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2332)
datanode_2  | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2326)
datanode_2  | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2291)
datanode_2  | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:2152)
datanode_2  | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:2530)
datanode_2  | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:2465)
datanode_2  | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:96)
datanode_2  | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:87)
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.main(HddsDatanodeService.java:149)
datanode_2  | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
datanode_2  | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
datanode_2  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
datanode_2  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_2  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
datanode_2  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode_2  | 
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2  | 	at com.sun.proxy.$Proxy18.submitRequest(Unknown Source)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_2  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
datanode_2  | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
datanode_2  | 	at com.sun.proxy.$Proxy18.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.submitRequest(SCMSecurityProtocolClientSideTranslatorPB.java:104)
datanode_2  | 	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.getDataNodeCertificateChain(SCMSecurityProtocolClientSideTranslatorPB.java:263)
kdc_1       | Checking the availablility of the keytab
kdc_1       | krb5kdc: starting...
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | kadmin: Communication failure with server while initializing kadmin interface
kdc_1       | KDC is not yet available.  Shell return code is 1
kdc_1       | Checking the availablility of the keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | KDC is not yet available.  Shell return code is 1
kdc_1       | kadmin: Communication failure with server while initializing kadmin interface
kdc_1       | Checking the availablility of the keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | kadmin: Communication failure with server while initializing kadmin interface
kdc_1       | KDC is not yet available.  Shell return code is 1
kdc_1       | Checking the availablility of the keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | kadmin: Communication failure with server while initializing kadmin interface
kdc_1       | KDC is not yet available.  Shell return code is 1
kdc_1       | kadmind: starting...
kdc_1       | Checking the availablility of the keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | K/M@EXAMPLE.COM
kdc_1       | admin/admin@EXAMPLE.COM
kdc_1       | kadmin/admin@EXAMPLE.COM
kdc_1       | kadmin/b43a6548b73b@EXAMPLE.COM
kdc_1       | kadmin/changepw@EXAMPLE.COM
kdc_1       | kiprop/b43a6548b73b@EXAMPLE.COM
kdc_1       | krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:01:51 kdc kadmind[26](info): setting up network...
kdc_1       | kadmind: setsockopt(9,IPV6_V6ONLY,1) worked
kdc_1       | kadmind: setsockopt(11,IPV6_V6ONLY,1) worked
kdc_1       | kadmind: setsockopt(13,IPV6_V6ONLY,1) worked
kdc_1       | Apr 17 01:01:51 kdc kadmind[26](info): set up 6 sockets
kdc_1       | Apr 17 01:01:51 kdc kadmind[26](info): Seeding random number generator
kdc_1       | Apr 17 01:01:51 kdc kadmind[26](info): starting
kdc_1       | Apr 17 01:01:51 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:51 kdc kadmind[26](Notice): Request: kadm5_get_principals, *, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:51 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:47 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621307, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621308, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621309, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:50 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:50 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621310, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621311, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Issuer is listening on : 8081WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "test/test@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/95170cd1a491@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/95170cd1a491@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/95170cd1a491@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.95170cd1a491.keytab.
kdc_1       | Entry for principal dn/95170cd1a491@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.95170cd1a491.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/95170cd1a491@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/95170cd1a491@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/95170cd1a491@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.95170cd1a491.keytab.
kdc_1       | Entry for principal HTTP/95170cd1a491@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.95170cd1a491.keytab.
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621318, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621318, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_2  | 	at org.apache.hadoop.ozone.HddsDatanodeService.getSCMSignedCert(HddsDatanodeService.java:349)
datanode_2  | 	... 16 more
datanode_2  | 2021-04-17 01:02:47,244 [shutdown-hook-0] INFO ozone.HddsDatanodeService: SHUTDOWN_MSG: 
datanode_2  | /************************************************************
datanode_2  | SHUTDOWN_MSG: Shutting down HddsDatanodeService at 95170cd1a491/172.18.0.7
datanode_2  | ************************************************************/
kms_1       | Sleeping for 5 seconds
kms_1       | /opt/starter.sh: line 66: SLEEP_SECONDS: command not found
kms_1       | Setting up kerberos!!
kms_1       | KDC ISSUER_SERVER => kdc:8081
kms_1       | Sleeping for  seconds
kms_1       | Got 200, KDC service ready!!
kms_1       | # Licensed to the Apache Software Foundation (ASF) under one or more
kms_1       | # contributor license agreements.  See the NOTICE file distributed with
kms_1       | # this work for additional information regarding copyright ownership.
kms_1       | # The ASF licenses this file to You under the Apache License, Version 2.0
kms_1       | # (the "License"); you may not use this file except in compliance with
kms_1       | # the License.  You may obtain a copy of the License at
kms_1       | #
kms_1       | #     http://www.apache.org/licenses/LICENSE-2.0
kms_1       | #
kms_1       | # Unless required by applicable law or agreed to in writing, software
kms_1       | # distributed under the License is distributed on an "AS IS" BASIS,
kms_1       | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
kms_1       | # See the License for the specific language governing permissions and
kms_1       | # limitations under the License.
kms_1       | 
kms_1       | [logging]
kms_1       |  default = FILE:/var/log/krb5libs.log
kms_1       |  kdc = FILE:/var/log/krb5kdc.log
kms_1       |  admin_server = FILE:/var/log/kadmind.log
kms_1       | 
kms_1       | [libdefaults]
kms_1       |  dns_canonicalize_hostname = false
kms_1       |  dns_lookup_realm = false
kms_1       |  ticket_lifetime = 24h
kms_1       |  renew_lifetime = 7d
kms_1       |  forwardable = true
kms_1       |  rdns = false
kms_1       |  default_realm = EXAMPLE.COM
kms_1       | 
kms_1       | [realms]
kms_1       |  EXAMPLE.COM = {
kms_1       |   kdc = kdc
kms_1       |   admin_server = kdc
kms_1       |  }
kms_1       | 
kms_1       | [domain_realm]
kms_1       |  .example.com = EXAMPLE.COM
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode_3  | 2021-04-17 01:03:13,299 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2021-04-17 01:03:13,302 [pool-20-thread-1] INFO server.RaftServer$Division: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF: ConfigurationManager, init=-1: [6a2218ae-2ed2-4a70-82aa-b47f176c4c61|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_3  | 2021-04-17 01:03:13,306 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2021-04-17 01:03:13,315 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2021-04-17 01:03:13,325 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e359a3e6-9a86-4080-9bb7-297e31173cbf does not exist. Creating ...
datanode_3  | 2021-04-17 01:03:13,365 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e359a3e6-9a86-4080-9bb7-297e31173cbf/in_use.lock acquired by nodename 7@e1ee43307ac4
datanode_3  | 2021-04-17 01:03:13,389 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e359a3e6-9a86-4080-9bb7-297e31173cbf has been successfully formatted.
datanode_3  | 2021-04-17 01:03:13,421 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-297E31173CBF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2021-04-17 01:03:13,422 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2021-04-17 01:03:13,430 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2021-04-17 01:03:13,484 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2021-04-17 01:03:13,484 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2021-04-17 01:03:13,505 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF
datanode_3  | 2021-04-17 01:03:13,562 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2021-04-17 01:03:13,633 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2021-04-17 01:03:13,633 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2021-04-17 01:03:13,662 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e359a3e6-9a86-4080-9bb7-297e31173cbf
datanode_3  | 2021-04-17 01:03:13,662 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2021-04-17 01:03:13,662 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2021-04-17 01:03:13,663 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2021-04-17 01:03:13,688 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2021-04-17 01:03:13,689 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2021-04-17 01:03:13,690 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2021-04-17 01:03:13,690 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2021-04-17 01:03:13,690 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2021-04-17 01:03:13,745 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2021-04-17 01:03:13,752 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2021-04-17 01:03:13,764 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2021-04-17 01:03:13,768 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2021-04-17 01:03:13,784 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2021-04-17 01:03:13,785 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2021-04-17 01:03:13,788 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2021-04-17 01:03:13,790 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2021-04-17 01:03:13,796 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2021-04-17 01:03:13,797 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 2021-04-17 01:03:13,874 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF
datanode_3  | 2021-04-17 01:03:13,882 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF
datanode_3  | 2021-04-17 01:03:13,901 [pool-20-thread-1] INFO server.RaftServer$Division: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF: start as a follower, conf=-1: [6a2218ae-2ed2-4a70-82aa-b47f176c4c61|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|priority:1], old=null
datanode_3  | 2021-04-17 01:03:13,913 [pool-20-thread-1] INFO server.RaftServer$Division: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2021-04-17 01:03:13,914 [pool-20-thread-1] INFO impl.RoleInfo: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: start 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-FollowerState
datanode_3  | 2021-04-17 01:03:13,934 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-297E31173CBF,id=6a2218ae-2ed2-4a70-82aa-b47f176c4c61
datanode_3  | 2021-04-17 01:03:13,941 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF
datanode_3  | 2021-04-17 01:03:13,975 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e359a3e6-9a86-4080-9bb7-297e31173cbf
datanode_3  | 2021-04-17 01:03:13,978 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=e359a3e6-9a86-4080-9bb7-297e31173cbf.
datanode_3  | 2021-04-17 01:03:19,015 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-FollowerState] INFO impl.FollowerState: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5101575800ns, electionTimeout:5086ms
datanode_3  | 2021-04-17 01:03:19,016 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-FollowerState] INFO impl.RoleInfo: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: shutdown 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-FollowerState
datanode_3  | 2021-04-17 01:03:19,016 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-FollowerState] INFO server.RaftServer$Division: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2021-04-17 01:03:19,019 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2021-04-17 01:03:19,019 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-FollowerState] INFO impl.RoleInfo: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: start 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1
datanode_3  | 2021-04-17 01:03:19,028 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO impl.LeaderElection: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [6a2218ae-2ed2-4a70-82aa-b47f176c4c61|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|priority:1], old=null
datanode_3  | 2021-04-17 01:03:19,029 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO impl.LeaderElection: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_3  | 2021-04-17 01:03:19,029 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO impl.RoleInfo: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: shutdown 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1
datanode_3  | 2021-04-17 01:03:19,030 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServer$Division: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2021-04-17 01:03:19,030 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-297E31173CBF with new leaderId: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61
datanode_3  | 2021-04-17 01:03:19,031 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServer$Division: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF: change Leader from null to 6a2218ae-2ed2-4a70-82aa-b47f176c4c61 at term 1 for becomeLeader, leader elected after 5607ms
datanode_3  | 2021-04-17 01:03:19,044 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2021-04-17 01:03:19,045 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF
datanode_3  | 2021-04-17 01:03:19,053 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2021-04-17 01:03:19,054 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2021-04-17 01:03:19,058 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2021-04-17 01:03:19,061 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2021-04-17 01:03:19,062 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2021-04-17 01:03:19,076 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO impl.RoleInfo: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61: start 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderStateImpl
datanode_3  | 2021-04-17 01:03:19,117 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2021-04-17 01:03:19,222 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-LeaderElection1] INFO server.RaftServer$Division: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF: set configuration 0: [6a2218ae-2ed2-4a70-82aa-b47f176c4c61|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:|priority:1], old=null
datanode_3  | 2021-04-17 01:03:19,303 [6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61@group-297E31173CBF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e359a3e6-9a86-4080-9bb7-297e31173cbf/current/log_inprogress_0
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos daApr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_create_principal, dn/95170cd1a491@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, dn/95170cd1a491@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_get_principal, dn/95170cd1a491@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_create_principal, HTTP/95170cd1a491@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, HTTP/95170cd1a491@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](Notice): Request: kadm5_get_principal, HTTP/95170cd1a491@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:58 kdc kadmind[26](info): closing down fd 18
kdc_1       | tabase
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621318, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621318, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621318, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621318, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for om/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "om/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_create_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
s3g_1       | Sleeping for 5 seconds
s3g_1       | Setting up kerberos!!
s3g_1       | KDC ISSUER_SERVER => kdc:8081
s3g_1       | Sleeping for 5 seconds
s3g_1       | Got 200, KDC service ready!!
s3g_1       | Download s3g/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
s3g_1       | --2021-04-17 01:01:59--  http://kdc:8081/keytab/s3g/s3g
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 142 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 18.1M=0s
s3g_1       | 
s3g_1       | 2021-04-17 01:02:00 (18.1 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 04/17/21 01:02:00 s3g/s3g@EXAMPLE.COM
s3g_1       |    2 04/17/21 01:02:00 s3g/s3g@EXAMPLE.COM
s3g_1       | Download HTTP/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
s3g_1       | --2021-04-17 01:02:00--  http://kdc:8081/keytab/s3g/HTTP
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 144 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 17.4M=0s
s3g_1       | 
s3g_1       | 2021-04-17 01:02:00 (17.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 04/17/21 01:02:00 HTTP/s3g@EXAMPLE.COM
s3g_1       |    2 04/17/21 01:02:00 HTTP/s3g@EXAMPLE.COM
s3g_1       | Download testuser/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
s3g_1       | --2021-04-17 01:02:00--  http://kdc:8081/keytab/s3g/testuser
s3g_1       | Resolving kdc (kdc)... 172.18.0.2
s3g_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 152 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 19.9M=0s
s3g_1       | 
s3g_1       | 2021-04-17 01:02:00 (19.9 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 04/17/21 01:02:00 testuser/s3g@EXAMPLE.COM
s3g_1       |    2 04/17/21 01:02:00 testuser/s3g@EXAMPLE.COM
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2021-04-17 01:02:11,977 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2021-04-17 01:02:12,036 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1       | 2021-04-17 01:02:12,036 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1       | 2021-04-17 01:02:12,415 [main] INFO util.log: Logging initialized @11069ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2021-04-17 01:02:13,434 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2021-04-17 01:02:13,485 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2021-04-17 01:02:13,493 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1       | 2021-04-17 01:02:13,499 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1       | 2021-04-17 01:02:13,502 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1       | 2021-04-17 01:02:13,538 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1       | 2021-04-17 01:02:14,200 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = s3g/172.18.0.4
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om_1        | Sleeping for 5 seconds
om_1        | Setting up kerberos!!
om_1        | KDC ISSUER_SERVER => kdc:8081
om_1        | Sleeping for 5 seconds
om_1        | Got 200, KDC service ready!!
om_1        | Download om/om@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om_1        | --2021-04-17 01:01:59--  http://kdc:8081/keytab/om/om
om_1        | Resolving kdc (kdc)... 172.18.0.2
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 138 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/om.keytab'
om_1        | 
om_1        |      0K                                                       100% 3.81M=0s
om_1        | 
om_1        | 2021-04-17 01:01:59 (3.81 MB/s) - '/etc/security/keytabs/om.keytab' saved [138/138]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 04/17/21 01:01:59 om/om@EXAMPLE.COM
om_1        |    2 04/17/21 01:01:59 om/om@EXAMPLE.COM
om_1        | Download HTTP/om@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om_1        | --2021-04-17 01:01:59--  http://kdc:8081/keytab/om/HTTP
om_1        | Resolving kdc (kdc)... 172.18.0.2
om_1        | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 142 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        | 
om_1        |      0K                                                       100% 18.8M=0s
om_1        | 
om_1        | 2021-04-17 01:01:59 (18.8 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [142/142]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 04/17/21 01:01:59 HTTP/om@EXAMPLE.COM
om_1        |    2 04/17/21 01:01:59 HTTP/om@EXAMPLE.COM
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2021-04-17 01:02:06,747 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.18.0.9
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:51Z
om_1        | STARTUP_MSG:   java = 11.0.10
om_1        | ************************************************************/
om_1        | 2021-04-17 01:02:06,818 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2021-04-17 01:02:17,815 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2021-04-17 01:02:18,194 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.9:9862
om_1        | 2021-04-17 01:02:18,194 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2021-04-17 01:02:18,202 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1        | 2021-04-17 01:02:19,475 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om_1        | 2021-04-17 01:02:19,484 [main] INFO om.OzoneManager: Ozone Manager login successful.
om_1        | 2021-04-17 01:02:19,557 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2021-04-17 01:02:24,048 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:26,049 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:28,051 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:30,052 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:32,059 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:34,063 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:36,064 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_get_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_create_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](Notice): Request: kadm5_get_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:01:59 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:01:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621319, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621319, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621319, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:01:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:01:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621319, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_create_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmApr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621320, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621320, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621320, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621320, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/javassist-3.25.0-GA.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:51Z
s3g_1       | STARTUP_MSG:   java = 11.0.10
s3g_1       | ************************************************************/
s3g_1       | 2021-04-17 01:02:14,281 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2021-04-17 01:02:14,589 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2021-04-17 01:02:14,635 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2021-04-17 01:02:14,639 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
s3g_1       | 2021-04-17 01:02:15,104 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2021-04-17 01:02:15,104 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2021-04-17 01:02:15,108 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2021-04-17 01:02:15,402 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1       | 2021-04-17 01:02:15,633 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@13cf7d52{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2021-04-17 01:02:15,647 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@45e37a7e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | 2021-04-17 01:02:27,472 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1       | Apr 17, 2021 1:02:30 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2021-04-17 01:02:30,637 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@63f2e0b{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-1_1_0-SNAPSHOT_jar-_-any-15378589165356835639/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2021-04-17 01:02:30,676 [main] INFO server.AbstractConnector: Started ServerConnector@47db5fa5{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1       | 2021-04-17 01:02:30,676 [main] INFO server.Server: Started @29332ms
s3g_1       | 2021-04-17 01:02:30,681 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621320, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621320, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | ind[26](Notice): Request: kadm5_get_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_create_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_get_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_create_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](Notice): Request: kadm5_get_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:00 kdc kadmind[26](info): closing down fd 18
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/e1ee43307ac4@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/e1ee43307ac4@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/e1ee43307ac4@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.e1ee43307ac4.keytab.
kdc_1       | Entry for principal dn/e1ee43307ac4@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.e1ee43307ac4.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/e1ee43307ac4@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/e1ee43307ac4@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/e1ee43307ac4@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.e1ee43307ac4.keytab.
kdc_1       | Entry for principal HTTP/e1ee43307ac4@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.e1ee43307ac4.keytab.
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621321, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621321, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621321, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621321, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_create_principal, dn/e1ee43307ac4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, dn/e1ee43307ac4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
om_1        | 2021-04-17 01:02:38,066 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | Sleeping for 5 seconds
recon_1     | Setting up kerberos!!
recon_1     | KDC ISSUER_SERVER => kdc:8081
recon_1     | Sleeping for 5 seconds
recon_1     | Got 200, KDC service ready!!
recon_1     | Download recon/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/recon.keytab
recon_1     | --2021-04-17 01:02:01--  http://kdc:8081/keytab/recon/recon
recon_1     | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 150 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/recon.keytab'
recon_1     | 
recon_1     |      0K                                                       100% 18.1M=0s
recon_1     | 
recon_1     | 2021-04-17 01:02:02 (18.1 MB/s) - '/etc/security/keytabs/recon.keytab' saved [150/150]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/recon.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 04/17/21 01:02:02 recon/recon@EXAMPLE.COM
recon_1     |    2 04/17/21 01:02:02 recon/recon@EXAMPLE.COM
recon_1     | Download HTTP/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
recon_1     | --2021-04-17 01:02:02--  http://kdc:8081/keytab/recon/HTTP
recon_1     | Resolving kdc (kdc)... 172.18.0.2
recon_1     | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 148 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/HTTP.keytab'
recon_1     | 
recon_1     |      0K                                                       100% 18.6M=0s
recon_1     | 
recon_1     | 2021-04-17 01:02:02 (18.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [148/148]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 04/17/21 01:02:02 HTTP/recon@EXAMPLE.COM
recon_1     |    2 04/17/21 01:02:02 HTTP/recon@EXAMPLE.COM
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2021-04-17 01:02:10,097 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1     | /************************************************************
recon_1     | STARTUP_MSG: Starting ReconServer
recon_1     | STARTUP_MSG:   host = recon/172.18.0.5
recon_1     | STARTUP_MSG:   args = []
recon_1     | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_get_principal, dn/e1ee43307ac4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_create_principal, HTTP/e1ee43307ac4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, HTTP/e1ee43307ac4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](Notice): Request: kadm5_get_principal, HTTP/e1ee43307ac4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:01 kdc kadmind[26](info): closing down fd 18
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for recon/recon@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "recon/recon@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal recon/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/recon.recon.keytab.
kdc_1       | Entry for principal recon/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/recon.recon.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/recon@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/recon@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:01 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621321, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621322, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621322, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621322, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_create_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_get_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_create_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](Notice): Request: kadm5_get_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:02 kdc kadmind[26](info): closing down fd 18
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/22b4ef3d5c71@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/22b4ef3d5c71@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/22b4ef3d5c71@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.22b4ef3d5c71.keytab.
kdc_1       | Entry for principal dn/22b4ef3d5c71@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.22b4ef3d5c71.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
om_1        | 2021-04-17 01:02:40,073 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:42,076 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:44,077 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.9 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:47,176 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
om_1        | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
om_1        | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:111)
om_1        | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13874)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om_1        | , while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:49,179 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
om_1        | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
om_1        | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:111)
om_1        | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13874)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om_1        | , while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9863 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2021-04-17 01:02:51,278 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om_1        | 2021-04-17 01:02:52,228 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om_1        | 2021-04-17 01:02:52,229 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om_1        | 2021-04-17 01:02:52,230 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om_1        | 2021-04-17 01:02:54,825 [main] INFO om.OzoneManager: Init response: GETCERT
om_1        | 2021-04-17 01:02:54,935 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.9,host:om
om_1        | 2021-04-17 01:02:54,936 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om_1        | 2021-04-17 01:02:54,938 [main] ERROR client.OMCertificateClient: Invalid domain om
om_1        | 2021-04-17 01:02:54,955 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2021-04-17 01:02:54,955 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.9:9862
om_1        | 2021-04-17 01:02:54,955 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2021-04-17 01:02:54,955 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1        | 2021-04-17 01:02:54,959 [main] INFO om.OzoneManager: Creating csr for OM->dns:om,ip:172.18.0.9,scmId:92a4fd30-ea6b-474a-81b8-f37828bbc4f5,clusterId:CID-aff45684-ddef-48b5-9a56-b03036dac515,subject:om
om_1        | 2021-04-17 01:02:55,518 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om_1        | value: 9862
om_1        | ]
om_1        | 2021-04-17 01:02:56,333 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-aff45684-ddef-48b5-9a56-b03036dac515;layoutVersion=0
om_1        | 2021-04-17 01:02:56,407 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.18.0.9
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2021-04-17 01:03:01,653 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.18.0.9
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
kdc_1       | WARNING: no policy specified for HTTP/22b4ef3d5c71@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/22b4ef3d5c71@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/22b4ef3d5c71@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.22b4ef3d5c71.keytab.
kdc_1       | Entry for principal HTTP/22b4ef3d5c71@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.22b4ef3d5c71.keytab.
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621323, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621323, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621323, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621323, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_create_principal, dn/22b4ef3d5c71@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, dn/22b4ef3d5c71@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_get_principal, dn/22b4ef3d5c71@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_create_principal, HTTP/22b4ef3d5c71@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, HTTP/22b4ef3d5c71@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](Notice): Request: kadm5_get_principal, HTTP/22b4ef3d5c71@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:03 kdc kadmind[26](info): closing down fd 18
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "scm/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621323, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621324, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621324, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621324, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_create_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_get_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_create_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_get_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](info): closing down fd 18
kdc_1       | WARNING: no policy specified for testuser/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-reconcodegen-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/javassist-3.25.0-GA.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:51Z
recon_1     | STARTUP_MSG:   java = 11.0.10
recon_1     | ************************************************************/
recon_1     | 2021-04-17 01:02:10,206 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 2021-04-17 01:02:16,826 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1     | 2021-04-17 01:02:20,052 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2021-04-17 01:02:20,448 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1     | 2021-04-17 01:02:21,938 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file /etc/security/keytabs/recon.keytab
recon_1     | 2021-04-17 01:02:21,938 [main] INFO recon.ReconServer: Recon login successful.
recon_1     | 2021-04-17 01:02:22,825 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2021-04-17 01:02:27,206 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1     | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2021-04-17 01:02:28,114 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2021-04-17 01:02:28,217 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2021-04-17 01:02:28,219 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | 2021-04-17 01:02:30,525 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2021-04-17 01:02:30,530 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1     | 2021-04-17 01:02:30,530 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1     | 2021-04-17 01:02:30,613 [main] INFO util.log: Logging initialized @27672ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2021-04-17 01:02:30,867 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2021-04-17 01:02:30,884 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2021-04-17 01:02:30,906 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1     | 2021-04-17 01:02:30,913 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 2021-04-17 01:02:30,916 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1     | 2021-04-17 01:02:30,933 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1     | 2021-04-17 01:02:31,228 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2021-04-17 01:02:31,653 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2021-04-17 01:02:31,676 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1     | 2021-04-17 01:02:31,751 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1     | 2021-04-17 01:02:31,751 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
recon_1     | 2021-04-17 01:02:32,690 [main] INFO Configuration.deprecation: No unit for ozone.recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1     | 2021-04-17 01:02:32,850 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2021-04-17 01:02:33,003 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
recon_1     | 2021-04-17 01:02:33,004 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
recon_1     | 2021-04-17 01:02:33,043 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2021-04-17 01:02:33,067 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1     | 2021-04-17 01:02:33,070 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2021-04-17 01:02:33,196 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2021-04-17 01:02:33,299 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1     | 2021-04-17 01:02:33,319 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
recon_1     | 2021-04-17 01:02:33,319 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
recon_1     | 2021-04-17 01:02:33,319 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 180000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 180000.
recon_1     | 2021-04-17 01:02:33,322 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2021-04-17 01:02:33,333 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:51Z
om_1        | STARTUP_MSG:   java = 11.0.10
om_1        | ************************************************************/
om_1        | 2021-04-17 01:03:01,690 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2021-04-17 01:03:06,485 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2021-04-17 01:03:06,560 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.9:9862
om_1        | 2021-04-17 01:03:06,560 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2021-04-17 01:03:06,560 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1        | 2021-04-17 01:03:06,594 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2021-04-17 01:03:07,012 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
recon_1     | 2021-04-17 01:02:33,337 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1     | 2021-04-17 01:02:33,366 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2021-04-17 01:02:33,403 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2021-04-17 01:02:33,438 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: No pipeline exists in current db
recon_1     | 2021-04-17 01:02:33,495 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2021-04-17 01:02:33,495 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1     | 2021-04-17 01:02:33,555 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2021-04-17 01:02:33,565 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2021-04-17 01:02:33,565 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2021-04-17 01:02:33,812 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2021-04-17 01:02:33,814 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
recon_1     | 2021-04-17 01:02:33,850 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2021-04-17 01:02:33,850 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2021-04-17 01:02:33,851 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1     | 2021-04-17 01:02:33,868 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1     | 2021-04-17 01:02:33,874 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@195498aa{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2021-04-17 01:02:33,875 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@523abba9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2021-04-17 01:02:34,290 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1     | Apr 17, 2021 1:02:35 AM org.glassfish.jersey.server.wadl.WadlFeature configure
recon_1     | WARNING: JAXBContext implementation could not be found. WADL feature is disabled.
recon_1     | 2021-04-17 01:02:35,600 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@e08853d{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-1_1_0-SNAPSHOT_jar-_-any-13293541985306168006/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2021-04-17 01:02:35,609 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@290c266c{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1     | 2021-04-17 01:02:35,610 [Listener at 0.0.0.0/9891] INFO server.Server: Started @32668ms
recon_1     | 2021-04-17 01:02:35,613 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2021-04-17 01:02:35,613 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2021-04-17 01:02:35,614 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2021-04-17 01:02:35,615 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2021-04-17 01:02:35,624 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
om_1        | 2021-04-17 01:03:07,017 [main] INFO om.OzoneManager: Ozone Manager login successful.
om_1        | 2021-04-17 01:03:07,017 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2021-04-17 01:03:10,599 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om_1        | 2021-04-17 01:03:10,974 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-540203851203.crt.
om_1        | 2021-04-17 01:03:10,981 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/557172838041.crt.
om_1        | 2021-04-17 01:03:10,993 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om_1        | 2021-04-17 01:03:11,086 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2021-04-17 01:03:11,407 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1        | 2021-04-17 01:03:11,409 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1        | 2021-04-17 01:03:11,716 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om_1        | 2021-04-17 01:03:11,720 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om_1        | 2021-04-17 01:03:11,721 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om_1        | 2021-04-17 01:03:12,145 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om_1        | 2021-04-17 01:03:12,169 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2021-04-17 01:03:12,180 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om_1        | 2021-04-17 01:03:12,195 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1        | 2021-04-17 01:03:12,283 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2021-04-17 01:03:12,379 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: omServiceIdDefault and Raft Peers: om:9872
om_1        | 2021-04-17 01:03:12,420 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om_1        | 2021-04-17 01:03:12,507 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om_1        | 2021-04-17 01:03:12,632 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om_1        | 2021-04-17 01:03:12,634 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1        | 2021-04-17 01:03:12,634 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om_1        | 2021-04-17 01:03:12,635 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1        | 2021-04-17 01:03:12,635 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1        | 2021-04-17 01:03:12,638 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om_1        | 2021-04-17 01:03:12,648 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2021-04-17 01:03:12,651 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1        | 2021-04-17 01:03:12,651 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om_1        | 2021-04-17 01:03:14,535 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om_1        | 2021-04-17 01:03:14,536 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2021-04-17 01:03:14,536 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2021-04-17 01:03:14,548 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2021-04-17 01:03:14,553 [main] INFO server.RaftServer: om1: addNew group-C5BA1605619E:[om1|rpc:om:9872|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@50e4d8cd[Not completed]
om_1        | 2021-04-17 01:03:14,554 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om_1        | 2021-04-17 01:03:14,617 [pool-18-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:om:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om_1        | 2021-04-17 01:03:14,629 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2021-04-17 01:03:14,630 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2021-04-17 01:03:14,630 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2021-04-17 01:03:14,630 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2021-04-17 01:03:14,630 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2021-04-17 01:03:14,630 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        | 2021-04-17 01:03:14,631 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | 2021-04-17 01:03:14,635 [pool-18-thread-1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:om:9872|priority:0], old=null, confs=<EMPTY_MAP>
om_1        | 2021-04-17 01:03:14,640 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2021-04-17 01:03:14,644 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2021-04-17 01:03:14,652 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2021-04-17 01:03:14,654 [pool-18-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
om_1        | 2021-04-17 01:03:14,680 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2021-04-17 01:03:14,704 [pool-18-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 8@om
om_1        | 2021-04-17 01:03:14,751 [pool-18-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
om_1        | 2021-04-17 01:03:14,760 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1        | 2021-04-17 01:03:14,763 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2021-04-17 01:03:14,783 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2021-04-17 01:03:14,783 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2021-04-17 01:02:35,628 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2021-04-17 01:02:35,628 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2021-04-17 01:02:35,628 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2021-04-17 01:02:35,629 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2021-04-17 01:02:35,630 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2021-04-17 01:02:37,719 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.5 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy42.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2021-04-17 01:02:39,721 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.5 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy42.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2021-04-17 01:02:41,722 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.5 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy42.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2021-04-17 01:02:43,724 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.5 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy42.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2021-04-17 01:02:47,427 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
recon_1     | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:145)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:43838)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
recon_1     | , while invoking $Proxy42.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2021-04-17 01:02:49,429 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.ratis.protocol.exceptions.NotLeaderException): Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
recon_1     | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:145)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:43838)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
recon_1     | , while invoking $Proxy42.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.8:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2021-04-17 01:02:52,604 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2021-04-17 01:02:52,605 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2021-04-17 01:02:52,608 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2021-04-17 01:02:52,694 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2021-04-17 01:02:52,728 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2021-04-17 01:02:53,144 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1     | 2021-04-17 01:02:53,152 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1     | 2021-04-17 01:02:53,172 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2021-04-17 01:02:53,177 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2021-04-17 01:02:53,268 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2021-04-17 01:02:53,276 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 91 milliseconds.
recon_1     | 2021-04-17 01:02:53,444 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 279 milliseconds to process 0 existing database records.
recon_1     | 2021-04-17 01:02:53,512 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 60 milliseconds for processing 0 containers.
recon_1     | 2021-04-17 01:02:55,631 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1       | Generating keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser2/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser2/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621324, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621324, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos daApr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_create_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_get_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_create_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](info): closing down fd 18
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_randkey_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](Notice): Request: kadm5_get_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Apr 17 01:02:04 kdc kadmind[26](info): closing down fd 18
kdc_1       | tabase
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621324, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
recon_1     | 2021-04-17 01:02:55,636 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2021-04-17 01:02:57,762 [pool-17-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.5 to om:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover after sleeping for 4000ms.
recon_1     | 2021-04-17 01:03:01,764 [pool-17-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.5 to om:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=null,nodeAddress=om:9862 after 2 failover attempts. Trying to failover after sleeping for 6000ms.
recon_1     | 2021-04-17 01:03:07,766 [pool-17-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.5 to om:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy41.submitRequest over nodeId=null,nodeAddress=om:9862 after 3 failover attempts. Trying to failover after sleeping for 8000ms.
recon_1     | 2021-04-17 01:03:07,818 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42645
recon_1     | 2021-04-17 01:03:07,851 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:03:08,309 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:43533
recon_1     | 2021-04-17 01:03:08,326 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:03:09,860 [IPC Server handler 20 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/129c26c3-a794-4177-9973-54b2e59dd63f
recon_1     | 2021-04-17 01:03:09,863 [IPC Server handler 20 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 129c26c3-a794-4177-9973-54b2e59dd63f{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 552803055385, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2021-04-17 01:03:10,011 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 129c26c3-a794-4177-9973-54b2e59dd63f to Node DB.
recon_1     | 2021-04-17 01:03:10,354 [IPC Server handler 0 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6a2218ae-2ed2-4a70-82aa-b47f176c4c61
recon_1     | 2021-04-17 01:03:10,355 [IPC Server handler 0 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 6a2218ae-2ed2-4a70-82aa-b47f176c4c61{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 553573924627, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2021-04-17 01:03:10,355 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 6a2218ae-2ed2-4a70-82aa-b47f176c4c61 to Node DB.
recon_1     | 2021-04-17 01:03:12,966 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=fa3cfe8a-2730-45c8-bb06-aa2c80c06e39. Trying to get from SCM.
recon_1     | 2021-04-17 01:03:13,072 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: fa3cfe8a-2730-45c8-bb06-aa2c80c06e39, Nodes: 129c26c3-a794-4177-9973-54b2e59dd63f{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:129c26c3-a794-4177-9973-54b2e59dd63f, CreationTimestamp2021-04-17T01:03:10.079Z] to Recon pipeline metadata.
recon_1     | 2021-04-17 01:03:13,148 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fa3cfe8a-2730-45c8-bb06-aa2c80c06e39, Nodes: 129c26c3-a794-4177-9973-54b2e59dd63f{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:129c26c3-a794-4177-9973-54b2e59dd63f, CreationTimestamp2021-04-17T01:03:10.079Z].
recon_1     | 2021-04-17 01:03:13,159 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@310ffc79, cost 62539.156us
recon_1     | 2021-04-17 01:03:13,502 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e359a3e6-9a86-4080-9bb7-297e31173cbf. Trying to get from SCM.
recon_1     | 2021-04-17 01:03:13,509 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e359a3e6-9a86-4080-9bb7-297e31173cbf, Nodes: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:6a2218ae-2ed2-4a70-82aa-b47f176c4c61, CreationTimestamp2021-04-17T01:03:10.565Z] to Recon pipeline metadata.
recon_1     | 2021-04-17 01:03:13,510 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e359a3e6-9a86-4080-9bb7-297e31173cbf, Nodes: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:6a2218ae-2ed2-4a70-82aa-b47f176c4c61, CreationTimestamp2021-04-17T01:03:10.565Z].
recon_1     | 2021-04-17 01:03:13,511 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.MockSCMHAManager$MockRatisServer@310ffc79, cost 1479.408us
scm_1       | Sleeping for 5 seconds
scm_1       | Setting up kerberos!!
scm_1       | KDC ISSUER_SERVER => kdc:8081
scm_1       | Sleeping for 5 seconds
scm_1       | Got 200, KDC service ready!!
scm_1       | Download scm/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
scm_1       | --2021-04-17 01:02:03--  http://kdc:8081/keytab/scm/scm
scm_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 142 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/scm.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 23.0M=0s
scm_1       | 
scm_1       | 2021-04-17 01:02:04 (23.0 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 04/17/21 01:02:04 scm/scm@EXAMPLE.COM
scm_1       |    2 04/17/21 01:02:04 scm/scm@EXAMPLE.COM
scm_1       | Download HTTP/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1       | --2021-04-17 01:02:04--  http://kdc:8081/keytab/scm/HTTP
scm_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 144 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 19.9M=0s
scm_1       | 
scm_1       | 2021-04-17 01:02:04 (19.9 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 04/17/21 01:02:04 HTTP/scm@EXAMPLE.COM
scm_1       |    2 04/17/21 01:02:04 HTTP/scm@EXAMPLE.COM
scm_1       | Download testuser/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
scm_1       | --2021-04-17 01:02:04--  http://kdc:8081/keytab/scm/testuser
scm_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 152 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 18.3M=0s
scm_1       | 
scm_1       | 2021-04-17 01:02:04 (18.3 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 04/17/21 01:02:04 testuser/scm@EXAMPLE.COM
scm_1       |    2 04/17/21 01:02:04 testuser/scm@EXAMPLE.COM
scm_1       | --2021-04-17 01:02:04--  http://kdc:8081/keytab/scm/testuser2
scm_1       | Download testuser2/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       | Resolving kdc (kdc)... 172.18.0.2
scm_1       | Connecting to kdc (kdc)|172.18.0.2|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 154 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 18.8M=0s
scm_1       | 
scm_1       | 2021-04-17 01:02:04 (18.8 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
recon_1     | 2021-04-17 01:03:17,609 [pool-17-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1     | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
recon_1     | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
recon_1     | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
recon_1     | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1     | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
recon_1     | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
recon_1     | , while invoking $Proxy41.submitRequest over nodeId=null,nodeAddress=om:9862 after 4 failover attempts. Trying to failover after sleeping for 10000ms.
recon_1     | 2021-04-17 01:03:28,327 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1618621375636
recon_1     | 2021-04-17 01:03:28,329 [pool-17-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2021-04-17 01:03:28,332 [pool-17-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1     | 2021-04-17 01:03:28,368 [pool-17-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1618621375636.
recon_1     | 2021-04-17 01:03:28,397 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2021-04-17 01:03:28,568 [pool-18-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
recon_1     | 2021-04-17 01:03:28,570 [pool-18-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2021-04-17 01:03:28,614 [pool-18-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1618621408572
recon_1     | 2021-04-17 01:03:28,615 [pool-18-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container key DB at /data/metadata/recon/recon-container-key.db_1618621341973.
recon_1     | 2021-04-17 01:03:28,631 [pool-18-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2021-04-17 01:03:28,631 [pool-18-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.06 seconds to process 0 keys.
recon_1     | 2021-04-17 01:03:28,652 [pool-18-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
recon_1     | 2021-04-17 01:03:28,652 [pool-18-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2021-04-17 01:03:48,729 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:46435
recon_1     | 2021-04-17 01:03:48,734 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:03:49,079 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:45185
recon_1     | 2021-04-17 01:03:49,088 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:04:18,733 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42333
recon_1     | 2021-04-17 01:04:18,743 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:04:19,054 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:44347
recon_1     | 2021-04-17 01:04:19,075 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:04:28,666 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2021-04-17 01:04:28,668 [pool-17-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1     | 2021-04-17 01:04:28,669 [pool-17-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2021-04-17 01:04:28,669 [pool-17-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2021-04-17 01:04:28,669 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2021-04-17 01:04:28,706 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0
recon_1     | 2021-04-17 01:04:48,704 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39343
recon_1     | 2021-04-17 01:04:48,718 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:04:49,070 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:46877
recon_1     | 2021-04-17 01:04:49,088 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:05:18,704 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39285
recon_1     | 2021-04-17 01:05:18,722 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:05:19,047 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:44733
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 04/17/21 01:02:04 testuser2/scm@EXAMPLE.COM
scm_1       |    2 04/17/21 01:02:04 testuser2/scm@EXAMPLE.COM
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2021-04-17 01:02:22,916 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = scm/172.18.0.8
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om_1        | 2021-04-17 01:03:14,792 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om1@group-C5BA1605619E
om_1        | 2021-04-17 01:03:14,835 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2021-04-17 01:03:14,854 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 2021-04-17 01:03:14,861 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om_1        | 2021-04-17 01:03:14,871 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e
om_1        | 2021-04-17 01:03:14,872 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om_1        | 2021-04-17 01:03:14,876 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om_1        | 2021-04-17 01:03:14,876 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2021-04-17 01:03:14,877 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om_1        | 2021-04-17 01:03:14,877 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2021-04-17 01:03:14,881 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2021-04-17 01:03:14,881 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2021-04-17 01:03:14,886 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2021-04-17 01:03:14,913 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om_1        | 2021-04-17 01:03:14,913 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om_1        | 2021-04-17 01:03:14,923 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2021-04-17 01:03:14,923 [pool-18-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om_1        | 2021-04-17 01:03:14,964 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2021-04-17 01:03:14,965 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om_1        | 2021-04-17 01:03:14,965 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om_1        | 2021-04-17 01:03:14,966 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om_1        | 2021-04-17 01:03:14,966 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om_1        | 2021-04-17 01:03:14,967 [pool-18-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | 2021-04-17 01:03:15,030 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om1@group-C5BA1605619E
om_1        | 2021-04-17 01:03:15,046 [pool-18-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om1@group-C5BA1605619E
om_1        | 2021-04-17 01:03:15,099 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2021-04-17 01:03:15,131 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2021-04-17 01:03:15,131 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2021-04-17 01:03:15,212 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.18.0.9:9862
om_1        | 2021-04-17 01:03:15,212 [Listener at om/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om_1        | 2021-04-17 01:03:15,214 [Listener at om/9862] INFO server.RaftServer$Division: om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:om:9872|priority:0], old=null
om_1        | 2021-04-17 01:03:15,215 [Listener at om/9862] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2021-04-17 01:03:15,220 [Listener at om/9862] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-FollowerState
om_1        | 2021-04-17 01:03:15,221 [Listener at om/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
om_1        | 2021-04-17 01:03:15,223 [Listener at om/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om1@group-C5BA1605619E
om_1        | 2021-04-17 01:03:15,239 [Listener at om/9862] INFO server.RaftServer: om1: start RPC server
om_1        | 2021-04-17 01:03:15,283 [Listener at om/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om_1        | 2021-04-17 01:03:15,312 [Listener at om/9862] INFO om.OzoneManager: Reading keypair and certificate from file system.
om_1        | 2021-04-17 01:03:15,314 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$383/0x0000000840547040@58dea0a7] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om_1        | 2021-04-17 01:03:15,315 [Listener at om/9862] INFO om.OzoneManager: Starting OM block token secret manager
om_1        | 2021-04-17 01:03:15,316 [Listener at om/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om_1        | 2021-04-17 01:03:15,318 [Listener at om/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om_1        | 2021-04-17 01:03:15,318 [Listener at om/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om_1        | 2021-04-17 01:03:15,328 [Thread[Thread-14,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om_1        | 2021-04-17 01:03:15,393 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2021-04-17 01:03:15,394 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om_1        | 2021-04-17 01:03:15,395 [Listener at om/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om_1        | 2021-04-17 01:03:15,438 [Listener at om/9862] INFO util.log: Logging initialized @18074ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2021-04-17 01:03:15,585 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2021-04-17 01:03:15,594 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2021-04-17 01:03:15,595 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om_1        | 2021-04-17 01:03:15,595 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1        | 2021-04-17 01:03:15,596 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 2021-04-17 01:05:19,057 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:05:28,710 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2021-04-17 01:05:28,711 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2021-04-17 01:05:28,760 [pool-17-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0
recon_1     | 2021-04-17 01:05:48,720 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38943
recon_1     | 2021-04-17 01:05:48,751 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2021-04-17 01:05:49,074 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:36503
recon_1     | 2021-04-17 01:05:49,104 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Apr 17 01:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1618621324, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Apr 17 01:02:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621325, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:02:07 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.7: ISSUE: authtime 1618621327, etypes {rep=18 tkt=18 ses=18}, dn/95170cd1a491@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:02:19 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.9: ISSUE: authtime 1618621339, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:02:20 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.10: ISSUE: authtime 1618621340, etypes {rep=18 tkt=18 ses=18}, dn/e1ee43307ac4@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:02:21 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.5: ISSUE: authtime 1618621341, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:02:22 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.6: ISSUE: authtime 1618621342, etypes {rep=18 tkt=18 ses=18}, dn/22b4ef3d5c71@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:02:41 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.8: ISSUE: authtime 1618621361, etypes {rep=18 tkt=18 ses=18}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:02:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1618621341, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:02:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1618621342, etypes {rep=18 tkt=18 ses=18}, dn/22b4ef3d5c71@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:02:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.7: ISSUE: authtime 1618621327, etypes {rep=18 tkt=18 ses=18}, dn/95170cd1a491@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:02:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1618621340, etypes {rep=18 tkt=18 ses=18}, dn/e1ee43307ac4@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:02:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1618621339, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:02:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621325, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:02:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621377, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:06 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.18.0.9: ISSUE: authtime 1618621386, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.6: ISSUE: authtime 1618621342, etypes {rep=18 tkt=18 ses=18}, dn/22b4ef3d5c71@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Apr 17 01:03:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.10: ISSUE: authtime 1618621340, etypes {rep=18 tkt=18 ses=18}, dn/e1ee43307ac4@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Apr 17 01:03:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.9: ISSUE: authtime 1618621386, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:03:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621377, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:03:15 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621395, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1618621341, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Apr 17 01:03:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621395, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:03:23 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621403, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621403, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:03:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.5: ISSUE: authtime 1618621341, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
kdc_1       | Apr 17 01:03:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621409, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621409, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:03:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621416, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621416, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:03:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621423, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621423, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:03:50 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621430, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621430, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:03:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621436, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:03:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621436, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:04:03 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621443, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621443, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:50Z
scm_1       | STARTUP_MSG:   java = 11.0.10
scm_1       | ************************************************************/
scm_1       | 2021-04-17 01:02:23,061 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2021-04-17 01:02:24,557 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2021-04-17 01:02:24,778 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1       | 2021-04-17 01:02:24,790 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1       | 2021-04-17 01:02:26,417 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm_1       | 2021-04-17 01:02:26,706 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm_1       | 2021-04-17 01:02:26,718 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9865 (custom)
scm_1       | 2021-04-17 01:02:26,729 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm_1       | 2021-04-17 01:02:26,729 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9865 (custom)
scm_1       | 2021-04-17 01:02:26,732 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9865 (custom)
scm_1       | 2021-04-17 01:02:26,733 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm_1       | 2021-04-17 01:02:26,741 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2021-04-17 01:02:26,750 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1       | 2021-04-17 01:02:26,759 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2021-04-17 01:02:28,076 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm_1       | 2021-04-17 01:02:28,078 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1       | 2021-04-17 01:02:28,084 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2021-04-17 01:02:28,174 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1       | 2021-04-17 01:02:28,320 [main] INFO server.RaftServer: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: addNew group-B03036DAC515:[92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|priority:0] returns group-B03036DAC515:java.util.concurrent.CompletableFuture@40021799[Not completed]
scm_1       | 2021-04-17 01:02:28,432 [pool-2-thread-1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: new RaftServerImpl for group-B03036DAC515:[92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|priority:0] with SCMStateMachine:uninitialized
scm_1       | 2021-04-17 01:02:28,433 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm_1       | 2021-04-17 01:02:28,434 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2021-04-17 01:02:28,434 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1       | 2021-04-17 01:02:28,434 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1       | 2021-04-17 01:02:28,434 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2021-04-17 01:03:15,604 [Listener at om/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om_1        | 2021-04-17 01:03:15,776 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2021-04-17 01:03:15,778 [Listener at om/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om_1        | 2021-04-17 01:03:15,930 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2021-04-17 01:03:15,930 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2021-04-17 01:03:15,932 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1        | 2021-04-17 01:03:15,950 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2021-04-17 01:03:15,956 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6b6c882c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2021-04-17 01:03:15,957 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@9bd477c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2021-04-17 01:03:16,172 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2021-04-17 01:03:16,190 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2b3e2039{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-18210977248311129667/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2021-04-17 01:03:16,205 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@2e549515{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om_1        | 2021-04-17 01:03:16,207 [Listener at om/9862] INFO server.Server: Started @18843ms
om_1        | 2021-04-17 01:03:16,215 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2021-04-17 01:03:16,215 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2021-04-17 01:03:16,217 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2021-04-17 01:03:16,222 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2021-04-17 01:03:16,241 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2021-04-17 01:03:16,482 [Listener at om/9862] INFO om.TrashPolicyOzone: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
om_1        | 2021-04-17 01:03:16,511 [Listener at om/9862] INFO om.TrashPolicyOzone: Ozone Manager trash configuration: Deletion interval = 1 minutes, Emptier interval = 1 minutes.
om_1        | 2021-04-17 01:03:16,572 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72364a40] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2021-04-17 01:03:16,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44769
om_1        | 2021-04-17 01:03:16,610 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2021-04-17 01:03:17,591 [IPC Server handler 0 on default port 9862] INFO ipc.Server: IPC Server handler 0 on default port 9862, call Call#2 Retry#4 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.18.0.5:44769
om_1        | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om_1        | 2021-04-17 01:03:20,417 [om1@group-C5BA1605619E-FollowerState] INFO impl.FollowerState: om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5200869843ns, electionTimeout:5185ms
om_1        | 2021-04-17 01:03:20,418 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-FollowerState
om_1        | 2021-04-17 01:03:20,419 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2021-04-17 01:03:20,421 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om_1        | 2021-04-17 01:03:20,421 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderElection1
om_1        | 2021-04-17 01:03:20,441 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om:9872|priority:0], old=null
om_1        | 2021-04-17 01:03:20,442 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
om_1        | 2021-04-17 01:03:20,442 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-LeaderElection1
om_1        | 2021-04-17 01:03:20,443 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2021-04-17 01:03:20,443 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 5687ms
om_1        | 2021-04-17 01:03:20,452 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2021-04-17 01:02:28,435 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm_1       | 2021-04-17 01:02:28,435 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2021-04-17 01:02:28,439 [pool-2-thread-1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: ConfigurationManager, init=-1: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|priority:0], old=null, confs=<EMPTY_MAP>
scm_1       | 2021-04-17 01:02:28,465 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1       | 2021-04-17 01:02:28,471 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 2021-04-17 01:02:28,496 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515 does not exist. Creating ...
scm_1       | 2021-04-17 01:02:28,598 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515/in_use.lock acquired by nodename 70@scm
scm_1       | 2021-04-17 01:02:28,748 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515 has been successfully formatted.
scm_1       | 2021-04-17 01:02:28,781 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1       | 2021-04-17 01:02:28,787 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2021-04-17 01:02:28,856 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2021-04-17 01:02:28,856 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2021-04-17 01:02:28,931 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2021-04-17 01:02:28,944 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:28,948 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:28,956 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm_1       | 2021-04-17 01:02:28,979 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 2021-04-17 01:02:28,984 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm_1       | 2021-04-17 01:02:28,991 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515
scm_1       | 2021-04-17 01:02:29,044 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm_1       | 2021-04-17 01:02:29,045 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm_1       | 2021-04-17 01:02:29,046 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm_1       | 2021-04-17 01:02:29,047 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 2021-04-17 01:02:29,055 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2021-04-17 01:02:29,061 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2021-04-17 01:02:29,070 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2021-04-17 01:02:29,073 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2021-04-17 01:02:29,142 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm_1       | 2021-04-17 01:02:29,144 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm_1       | 2021-04-17 01:02:29,215 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2021-04-17 01:02:29,215 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2021-04-17 01:02:29,250 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2021-04-17 01:02:29,251 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm_1       | 2021-04-17 01:02:29,271 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm_1       | 2021-04-17 01:02:29,287 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1       | 2021-04-17 01:02:29,289 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm_1       | 2021-04-17 01:02:29,289 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm_1       | 2021-04-17 01:02:29,436 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:29,443 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:29,494 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:29,499 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:29,538 [main] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: start as a follower, conf=-1: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|priority:0], old=null
scm_1       | 2021-04-17 01:02:29,545 [main] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2021-04-17 01:02:29,546 [main] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: start 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState
scm_1       | 2021-04-17 01:02:30,370 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B03036DAC515,id=92a4fd30-ea6b-474a-81b8-f37828bbc4f5
scm_1       | 2021-04-17 01:02:30,401 [main] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:30,409 [main] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:30,438 [main] INFO server.RaftServer: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: start RPC server
scm_1       | 2021-04-17 01:02:30,754 [main] INFO server.GrpcService: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: GrpcService started, listening on 9865
scm_1       | 2021-04-17 01:02:30,793 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$307/0x0000000840278040@4a0df195] INFO util.JvmPauseMonitor: JvmPauseMonitor-92a4fd30-ea6b-474a-81b8-f37828bbc4f5: Started
scm_1       | 2021-04-17 01:02:34,719 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO impl.FollowerState: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5172832853ns, electionTimeout:5128ms
scm_1       | 2021-04-17 01:02:34,720 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: shutdown 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState
scm_1       | 2021-04-17 01:02:34,720 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | 2021-04-17 01:02:34,724 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2021-04-17 01:02:34,724 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: start 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1
scm_1       | 2021-04-17 01:02:34,733 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO impl.LeaderElection: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|priority:0], old=null
scm_1       | 2021-04-17 01:02:34,734 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO impl.LeaderElection: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm_1       | 2021-04-17 01:02:34,735 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: shutdown 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1
scm_1       | 2021-04-17 01:02:34,735 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1       | 2021-04-17 01:02:34,736 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: change Leader from null to 92a4fd30-ea6b-474a-81b8-f37828bbc4f5 at term 1 for becomeLeader, leader elected after 5954ms
scm_1       | 2021-04-17 01:02:34,740 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2021-04-17 01:02:34,742 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:34,743 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:34,746 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2021-04-17 01:02:34,747 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm_1       | 2021-04-17 01:02:34,755 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1       | 2021-04-17 01:02:34,756 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1       | 2021-04-17 01:02:34,757 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 2021-04-17 01:02:34,770 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: start 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderStateImpl
scm_1       | 2021-04-17 01:02:34,811 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2021-04-17 01:02:34,905 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: set configuration 0: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|admin:|client:|dataStream:|priority:0], old=null
scm_1       | 2021-04-17 01:02:35,020 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515/current/log_inprogress_0
scm_1       | 2021-04-17 01:02:36,795 [main] INFO server.RaftServer: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: close
scm_1       | 2021-04-17 01:02:36,797 [main] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: shutdown
scm_1       | 2021-04-17 01:02:36,797 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B03036DAC515,id=92a4fd30-ea6b-474a-81b8-f37828bbc4f5
scm_1       | 2021-04-17 01:02:36,798 [main] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: shutdown 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderStateImpl
scm_1       | 2021-04-17 01:02:36,814 [main] INFO impl.PendingRequests: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-PendingRequests: sendNotLeaderResponses
scm_1       | 2021-04-17 01:02:36,815 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:36,815 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:36,816 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-StateMachineUpdater] INFO impl.StateMachineUpdater: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-StateMachineUpdater: Took a snapshot at index 0
scm_1       | 2021-04-17 01:02:36,816 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-StateMachineUpdater] INFO impl.StateMachineUpdater: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm_1       | 2021-04-17 01:02:36,823 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:36,818 [main] INFO impl.StateMachineUpdater: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-StateMachineUpdater: set stopIndex = 0
scm_1       | 2021-04-17 01:02:36,832 [main] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: closes. applyIndex: 0
scm_1       | 2021-04-17 01:02:36,834 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm_1       | 2021-04-17 01:02:36,835 [main] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker close()
scm_1       | 2021-04-17 01:02:36,835 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:36,835 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:36,835 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:36,836 [main] INFO server.GrpcService: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: shutdown server with port 9865 now
scm_1       | 2021-04-17 01:02:36,842 [main] INFO server.GrpcService: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: shutdown server with port 9865 successfully
scm_1       | 2021-04-17 01:02:36,842 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$307/0x0000000840278040@4a0df195] INFO util.JvmPauseMonitor: JvmPauseMonitor-92a4fd30-ea6b-474a-81b8-f37828bbc4f5: Stopped
scm_1       | 2021-04-17 01:02:36,854 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm_1       | 2021-04-17 01:02:37,501 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm_1       | 2021-04-17 01:02:37,501 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm_1       | 2021-04-17 01:02:37,503 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm_1       | 2021-04-17 01:02:38,340 [main] INFO ha.HASecurityUtils: Init response: GETCERT
om_1        | 2021-04-17 01:03:20,455 [om1@group-C5BA1605619E-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.om1@group-C5BA1605619E
om_1        | 2021-04-17 01:03:20,460 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2021-04-17 01:03:20,463 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om_1        | 2021-04-17 01:03:20,483 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om_1        | 2021-04-17 01:03:20,483 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 2021-04-17 01:03:20,484 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1        | 2021-04-17 01:03:20,491 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderStateImpl
om_1        | 2021-04-17 01:03:20,514 [om1@group-C5BA1605619E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 2021-04-17 01:03:20,545 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: set configuration 0: [om1|rpc:om:9872|admin:|client:|dataStream:|priority:0], old=null
om_1        | 2021-04-17 01:03:20,614 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
om_1        | 2021-04-17 01:03:27,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43791
om_1        | 2021-04-17 01:03:27,629 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2021-04-17 01:03:28,254 [qtp1082126943-45] INFO utils.DBCheckpointServlet: Received request to obtain DB checkpoint snapshot
om_1        | 2021-04-17 01:03:28,274 [qtp1082126943-45] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1618621408255 in 19 milliseconds
om_1        | 2021-04-17 01:03:28,290 [qtp1082126943-45] INFO utils.DBCheckpointServlet: Time taken to write the checkpoint to response output stream: 14 milliseconds
om_1        | 2021-04-17 01:03:28,290 [qtp1082126943-45] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1618621408255
om_1        | 2021-04-17 01:04:28,685 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43091
om_1        | 2021-04-17 01:04:28,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2021-04-17 01:05:28,745 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35677
om_1        | 2021-04-17 01:05:28,756 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Apr 17 01:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621449, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621449, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:04:16 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621456, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621456, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:04:23 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621463, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621463, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:04:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621469, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621469, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:04:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621476, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621476, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:04:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621483, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621483, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:04:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621489, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621489, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:04:56 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621496, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:04:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621496, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:05:02 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621502, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:05:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621502, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:05:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621509, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:05:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621509, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:05:15 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621515, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:05:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621515, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:05:22 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621522, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:05:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621522, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:05:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621529, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:05:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621529, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:05:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621536, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:05:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621536, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:05:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621542, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:05:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621542, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Apr 17 01:05:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.18.0.8: ISSUE: authtime 1618621549, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Apr 17 01:05:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.18.0.8: ISSUE: authtime 1618621549, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
scm_1       | 2021-04-17 01:02:38,956 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.8,host:scm
scm_1       | 2021-04-17 01:02:38,957 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm_1       | 2021-04-17 01:02:39,041 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.8,host:scm
scm_1       | 2021-04-17 01:02:39,042 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm_1       | 2021-04-17 01:02:39,042 [main] ERROR client.SCMCertificateClient: Invalid domain scm
scm_1       | 2021-04-17 01:02:39,043 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm,scmId:92a4fd30-ea6b-474a-81b8-f37828bbc4f5,clusterId:CID-aff45684-ddef-48b5-9a56-b03036dac515,subject:scm-sub@scm
scm_1       | 2021-04-17 01:02:39,094 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm_1       | 2021-04-17 01:02:39,097 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-aff45684-ddef-48b5-9a56-b03036dac515; layoutVersion=0; scmId=92a4fd30-ea6b-474a-81b8-f37828bbc4f5
scm_1       | 2021-04-17 01:02:39,109 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.8
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2021-04-17 01:02:40,493 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = scm/172.18.0.8
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/8a80c8038131bac50c4067a04b9b4d9377be3e72 ; compiled by 'runner' on 2021-04-17T00:50Z
scm_1       | STARTUP_MSG:   java = 11.0.10
scm_1       | ************************************************************/
scm_1       | 2021-04-17 01:02:40,502 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2021-04-17 01:02:40,639 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1       | 2021-04-17 01:02:40,644 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1       | 2021-04-17 01:02:40,763 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2021-04-17 01:02:41,315 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm_1       | 2021-04-17 01:02:41,403 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/540203851203.crt.
scm_1       | 2021-04-17 01:02:41,406 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm_1       | 2021-04-17 01:02:41,410 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm_1       | 2021-04-17 01:02:41,562 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm_1       | 2021-04-17 01:02:41,562 [main] INFO server.StorageContainerManager: SCM login successful.
scm_1       | 2021-04-17 01:02:41,611 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2021-04-17 01:02:41,771 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2021-04-17 01:02:41,955 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar!/network-topology-default.xml]
scm_1       | 2021-04-17 01:02:41,955 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2021-04-17 01:02:42,061 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:92a4fd30-ea6b-474a-81b8-f37828bbc4f5
scm_1       | 2021-04-17 01:02:42,199 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm_1       | 2021-04-17 01:02:42,277 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm_1       | 2021-04-17 01:02:42,277 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9865 (custom)
scm_1       | 2021-04-17 01:02:42,278 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm_1       | 2021-04-17 01:02:42,278 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9865 (custom)
scm_1       | 2021-04-17 01:02:42,278 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9865 (custom)
scm_1       | 2021-04-17 01:02:42,279 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm_1       | 2021-04-17 01:02:42,280 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2021-04-17 01:02:42,281 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1       | 2021-04-17 01:02:42,282 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm_1       | 2021-04-17 01:02:42,940 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm_1       | 2021-04-17 01:02:42,942 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1       | 2021-04-17 01:02:42,942 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2021-04-17 01:02:42,953 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1       | 2021-04-17 01:02:42,957 [main] INFO server.RaftServer: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: found a subdirectory /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515
scm_1       | 2021-04-17 01:02:42,962 [main] INFO server.RaftServer: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: addNew group-B03036DAC515:[] returns group-B03036DAC515:java.util.concurrent.CompletableFuture@35d60381[Not completed]
scm_1       | 2021-04-17 01:02:42,974 [pool-14-thread-1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: new RaftServerImpl for group-B03036DAC515:[] with SCMStateMachine:uninitialized
scm_1       | 2021-04-17 01:02:42,976 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm_1       | 2021-04-17 01:02:42,976 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2021-04-17 01:02:42,977 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1       | 2021-04-17 01:02:42,977 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1       | 2021-04-17 01:02:42,978 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2021-04-17 01:02:42,978 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm_1       | 2021-04-17 01:02:42,978 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2021-04-17 01:02:42,982 [pool-14-thread-1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm_1       | 2021-04-17 01:02:42,982 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1       | 2021-04-17 01:02:42,984 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 2021-04-17 01:02:43,002 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515/in_use.lock acquired by nodename 7@scm
scm_1       | 2021-04-17 01:02:43,006 [pool-14-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=92a4fd30-ea6b-474a-81b8-f37828bbc4f5} from /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515/current/raft-meta
scm_1       | 2021-04-17 01:02:43,044 [pool-14-thread-1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: set configuration 0: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|admin:|client:|dataStream:|priority:0], old=null
scm_1       | 2021-04-17 01:02:43,045 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1       | 2021-04-17 01:02:43,047 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2021-04-17 01:02:43,055 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2021-04-17 01:02:43,055 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2021-04-17 01:02:43,063 [pool-14-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2021-04-17 01:02:43,066 [pool-14-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:43,068 [pool-14-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:43,070 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm_1       | 2021-04-17 01:02:43,077 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 2021-04-17 01:02:43,077 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm_1       | 2021-04-17 01:02:43,087 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515
scm_1       | 2021-04-17 01:02:43,088 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm_1       | 2021-04-17 01:02:43,088 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm_1       | 2021-04-17 01:02:43,089 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm_1       | 2021-04-17 01:02:43,090 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 2021-04-17 01:02:43,090 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2021-04-17 01:02:43,096 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2021-04-17 01:02:43,099 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2021-04-17 01:02:43,100 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2021-04-17 01:02:43,109 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm_1       | 2021-04-17 01:02:43,109 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm_1       | 2021-04-17 01:02:43,140 [pool-14-thread-1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: set configuration 0: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|admin:|client:|dataStream:|priority:0], old=null
scm_1       | 2021-04-17 01:02:43,141 [pool-14-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515/current/log_inprogress_0
scm_1       | 2021-04-17 01:02:43,145 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm_1       | 2021-04-17 01:02:43,145 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2021-04-17 01:02:43,223 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2021-04-17 01:02:43,224 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm_1       | 2021-04-17 01:02:43,228 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm_1       | 2021-04-17 01:02:43,229 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1       | 2021-04-17 01:02:43,230 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm_1       | 2021-04-17 01:02:43,231 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm_1       | 2021-04-17 01:02:43,252 [pool-14-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:43,252 [pool-14-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:43,256 [pool-14-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:43,256 [pool-14-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:43,265 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm_1       | 2021-04-17 01:02:43,265 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1       | 2021-04-17 01:02:43,266 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm_1       | 2021-04-17 01:02:43,290 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm_1       | 2021-04-17 01:02:43,290 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm_1       | 2021-04-17 01:02:43,294 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm_1       | 2021-04-17 01:02:43,296 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm_1       | 2021-04-17 01:02:43,343 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
scm_1       | 2021-04-17 01:02:43,344 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
scm_1       | 2021-04-17 01:02:43,344 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 180000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 180000.
scm_1       | 2021-04-17 01:02:43,350 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2021-04-17 01:02:43,423 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2021-04-17 01:02:43,440 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
scm_1       | 2021-04-17 01:02:43,469 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm_1       | 2021-04-17 01:02:43,514 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm_1       | 2021-04-17 01:02:43,515 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm_1       | 2021-04-17 01:02:43,554 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1       | 2021-04-17 01:02:43,588 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm_1       | 2021-04-17 01:02:43,645 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm_1       | 2021-04-17 01:02:43,650 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2021-04-17 01:02:43,658 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:02:43,670 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2021-04-17 01:02:43,672 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2021-04-17 01:02:43,710 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm_1       | 2021-04-17 01:02:43,716 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm_1       | 2021-04-17 01:02:43,717 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 540203851203 on primary SCM
scm_1       | 2021-04-17 01:02:43,726 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm_1       | 2021-04-17 01:02:43,764 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2021-04-17 01:02:43,785 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm_1       | 2021-04-17 01:02:44,745 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2021-04-17 01:02:44,748 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2021-04-17 01:02:44,808 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2021-04-17 01:02:44,812 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2021-04-17 01:02:44,833 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2021-04-17 01:02:44,833 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2021-04-17 01:02:44,848 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Container Balancer status:
scm_1       | Key                            Value
scm_1       | Running                        false
scm_1       | Container Balancer Configuration values:
scm_1       | Key                            Value
scm_1       | Threshold                      0.100000
scm_1       | Max Datanodes to Balance       5
scm_1       | Max Size to Move               10737418240B
scm_1       | 
scm_1       | 2021-04-17 01:02:44,849 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1       | 2021-04-17 01:02:44,849 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm_1       | 2021-04-17 01:02:44,852 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2021-04-17 01:02:44,855 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9865
scm_1       | 2021-04-17 01:02:44,860 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: start as a follower, conf=0: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|admin:|client:|dataStream:|priority:0], old=null
scm_1       | 2021-04-17 01:02:44,861 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm_1       | 2021-04-17 01:02:44,863 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: start 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState
scm_1       | 2021-04-17 01:02:44,871 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B03036DAC515,id=92a4fd30-ea6b-474a-81b8-f37828bbc4f5
scm_1       | 2021-04-17 01:02:44,872 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:44,877 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:44,879 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: start RPC server
scm_1       | 2021-04-17 01:02:45,012 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: GrpcService started, listening on 9865
scm_1       | 2021-04-17 01:02:45,020 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$407/0x0000000840499040@34001c5d] INFO util.JvmPauseMonitor: JvmPauseMonitor-92a4fd30-ea6b-474a-81b8-f37828bbc4f5: Started
scm_1       | 2021-04-17 01:02:45,022 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|admin:|client:|dataStream:|priority:0]
scm_1       | 2021-04-17 01:02:45,159 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2021-04-17 01:02:45,169 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2021-04-17 01:02:45,170 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2021-04-17 01:02:45,421 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2021-04-17 01:02:45,422 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2021-04-17 01:02:45,423 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2021-04-17 01:02:45,508 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2021-04-17 01:02:45,509 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2021-04-17 01:02:45,510 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2021-04-17 01:02:45,516 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2021-04-17 01:02:45,555 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2021-04-17 01:02:45,560 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2021-04-17 01:02:45,567 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2021-04-17 01:02:45,571 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2021-04-17 01:02:45,632 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm_1       | 2021-04-17 01:02:45,633 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2021-04-17 01:02:45,633 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm_1       | 2021-04-17 01:02:45,654 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1822a61b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2021-04-17 01:02:45,719 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2021-04-17 01:02:45,719 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm_1       | 2021-04-17 01:02:45,721 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm_1       | 2021-04-17 01:02:45,892 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @6566ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2021-04-17 01:02:46,749 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45969
scm_1       | 2021-04-17 01:02:46,791 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/95170cd1a491@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:39045
scm_1       | 2021-04-17 01:02:46,808 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:40315
scm_1       | 2021-04-17 01:02:46,773 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:44893
scm_1       | 2021-04-17 01:02:46,850 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:02:46,852 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35757
scm_1       | 2021-04-17 01:02:46,851 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2021-04-17 01:02:46,853 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/95170cd1a491@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:02:46,896 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:02:46,898 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:02:46,906 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2021-04-17 01:02:46,913 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2021-04-17 01:02:46,915 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm_1       | 2021-04-17 01:02:46,915 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1       | 2021-04-17 01:02:46,915 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1       | 2021-04-17 01:02:46,918 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm_1       | 2021-04-17 01:02:46,931 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44007
scm_1       | 2021-04-17 01:02:46,974 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:02:46,982 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2021-04-17 01:02:46,984 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
scm_1       | 2021-04-17 01:02:47,143 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2021-04-17 01:02:47,147 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2021-04-17 01:02:47,156 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2021-04-17 01:02:47,156 [IPC Server handler 9 on default port 9863] INFO ipc.Server: IPC Server handler 9 on default port 9863, call Call#0 Retry#12 org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol.send from 172.18.0.9:44893
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:111)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13874)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:47,189 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#15 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.7:39045
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:47,198 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#10 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.10:35757
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:47,204 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.8:44007
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:47,205 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.6:40315
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:47,246 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1       | 2021-04-17 01:02:47,253 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@389a9ff6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2021-04-17 01:02:47,268 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d200dce{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2021-04-17 01:02:47,414 [IPC Server handler 0 on default port 9860] INFO ipc.Server: IPC Server handler 0 on default port 9860, call Call#0 Retry#5 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.18.0.5:45969
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:145)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:43838)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:47,489 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1       | 2021-04-17 01:02:47,571 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@678b3746{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0-SNAPSHOT_jar-_-any-9510368435778630156/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2021-04-17 01:02:47,598 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@6fd07a56{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1       | 2021-04-17 01:02:47,600 [Listener at 0.0.0.0/9860] INFO server.Server: Started @8274ms
scm_1       | 2021-04-17 01:02:47,602 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2021-04-17 01:02:47,602 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2021-04-17 01:02:47,605 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2021-04-17 01:02:48,659 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:02:49,178 [IPC Server handler 9 on default port 9863] INFO ipc.Server: IPC Server handler 9 on default port 9863, call Call#0 Retry#13 org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol.send from 172.18.0.9:44893
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:111)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13874)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:49,207 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#11 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.10:35757
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:49,221 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.8:44007
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:49,251 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#10 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.6:40315
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:94)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:13388)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:49,428 [IPC Server handler 0 on default port 9860] INFO ipc.Server: IPC Server handler 0 on default port 9860, call Call#0 Retry#6 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.18.0.5:45969
scm_1       | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515 is not the leader
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:280)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:145)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:43838)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm_1       | 2021-04-17 01:02:50,002 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO impl.FollowerState: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5139368395ns, electionTimeout:5128ms
scm_1       | 2021-04-17 01:02:50,003 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: shutdown 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState
scm_1       | 2021-04-17 01:02:50,004 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm_1       | 2021-04-17 01:02:50,006 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2021-04-17 01:02:50,006 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-FollowerState] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: start 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1
scm_1       | 2021-04-17 01:02:50,034 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO impl.LeaderElection: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|admin:|client:|dataStream:|priority:0], old=null
scm_1       | 2021-04-17 01:02:50,035 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO impl.LeaderElection: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm_1       | 2021-04-17 01:02:50,036 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: shutdown 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1
scm_1       | 2021-04-17 01:02:50,036 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm_1       | 2021-04-17 01:02:50,036 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm_1       | 2021-04-17 01:02:50,036 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm_1       | 2021-04-17 01:02:50,037 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm_1       | 2021-04-17 01:02:50,039 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: change Leader from null to 92a4fd30-ea6b-474a-81b8-f37828bbc4f5 at term 2 for becomeLeader, leader elected after 6991ms
scm_1       | 2021-04-17 01:02:50,044 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2021-04-17 01:02:50,046 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515
scm_1       | 2021-04-17 01:02:50,046 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | 2021-04-17 01:02:50,049 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2021-04-17 01:02:50,050 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm_1       | 2021-04-17 01:02:50,055 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1       | 2021-04-17 01:02:50,055 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1       | 2021-04-17 01:02:50,057 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 2021-04-17 01:02:50,063 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO impl.RoleInfo: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5: start 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderStateImpl
scm_1       | 2021-04-17 01:02:50,072 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm_1       | 2021-04-17 01:02:50,076 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515/current/log_inprogress_0 to /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515/current/log_0-0
scm_1       | 2021-04-17 01:02:50,083 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-LeaderElection1] INFO server.RaftServer$Division: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515: set configuration 1: [92a4fd30-ea6b-474a-81b8-f37828bbc4f5|rpc:scm:9865|admin:|client:|dataStream:|priority:0], old=null
scm_1       | 2021-04-17 01:02:50,087 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/aff45684-ddef-48b5-9a56-b03036dac515/current/log_inprogress_1
scm_1       | 2021-04-17 01:02:51,282 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn e1ee43307ac4, UUID: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61
scm_1       | 2021-04-17 01:02:51,328 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 22b4ef3d5c71, UUID: 129c26c3-a794-4177-9973-54b2e59dd63f
scm_1       | 2021-04-17 01:02:52,431 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 548415.66us
scm_1       | 2021-04-17 01:02:52,648 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 48390.979us
scm_1       | 2021-04-17 01:02:52,821 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46097
scm_1       | 2021-04-17 01:02:52,865 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:02:53,660 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:02:55,965 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:38461
scm_1       | 2021-04-17 01:02:55,978 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:02:55,994 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: ca1f21f1-a8ed-44d3-b072-978d9cf1ad7b
scm_1       | 2021-04-17 01:02:56,146 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 15953.792us
scm_1       | 2021-04-17 01:02:58,660 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:03,669 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:07,812 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:40383
scm_1       | 2021-04-17 01:03:07,848 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:03:08,237 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:44569
scm_1       | 2021-04-17 01:03:08,359 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:03:08,677 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:08,876 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:46183
scm_1       | 2021-04-17 01:03:08,950 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2021-04-17 01:03:10,025 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/129c26c3-a794-4177-9973-54b2e59dd63f
scm_1       | 2021-04-17 01:03:10,041 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2021-04-17 01:03:10,040 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 129c26c3-a794-4177-9973-54b2e59dd63f{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 552803055385, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2021-04-17 01:03:10,090 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2021-04-17 01:03:10,191 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fa3cfe8a-2730-45c8-bb06-aa2c80c06e39 to datanode:129c26c3-a794-4177-9973-54b2e59dd63f
scm_1       | 2021-04-17 01:03:10,188 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2021-04-17 01:03:10,242 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:03:10,356 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6a2218ae-2ed2-4a70-82aa-b47f176c4c61
scm_1       | 2021-04-17 01:03:10,366 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6a2218ae-2ed2-4a70-82aa-b47f176c4c61{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 553573924627, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2021-04-17 01:03:10,366 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2021-04-17 01:03:10,377 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:03:10,377 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2021-04-17 01:03:10,377 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2021-04-17 01:03:10,544 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44241
scm_1       | 2021-04-17 01:03:10,540 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fa3cfe8a-2730-45c8-bb06-aa2c80c06e39, Nodes: 129c26c3-a794-4177-9973-54b2e59dd63f{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-04-17T01:03:10.079Z].
scm_1       | 2021-04-17 01:03:10,547 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 30749.576us
scm_1       | 2021-04-17 01:03:10,565 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e359a3e6-9a86-4080-9bb7-297e31173cbf to datanode:6a2218ae-2ed2-4a70-82aa-b47f176c4c61
scm_1       | 2021-04-17 01:03:10,569 [92a4fd30-ea6b-474a-81b8-f37828bbc4f5@group-B03036DAC515-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e359a3e6-9a86-4080-9bb7-297e31173cbf, Nodes: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-04-17T01:03:10.565Z].
scm_1       | 2021-04-17 01:03:10,575 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 9297.053us
scm_1       | 2021-04-17 01:03:10,636 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:03:11,300 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37025
scm_1       | 2021-04-17 01:03:11,313 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:03:12,940 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:03:12,941 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: fa3cfe8a-2730-45c8-bb06-aa2c80c06e39, Nodes: 129c26c3-a794-4177-9973-54b2e59dd63f{ip: 172.18.0.6, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:129c26c3-a794-4177-9973-54b2e59dd63f, CreationTimestamp2021-04-17T01:03:10.079Z] moved to OPEN state
scm_1       | 2021-04-17 01:03:12,952 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 10930.562us
scm_1       | 2021-04-17 01:03:12,961 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:03:13,014 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39277
scm_1       | 2021-04-17 01:03:13,031 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:03:13,486 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:03:13,488 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: e359a3e6-9a86-4080-9bb7-297e31173cbf, Nodes: 6a2218ae-2ed2-4a70-82aa-b47f176c4c61{ip: 172.18.0.10, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6a2218ae-2ed2-4a70-82aa-b47f176c4c61, CreationTimestamp2021-04-17T01:03:10.565Z] moved to OPEN state
scm_1       | 2021-04-17 01:03:13,493 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 4843.428us
scm_1       | 2021-04-17 01:03:13,493 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:03:13,680 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:18,683 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:18,701 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:03:18,703 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:03:19,038 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:03:19,039 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:03:19,918 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39189
scm_1       | 2021-04-17 01:03:19,933 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:03:20,213 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:45237
scm_1       | 2021-04-17 01:03:20,218 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:03:23,685 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:26,476 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38967
scm_1       | 2021-04-17 01:03:26,489 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:03:26,765 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37379
scm_1       | 2021-04-17 01:03:26,780 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:03:28,685 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:32,962 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46397
scm_1       | 2021-04-17 01:03:32,975 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:03:33,172 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46455
scm_1       | 2021-04-17 01:03:33,176 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:03:33,686 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:38,686 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:39,596 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37003
scm_1       | 2021-04-17 01:03:39,615 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:03:39,834 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39427
scm_1       | 2021-04-17 01:03:39,847 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:03:43,686 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:45,697 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 21142.418us
scm_1       | 2021-04-17 01:03:46,411 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:34663
scm_1       | 2021-04-17 01:03:46,426 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:03:46,758 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46039
scm_1       | 2021-04-17 01:03:46,767 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:03:48,687 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:48,708 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:44641
scm_1       | 2021-04-17 01:03:48,717 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:03:48,717 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:03:48,718 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:03:49,053 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:38575
scm_1       | 2021-04-17 01:03:49,092 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:03:49,093 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:03:49,094 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:03:53,167 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46639
scm_1       | 2021-04-17 01:03:53,182 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:03:53,374 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46069
scm_1       | 2021-04-17 01:03:53,385 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:03:53,688 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:58,689 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:03:59,689 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42835
scm_1       | 2021-04-17 01:03:59,703 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:03:59,975 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:43537
scm_1       | 2021-04-17 01:03:59,980 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:03,689 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:06,291 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44909
scm_1       | 2021-04-17 01:04:06,304 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:06,534 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41105
scm_1       | 2021-04-17 01:04:06,541 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:08,690 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:12,787 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:43719
scm_1       | 2021-04-17 01:04:12,797 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:13,098 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44465
scm_1       | 2021-04-17 01:04:13,106 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:13,690 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:18,700 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:18,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39321
scm_1       | 2021-04-17 01:04:18,762 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:04:18,771 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:04:18,771 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:04:19,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35617
scm_1       | 2021-04-17 01:04:19,095 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:04:19,097 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:04:19,098 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:04:19,565 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36571
scm_1       | 2021-04-17 01:04:19,576 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:19,848 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42445
scm_1       | 2021-04-17 01:04:19,860 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:23,702 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:26,541 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46083
scm_1       | 2021-04-17 01:04:26,550 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:26,792 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:45519
scm_1       | 2021-04-17 01:04:26,800 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:28,702 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:33,196 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:43979
scm_1       | 2021-04-17 01:04:33,210 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:33,497 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:35399
scm_1       | 2021-04-17 01:04:33,514 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:33,706 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:38,709 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:39,732 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37701
scm_1       | 2021-04-17 01:04:39,752 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:39,996 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41371
scm_1       | 2021-04-17 01:04:40,003 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:43,710 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:45,691 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 21511.617us
scm_1       | 2021-04-17 01:04:46,411 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41911
scm_1       | 2021-04-17 01:04:46,425 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:46,688 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36867
scm_1       | 2021-04-17 01:04:46,696 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:48,703 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:43889
scm_1       | 2021-04-17 01:04:48,709 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:04:48,710 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:48,711 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:04:48,713 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:04:49,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:38685
scm_1       | 2021-04-17 01:04:49,078 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:04:49,079 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:04:49,090 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:04:52,875 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36119
scm_1       | 2021-04-17 01:04:52,886 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:53,125 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:34337
scm_1       | 2021-04-17 01:04:53,127 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:04:53,711 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:58,711 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:04:59,233 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37211
scm_1       | 2021-04-17 01:04:59,247 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:04:59,525 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42211
scm_1       | 2021-04-17 01:04:59,530 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:03,712 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:05,668 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41247
scm_1       | 2021-04-17 01:05:05,677 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:05:06,005 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33077
scm_1       | 2021-04-17 01:05:06,014 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:08,712 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:12,287 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41781
scm_1       | 2021-04-17 01:05:12,300 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:05:12,537 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33549
scm_1       | 2021-04-17 01:05:12,544 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:13,713 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:18,713 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:18,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:46395
scm_1       | 2021-04-17 01:05:18,750 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:05:18,754 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:05:18,755 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:05:19,002 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38839
scm_1       | 2021-04-17 01:05:19,026 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:05:19,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:36439
scm_1       | 2021-04-17 01:05:19,078 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:05:19,080 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:05:19,081 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:05:19,393 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41037
scm_1       | 2021-04-17 01:05:19,395 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:23,714 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:25,907 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36671
scm_1       | 2021-04-17 01:05:25,917 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:05:26,210 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37187
scm_1       | 2021-04-17 01:05:26,223 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:28,715 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:32,612 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37715
scm_1       | 2021-04-17 01:05:32,626 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:05:32,911 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37709
scm_1       | 2021-04-17 01:05:32,920 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:33,716 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:38,717 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:39,109 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36643
scm_1       | 2021-04-17 01:05:39,120 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:05:39,413 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37005
scm_1       | 2021-04-17 01:05:39,423 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:43,717 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:45,674 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@76301865, cost 4262.822us
scm_1       | 2021-04-17 01:05:45,797 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38095
scm_1       | 2021-04-17 01:05:45,810 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:05:46,019 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42099
scm_1       | 2021-04-17 01:05:46,024 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:48,717 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm_1       | 2021-04-17 01:05:48,737 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:43569
scm_1       | 2021-04-17 01:05:48,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/22b4ef3d5c71@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:05:48,758 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:05:48,759 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:05:49,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:33555
scm_1       | 2021-04-17 01:05:49,092 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e1ee43307ac4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2021-04-17 01:05:49,093 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2021-04-17 01:05:49,093 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2021-04-17 01:05:52,473 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39237
scm_1       | 2021-04-17 01:05:52,489 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2021-04-17 01:05:52,680 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39617
scm_1       | 2021-04-17 01:05:52,684 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2021-04-17 01:05:53,718 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
