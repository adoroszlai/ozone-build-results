Attaching to ozonesecure-ha_om3_1, ozonesecure-ha_s3g_1, ozonesecure-ha_kms_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_om1_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_recon_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_om2_1, ozonesecure-ha_kdc_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2021-06-28 10:18:11,843 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 1c475e88bcbd/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
datanode1_1  | STARTUP_MSG:   java = 11.0.10
datanode1_1  | ************************************************************/
datanode1_1  | 2021-06-28 10:18:11,931 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2021-06-28 10:18:14,213 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2021-06-28 10:18:14,913 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2021-06-28 10:18:16,459 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2021-06-28 10:18:16,460 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2021-06-28 10:18:17,288 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:1c475e88bcbd ip:172.25.0.102
datanode1_1  | 2021-06-28 10:18:20,461 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-06-28 10:18:21,864 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode1_1  | 2021-06-28 10:18:21,882 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2021-06-28 10:18:23,837 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2021-06-28 10:18:23,839 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2021-06-28 10:18:23,839 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2021-06-28 10:18:23,843 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2021-06-28 10:18:27,579 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2021-06-28 10:18:27,692 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:1c475e88bcbd
datanode1_1  | 2021-06-28 10:18:27,693 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2021-06-28 10:18:27,723 [main] ERROR client.DNCertificateClient: Invalid domain 1c475e88bcbd
datanode1_1  | 2021-06-28 10:18:27,724 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@1c475e88bcbd
datanode1_1  | 2021-06-28 10:18:32,523 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2021-06-28 10:18:32,589 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2506470198331.crt.
datanode1_1  | 2021-06-28 10:18:32,618 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2423078939712.crt.
datanode1_1  | 2021-06-28 10:18:32,670 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2021-06-28 10:18:32,670 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2021-06-28 10:18:34,157 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2021-06-28 10:18:34,212 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2021-06-28 10:18:34,245 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2021-06-28 10:18:34,267 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2021-06-28 10:18:34,712 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2021-06-28 10:18:34,926 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-06-28 10:18:34,943 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2021-06-28 10:18:35,010 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2021-06-28 10:18:35,213 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode1_1  | 2021-06-28 10:18:35,234 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode1_1  | 2021-06-28 10:18:35,256 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2021-06-28 10:18:35,257 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2021-06-28 10:18:42,025 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2021-06-28 10:18:42,798 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2021-06-28 10:18:43,756 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2021-06-28 10:18:43,762 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2021-06-28 10:18:43,772 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2021-06-28 10:18:43,795 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2021-06-28 10:18:43,800 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-28 10:18:43,813 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2021-06-28 10:18:43,843 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-06-28 10:18:51,145 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2021-06-28 10:18:51,162 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-06-28 10:18:51,165 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-06-28 10:18:51,256 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-06-28 10:18:54,436 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2021-06-28 10:18:54,437 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2021-06-28 10:18:54,437 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2021-06-28 10:18:54,646 [main] INFO util.log: Logging initialized @51048ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2021-06-28 10:18:55,271 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2021-06-28 10:18:55,298 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2021-06-28 10:18:55,301 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2021-06-28 10:18:55,318 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2021-06-28 10:18:55,318 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2021-06-28 10:18:55,329 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2021-06-28 10:18:55,551 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2021-06-28 10:18:55,553 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode1_1  | 2021-06-28 10:18:55,748 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2021-06-28 10:18:55,749 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2021-06-28 10:18:55,765 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2021-06-28 10:18:55,910 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-06-28 10:18:55,937 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68aa1164{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2021-06-28 10:18:55,950 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5345552f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2021-06-28 10:18:56,569 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2021-06-28 10:18:56,678 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@79aa675b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-4576500659745458606/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2021-06-28 10:18:56,769 [main] INFO server.AbstractConnector: Started ServerConnector@5b5e45bc{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2021-06-28 10:18:56,769 [main] INFO server.Server: Started @53171ms
datanode1_1  | 2021-06-28 10:18:56,783 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2021-06-28 10:18:56,783 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2021-06-28 10:18:56,800 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2021-06-28 10:18:56,891 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@578f5bbd] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2021-06-28 10:18:57,343 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2021-06-28 10:19:01,421 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2021-06-28 10:19:01,428 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2021-06-28 10:19:01,807 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode1_1  | 2021-06-28 10:19:01,909 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: start RPC server
datanode1_1  | 2021-06-28 10:19:01,920 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: GrpcService started, listening on 9856
datanode1_1  | 2021-06-28 10:19:01,922 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: GrpcService started, listening on 9857
datanode1_1  | 2021-06-28 10:19:01,929 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: GrpcService started, listening on 9858
datanode1_1  | 2021-06-28 10:19:01,941 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 is started using port 9858 for RATIS
datanode1_1  | 2021-06-28 10:19:01,946 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2021-06-28 10:19:01,946 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2021-06-28 10:19:01,962 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$322/0x0000000840576c40@43b25c8] INFO util.JvmPauseMonitor: JvmPauseMonitor-87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Started
datanode1_1  | 2021-06-28 10:19:02,020 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-06-28 10:19:02,021 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2021-06-28 10:19:03,271 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:05,027 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode1_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:244)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:429)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2021-06-28 10:18:11,596 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 0a2e2cce409d/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	... 1 more
datanode1_1  | 2021-06-28 10:19:06,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:09,366 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:12,438 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:15,515 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:18,169 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode1_1  | 2021-06-28 10:19:18,349 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Failed requestVote 264e17c6-d8b4-4795-92be-7db9d85d28e1->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-6D6802BBD247 not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-06-28 10:19:18,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:19,244 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Failed requestVote 264e17c6-d8b4-4795-92be-7db9d85d28e1->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-6D6802BBD247 not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-06-28 10:19:20,146 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Failed requestVote 89aa20a7-dff6-484e-91c9-5fa0b70dff48->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-6D6802BBD247 not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
datanode2_1  | STARTUP_MSG:   java = 11.0.10
datanode2_1  | ************************************************************/
datanode2_1  | 2021-06-28 10:18:11,726 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2021-06-28 10:18:14,046 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2021-06-28 10:18:14,759 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2021-06-28 10:18:16,107 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2021-06-28 10:18:16,118 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2021-06-28 10:18:17,208 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:0a2e2cce409d ip:172.25.0.103
datanode2_1  | 2021-06-28 10:18:21,223 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-06-28 10:18:22,708 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode2_1  | 2021-06-28 10:18:22,746 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2021-06-28 10:18:24,389 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2021-06-28 10:18:24,406 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2021-06-28 10:18:24,406 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2021-06-28 10:18:24,418 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2021-06-28 10:18:32,814 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2021-06-28 10:18:32,912 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:0a2e2cce409d
datanode2_1  | 2021-06-28 10:18:32,918 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2021-06-28 10:18:32,937 [main] ERROR client.DNCertificateClient: Invalid domain 0a2e2cce409d
datanode2_1  | 2021-06-28 10:18:32,943 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@0a2e2cce409d
datanode2_1  | 2021-06-28 10:18:37,952 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2021-06-28 10:18:38,003 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2423078939712.crt.
datanode2_1  | 2021-06-28 10:18:38,008 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2021-06-28 10:18:38,027 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2511752401050.crt.
datanode2_1  | 2021-06-28 10:18:38,030 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2021-06-28 10:18:39,324 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2021-06-28 10:18:39,385 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2021-06-28 10:18:39,412 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2021-06-28 10:18:39,465 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2021-06-28 10:18:39,715 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2021-06-28 10:18:39,936 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-06-28 10:18:39,971 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2021-06-28 10:18:39,998 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2021-06-28 10:18:40,226 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode2_1  | 2021-06-28 10:18:40,246 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode2_1  | 2021-06-28 10:18:40,254 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2021-06-28 10:18:40,254 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2021-06-28 10:18:47,426 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2021-06-28 10:18:48,266 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2021-06-28 10:18:49,044 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2021-06-28 10:18:49,069 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2021-06-28 10:18:49,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2021-06-28 10:18:49,077 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2021-06-28 10:18:49,078 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-06-28 10:18:49,087 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2021-06-28 10:18:49,131 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2021-06-28 10:18:56,534 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2021-06-28 10:18:56,536 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-06-28 10:18:56,540 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-06-28 10:19:20,564 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Failed requestVote 264e17c6-d8b4-4795-92be-7db9d85d28e1->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-4435DCC970FA not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-06-28 10:19:21,654 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:24,726 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:25,986 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Failed startLeaderElection 264e17c6-d8b4-4795-92be-7db9d85d28e1->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-4435DCC970FA not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.startLeaderElection(RaftServerProxy.java:553)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.startLeaderElection(GrpcServerProtocolService.java:185)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:398)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-06-28 10:19:27,798 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:30,870 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:31,187 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Failed startLeaderElection 264e17c6-d8b4-4795-92be-7db9d85d28e1->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-4435DCC970FA not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.startLeaderElection(RaftServerProxy.java:553)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.startLeaderElection(GrpcServerProtocolService.java:185)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:398)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-06-28 10:19:33,943 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:36,048 [Command processor thread] INFO server.RaftServer: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: addNew group-A9418C9E01B7:[87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-A9418C9E01B7:java.util.concurrent.CompletableFuture@3b26ab2[Not completed]
datanode1_1  | 2021-06-28 10:19:36,068 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: new RaftServerImpl for group-A9418C9E01B7:[87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-06-28 10:19:36,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-06-28 10:19:36,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-06-28 10:19:36,073 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-06-28 10:19:36,073 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-06-28 10:19:36,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-06-28 10:19:36,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-06-28 10:19:36,080 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-28 10:19:36,088 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7: ConfigurationManager, init=-1: [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2021-06-28 10:18:11,836 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = e668f0a27607/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.2.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
datanode3_1  | STARTUP_MSG:   java = 11.0.10
datanode3_1  | ************************************************************/
datanode3_1  | 2021-06-28 10:18:11,934 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2021-06-28 10:18:14,118 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2021-06-28 10:18:14,710 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2021-06-28 10:18:15,413 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2021-06-28 10:18:15,414 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2021-06-28 10:18:16,736 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e668f0a27607 ip:172.25.0.104
datanode3_1  | 2021-06-28 10:18:20,670 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-06-28 10:18:22,122 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode3_1  | 2021-06-28 10:18:22,134 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2021-06-28 10:18:24,131 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2021-06-28 10:18:24,134 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2021-06-28 10:18:24,138 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2021-06-28 10:18:24,149 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2021-06-28 10:18:28,375 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2021-06-28 10:18:28,448 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:e668f0a27607
datanode3_1  | 2021-06-28 10:18:28,454 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2021-06-28 10:18:28,483 [main] ERROR client.DNCertificateClient: Invalid domain e668f0a27607
datanode3_1  | 2021-06-28 10:18:28,485 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@e668f0a27607
datanode3_1  | 2021-06-28 10:18:33,834 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2021-06-28 10:18:33,917 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/2507416097209.crt.
datanode3_1  | 2021-06-28 10:18:33,946 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-2423078939712.crt.
datanode3_1  | 2021-06-28 10:18:33,968 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2021-06-28 10:18:33,977 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2021-06-28 10:18:35,353 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2021-06-28 10:18:35,392 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2021-06-28 10:18:35,424 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2021-06-28 10:18:35,436 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2021-06-28 10:18:35,756 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2021-06-28 10:18:36,043 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-06-28 10:18:36,064 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2021-06-28 10:18:36,109 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2021-06-28 10:18:36,374 [main] INFO ozoneimpl.ContainerReader: Running in upgrade mode:true
datanode3_1  | 2021-06-28 10:18:36,396 [Thread-8] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode3_1  | 2021-06-28 10:18:36,418 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2021-06-28 10:18:36,418 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2021-06-28 10:18:44,427 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2021-06-28 10:18:45,250 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2021-06-28 10:18:45,971 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2021-06-28 10:18:45,989 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2021-06-28 10:18:45,990 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2021-06-28 10:18:45,990 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2021-06-28 10:18:45,991 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-28 10:18:45,995 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2021-06-28 10:18:46,056 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-06-28 10:18:53,917 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2021-06-28 10:18:53,926 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-06-28 10:18:53,936 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-06-28 10:18:53,987 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-28 10:18:56,590 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-28 10:18:58,783 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2021-06-28 10:18:58,784 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2021-06-28 10:18:58,784 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2021-06-28 10:18:58,989 [main] INFO util.log: Logging initialized @55282ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2021-06-28 10:18:59,689 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2021-06-28 10:18:59,770 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2021-06-28 10:19:36,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-06-28 10:19:36,092 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-06-28 10:19:36,094 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/585bdc5b-ad84-49e1-9117-a9418c9e01b7 does not exist. Creating ...
datanode1_1  | 2021-06-28 10:19:36,098 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/585bdc5b-ad84-49e1-9117-a9418c9e01b7/in_use.lock acquired by nodename 7@1c475e88bcbd
datanode1_1  | 2021-06-28 10:19:36,103 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/585bdc5b-ad84-49e1-9117-a9418c9e01b7 has been successfully formatted.
datanode1_1  | 2021-06-28 10:19:36,118 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-A9418C9E01B7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-06-28 10:19:36,130 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-06-28 10:19:36,135 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-06-28 10:19:36,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-06-28 10:19:36,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-28 10:19:36,164 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7
datanode1_1  | 2021-06-28 10:19:36,187 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,198 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-06-28 10:19:36,211 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-06-28 10:19:36,220 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/585bdc5b-ad84-49e1-9117-a9418c9e01b7
datanode1_1  | 2021-06-28 10:19:36,222 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-06-28 10:19:36,223 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-06-28 10:19:36,224 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,224 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-06-28 10:19:36,224 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-06-28 10:19:36,225 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-06-28 10:19:36,225 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-06-28 10:19:36,226 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-06-28 10:19:36,233 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,235 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-06-28 10:19:36,246 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-28 10:19:36,247 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-28 10:19:36,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-06-28 10:19:36,254 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-06-28 10:19:36,254 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-06-28 10:18:56,902 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2021-06-28 10:18:56,914 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2021-06-28 10:18:56,914 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2021-06-28 10:18:57,402 [main] INFO util.log: Logging initialized @53655ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2021-06-28 10:18:58,044 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2021-06-28 10:18:58,100 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2021-06-28 10:18:59,781 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2021-06-28 10:18:59,794 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2021-06-28 10:18:59,794 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2021-06-28 10:18:59,819 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2021-06-28 10:19:00,263 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2021-06-28 10:19:00,291 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode2_1  | 2021-06-28 10:19:00,638 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2021-06-28 10:19:00,650 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2021-06-28 10:19:00,666 [main] INFO server.session: node0 Scavenging every 660000ms
datanode2_1  | 2021-06-28 10:19:00,848 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-06-28 10:19:00,899 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@25d87313{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2021-06-28 10:19:00,900 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@244c0fbe{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2021-06-28 10:19:01,635 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2021-06-28 10:19:01,810 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4830c979{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-1420227537516101483/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2021-06-28 10:19:01,867 [main] INFO server.AbstractConnector: Started ServerConnector@1eb207c3{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2021-06-28 10:19:01,872 [main] INFO server.Server: Started @58165ms
datanode2_1  | 2021-06-28 10:19:01,896 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2021-06-28 10:19:01,896 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2021-06-28 10:19:01,907 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2021-06-28 10:19:02,206 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@62d74207] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2021-06-28 10:19:02,573 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2021-06-28 10:19:04,870 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2021-06-28 10:19:04,878 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2021-06-28 10:19:05,370 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode2_1  | 2021-06-28 10:19:05,529 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start RPC server
datanode2_1  | 2021-06-28 10:19:05,561 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: GrpcService started, listening on 9856
datanode2_1  | 2021-06-28 10:19:05,566 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: GrpcService started, listening on 9857
datanode2_1  | 2021-06-28 10:19:05,569 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: GrpcService started, listening on 9858
datanode2_1  | 2021-06-28 10:19:05,586 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 89aa20a7-dff6-484e-91c9-5fa0b70dff48 is started using port 9858 for RATIS
datanode2_1  | 2021-06-28 10:19:05,586 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 89aa20a7-dff6-484e-91c9-5fa0b70dff48 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2021-06-28 10:19:05,586 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 89aa20a7-dff6-484e-91c9-5fa0b70dff48 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2021-06-28 10:19:05,586 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$323/0x0000000840576840@3d5f1ef1] INFO util.JvmPauseMonitor: JvmPauseMonitor-89aa20a7-dff6-484e-91c9-5fa0b70dff48: Started
datanode2_1  | 2021-06-28 10:19:05,609 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-06-28 10:19:05,617 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2021-06-28 10:19:08,234 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode2_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:244)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:429)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	... 1 more
datanode2_1  | 2021-06-28 10:19:08,293 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:09,313 [Command processor thread] INFO server.RaftServer: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: addNew group-18130CB94390:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-18130CB94390:java.util.concurrent.CompletableFuture@17a2b5b6[Not completed]
datanode2_1  | 2021-06-28 10:19:09,521 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: new RaftServerImpl for group-18130CB94390:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-06-28 10:19:09,534 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-06-28 10:19:09,544 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-06-28 10:19:09,544 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-06-28 10:19:09,544 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-06-28 10:19:09,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-06-28 10:19:09,558 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-06-28 10:19:09,562 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-06-28 10:19:09,591 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390: ConfigurationManager, init=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-06-28 10:19:09,598 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-28 10:19:09,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-06-28 10:19:09,652 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/682582ca-26c3-4aee-8c4e-18130cb94390 does not exist. Creating ...
datanode2_1  | 2021-06-28 10:19:09,663 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/682582ca-26c3-4aee-8c4e-18130cb94390/in_use.lock acquired by nodename 8@0a2e2cce409d
datanode2_1  | 2021-06-28 10:19:09,695 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/682582ca-26c3-4aee-8c4e-18130cb94390 has been successfully formatted.
datanode2_1  | 2021-06-28 10:19:09,719 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-18130CB94390: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-06-28 10:19:09,735 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-06-28 10:19:09,754 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-06-28 10:19:09,818 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-06-28 10:19:09,825 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-06-28 10:19:09,927 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390
datanode2_1  | 2021-06-28 10:19:10,138 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:10,245 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-06-28 10:19:10,268 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-06-28 10:19:10,327 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/682582ca-26c3-4aee-8c4e-18130cb94390
datanode2_1  | 2021-06-28 10:19:10,338 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-06-28 10:19:10,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-06-28 10:19:10,357 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:10,358 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-06-28 10:19:10,370 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-06-28 10:19:10,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-06-28 10:19:10,388 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-06-28 10:19:10,389 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-06-28 10:19:10,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:10,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-06-28 10:19:10,568 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-28 10:19:10,586 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-28 10:19:10,773 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$323/0x0000000840576840@3d5f1ef1] WARN util.JvmPauseMonitor: JvmPauseMonitor-89aa20a7-dff6-484e-91c9-5fa0b70dff48: Detected pause in JVM or host machine (eg GC): pause of approximately 126747855ns.
datanode2_1  | GC pool 'ParNew' had collection(s): count=1 time=100ms
datanode2_1  | 2021-06-28 10:19:10,791 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-06-28 10:19:10,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-06-28 10:19:10,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-06-28 10:19:36,255 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-06-28 10:19:36,256 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-06-28 10:19:36,256 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-06-28 10:19:36,274 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7
datanode1_1  | 2021-06-28 10:19:36,278 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7
datanode1_1  | 2021-06-28 10:19:36,284 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7: start as a follower, conf=-1: [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-06-28 10:19:36,285 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-06-28 10:19:36,286 [pool-23-thread-1] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: start 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-FollowerState
datanode1_1  | 2021-06-28 10:19:36,289 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A9418C9E01B7,id=87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode1_1  | 2021-06-28 10:19:36,290 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7
datanode1_1  | 2021-06-28 10:19:36,302 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=585bdc5b-ad84-49e1-9117-a9418c9e01b7
datanode1_1  | 2021-06-28 10:19:36,303 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=585bdc5b-ad84-49e1-9117-a9418c9e01b7.
datanode1_1  | 2021-06-28 10:19:36,303 [Command processor thread] INFO server.RaftServer: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: addNew group-6D6802BBD247:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-6D6802BBD247:java.util.concurrent.CompletableFuture@1697aeff[Not completed]
datanode1_1  | 2021-06-28 10:19:36,312 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: new RaftServerImpl for group-6D6802BBD247:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-06-28 10:19:36,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-06-28 10:19:36,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-06-28 10:19:36,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-06-28 10:19:36,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-06-28 10:19:36,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-06-28 10:19:36,313 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-06-28 10:19:36,313 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-28 10:19:36,313 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247: ConfigurationManager, init=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-06-28 10:19:36,313 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-06-28 10:19:36,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-06-28 10:19:36,314 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247 does not exist. Creating ...
datanode1_1  | 2021-06-28 10:19:36,315 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247/in_use.lock acquired by nodename 7@1c475e88bcbd
datanode1_1  | 2021-06-28 10:19:36,317 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247 has been successfully formatted.
datanode1_1  | 2021-06-28 10:19:36,318 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-6D6802BBD247: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-06-28 10:19:36,323 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-06-28 10:19:36,323 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-06-28 10:19:36,324 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-06-28 10:19:36,335 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-28 10:19:36,335 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247
datanode1_1  | 2021-06-28 10:19:36,336 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,337 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-06-28 10:19:36,337 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-06-28 10:19:36,337 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247
datanode1_1  | 2021-06-28 10:19:36,356 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-06-28 10:19:36,359 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-06-28 10:19:36,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-06-28 10:18:58,111 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2021-06-28 10:18:58,119 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2021-06-28 10:18:58,122 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2021-06-28 10:18:58,140 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2021-06-28 10:18:58,370 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2021-06-28 10:18:58,384 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
datanode3_1  | 2021-06-28 10:18:58,551 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2021-06-28 10:18:58,551 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2021-06-28 10:18:58,555 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2021-06-28 10:18:58,634 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-06-28 10:18:58,647 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4687fee7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2021-06-28 10:18:58,655 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3203a4ae{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2021-06-28 10:18:59,234 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2021-06-28 10:18:59,332 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@38affd02{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_2_0-SNAPSHOT_jar-_-any-4859150678815710765/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2021-06-28 10:18:59,445 [main] INFO server.AbstractConnector: Started ServerConnector@4981b83{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2021-06-28 10:18:59,445 [main] INFO server.Server: Started @55698ms
datanode3_1  | 2021-06-28 10:18:59,473 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2021-06-28 10:18:59,474 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2021-06-28 10:18:59,478 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2021-06-28 10:18:59,609 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@205233a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2021-06-28 10:19:00,159 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2021-06-28 10:19:02,322 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2021-06-28 10:19:02,336 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2021-06-28 10:19:02,725 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode3_1  | 2021-06-28 10:19:02,849 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start RPC server
datanode3_1  | 2021-06-28 10:19:02,853 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 264e17c6-d8b4-4795-92be-7db9d85d28e1: GrpcService started, listening on 9856
datanode3_1  | 2021-06-28 10:19:02,857 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 264e17c6-d8b4-4795-92be-7db9d85d28e1: GrpcService started, listening on 9857
datanode3_1  | 2021-06-28 10:19:02,860 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 264e17c6-d8b4-4795-92be-7db9d85d28e1: GrpcService started, listening on 9858
datanode3_1  | 2021-06-28 10:19:02,876 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 264e17c6-d8b4-4795-92be-7db9d85d28e1 is started using port 9858 for RATIS
datanode3_1  | 2021-06-28 10:19:02,876 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 264e17c6-d8b4-4795-92be-7db9d85d28e1 is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2021-06-28 10:19:02,876 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 264e17c6-d8b4-4795-92be-7db9d85d28e1 is started using port 9856 for RATIS_SERVER
datanode3_1  | 2021-06-28 10:19:02,893 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$323/0x0000000840576840@4385dbbc] INFO util.JvmPauseMonitor: JvmPauseMonitor-264e17c6-d8b4-4795-92be-7db9d85d28e1: Started
datanode3_1  | 2021-06-28 10:19:02,922 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-06-28 10:19:02,922 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2021-06-28 10:19:05,558 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$323/0x0000000840576840@4385dbbc] WARN util.JvmPauseMonitor: JvmPauseMonitor-264e17c6-d8b4-4795-92be-7db9d85d28e1: Detected pause in JVM or host machine (eg GC): pause of approximately 103601615ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=138ms
datanode3_1  | 2021-06-28 10:19:05,819 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode3_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:629)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:244)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:429)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: java.util.concurrent.TimeoutException
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	... 1 more
datanode3_1  | 2021-06-28 10:19:05,943 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:06,856 [Command processor thread] INFO server.RaftServer: 264e17c6-d8b4-4795-92be-7db9d85d28e1: addNew group-AD5185786B12:[264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-AD5185786B12:java.util.concurrent.CompletableFuture@be088c4[Not completed]
datanode3_1  | 2021-06-28 10:19:07,065 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1: new RaftServerImpl for group-AD5185786B12:[264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-06-28 10:19:07,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-06-28 10:19:07,074 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-06-28 10:19:07,075 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-06-28 10:19:07,075 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-06-28 10:19:07,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-06-28 10:19:07,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-06-28 10:19:07,080 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-28 10:19:07,087 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12: ConfigurationManager, init=-1: [264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-06-28 10:19:07,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-06-28 10:19:07,103 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-06-28 10:19:07,107 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6316ee16-cb24-4652-ad4f-ad5185786b12 does not exist. Creating ...
datanode1_1  | 2021-06-28 10:19:36,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-06-28 10:19:36,363 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-06-28 10:19:36,363 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-06-28 10:19:36,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-06-28 10:19:36,368 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-06-28 10:19:36,369 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-28 10:19:36,370 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-28 10:19:36,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-06-28 10:19:36,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-06-28 10:19:36,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-06-28 10:19:36,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-06-28 10:19:36,381 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-06-28 10:19:36,381 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-06-28 10:19:36,381 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247
datanode1_1  | 2021-06-28 10:19:36,382 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247
datanode1_1  | 2021-06-28 10:19:36,385 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247: start as a follower, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2021-06-28 10:19:36,385 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-06-28 10:19:36,385 [pool-23-thread-1] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: start 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247-FollowerState
datanode1_1  | 2021-06-28 10:19:36,390 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D6802BBD247,id=87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode1_1  | 2021-06-28 10:19:36,390 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247
datanode1_1  | 2021-06-28 10:19:36,395 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247
datanode1_1  | 2021-06-28 10:19:36,396 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Failed startLeaderElection 264e17c6-d8b4-4795-92be-7db9d85d28e1->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-4435DCC970FA not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.startLeaderElection(RaftServerProxy.java:553)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.startLeaderElection(GrpcServerProtocolService.java:185)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:398)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | 2021-06-28 10:19:36,435 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-9E80B2C51F5A->89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode1_1  | 2021-06-28 10:19:36,760 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-06-28 10:19:36,763 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5360E3F05742->264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode1_1  | 2021-06-28 10:19:36,911 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-06-28 10:19:36,913 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247.
datanode1_1  | 2021-06-28 10:19:36,913 [Command processor thread] INFO server.RaftServer: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: addNew group-4435DCC970FA:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-4435DCC970FA:java.util.concurrent.CompletableFuture@15dcf9fe[Not completed]
datanode1_1  | 2021-06-28 10:19:36,916 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: new RaftServerImpl for group-4435DCC970FA:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2021-06-28 10:19:36,916 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2021-06-28 10:19:36,916 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: ConfigurationManager, init=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2021-06-28 10:19:36,918 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa does not exist. Creating ...
datanode1_1  | 2021-06-28 10:19:36,920 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/in_use.lock acquired by nodename 7@1c475e88bcbd
datanode1_1  | 2021-06-28 10:19:36,922 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa has been successfully formatted.
datanode1_1  | 2021-06-28 10:19:36,923 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-4435DCC970FA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2021-06-28 10:19:36,923 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2021-06-28 10:19:36,923 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2021-06-28 10:19:36,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2021-06-28 10:19:36,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-28 10:19:36,924 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA
datanode1_1  | 2021-06-28 10:19:36,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,925 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2021-06-28 10:19:36,925 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2021-06-28 10:19:36,934 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa
datanode1_1  | 2021-06-28 10:19:36,934 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2021-06-28 10:19:36,934 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2021-06-28 10:19:36,934 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2021-06-28 10:19:36,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2021-06-28 10:19:36,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2021-06-28 10:19:36,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2021-06-28 10:19:36,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2021-06-28 10:19:36,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2021-06-28 10:19:36,938 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2021-06-28 10:19:36,938 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-28 10:19:36,938 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2021-06-28 10:19:36,951 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2021-06-28 10:19:36,952 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2021-06-28 10:19:36,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2021-06-28 10:19:36,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2021-06-28 10:19:36,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2021-06-28 10:19:36,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2021-06-28 10:19:36,955 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA
datanode1_1  | 2021-06-28 10:19:36,957 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA
datanode1_1  | 2021-06-28 10:19:36,959 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: start as a follower, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-06-28 10:19:36,960 [pool-23-thread-1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2021-06-28 10:19:36,960 [pool-23-thread-1] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: start 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-FollowerState
datanode1_1  | 2021-06-28 10:19:36,966 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4435DCC970FA,id=87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode1_1  | 2021-06-28 10:19:36,966 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA
datanode1_1  | 2021-06-28 10:19:36,967 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa
datanode2_1  | 2021-06-28 10:19:10,802 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-06-28 10:19:10,804 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-06-28 10:19:10,809 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-06-28 10:19:10,944 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390
datanode2_1  | 2021-06-28 10:19:10,996 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390
datanode2_1  | 2021-06-28 10:19:11,024 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390: start as a follower, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-06-28 10:19:11,025 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-06-28 10:19:11,057 [pool-23-thread-1] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-FollowerState
datanode2_1  | 2021-06-28 10:19:11,069 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18130CB94390,id=89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode2_1  | 2021-06-28 10:19:11,074 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390
datanode2_1  | 2021-06-28 10:19:11,198 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=682582ca-26c3-4aee-8c4e-18130cb94390
datanode2_1  | 2021-06-28 10:19:11,221 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=682582ca-26c3-4aee-8c4e-18130cb94390.
datanode2_1  | 2021-06-28 10:19:11,223 [Command processor thread] INFO server.RaftServer: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: addNew group-6D6802BBD247:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-6D6802BBD247:java.util.concurrent.CompletableFuture@499b118[Not completed]
datanode2_1  | 2021-06-28 10:19:11,240 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: new RaftServerImpl for group-6D6802BBD247:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-06-28 10:19:11,250 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-06-28 10:19:11,252 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-06-28 10:19:11,254 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-06-28 10:19:11,259 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-06-28 10:19:11,262 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-06-28 10:19:11,262 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-06-28 10:19:11,262 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-06-28 10:19:11,263 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: ConfigurationManager, init=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-06-28 10:19:11,263 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-28 10:19:11,267 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-06-28 10:19:11,269 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247 does not exist. Creating ...
datanode2_1  | 2021-06-28 10:19:11,278 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247/in_use.lock acquired by nodename 8@0a2e2cce409d
datanode2_1  | 2021-06-28 10:19:11,289 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247 has been successfully formatted.
datanode2_1  | 2021-06-28 10:19:11,290 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-6D6802BBD247: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-06-28 10:19:11,298 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-06-28 10:19:11,298 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-06-28 10:19:11,299 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-06-28 10:19:11,310 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-06-28 10:19:11,310 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247
datanode2_1  | 2021-06-28 10:19:11,311 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:11,324 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-06-28 10:19:11,332 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-06-28 10:19:11,332 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247
datanode2_1  | 2021-06-28 10:19:11,332 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-06-28 10:19:11,332 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-06-28 10:19:11,333 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:11,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-06-28 10:19:11,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-06-28 10:19:11,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-06-28 10:19:11,351 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-06-28 10:19:11,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:11,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-06-28 10:19:11,389 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:11,396 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-06-28 10:19:11,404 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-28 10:19:11,404 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-28 10:19:11,405 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-06-28 10:19:11,405 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-06-28 10:19:11,406 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-06-28 10:19:11,406 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-06-28 10:19:11,410 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-06-28 10:19:11,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-06-28 10:19:11,412 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247
datanode2_1  | 2021-06-28 10:19:11,413 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247
datanode2_1  | 2021-06-28 10:19:11,414 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: start as a follower, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-06-28 10:19:11,417 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-06-28 10:19:11,422 [pool-23-thread-1] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState
datanode2_1  | 2021-06-28 10:19:11,422 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D6802BBD247,id=89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode2_1  | 2021-06-28 10:19:11,424 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247
datanode2_1  | 2021-06-28 10:19:11,454 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247
datanode2_1  | 2021-06-28 10:19:11,679 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1237DE927600->264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode2_1  | 2021-06-28 10:19:14,437 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:14,920 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-06-28 10:19:14,954 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-7925E787CAFA->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode3_1  | 2021-06-28 10:19:07,118 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6316ee16-cb24-4652-ad4f-ad5185786b12/in_use.lock acquired by nodename 7@e668f0a27607
datanode3_1  | 2021-06-28 10:19:07,131 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6316ee16-cb24-4652-ad4f-ad5185786b12 has been successfully formatted.
datanode3_1  | 2021-06-28 10:19:07,218 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-AD5185786B12: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-06-28 10:19:07,243 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-06-28 10:19:07,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-06-28 10:19:07,434 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-06-28 10:19:07,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-28 10:19:07,508 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12
datanode3_1  | 2021-06-28 10:19:07,645 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:07,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-06-28 10:19:07,744 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-06-28 10:19:07,761 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6316ee16-cb24-4652-ad4f-ad5185786b12
datanode3_1  | 2021-06-28 10:19:07,802 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-06-28 10:19:07,802 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-06-28 10:19:07,818 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:07,818 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-06-28 10:19:07,819 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-06-28 10:19:07,828 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-06-28 10:19:07,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-06-28 10:19:07,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-06-28 10:19:07,894 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:07,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-06-28 10:19:07,967 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-28 10:19:07,977 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-28 10:19:08,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-06-28 10:19:08,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-06-28 10:19:08,090 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-06-28 10:19:08,091 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-06-28 10:19:08,094 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-06-28 10:19:08,098 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-06-28 10:19:08,209 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12
datanode1_1  | 2021-06-28 10:19:36,971 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-3916D2E05AC2->89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode1_1  | 2021-06-28 10:19:37,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:37,104 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode1_1  | 2021-06-28 10:19:37,106 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-620EB2FDB9EF->264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode1_1  | 2021-06-28 10:19:37,263 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode1_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode1_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode1_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode1_1  | 	... 18 more
datanode3_1  | 2021-06-28 10:19:08,236 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12
datanode3_1  | 2021-06-28 10:19:08,308 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12: start as a follower, conf=-1: [264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-28 10:19:08,337 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-06-28 10:19:08,343 [pool-23-thread-1] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-FollowerState
datanode3_1  | 2021-06-28 10:19:08,393 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AD5185786B12,id=264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode3_1  | 2021-06-28 10:19:08,399 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12
datanode3_1  | 2021-06-28 10:19:08,697 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=6316ee16-cb24-4652-ad4f-ad5185786b12
datanode3_1  | 2021-06-28 10:19:08,699 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=6316ee16-cb24-4652-ad4f-ad5185786b12.
datanode3_1  | 2021-06-28 10:19:08,700 [Command processor thread] INFO server.RaftServer: 264e17c6-d8b4-4795-92be-7db9d85d28e1: addNew group-6D6802BBD247:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-6D6802BBD247:java.util.concurrent.CompletableFuture@25ce9e79[Not completed]
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1: new RaftServerImpl for group-6D6802BBD247:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-28 10:19:08,783 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247: ConfigurationManager, init=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-06-28 10:19:08,784 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-06-28 10:19:08,806 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-06-28 10:19:08,806 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247 does not exist. Creating ...
datanode3_1  | 2021-06-28 10:19:08,822 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247/in_use.lock acquired by nodename 7@e668f0a27607
datanode3_1  | 2021-06-28 10:19:08,832 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247 has been successfully formatted.
datanode3_1  | 2021-06-28 10:19:08,833 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-6D6802BBD247: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-06-28 10:19:08,833 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-06-28 10:19:08,833 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-06-28 10:19:08,833 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-06-28 10:19:08,833 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-28 10:19:08,833 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247
datanode3_1  | 2021-06-28 10:19:08,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:08,885 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-06-28 10:19:08,887 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-06-28 10:19:08,887 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247
datanode3_1  | 2021-06-28 10:19:08,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-06-28 10:19:08,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2021-06-28 10:19:08,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:08,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-06-28 10:19:08,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-06-28 10:19:08,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-06-28 10:19:08,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-06-28 10:19:08,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode3_1  | 2021-06-28 10:19:08,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:08,892 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-06-28 10:19:08,892 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-28 10:19:08,893 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-28 10:19:08,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-06-28 10:19:08,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-06-28 10:19:08,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-06-28 10:19:08,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-06-28 10:19:08,919 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-06-28 10:19:08,919 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-06-28 10:19:08,919 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247
datanode3_1  | 2021-06-28 10:19:08,920 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247
datanode3_1  | 2021-06-28 10:19:08,922 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247: start as a follower, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-06-28 10:19:08,928 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-06-28 10:19:08,928 [pool-23-thread-1] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-FollowerState
datanode3_1  | 2021-06-28 10:19:08,935 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6D6802BBD247,id=264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode3_1  | 2021-06-28 10:19:08,937 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247
datanode3_1  | 2021-06-28 10:19:08,939 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247
datanode3_1  | 2021-06-28 10:19:09,022 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:09,201 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0D77847FC354->89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode3_1  | 2021-06-28 10:19:12,090 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:13,103 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-06-28 10:19:13,119 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0A396733CCFE->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
kdc_1        | Jun 28 10:16:42 kdc krb5kdc[7](info): Loaded
kdc_1        | Jun 28 10:16:42 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Jun 28 10:16:42 kdc krb5kdc[7](info): setting up network...
kdc_1        | Jun 28 10:16:42 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Jun 28 10:16:42 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Jun 28 10:16:42 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Jun 28 10:16:42 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Jun 28 10:16:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875408, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:17:12 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1624875432, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:17:18 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1624875438, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:17:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875408, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:17:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624875432, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:17:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:17:38 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1624875458, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:17:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:17:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624875458, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:17:44 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875464, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:17:48 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1624875468, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:17:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1624875468, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:17:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875464, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:17:55 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1624875475, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:17:57 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875477, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:18:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1624875475, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:18:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875477, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  | 2021-06-28 10:19:13,570 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-FollowerState] INFO impl.FollowerState: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5227933090ns, electionTimeout:5191ms
datanode3_1  | 2021-06-28 10:19:13,571 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-FollowerState] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: shutdown 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-FollowerState
datanode3_1  | 2021-06-28 10:19:13,587 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-FollowerState] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-06-28 10:19:13,590 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-06-28 10:19:13,590 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-FollowerState] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1
datanode3_1  | 2021-06-28 10:19:13,619 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2021-06-28 10:19:13,621 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2021-06-28 10:19:13,632 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: shutdown 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1
datanode3_1  | 2021-06-28 10:19:13,634 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2021-06-28 10:19:13,634 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AD5185786B12 with new leaderId: 264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode3_1  | 2021-06-28 10:19:13,655 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12: change Leader from null to 264e17c6-d8b4-4795-92be-7db9d85d28e1 at term 1 for becomeLeader, leader elected after 6391ms
datanode3_1  | 2021-06-28 10:19:13,736 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-06-28 10:19:13,824 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12
datanode3_1  | 2021-06-28 10:19:13,835 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-06-28 10:19:13,842 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-06-28 10:19:13,908 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-06-28 10:19:13,924 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-06-28 10:19:13,925 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-06-28 10:19:14,001 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-FollowerState] INFO impl.FollowerState: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5073571947ns, electionTimeout:5063ms
datanode3_1  | 2021-06-28 10:19:14,007 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-FollowerState] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: shutdown 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-FollowerState
datanode3_1  | 2021-06-28 10:19:14,007 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-FollowerState] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-06-28 10:19:14,007 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-06-28 10:19:14,008 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-FollowerState] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2
datanode3_1  | 2021-06-28 10:19:14,048 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderStateImpl
datanode3_1  | 2021-06-28 10:19:14,073 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-06-28 10:19:14,520 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-06-28 10:19:14,907 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-06-28 10:18:12,198 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-06-28 10:18:12,306 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-06-28 10:18:24,073 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-06-28 10:18:24,709 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-06-28 10:18:24,714 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-06-28 10:18:24,714 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-06-28 10:18:25,983 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om1_1        | 2021-06-28 10:18:26,082 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-06-28 10:18:26,282 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-06-28 10:18:30,016 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2021-06-28 10:18:33,696 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2021-06-28 10:18:33,696 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2021-06-28 10:18:33,729 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2021-06-28 10:18:40,711 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2021-06-28 10:18:41,129 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2021-06-28 10:18:41,142 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2021-06-28 10:18:41,165 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2021-06-28 10:18:41,166 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-06-28 10:18:41,173 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-06-28 10:18:41,174 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-06-28 10:18:41,174 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-06-28 10:18:41,193 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:00b677bc-7bb5-4c8c-9cb8-b10bc61671d0,clusterId:CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5,subject:om1
om1_1        | 2021-06-28 10:18:42,032 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2021-06-28 10:18:43,671 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5;layoutVersion=0
om1_1        | 2021-06-28 10:18:43,887 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2021-06-28 10:18:53,535 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-06-28 10:19:14,938 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247.
datanode3_1  | 2021-06-28 10:19:14,939 [Command processor thread] INFO server.RaftServer: 264e17c6-d8b4-4795-92be-7db9d85d28e1: addNew group-4435DCC970FA:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-4435DCC970FA:java.util.concurrent.CompletableFuture@142b885[Not completed]
datanode3_1  | 2021-06-28 10:19:14,941 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1: new RaftServerImpl for group-4435DCC970FA:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2021-06-28 10:19:14,966 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2021-06-28 10:19:14,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2021-06-28 10:19:14,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2021-06-28 10:19:14,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2021-06-28 10:19:14,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2021-06-28 10:19:14,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2021-06-28 10:19:14,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-28 10:19:14,968 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: ConfigurationManager, init=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2021-06-28 10:19:14,968 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2021-06-28 10:19:14,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2021-06-28 10:19:14,976 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa does not exist. Creating ...
datanode3_1  | 2021-06-28 10:19:15,012 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/in_use.lock acquired by nodename 7@e668f0a27607
datanode3_1  | 2021-06-28 10:19:15,113 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa has been successfully formatted.
datanode3_1  | 2021-06-28 10:19:15,115 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-4435DCC970FA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2021-06-28 10:19:15,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2021-06-28 10:19:15,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2021-06-28 10:19:15,124 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2021-06-28 10:19:15,124 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-28 10:19:15,126 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:15,148 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:15,148 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2021-06-28 10:19:15,148 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2021-06-28 10:19:15,149 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa
datanode3_1  | 2021-06-28 10:19:15,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2021-06-28 10:19:15,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-06-28 10:19:15,832 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-06-28 10:19:15,833 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247.
datanode2_1  | 2021-06-28 10:19:15,833 [Command processor thread] INFO server.RaftServer: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: addNew group-4435DCC970FA:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-4435DCC970FA:java.util.concurrent.CompletableFuture@2d2981e2[Not completed]
datanode2_1  | 2021-06-28 10:19:15,849 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: new RaftServerImpl for group-4435DCC970FA:[89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2021-06-28 10:19:15,858 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2021-06-28 10:19:15,858 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2021-06-28 10:19:15,858 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2021-06-28 10:19:15,858 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2021-06-28 10:19:15,858 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2021-06-28 10:19:15,859 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2021-06-28 10:19:15,859 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2021-06-28 10:19:15,859 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: ConfigurationManager, init=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2021-06-28 10:19:15,859 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2021-06-28 10:19:15,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-06-28 10:19:15,869 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa does not exist. Creating ...
datanode2_1  | 2021-06-28 10:19:15,872 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/in_use.lock acquired by nodename 8@0a2e2cce409d
datanode2_1  | 2021-06-28 10:19:15,873 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa has been successfully formatted.
datanode2_1  | 2021-06-28 10:19:15,874 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-4435DCC970FA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2021-06-28 10:19:15,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2021-06-28 10:19:15,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2021-06-28 10:19:15,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2021-06-28 10:19:15,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2021-06-28 10:19:15,875 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA
datanode2_1  | 2021-06-28 10:19:15,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:15,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2021-06-28 10:19:15,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2021-06-28 10:19:15,875 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa
datanode2_1  | 2021-06-28 10:19:15,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2021-06-28 10:19:15,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2021-06-28 10:19:15,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:15,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2021-06-28 10:19:15,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2021-06-28 10:19:15,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2021-06-28 10:19:15,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2021-06-28 10:19:15,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2021-06-28 10:19:15,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2021-06-28 10:19:15,898 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2021-06-28 10:19:15,898 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-28 10:19:15,898 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-28 10:19:15,902 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2021-06-28 10:19:15,902 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2021-06-28 10:19:15,908 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2021-06-28 10:19:15,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2021-06-28 10:19:15,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2021-06-28 10:19:15,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2021-06-28 10:19:15,910 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA
datanode2_1  | 2021-06-28 10:19:15,911 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA
datanode2_1  | 2021-06-28 10:19:15,918 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: start as a follower, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode2_1  | 2021-06-28 10:19:15,943 [pool-23-thread-1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2021-06-28 10:19:15,944 [pool-23-thread-1] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState
datanode2_1  | 2021-06-28 10:19:15,980 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4435DCC970FA,id=89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode2_1  | 2021-06-28 10:19:15,980 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA
datanode2_1  | 2021-06-28 10:19:15,996 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa
datanode2_1  | 2021-06-28 10:19:16,012 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0B0B88C579F6->264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode2_1  | 2021-06-28 10:19:16,115 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-FollowerState] INFO impl.FollowerState: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5058979978ns, electionTimeout:5047ms
datanode2_1  | 2021-06-28 10:19:16,170 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-FollowerState] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: shutdown 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-FollowerState
datanode2_1  | 2021-06-28 10:19:16,188 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-FollowerState] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-06-28 10:19:16,211 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-06-28 10:19:16,214 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-FollowerState] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1
datanode2_1  | 2021-06-28 10:19:16,305 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO impl.LeaderElection: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2021-06-28 10:19:16,314 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO impl.LeaderElection: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2021-06-28 10:19:16,320 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: shutdown 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1
datanode2_1  | 2021-06-28 10:19:16,322 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2021-06-28 10:19:16,324 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18130CB94390 with new leaderId: 89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode2_1  | 2021-06-28 10:19:16,326 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390: change Leader from null to 89aa20a7-dff6-484e-91c9-5fa0b70dff48 at term 1 for becomeLeader, leader elected after 6588ms
datanode2_1  | 2021-06-28 10:19:16,435 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2021-06-28 10:19:16,463 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390
datanode2_1  | 2021-06-28 10:19:16,500 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2021-06-28 10:19:16,504 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode2_1  | 2021-06-28 10:19:16,506 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState] INFO impl.FollowerState: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5083987325ns, electionTimeout:5079ms
datanode2_1  | 2021-06-28 10:19:16,518 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: shutdown 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState
datanode2_1  | 2021-06-28 10:19:16,518 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2021-06-28 10:19:16,518 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2021-06-28 10:19:16,526 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2
datanode2_1  | 2021-06-28 10:19:16,543 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2021-06-28 10:19:16,587 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2021-06-28 10:19:16,589 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2021-06-28 10:19:16,607 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-06-28 10:19:16,703 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderStateImpl
datanode2_1  | 2021-06-28 10:19:17,062 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-06-28 10:19:17,501 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:17,790 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-LeaderElection1] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390: set configuration 0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-06-28 10:19:18,770 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode2_1  | 2021-06-28 10:19:18,920 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: receive requestVote(ELECTION, 264e17c6-d8b4-4795-92be-7db9d85d28e1, group-6D6802BBD247, 1, (t:0, i:0))
datanode2_1  | 2021-06-28 10:19:18,930 [grpc-default-executor-0] INFO impl.VoteContext: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-CANDIDATE: reject ELECTION from 264e17c6-d8b4-4795-92be-7db9d85d28e1: already has voted for 89aa20a7-dff6-484e-91c9-5fa0b70dff48 at current term 1
datanode2_1  | 2021-06-28 10:19:18,998 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode1_1  | 2021-06-28 10:19:37,271 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa.
datanode1_1  | 2021-06-28 10:19:37,923 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6D6802BBD247 with new leaderId: 264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode1_1  | 2021-06-28 10:19:37,923 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247: change Leader from null to 264e17c6-d8b4-4795-92be-7db9d85d28e1 at term 2 for appendEntries, leader elected after 1599ms
datanode1_1  | 2021-06-28 10:19:37,927 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247: Failed appendEntries as previous log entry ((t:2, i:0)) is not found
datanode1_1  | 2021-06-28 10:19:37,936 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247: inconsistency entries. Reply:264e17c6-d8b4-4795-92be-7db9d85d28e1<-87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#9:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode1_1  | 2021-06-28 10:19:37,969 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247: set configuration 0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2021-06-28 10:19:37,976 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-06-28 10:19:38,090 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-6D6802BBD247-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247/current/log_inprogress_0
datanode1_1  | 2021-06-28 10:19:38,438 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4435DCC970FA with new leaderId: 264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode1_1  | 2021-06-28 10:19:38,438 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: change Leader from null to 264e17c6-d8b4-4795-92be-7db9d85d28e1 at term 1 for appendEntries, leader elected after 1514ms
datanode1_1  | 2021-06-28 10:19:38,439 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode1_1  | 2021-06-28 10:19:38,439 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: inconsistency entries. Reply:264e17c6-d8b4-4795-92be-7db9d85d28e1<-87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#9:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode1_1  | 2021-06-28 10:19:38,447 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: set configuration 0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-06-28 10:19:38,447 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-06-28 10:19:38,450 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_0
datanode1_1  | 2021-06-28 10:19:40,086 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:41,486 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-FollowerState] INFO impl.FollowerState: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5199976532ns, electionTimeout:5194ms
datanode1_1  | 2021-06-28 10:19:41,486 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-FollowerState] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: shutdown 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-FollowerState
datanode1_1  | 2021-06-28 10:19:41,487 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-FollowerState] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2021-06-28 10:19:41,492 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2021-06-28 10:19:41,492 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-FollowerState] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: start 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1
datanode1_1  | 2021-06-28 10:19:41,502 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO impl.LeaderElection: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2021-06-28 10:19:41,503 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO impl.LeaderElection: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2021-06-28 10:19:41,504 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: shutdown 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1
datanode1_1  | 2021-06-28 10:19:41,504 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2021-06-28 10:19:41,505 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A9418C9E01B7 with new leaderId: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode1_1  | 2021-06-28 10:19:41,506 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7: change Leader from null to 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 at term 1 for becomeLeader, leader elected after 5375ms
datanode1_1  | 2021-06-28 10:19:41,509 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-06-28 10:19:41,512 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7
kdc_1        | Jun 28 10:18:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875496, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:18:21 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1624875501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:18:21 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1624875501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:18:22 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1624875502, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:18:25 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1624875505, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:18:26 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1624875506, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:18:26 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1624875506, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:18:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1624875506, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:18:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1624875505, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:18:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1624875506, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:18:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1624875501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:18:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1624875501, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:18:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1624875502, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:18:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875496, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:18:52 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875532, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:19:03 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1624875543, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:19:05 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1624875545, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:19:07 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1624875547, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:19:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1624875543, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:19:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1624875545, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode1_1  | 2021-06-28 10:19:41,529 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-06-28 10:19:41,532 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode1_1  | 2021-06-28 10:19:41,546 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2021-06-28 10:19:41,550 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-06-28 10:19:41,551 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2021-06-28 10:19:41,563 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: start 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderStateImpl
datanode1_1  | 2021-06-28 10:19:41,570 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2021-06-28 10:19:41,574 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/585bdc5b-ad84-49e1-9117-a9418c9e01b7/current/log_inprogress_0
datanode1_1  | 2021-06-28 10:19:41,584 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7-LeaderElection1] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-A9418C9E01B7: set configuration 0: [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-06-28 10:19:41,591 [grpc-default-executor-0] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: shutdown 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-FollowerState
datanode1_1  | 2021-06-28 10:19:41,591 [grpc-default-executor-0] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode1_1  | 2021-06-28 10:19:41,591 [grpc-default-executor-0] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: start 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2
datanode1_1  | 2021-06-28 10:19:41,607 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: change Leader from 264e17c6-d8b4-4795-92be-7db9d85d28e1 to null at term 1 for ELECTION
datanode1_1  | 2021-06-28 10:19:41,591 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-FollowerState] INFO impl.FollowerState: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2021-06-28 10:19:41,625 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO impl.LeaderElection: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for 0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-06-28 10:19:42,030 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO impl.LeaderElection: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2021-06-28 10:19:42,030 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO impl.LeaderElection:   Response 0: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21<-89aa20a7-dff6-484e-91c9-5fa0b70dff48#0:OK-t2
datanode1_1  | 2021-06-28 10:19:42,031 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO impl.LeaderElection: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2 ELECTION round 0: result PASSED
datanode1_1  | 2021-06-28 10:19:42,037 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: shutdown 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2
datanode1_1  | 2021-06-28 10:19:42,037 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode1_1  | 2021-06-28 10:19:42,037 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4435DCC970FA with new leaderId: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode1_1  | 2021-06-28 10:19:42,038 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: change Leader from null to 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 at term 2 for becomeLeader, leader elected after 429ms
datanode1_1  | 2021-06-28 10:19:42,038 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2021-06-28 10:19:42,038 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode1_1  | 2021-06-28 10:19:42,039 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA
datanode1_1  | 2021-06-28 10:19:42,048 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2021-06-28 10:19:42,048 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode1_1  | 2021-06-28 10:19:42,048 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2021-06-28 10:19:42,049 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2021-06-28 10:19:42,049 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
kdc_1        | Jun 28 10:19:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1624875547, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:19:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875532, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:19:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875567, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:19:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875567, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:19:38 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875578, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:19:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875578, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:19:44 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:19:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:19:53 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:20:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:20:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:20:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:20:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:20:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:20:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:20:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:20:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om1_1        | STARTUP_MSG:   java = 11.0.10
om1_1        | ************************************************************/
om1_1        | 2021-06-28 10:18:53,586 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-06-28 10:19:03,305 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2021-06-28 10:19:04,055 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2021-06-28 10:19:04,072 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2021-06-28 10:19:04,076 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2021-06-28 10:19:04,198 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-06-28 10:19:06,608 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om1_1        | 2021-06-28 10:19:06,608 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2021-06-28 10:19:06,622 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-06-28 10:19:15,164 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2021-06-28 10:19:16,206 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2518085732743.crt.
om1_1        | 2021-06-28 10:19:16,258 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2423078939712.crt.
om1_1        | 2021-06-28 10:19:16,302 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2021-06-28 10:19:16,638 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2021-06-28 10:19:17,682 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-06-28 10:19:17,700 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2021-06-28 10:19:18,980 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om1_1        | 2021-06-28 10:19:19,011 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2021-06-28 10:19:19,022 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2021-06-28 10:19:19,838 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2021-06-28 10:19:19,877 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-06-28 10:19:19,887 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2021-06-28 10:19:19,901 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2021-06-28 10:19:20,860 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2021-06-28 10:19:21,058 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2021-06-28 10:19:21,305 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om1:9872, om2:9872, om3:9872
datanode1_1  | 2021-06-28 10:19:42,117 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2021-06-28 10:19:42,118 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-28 10:19:42,120 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2021-06-28 10:19:42,130 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2021-06-28 10:19:42,134 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-06-28 10:19:42,135 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-28 10:19:42,136 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA
datanode1_1  | 2021-06-28 10:19:42,148 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2021-06-28 10:19:42,149 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2021-06-28 10:19:42,149 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2021-06-28 10:19:42,149 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2021-06-28 10:19:42,149 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2021-06-28 10:19:42,150 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Completed APPEND_ENTRIES, lastRequest: 264e17c6-d8b4-4795-92be-7db9d85d28e1->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21#10-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
datanode1_1  | 2021-06-28 10:19:42,152 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2021-06-28 10:19:42,163 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO impl.RoleInfo: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: start 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderStateImpl
datanode1_1  | 2021-06-28 10:19:42,165 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode1_1  | 2021-06-28 10:19:42,167 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_0 to /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_0-0
datanode1_1  | 2021-06-28 10:19:42,173 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_1
datanode1_1  | 2021-06-28 10:19:42,183 [87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA-LeaderElection2] INFO server.RaftServer$Division: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21@group-4435DCC970FA: set configuration 1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2021-06-28 10:19:43,158 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:46,230 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:48,304 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode1_1  | java.net.NoRouteToHostException: No Route to Host from  1c475e88bcbd/172.25.0.102 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:787)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
datanode1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode1_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode1_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode1_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode3_1  | 2021-06-28 10:19:15,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:15,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2021-06-28 10:19:15,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2021-06-28 10:19:15,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2021-06-28 10:19:15,154 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2021-06-28 10:19:15,154 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2021-06-28 10:19:15,154 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2021-06-28 10:19:15,183 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:15,207 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2021-06-28 10:19:15,248 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-28 10:19:15,248 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2021-06-28 10:19:15,302 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2021-06-28 10:19:15,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2021-06-28 10:19:15,305 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2021-06-28 10:19:15,305 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2021-06-28 10:19:15,305 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2021-06-28 10:19:15,310 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2021-06-28 10:19:15,310 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:15,314 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:15,315 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: start as a follower, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode3_1  | 2021-06-28 10:19:15,338 [pool-23-thread-1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2021-06-28 10:19:15,338 [pool-23-thread-1] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState
datanode3_1  | 2021-06-28 10:19:15,396 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4435DCC970FA,id=264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode3_1  | 2021-06-28 10:19:15,396 [pool-23-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:15,425 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-LeaderElection1] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12: set configuration 0: [264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-06-28 10:19:15,496 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa
datanode3_1  | 2021-06-28 10:19:15,500 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BC308C381936->89aa20a7-dff6-484e-91c9-5fa0b70dff48
datanode3_1  | 2021-06-28 10:19:16,299 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-AD5185786B12-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6316ee16-cb24-4652-ad4f-ad5185786b12/current/log_inprogress_0
datanode3_1  | 2021-06-28 10:19:17,567 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-06-28 10:19:19,046 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A9E7021D72F8->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode2_1  | 2021-06-28 10:19:19,100 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-18130CB94390-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/682582ca-26c3-4aee-8c4e-18130cb94390/current/log_inprogress_0
datanode2_1  | 2021-06-28 10:19:19,116 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247 replies to ELECTION vote request: 264e17c6-d8b4-4795-92be-7db9d85d28e1<-89aa20a7-dff6-484e-91c9-5fa0b70dff48#0:FAIL-t1. Peer's state: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247:t1, leader=null, voted=89aa20a7-dff6-484e-91c9-5fa0b70dff48, raftlog=89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-06-28 10:19:19,395 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: receive requestVote(ELECTION, 264e17c6-d8b4-4795-92be-7db9d85d28e1, group-6D6802BBD247, 2, (t:0, i:0))
datanode2_1  | 2021-06-28 10:19:19,399 [grpc-default-executor-0] INFO impl.VoteContext: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-CANDIDATE: accept ELECTION from 264e17c6-d8b4-4795-92be-7db9d85d28e1: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-06-28 10:19:19,399 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: changes role from CANDIDATE to FOLLOWER at term 2 for candidate:264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode2_1  | 2021-06-28 10:19:19,399 [grpc-default-executor-0] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: shutdown 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2
datanode2_1  | 2021-06-28 10:19:19,400 [grpc-default-executor-0] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-FollowerState
datanode2_1  | 2021-06-28 10:19:19,454 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247 replies to ELECTION vote request: 264e17c6-d8b4-4795-92be-7db9d85d28e1<-89aa20a7-dff6-484e-91c9-5fa0b70dff48#0:OK-t2. Peer's state: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247:t2, leader=null, voted=264e17c6-d8b4-4795-92be-7db9d85d28e1, raftlog=89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode2_1  | 2021-06-28 10:19:19,809 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6D6802BBD247 with new leaderId: 264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode2_1  | 2021-06-28 10:19:19,813 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: change Leader from null to 264e17c6-d8b4-4795-92be-7db9d85d28e1 at term 2 for appendEntries, leader elected after 8511ms
datanode2_1  | 2021-06-28 10:19:20,133 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247: set configuration 0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2021-06-28 10:19:20,134 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-06-28 10:19:20,174 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247/current/log_inprogress_0
datanode2_1  | 2021-06-28 10:19:20,345 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2: ELECTION DISCOVERED_A_NEW_TERM (term=2) received 1 response(s) and 0 exception(s):
datanode2_1  | 2021-06-28 10:19:20,345 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection:   Response 0: 89aa20a7-dff6-484e-91c9-5fa0b70dff48<-264e17c6-d8b4-4795-92be-7db9d85d28e1#0:FAIL-t2
datanode2_1  | 2021-06-28 10:19:20,346 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-6D6802BBD247-LeaderElection2 ELECTION round 0: result DISCOVERED_A_NEW_TERM (term=2)
datanode2_1  | 2021-06-28 10:19:20,574 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:20,601 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: receive requestVote(ELECTION, 264e17c6-d8b4-4795-92be-7db9d85d28e1, group-4435DCC970FA, 1, (t:0, i:0))
datanode2_1  | 2021-06-28 10:19:20,602 [grpc-default-executor-0] INFO impl.VoteContext: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FOLLOWER: accept ELECTION from 264e17c6-d8b4-4795-92be-7db9d85d28e1: our priority 0 <= candidate's priority 0
datanode2_1  | 2021-06-28 10:19:20,602 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode2_1  | 2021-06-28 10:19:20,602 [grpc-default-executor-0] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: shutdown 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState
datanode2_1  | 2021-06-28 10:19:20,603 [grpc-default-executor-0] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState
datanode2_1  | 2021-06-28 10:19:20,603 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState] INFO impl.FollowerState: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2021-06-28 10:19:20,626 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA replies to ELECTION vote request: 264e17c6-d8b4-4795-92be-7db9d85d28e1<-89aa20a7-dff6-484e-91c9-5fa0b70dff48#0:OK-t1. Peer's state: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA:t1, leader=null, voted=264e17c6-d8b4-4795-92be-7db9d85d28e1, raftlog=89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode2_1  | 2021-06-28 10:19:20,773 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4435DCC970FA with new leaderId: 264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode2_1  | 2021-06-28 10:19:20,778 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: change Leader from null to 264e17c6-d8b4-4795-92be-7db9d85d28e1 at term 1 for appendEntries, leader elected after 4898ms
datanode2_1  | 2021-06-28 10:19:20,822 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: set configuration 0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-06-28 10:19:20,839 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2021-06-28 10:19:20,848 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_0
datanode2_1  | 2021-06-28 10:19:21,026 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode2_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode2_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode2_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode2_1  | 	... 18 more
datanode2_1  | 2021-06-28 10:19:21,045 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa.
datanode2_1  | 2021-06-28 10:19:23,639 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:26,710 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:29,783 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:32,854 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:35,926 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:39,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:42,002 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: receive requestVote(ELECTION, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21, group-4435DCC970FA, 2, (t:1, i:0))
datanode2_1  | 2021-06-28 10:19:42,003 [grpc-default-executor-0] INFO impl.VoteContext: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FOLLOWER: accept ELECTION from 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: our priority 0 <= candidate's priority 1
datanode2_1  | 2021-06-28 10:19:42,003 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: change Leader from 264e17c6-d8b4-4795-92be-7db9d85d28e1 to null at term 2 for updateCurrentTerm
datanode2_1  | 2021-06-28 10:19:42,003 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode2_1  | 2021-06-28 10:19:42,003 [grpc-default-executor-0] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: shutdown 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-06-28 10:19:17,591 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4A26407C11BE->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode3_1  | 2021-06-28 10:19:18,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:18,390 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
datanode3_1  | java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:92)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:217)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:178)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:96)
datanode3_1  | 	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:130)
datanode3_1  | 	at org.apache.ratis.client.impl.GroupManagementImpl.add(GroupManagementImpl.java:51)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:99)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:95)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$2(DatanodeStateMachine.java:525)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156)
datanode3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:413)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:180)
datanode3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:215)
datanode3_1  | 	... 18 more
datanode3_1  | 2021-06-28 10:19:18,391 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa.
datanode3_1  | 2021-06-28 10:19:18,516 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-6D6802BBD247 not found.
datanode3_1  | 2021-06-28 10:19:19,206 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2: ELECTION TIMEOUT received 0 response(s) and 1 exception(s):
datanode3_1  | 2021-06-28 10:19:19,206 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection:   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-6D6802BBD247 not found.
datanode3_1  | 2021-06-28 10:19:19,207 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2 ELECTION round 0: result TIMEOUT
datanode3_1  | 2021-06-28 10:19:19,209 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2 ELECTION round 1: submit vote requests at term 2 for -1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode3_1  | 2021-06-28 10:19:19,274 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-6D6802BBD247 not found.
datanode3_1  | 2021-06-28 10:19:19,505 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2: ELECTION PASSED received 1 response(s) and 1 exception(s):
kdc_1        | Jun 28 10:21:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:21:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875593, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875723, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:22:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875723, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875723, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875731, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:22:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875731, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875731, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875731, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875731, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:32 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:22:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875752, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875765, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:22:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875765, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875765, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:22:54 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875774, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:22:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875774, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875774, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875783, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:23:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875783, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875787, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:23:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875787, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:23:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 2021-06-28 10:19:19,506 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection:   Response 0: 264e17c6-d8b4-4795-92be-7db9d85d28e1<-89aa20a7-dff6-484e-91c9-5fa0b70dff48#0:OK-t2
datanode3_1  | 2021-06-28 10:19:19,506 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-6D6802BBD247 not found.
datanode3_1  | 2021-06-28 10:19:19,507 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2 ELECTION round 1: result PASSED
datanode3_1  | 2021-06-28 10:19:19,507 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: shutdown 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2
datanode3_1  | 2021-06-28 10:19:19,507 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode3_1  | 2021-06-28 10:19:19,507 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6D6802BBD247 with new leaderId: 264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode3_1  | 2021-06-28 10:19:19,508 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247: change Leader from null to 264e17c6-d8b4-4795-92be-7db9d85d28e1 at term 2 for becomeLeader, leader elected after 10674ms
datanode3_1  | 2021-06-28 10:19:19,508 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-06-28 10:19:19,508 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247
datanode3_1  | 2021-06-28 10:19:19,509 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-06-28 10:19:19,509 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-06-28 10:19:19,509 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode3_1  | 2021-06-28 10:19:19,510 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-06-28 10:19:19,510 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-06-28 10:19:19,510 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-06-28 10:19:19,522 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-06-28 10:19:19,538 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-28 10:19:19,538 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-06-28 10:19:19,544 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-06-28 10:19:19,554 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-06-28 10:19:19,554 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-28 10:19:19,555 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247
datanode3_1  | 2021-06-28 10:19:19,574 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-06-28 10:19:19,574 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-28 10:19:19,574 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-06-28 10:19:19,578 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-06-28 10:19:19,578 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-06-28 10:19:19,578 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-28 10:19:19,580 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderStateImpl
datanode3_1  | 2021-06-28 10:19:19,582 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-06-28 10:19:19,588 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cb80ed17-10cc-4c00-b001-6d6802bbd247/current/log_inprogress_0
datanode3_1  | 2021-06-28 10:19:19,623 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LeaderElection2] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247: set configuration 0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2021-06-28 10:19:20,134 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode3_1  | 2021-06-28 10:19:20,189 [grpc-default-executor-0] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247: receive requestVote(ELECTION, 89aa20a7-dff6-484e-91c9-5fa0b70dff48, group-6D6802BBD247, 1, (t:0, i:0))
kdc_1        | Jun 28 10:23:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875792, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:36 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875816, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:23:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875816, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875816, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875816, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875816, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:52 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875832, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:23:52 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875832, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:23:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875832, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:23:56 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875836, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:23:57 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875837, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:24:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875837, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875841, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode1_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode1_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:699)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:812)
datanode1_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)
datanode1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
datanode1_1  | 	... 12 more
datanode1_1  | 2021-06-28 10:19:52,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:55,446 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:19:58,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:01,591 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:04,662 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:07,734 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:10,806 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:10,924 [ChunkWriter-7-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2516449581439.
datanode1_1  | 2021-06-28 10:20:13,880 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:16,954 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:20,022 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:23,094 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:26,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:29,238 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:32,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:35,387 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:41,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:44,599 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:47,670 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:50,742 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:53,814 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:56,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:20:59,958 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:03,030 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:06,102 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:42,003 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState] INFO impl.FollowerState: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2021-06-28 10:19:42,004 [grpc-default-executor-0] INFO impl.RoleInfo: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: start 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-FollowerState
datanode2_1  | 2021-06-28 10:19:42,009 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA replies to ELECTION vote request: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21<-89aa20a7-dff6-484e-91c9-5fa0b70dff48#0:OK-t2. Peer's state: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA:t2, leader=null, voted=87b0b3c6-67c6-498c-a3d3-879b3c6d2c21, raftlog=89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-06-28 10:19:42,070 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:42,138 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 89aa20a7-dff6-484e-91c9-5fa0b70dff48: Completed APPEND_ENTRIES, lastRequest: 264e17c6-d8b4-4795-92be-7db9d85d28e1->89aa20a7-dff6-484e-91c9-5fa0b70dff48#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
datanode2_1  | 2021-06-28 10:19:42,213 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4435DCC970FA with new leaderId: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode2_1  | 2021-06-28 10:19:42,213 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: change Leader from null to 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 at term 2 for appendEntries, leader elected after 209ms
datanode2_1  | 2021-06-28 10:19:42,252 [grpc-default-executor-0] INFO server.RaftServer$Division: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA: set configuration 1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode2_1  | 2021-06-28 10:19:42,253 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode2_1  | 2021-06-28 10:19:42,256 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_0 to /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_0-0
datanode2_1  | 2021-06-28 10:19:42,263 [89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 89aa20a7-dff6-484e-91c9-5fa0b70dff48@group-4435DCC970FA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_1
datanode2_1  | 2021-06-28 10:19:45,142 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:48,214 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
kdc_1        | Jun 28 10:24:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875841, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:24:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875841, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875841, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875849, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:24:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875849, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875849, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875849, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875849, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:25 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875865, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:24:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875865, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875865, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875865, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875885, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:24:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875885, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875885, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:24:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875885, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:25:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875916, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:25:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875916, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 2021-06-28 10:19:20,192 [grpc-default-executor-0] INFO impl.VoteContext: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-LEADER: reject ELECTION from 89aa20a7-dff6-484e-91c9-5fa0b70dff48: current term 2 > candidate's term 1
datanode3_1  | 2021-06-28 10:19:20,237 [grpc-default-executor-0] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247 replies to ELECTION vote request: 89aa20a7-dff6-484e-91c9-5fa0b70dff48<-264e17c6-d8b4-4795-92be-7db9d85d28e1#0:FAIL-t2. Peer's state: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247:t2, leader=264e17c6-d8b4-4795-92be-7db9d85d28e1, voted=264e17c6-d8b4-4795-92be-7db9d85d28e1, raftlog=264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2021-06-28 10:19:20,520 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState] INFO impl.FollowerState: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5181790863ns, electionTimeout:5121ms
datanode3_1  | 2021-06-28 10:19:20,521 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: shutdown 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState
datanode3_1  | 2021-06-28 10:19:20,521 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2021-06-28 10:19:20,522 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2021-06-28 10:19:20,522 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3
datanode3_1  | 2021-06-28 10:19:20,548 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode3_1  | 2021-06-28 10:19:20,621 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-4435DCC970FA not found.
datanode3_1  | 2021-06-28 10:19:20,633 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3: ELECTION PASSED received 1 response(s) and 1 exception(s):
datanode3_1  | 2021-06-28 10:19:20,633 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO impl.LeaderElection:   Response 0: 264e17c6-d8b4-4795-92be-7db9d85d28e1<-89aa20a7-dff6-484e-91c9-5fa0b70dff48#0:OK-t1
datanode3_1  | 2021-06-28 10:19:20,633 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: group-4435DCC970FA not found.
datanode3_1  | 2021-06-28 10:19:20,634 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO impl.LeaderElection: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3 ELECTION round 0: result PASSED
datanode3_1  | 2021-06-28 10:19:20,638 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: shutdown 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3
datanode3_1  | 2021-06-28 10:19:20,640 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2021-06-28 10:19:20,644 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4435DCC970FA with new leaderId: 264e17c6-d8b4-4795-92be-7db9d85d28e1
datanode3_1  | 2021-06-28 10:19:20,645 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: change Leader from null to 264e17c6-d8b4-4795-92be-7db9d85d28e1 at term 1 for becomeLeader, leader elected after 5520ms
datanode3_1  | 2021-06-28 10:19:20,645 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2021-06-28 10:19:20,645 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:20,645 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2021-06-28 10:19:20,646 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode3_1  | 2021-06-28 10:19:20,646 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2021-06-28 10:19:20,661 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2021-06-28 10:19:20,661 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2021-06-28 10:19:20,661 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-06-28 10:19:20,661 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-28 10:19:20,662 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-06-28 10:19:20,662 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-06-28 10:19:20,662 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-06-28 10:19:20,670 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-28 10:19:20,671 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:20,672 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2021-06-28 10:19:20,681 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2021-06-28 10:19:20,681 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2021-06-28 10:19:20,682 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2021-06-28 10:19:20,686 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2021-06-28 10:19:20,686 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2021-06-28 10:19:20,686 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl
datanode3_1  | 2021-06-28 10:19:20,690 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2021-06-28 10:19:20,706 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_0
datanode3_1  | 2021-06-28 10:19:20,774 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderElection3] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: set configuration 0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-06-28 10:19:21,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:24,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:25,976 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl send StartLeaderElectionRequest to follower:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
datanode3_1  | 2021-06-28 10:19:27,454 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:30,522 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:31,180 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl send StartLeaderElectionRequest to follower:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
datanode3_1  | 2021-06-28 10:19:33,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:36,382 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl send StartLeaderElectionRequest to follower:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
datanode3_1  | 2021-06-28 10:19:36,662 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:37,956 [grpc-default-executor-0] INFO leader.FollowerInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2021-06-28 10:19:38,441 [grpc-default-executor-0] INFO leader.FollowerInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2021-06-28 10:19:39,734 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:41,584 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl send StartLeaderElectionRequest to follower:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 on term:1 because follower's priority:1 is higher than leader's:0 and follower's lastEntry index:0 catch up with leader's:0
datanode3_1  | 2021-06-28 10:19:41,609 [Thread-57] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl received success reply of StartLeaderElectionRequest from follower:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode3_1  | 2021-06-28 10:19:42,119 [grpc-default-executor-0] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: receive requestVote(ELECTION, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21, group-4435DCC970FA, 2, (t:1, i:0))
datanode3_1  | 2021-06-28 10:19:42,120 [grpc-default-executor-0] INFO impl.VoteContext: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LEADER: accept ELECTION from 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: our priority 0 <= candidate's priority 1
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-06-28 10:18:13,480 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-06-28 10:18:13,532 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-06-28 10:18:24,380 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-06-28 10:18:25,031 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-06-28 10:18:25,039 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-06-28 10:18:25,042 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-06-28 10:18:26,983 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om2_1        | 2021-06-28 10:18:26,984 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-06-28 10:18:27,121 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-06-28 10:18:31,037 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2021-06-28 10:18:34,295 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2021-06-28 10:18:34,295 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2021-06-28 10:18:34,297 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2021-06-28 10:18:40,742 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2021-06-28 10:18:41,112 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2021-06-28 10:18:41,126 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2021-06-28 10:18:41,135 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2021-06-28 10:18:41,158 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-06-28 10:18:41,170 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-06-28 10:18:41,170 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-06-28 10:18:41,171 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-06-28 10:18:41,184 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:00b677bc-7bb5-4c8c-9cb8-b10bc61671d0,clusterId:CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5,subject:om2
om2_1        | 2021-06-28 10:18:42,443 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2021-06-28 10:18:44,361 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5;layoutVersion=0
om2_1        | 2021-06-28 10:18:44,558 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2021-06-28 10:18:54,195 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om2_1        | STARTUP_MSG:   java = 11.0.10
om2_1        | ************************************************************/
om2_1        | 2021-06-28 10:18:54,291 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2021-06-28 10:19:04,583 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2021-06-28 10:19:05,473 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2021-06-28 10:19:05,478 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2021-06-28 10:19:05,478 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2021-06-28 10:19:05,637 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-06-28 10:19:07,686 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om2_1        | 2021-06-28 10:19:07,690 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2021-06-28 10:19:07,690 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-06-28 10:19:15,820 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2021-06-28 10:19:16,695 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2423078939712.crt.
om2_1        | 2021-06-28 10:19:16,718 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2021-06-28 10:19:16,743 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2518732241503.crt.
om2_1        | 2021-06-28 10:19:17,030 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2021-06-28 10:19:17,962 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-06-28 10:19:17,972 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2021-06-28 10:19:19,173 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om2_1        | 2021-06-28 10:19:19,228 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2021-06-28 10:19:19,230 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2021-06-28 10:19:20,036 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om2_1        | 2021-06-28 10:19:20,103 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-06-28 10:19:20,103 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
datanode1_1  | 2021-06-28 10:21:09,174 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:12,246 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:15,318 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:18,394 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:21,462 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:24,534 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:30,679 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:33,751 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:36,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:39,897 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:42,968 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:46,038 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:49,110 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:52,183 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:55,254 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:21:58,326 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:01,398 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:04,470 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:07,542 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:10,614 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:13,686 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:19,830 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:22,902 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:25,974 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:29,046 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:32,119 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:35,190 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:38,262 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-28 10:19:20,123 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2021-06-28 10:19:21,263 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2021-06-28 10:19:21,427 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2021-06-28 10:19:21,666 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om2:9872, om1:9872, om3:9872
datanode2_1  | 2021-06-28 10:19:51,286 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:19:53,359 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode2_1  | java.net.NoRouteToHostException: No Route to Host from  0a2e2cce409d/172.25.0.103 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:787)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
datanode2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode2_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode2_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode2_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode2_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode2_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:699)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:812)
datanode2_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)
datanode2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
datanode2_1  | 	... 12 more
datanode2_1  | 2021-06-28 10:19:57,440 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:00,502 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:03,576 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:06,647 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:09,718 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:10,895 [ChunkWriter-6-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2516449581439.
datanode2_1  | 2021-06-28 10:20:12,790 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:15,862 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:18,934 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:22,006 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:25,078 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:28,151 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:31,222 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
kdc_1        | Jun 28 10:25:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875924, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:25:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875924, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:25:39 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875939, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:25:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875939, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:26:10 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875970, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:26:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875970, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:26:18 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875978, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:26:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875978, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:26:26 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875986, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:26:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875986, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:26:33 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624875993, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:26:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624875993, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:26:40 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876000, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:26:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876000, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:28:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876083, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:28:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876083, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:28:19 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876099, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode3_1  | 2021-06-28 10:19:42,120 [grpc-default-executor-0] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: change Leader from 264e17c6-d8b4-4795-92be-7db9d85d28e1 to null at term 2 for updateCurrentTerm
datanode3_1  | 2021-06-28 10:19:42,121 [grpc-default-executor-0] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: changes role from    LEADER to FOLLOWER at term 2 for candidate:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode3_1  | 2021-06-28 10:19:42,121 [grpc-default-executor-0] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: shutdown 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-LeaderStateImpl
datanode3_1  | 2021-06-28 10:19:42,121 [grpc-default-executor-0] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis_grpc.log_appender.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:42,127 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->89aa20a7-dff6-484e-91c9-5fa0b70dff48-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->89aa20a7-dff6-484e-91c9-5fa0b70dff48-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode3_1  | 2021-06-28 10:19:42,136 [grpc-default-executor-0] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis_grpc.log_appender.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:42,136 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode3_1  | 2021-06-28 10:19:42,139 [grpc-default-executor-0] INFO impl.PendingRequests: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-PendingRequests: sendNotLeaderResponses
datanode3_1  | 2021-06-28 10:19:42,145 [grpc-default-executor-0] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:42,145 [grpc-default-executor-0] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA
datanode3_1  | 2021-06-28 10:19:42,145 [grpc-default-executor-0] INFO impl.RoleInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1: start 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-FollowerState
datanode3_1  | 2021-06-28 10:19:42,152 [grpc-default-executor-1] INFO server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->89aa20a7-dff6-484e-91c9-5fa0b70dff48-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode3_1  | 2021-06-28 10:19:42,177 [grpc-default-executor-2] INFO server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode3_1  | 2021-06-28 10:19:42,177 [grpc-default-executor-2] INFO leader.FollowerInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2021-06-28 10:19:42,155 [grpc-default-executor-1] INFO leader.FollowerInfo: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA->89aa20a7-dff6-484e-91c9-5fa0b70dff48: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2021-06-28 10:19:42,183 [grpc-default-executor-0] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA replies to ELECTION vote request: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21<-264e17c6-d8b4-4795-92be-7db9d85d28e1#0:OK-t2. Peer's state: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA:t2, leader=null, voted=87b0b3c6-67c6-498c-a3d3-879b3c6d2c21, raftlog=264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-06-28 10:19:42,257 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4435DCC970FA with new leaderId: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
datanode3_1  | 2021-06-28 10:19:42,261 [grpc-default-executor-0] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: change Leader from null to 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21 at term 2 for appendEntries, leader elected after 136ms
datanode3_1  | 2021-06-28 10:19:42,280 [grpc-default-executor-0] INFO server.RaftServer$Division: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA: set configuration 1: [89aa20a7-dff6-484e-91c9-5fa0b70dff48|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 264e17c6-d8b4-4795-92be-7db9d85d28e1|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode3_1  | 2021-06-28 10:19:42,280 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode3_1  | 2021-06-28 10:19:42,287 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_0 to /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_0-0
datanode3_1  | 2021-06-28 10:19:42,298 [264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-4435DCC970FA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/181b9da4-4150-4912-9b2a-4435dcc970fa/current/log_inprogress_1
datanode3_1  | 2021-06-28 10:19:42,806 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:45,878 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:48,950 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:51,023 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode3_1  | java.net.NoRouteToHostException: No Route to Host from  e668f0a27607/172.25.0.104 to recon:9891 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
datanode3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om1_1        | 2021-06-28 10:19:21,372 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2021-06-28 10:19:22,559 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2021-06-28 10:19:22,862 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2021-06-28 10:19:22,862 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-06-28 10:19:22,865 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2021-06-28 10:19:22,865 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-06-28 10:19:22,865 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2021-06-28 10:19:22,870 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2021-06-28 10:19:22,890 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-06-28 10:19:22,891 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2021-06-28 10:19:22,893 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2021-06-28 10:19:25,233 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2021-06-28 10:19:25,245 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-06-28 10:19:25,245 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-06-28 10:19:25,305 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-06-28 10:19:25,371 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@b3c7c75[Not completed]
om1_1        | 2021-06-28 10:19:25,373 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2021-06-28 10:19:25,480 [pool-22-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2021-06-28 10:19:25,483 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2021-06-28 10:19:25,489 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2021-06-28 10:19:25,489 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2021-06-28 10:19:25,494 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2021-06-28 10:19:25,494 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2021-06-28 10:19:25,495 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2021-06-28 10:19:25,496 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2021-06-28 10:19:25,517 [pool-22-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2021-06-28 10:19:25,539 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2021-06-28 10:19:25,568 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2021-06-28 10:19:25,578 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2021-06-28 10:19:25,582 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-06-28 10:19:25,626 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om1
om1_1        | 2021-06-28 10:19:25,685 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2021-06-28 10:19:25,760 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2021-06-28 10:19:25,769 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2021-06-28 10:19:25,777 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2021-06-28 10:19:25,828 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2021-06-28 10:19:25,845 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2021-06-28 10:19:25,897 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om1@group-562213E44849
om1_1        | 2021-06-28 10:19:26,000 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-06-28 10:19:26,297 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2021-06-28 10:19:26,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2021-06-28 10:19:26,368 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2021-06-28 10:19:26,372 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-06-28 10:19:26,377 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2021-06-28 10:19:26,383 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2021-06-28 10:19:26,394 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2021-06-28 10:19:26,394 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2021-06-28 10:19:26,413 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2021-06-28 10:19:26,414 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2021-06-28 10:19:26,443 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2021-06-28 10:19:26,585 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2021-06-28 10:19:26,612 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2021-06-28 10:19:26,708 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2021-06-28 10:19:26,709 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2021-06-28 10:19:26,763 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2021-06-28 10:19:26,768 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2021-06-28 10:19:26,786 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2021-06-28 10:19:26,794 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2021-06-28 10:19:26,795 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2021-06-28 10:19:26,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2021-06-28 10:19:27,163 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om1@group-562213E44849
om1_1        | 2021-06-28 10:19:27,202 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om1@group-562213E44849
om1_1        | 2021-06-28 10:19:27,242 [Listener at om1/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om1_1        | 2021-06-28 10:19:27,666 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2021-06-28 10:19:27,742 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2021-06-28 10:19:27,742 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2021-06-28 10:19:27,913 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2021-06-28 10:19:27,919 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2021-06-28 10:19:27,921 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-28 10:19:27,940 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2021-06-28 10:19:27,945 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-06-28 10:19:27,955 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
datanode2_1  | 2021-06-28 10:20:34,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:37,366 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:40,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-28 10:19:27,962 [Listener at om1/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om1@group-562213E44849
om1_1        | 2021-06-28 10:19:27,980 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2021-06-28 10:19:28,151 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2021-06-28 10:19:28,201 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$387/0x000000084058f040@3808bdfc] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2021-06-28 10:19:28,202 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2021-06-28 10:19:28,203 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-06-28 10:19:28,204 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2021-06-28 10:19:28,206 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2021-06-28 10:19:28,243 [Thread[Thread-15,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2021-06-28 10:19:28,349 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2021-06-28 10:19:28,350 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2021-06-28 10:19:28,350 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2021-06-28 10:19:28,468 [Listener at om1/9862] INFO util.log: Logging initialized @43409ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2021-06-28 10:19:29,040 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2021-06-28 10:19:29,066 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2021-06-28 10:19:29,071 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2021-06-28 10:19:29,073 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2021-06-28 10:19:29,074 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2021-06-28 10:19:29,080 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2021-06-28 10:19:29,150 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2021-06-28 10:19:29,152 [Listener at om1/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om1_1        | 2021-06-28 10:19:29,321 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2021-06-28 10:19:29,337 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2021-06-28 10:19:29,339 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2021-06-28 10:19:29,541 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-06-28 10:19:29,557 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ab6a093{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2021-06-28 10:19:29,558 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5e774546{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2021-06-28 10:19:29,863 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2021-06-28 10:19:29,899 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3ffa3cdb{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-16077522472813340213/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2021-06-28 10:19:29,938 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@21cb907d{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2021-06-28 10:19:29,938 [Listener at om1/9862] INFO server.Server: Started @44879ms
datanode1_1  | 2021-06-28 10:22:41,334 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:44,407 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:47,478 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:50,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:53,622 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:56,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:22:59,770 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:02,838 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:08,982 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:12,054 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:15,126 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:18,198 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:21,270 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:24,342 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:27,414 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:30,486 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:33,558 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:36,630 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:39,702 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:42,774 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:45,846 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:48,918 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:51,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:23:58,134 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:01,206 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:04,278 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:07,350 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
kdc_1        | Jun 28 10:28:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876099, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:28:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876122, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:28:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876122, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:28:52 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876132, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:28:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876132, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:29:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876149, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:29:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876149, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:29:15 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876155, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:29:15 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876155, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Jun 28 10:29:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:29:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:29:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:29:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:29:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:29:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:29:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:29:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om1_1        | 2021-06-28 10:19:29,941 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-06-28 10:19:29,941 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-06-28 10:19:29,944 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2021-06-28 10:19:29,945 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2021-06-28 10:19:29,955 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2021-06-28 10:19:30,042 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2021-06-28 10:19:30,058 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@532860c7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2021-06-28 10:19:33,103 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5157593189ns, electionTimeout:5141ms
om1_1        | 2021-06-28 10:19:33,110 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2021-06-28 10:19:33,132 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2021-06-28 10:19:33,149 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2021-06-28 10:19:33,154 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2021-06-28 10:19:33,196 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-28 10:19:34,595 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om1
om1_1        | 2021-06-28 10:19:34,643 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2021-06-28 10:19:34,666 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2021-06-28 10:19:34,706 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-28 10:19:35,526 [grpc-default-executor-2] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2021-06-28 10:19:35,526 [grpc-default-executor-2] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2021-06-28 10:19:35,528 [grpc-default-executor-2] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-28 10:19:35,674 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2021-06-28 10:19:35,675 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2021-06-28 10:19:35,675 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2021-06-28 10:19:35,675 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2021-06-28 10:19:35,677 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2021-06-28 10:19:35,677 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2021-06-28 10:19:35,678 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-06-28 10:19:40,050 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 2, (t:0, i:~))
om1_1        | 2021-06-28 10:19:40,052 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: accept ELECTION from om3: our priority 0 <= candidate's priority 0
om1_1        | 2021-06-28 10:19:40,052 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om3
om1_1        | 2021-06-28 10:19:40,052 [grpc-default-executor-0] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2021-06-28 10:19:40,052 [grpc-default-executor-0] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2021-06-28 10:19:40,058 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted: {}
om1_1        | java.lang.InterruptedException: sleep interrupted
om1_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om1_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om1_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om1_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om1_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om1_1        | 2021-06-28 10:19:40,075 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:OK-t2. Peer's state: om1@group-562213E44849:t2, leader=null, voted=om3, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2021-06-28 10:19:40,416 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om3 at term 2 for appendEntries, leader elected after 14649ms
om1_1        | 2021-06-28 10:19:40,527 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2021-06-28 10:19:40,554 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2021-06-28 10:19:40,754 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2021-06-28 10:19:48,213 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34212
datanode1_1  | 2021-06-28 10:24:10,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:13,494 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:16,566 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:19,638 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:22,710 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:25,782 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:28,854 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:31,926 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:34,998 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:38,070 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:41,142 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:47,290 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:50,358 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:53,430 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:56,502 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:24:59,578 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:02,646 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:05,718 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:08,794 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:11,862 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:14,934 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:18,006 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:21,078 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:24,150 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:27,222 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:30,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:36,438 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:39,510 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:787)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
datanode3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode3_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode3_1  | Caused by: java.net.NoRouteToHostException: No route to host
datanode3_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
datanode3_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
datanode3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
datanode3_1  | 	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:699)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:812)
datanode3_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:413)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1636)
datanode3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
datanode3_1  | 	... 12 more
datanode3_1  | 2021-06-28 10:19:55,094 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:19:58,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:01,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:04,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:07,383 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:09,803 [ChunkWriter-8-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:2516449581439.
datanode3_1  | 2021-06-28 10:20:10,454 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:13,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:16,598 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:19,670 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:22,742 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:25,814 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:28,891 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:31,958 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:35,030 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:37,957 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:2, i:0)
datanode3_1  | 2021-06-28 10:20:38,106 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:44,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-28 10:19:21,752 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2021-06-28 10:19:22,771 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2021-06-28 10:19:23,145 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2021-06-28 10:19:23,152 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-06-28 10:19:23,153 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2021-06-28 10:19:23,153 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-06-28 10:19:23,153 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2021-06-28 10:19:23,154 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2021-06-28 10:19:23,163 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-06-28 10:19:23,165 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2021-06-28 10:19:23,173 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2021-06-28 10:19:25,609 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2021-06-28 10:19:25,611 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-06-28 10:19:25,612 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-06-28 10:19:25,658 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-06-28 10:19:25,684 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@b3c7c75[Not completed]
om2_1        | 2021-06-28 10:19:25,684 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2021-06-28 10:19:25,750 [pool-22-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2021-06-28 10:19:25,783 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2021-06-28 10:19:25,786 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2021-06-28 10:19:25,792 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2021-06-28 10:19:25,792 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2021-06-28 10:19:25,794 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2021-06-28 10:19:25,794 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2021-06-28 10:19:25,795 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-06-28 10:19:25,822 [pool-22-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2021-06-28 10:19:25,823 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2021-06-28 10:19:25,849 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2021-06-28 10:19:25,858 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2021-06-28 10:19:25,916 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2021-06-28 10:19:25,961 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2021-06-28 10:19:26,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2021-06-28 10:19:26,216 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2021-06-28 10:19:26,225 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2021-06-28 10:19:26,232 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2021-06-28 10:19:26,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2021-06-28 10:19:26,317 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-06-28 10:19:26,359 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om2@group-562213E44849
om2_1        | 2021-06-28 10:19:26,502 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-06-28 10:19:26,602 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2021-06-28 10:19:26,610 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2021-06-28 10:19:26,655 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2021-06-28 10:19:26,670 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2021-06-28 10:19:26,674 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2021-06-28 10:19:26,675 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2021-06-28 10:19:26,681 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2021-06-28 10:19:26,687 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2021-06-28 10:19:26,726 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2021-06-28 10:19:26,731 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2021-06-28 10:19:26,739 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2021-06-28 10:19:27,013 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2021-06-28 10:19:27,025 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2021-06-28 10:19:27,069 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1        | Jun 28 10:29:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876213, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:30:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876213, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876216, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:30:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876216, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:20 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876220, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:30:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876220, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876220, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876220, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876220, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:36 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:30:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:30:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:10 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:31:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1624876270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:31:59 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:32:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 10:32:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:46 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624876366, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:32:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876366, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:49 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624876369, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:32:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876369, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:53 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624876373, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:32:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876373, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:32:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876373, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876373, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876373, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:33:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876389, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-06-28 10:18:12,577 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-06-28 10:18:12,719 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-06-28 10:18:24,582 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-06-28 10:18:25,486 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-06-28 10:18:25,486 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-06-28 10:18:25,486 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-06-28 10:18:26,778 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om3_1        | 2021-06-28 10:18:26,779 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-06-28 10:18:26,829 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-06-28 10:18:29,822 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2021-06-28 10:18:33,326 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2021-06-28 10:18:33,338 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2021-06-28 10:18:33,339 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2021-06-28 10:18:38,685 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2021-06-28 10:18:39,086 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2021-06-28 10:18:39,090 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2021-06-28 10:18:39,095 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2021-06-28 10:18:39,113 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-06-28 10:18:39,124 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-06-28 10:18:39,124 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-06-28 10:18:39,126 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-06-28 10:18:39,139 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:00b677bc-7bb5-4c8c-9cb8-b10bc61671d0,clusterId:CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5,subject:om3
om3_1        | 2021-06-28 10:18:40,044 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2021-06-28 10:18:42,092 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5;layoutVersion=0
kdc_1        | Jun 28 10:33:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 10:33:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:33:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:34:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2021-06-28 10:16:53,462 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om1_1        | 2021-06-28 10:19:48,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:04,184 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34292
om1_1        | 2021-06-28 10:20:04,196 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:05,731 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-06-28 10:20:18,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34372
om1_1        | 2021-06-28 10:20:18,969 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:19,460 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34380
om1_1        | 2021-06-28 10:20:19,464 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:24,226 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34410
om1_1        | 2021-06-28 10:20:24,250 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:24,983 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34416
om1_1        | 2021-06-28 10:20:24,990 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:29,500 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34444
om1_1        | 2021-06-28 10:20:29,518 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:37,701 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34498
om1_1        | 2021-06-28 10:20:37,713 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:43,109 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34524
om1_1        | 2021-06-28 10:20:43,125 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:43,729 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34530
om1_1        | 2021-06-28 10:20:43,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:48,346 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34556
om1_1        | 2021-06-28 10:20:48,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:20:53,036 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34580
om1_1        | 2021-06-28 10:20:53,059 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:08,113 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34664
om1_1        | 2021-06-28 10:21:08,153 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:08,917 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:08688-source for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-06-28 10:21:12,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34692
om1_1        | 2021-06-28 10:21:12,435 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:13,124 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:08688-target for user:testuser/scm@EXAMPLE.COM
om1_1        | 2021-06-28 10:21:16,470 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34714
om1_1        | 2021-06-28 10:21:16,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:20,587 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34728
om1_1        | 2021-06-28 10:21:20,609 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:29,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34780
om1_1        | 2021-06-28 10:21:29,864 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:34,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34822
om1_1        | 2021-06-28 10:21:34,346 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:18:42,347 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-06-28 10:18:51,250 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om3_1        | STARTUP_MSG:   java = 11.0.10
om3_1        | ************************************************************/
om3_1        | 2021-06-28 10:18:51,306 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2021-06-28 10:19:01,495 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2021-06-28 10:19:02,382 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2021-06-28 10:19:02,393 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2021-06-28 10:19:02,395 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2021-06-28 10:19:02,467 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-06-28 10:19:04,113 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om3_1        | 2021-06-28 10:19:04,143 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2021-06-28 10:19:04,143 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-06-28 10:19:12,783 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2021-06-28 10:19:13,290 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-2423078939712.crt.
om3_1        | 2021-06-28 10:19:13,350 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2021-06-28 10:19:13,362 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/2516449581439.crt.
om3_1        | 2021-06-28 10:19:13,592 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2021-06-28 10:19:14,521 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-06-28 10:19:14,531 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2021-06-28 10:19:16,179 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om3_1        | 2021-06-28 10:19:16,200 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2021-06-28 10:19:16,200 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2021-06-28 10:19:17,186 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2021-06-28 10:19:17,243 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-06-28 10:19:17,245 [main] WARN ratis.OzoneManagerRatisServer: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2021-06-28 10:19:17,268 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2021-06-28 10:19:18,339 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2021-06-28 10:19:18,526 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2021-06-28 10:19:18,683 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om3:9872, om1:9872, om2:9872
om3_1        | 2021-06-28 10:19:18,738 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2021-06-28 10:19:20,196 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2021-06-28 10:19:20,848 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2021-06-28 10:19:20,857 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-06-28 10:19:20,867 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2021-06-28 10:19:20,867 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-06-28 10:19:20,867 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2021-06-28 10:19:20,870 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2021-06-28 10:19:20,872 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-28 10:19:20,886 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2021-06-28 10:19:20,890 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-06-28 10:19:24,623 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2021-06-28 10:19:24,654 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-06-28 10:19:24,654 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-06-28 10:19:24,698 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-06-28 10:19:24,714 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@5d51203b[Not completed]
om3_1        | 2021-06-28 10:19:24,715 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2021-06-28 10:19:25,013 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2021-06-28 10:19:25,066 [pool-22-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2021-06-28 10:19:25,053 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2021-06-28 10:19:25,113 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2021-06-28 10:19:25,113 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2021-06-28 10:19:25,113 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2021-06-28 10:19:25,114 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2021-06-28 10:19:25,114 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2021-06-28 10:19:25,118 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2021-06-28 10:19:25,120 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-06-28 10:19:25,162 [pool-22-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2021-06-28 10:19:25,163 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2021-06-28 10:19:25,196 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2021-06-28 10:20:46,582 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:49,654 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:52,726 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:55,798 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:20:58,874 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:01,942 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:05,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:08,086 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:11,158 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:14,230 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:17,302 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:20,378 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:23,452 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:26,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:29,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:35,738 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:38,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:41,878 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:44,951 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:48,022 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:51,098 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:54,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:21:57,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:00,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:03,386 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:06,454 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:09,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:12,598 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:15,670 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:18,742 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:24,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:27,958 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:31,030 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:34,102 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:37,178 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:40,255 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:43,318 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:46,390 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:49,462 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:52,534 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:55,606 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:22:58,678 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:01,750 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:04,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:07,895 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:14,038 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:17,110 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:20,186 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:23,254 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:26,326 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:29,398 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:32,471 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:35,542 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:38,614 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:41,686 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:44,759 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:47,830 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:50,902 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:53,974 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:23:57,046 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:03,190 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:06,262 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:09,334 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:12,406 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:15,478 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:18,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:21,622 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:24,694 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:27,766 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:30,838 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:33,910 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:42,586 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:45,654 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:48,726 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:51,799 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:54,870 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:25:57,942 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:01,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:04,093 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:07,158 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:10,230 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:13,302 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:16,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:19,446 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:25,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:28,663 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:31,734 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:34,807 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:37,878 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:40,950 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:44,022 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:47,094 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:50,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:53,238 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:56,310 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:26:59,382 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:02,455 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:05,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:47,318 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:50,390 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:53,463 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:56,534 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:20:59,610 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:02,682 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:05,750 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:08,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:10,304 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=266,entriesCount=1,lastEntry=(t:2, i:1)
datanode3_1  | 2021-06-28 10:21:10,305 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=267,entriesCount=1,lastEntry=(t:2, i:2)
datanode3_1  | 2021-06-28 10:21:11,579 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=268,entriesCount=1,lastEntry=(t:2, i:3)
datanode3_1  | 2021-06-28 10:21:11,601 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=271,entriesCount=1,lastEntry=(t:2, i:4)
datanode3_1  | 2021-06-28 10:21:11,898 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:14,966 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:18,038 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:21,110 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:24,182 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:27,254 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:33,402 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:36,470 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:39,542 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:42,614 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:45,686 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:48,762 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:51,830 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:54,902 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:21:57,974 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-28 10:21:38,584 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34836
om1_1        | 2021-06-28 10:21:38,602 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:42,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34860
om1_1        | 2021-06-28 10:21:42,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:46,712 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34886
om1_1        | 2021-06-28 10:21:46,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:50,727 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34900
om1_1        | 2021-06-28 10:21:50,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:54,385 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34924
om1_1        | 2021-06-28 10:21:54,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:21:58,549 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34950
om1_1        | 2021-06-28 10:21:58,561 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:02,353 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34964
om1_1        | 2021-06-28 10:22:02,375 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:06,893 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35016
om1_1        | 2021-06-28 10:22:06,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:11,092 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35044
om1_1        | 2021-06-28 10:22:11,115 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:14,830 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35058
om1_1        | 2021-06-28 10:22:14,863 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:18,986 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35084
om1_1        | 2021-06-28 10:22:19,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:23,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35108
om1_1        | 2021-06-28 10:22:23,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:29,789 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35142
om1_1        | 2021-06-28 10:22:29,802 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:36,083 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35192
om1_1        | 2021-06-28 10:22:36,119 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:42,743 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35224
om1_1        | 2021-06-28 10:22:42,758 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:49,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35256
om1_1        | 2021-06-28 10:22:49,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:53,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35282
om1_1        | 2021-06-28 10:22:53,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:22:57,787 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35298
om1_1        | 2021-06-28 10:22:57,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:02,152 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35322
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/javassist-3.25.0-GA.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.11.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.2.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
recon_1      | STARTUP_MSG:   java = 11.0.10
recon_1      | ************************************************************/
recon_1      | 2021-06-28 10:16:53,494 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2021-06-28 10:16:56,482 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1      | 2021-06-28 10:16:58,172 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2021-06-28 10:16:58,608 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2021-06-28 10:16:59,013 [main] ERROR recon.ReconServer: Error login in as Recon service. 
recon_1      | org.apache.hadoop.security.KerberosAuthException: failure to login: for principal: recon/recon@EXAMPLE.COM from keytab /etc/security/keytabs/recon.keytab javax.security.auth.login.LoginException: Unable to obtain password from user
recon_1      | 
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1880)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytabAndReturnUGI(UserGroupInformation.java:1247)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:1016)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:315)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.loginReconUser(ReconServer.java:209)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.loginReconUserIfSecurityEnabled(ReconServer.java:184)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:95)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:53)
recon_1      | 	at picocli.CommandLine.executeUserObject(CommandLine.java:1933)
recon_1      | 	at picocli.CommandLine.access$1100(CommandLine.java:145)
recon_1      | 	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2332)
recon_1      | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2326)
recon_1      | 	at picocli.CommandLine$RunLast.handle(CommandLine.java:2291)
recon_1      | 	at picocli.CommandLine$AbstractParseResultHandler.handleParseResult(CommandLine.java:2152)
recon_1      | 	at picocli.CommandLine.parseWithHandlers(CommandLine.java:2530)
recon_1      | 	at picocli.CommandLine.parseWithHandler(CommandLine.java:2465)
recon_1      | 	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:96)
recon_1      | 	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:87)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconServer.main(ReconServer.java:67)
recon_1      | Caused by: javax.security.auth.login.LoginException: Unable to obtain password from user
recon_1      | 
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.promptForPass(Krb5LoginModule.java:875)
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:738)
recon_1      | 	at jdk.security.auth/com.sun.security.auth.module.Krb5LoginModule.login(Krb5LoginModule.java:592)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.invoke(LoginContext.java:726)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext$4.run(LoginContext.java:665)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext$4.run(LoginContext.java:663)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:663)
recon_1      | 	at java.base/javax.security.auth.login.LoginContext.login(LoginContext.java:574)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext.login(UserGroupInformation.java:1959)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1869)
recon_1      | 	... 18 more
recon_1      | 2021-06-28 10:16:59,871 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-06-28 10:17:02,614 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
om2_1        | 2021-06-28 10:19:27,073 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2021-06-28 10:19:27,107 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2021-06-28 10:19:27,129 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2021-06-28 10:19:27,130 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2021-06-28 10:19:27,130 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2021-06-28 10:19:27,145 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2021-06-28 10:19:27,145 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2021-06-28 10:19:27,369 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om2@group-562213E44849
om2_1        | 2021-06-28 10:19:27,415 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om2@group-562213E44849
om2_1        | 2021-06-28 10:19:27,604 [Listener at om2/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om2_1        | 2021-06-28 10:19:28,015 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2021-06-28 10:19:28,082 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2021-06-28 10:19:28,082 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2021-06-28 10:19:28,249 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2021-06-28 10:19:28,251 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2021-06-28 10:19:28,253 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-28 10:19:28,256 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2021-06-28 10:19:28,268 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-06-28 10:19:28,273 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2021-06-28 10:19:28,274 [Listener at om2/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om2@group-562213E44849
om2_1        | 2021-06-28 10:19:28,295 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2021-06-28 10:19:28,497 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2021-06-28 10:19:28,512 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2021-06-28 10:19:28,512 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-06-28 10:19:28,514 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2021-06-28 10:19:28,533 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-06-28 10:19:28,514 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$387/0x000000084058fc40@3808bdfc] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2021-06-28 10:19:28,548 [Thread[Thread-15,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2021-06-28 10:19:28,693 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2021-06-28 10:19:28,693 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2021-06-28 10:19:28,693 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2021-06-28 10:19:28,885 [Listener at om2/9862] INFO util.log: Logging initialized @43136ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2021-06-28 10:19:29,263 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2021-06-28 10:19:29,276 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2021-06-28 10:19:29,288 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2021-06-28 10:19:29,288 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2021-06-28 10:19:29,288 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2021-06-28 10:19:29,299 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2021-06-28 10:19:29,478 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2021-06-28 10:19:29,479 [Listener at om2/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om2_1        | 2021-06-28 10:19:29,631 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2021-06-28 10:19:29,639 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2021-06-28 10:19:29,649 [Listener at om2/9862] INFO server.session: node0 Scavenging every 660000ms
om2_1        | 2021-06-28 10:19:29,831 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2021-06-28 10:19:29,861 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ab6a093{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2021-06-28 10:19:29,865 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5e774546{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2021-06-28 10:19:30,101 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2021-06-28 10:19:30,133 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3ffa3cdb{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-1666233742635637672/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2021-06-28 10:19:30,148 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@21cb907d{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2021-06-28 10:19:30,148 [Listener at om2/9862] INFO server.Server: Started @44400ms
om2_1        | 2021-06-28 10:19:30,162 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2021-06-28 10:19:30,162 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2021-06-28 10:19:30,164 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2021-06-28 10:19:30,170 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-28 10:19:30,186 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2021-06-28 10:19:30,249 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1        | 2021-06-28 10:19:30,260 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@532860c7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2021-06-28 10:19:33,355 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5086957537ns, electionTimeout:5070ms
om2_1        | 2021-06-28 10:19:33,357 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-06-28 10:19:33,362 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2021-06-28 10:19:33,388 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2021-06-28 10:19:33,388 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2021-06-28 10:19:33,410 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-28 10:19:34,294 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om2
om2_1        | 2021-06-28 10:19:34,338 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-06-28 10:19:34,355 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2021-06-28 10:19:34,373 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-28 10:19:35,540 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2021-06-28 10:19:35,540 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2021-06-28 10:19:35,540 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2021-06-28 10:19:35,540 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2021-06-28 10:19:35,541 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2021-06-28 10:19:35,541 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2021-06-28 10:19:35,542 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-06-28 10:19:35,665 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2021-06-28 10:19:35,665 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2021-06-28 10:19:35,665 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-28 10:19:40,054 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2021-06-28 10:19:40,056 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om3: our priority 0 <= candidate's priority 0
datanode1_1  | 2021-06-28 10:27:08,598 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:13,035 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$322/0x0000000840576c40@43b25c8] WARN util.JvmPauseMonitor: JvmPauseMonitor-87b0b3c6-67c6-498c-a3d3-879b3c6d2c21: Detected pause in JVM or host machine (eg GC): pause of approximately 116968856ns.
datanode1_1  | GC pool 'ParNew' had collection(s): count=1 time=194ms
datanode1_1  | 2021-06-28 10:27:14,743 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:17,814 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:20,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:23,958 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:27,030 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:30,103 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:33,174 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:36,246 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:39,319 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:42,390 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:45,463 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:48,539 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:51,606 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:54,678 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:27:57,750 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:03,894 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:06,966 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:10,038 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:13,128 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:16,182 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:19,254 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:22,330 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:25,398 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:28,474 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:31,542 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:34,614 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:37,686 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:40,758 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:43,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:46,903 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:53,046 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:56,118 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:28:59,190 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:02,262 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:05,338 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:08,406 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:11,482 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:14,551 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:17,622 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:20,698 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:23,766 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:26,838 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:29,910 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:32,982 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:36,055 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:42,198 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:45,270 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:48,342 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:51,414 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:54,490 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:29:57,558 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:00,630 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:03,702 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:06,774 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:09,201 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 110.
datanode1_1  | 2021-06-28 10:30:09,201 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 110.
datanode1_1  | 2021-06-28 10:30:09,230 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 110.
datanode1_1  | 2021-06-28 10:30:09,850 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:12,918 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:15,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:19,065 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:22,138 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:25,206 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:31,350 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
kdc_1        | Jun 28 10:34:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:34:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:34:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:34:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 10:34:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1624876423, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode1_1  | 2021-06-28 10:30:34,422 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:37,494 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:40,566 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:43,638 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:46,711 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:49,782 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:52,854 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:55,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:30:58,998 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:02,070 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:05,142 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:08,218 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:11,286 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:14,358 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:20,502 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:23,574 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:26,650 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:29,718 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:32,790 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:35,862 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:38,938 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:42,006 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:45,078 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:48,150 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:51,223 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:54,298 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:31:57,366 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:00,438 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:03,510 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:09,654 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:12,730 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:15,798 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:18,874 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:21,943 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:25,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:28,086 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:31,158 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:34,230 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:37,302 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:40,297 [pool-37-thread-2] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 138.
datanode1_1  | 2021-06-28 10:32:40,305 [pool-37-thread-2] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 138.
datanode1_1  | 2021-06-28 10:32:40,323 [pool-37-thread-2] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 138.
datanode1_1  | 2021-06-28 10:32:40,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:43,446 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:46,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:49,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:32:52,662 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2021-06-28 10:17:03,530 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2021-06-28 10:17:03,573 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2021-06-28 10:17:03,586 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2021-06-28 10:17:05,951 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2021-06-28 10:17:05,951 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2021-06-28 10:17:05,951 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2021-06-28 10:17:05,981 [main] INFO util.log: Logging initialized @16124ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2021-06-28 10:17:06,289 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2021-06-28 10:17:06,313 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2021-06-28 10:17:06,315 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2021-06-28 10:17:06,315 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2021-06-28 10:17:06,315 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2021-06-28 10:17:06,322 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2021-06-28 10:17:06,827 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2021-06-28 10:17:07,545 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2021-06-28 10:17:07,555 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2021-06-28 10:17:07,606 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2021-06-28 10:17:08,579 [main] INFO Configuration.deprecation: No unit for ozone.recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1      | 2021-06-28 10:17:08,890 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-06-28 10:17:09,388 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-06-28 10:17:09,420 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2021-06-28 10:17:09,429 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2021-06-28 10:17:09,665 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2021-06-28 10:17:09,873 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2021-06-28 10:17:09,971 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2021-06-28 10:17:09,997 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2021-06-28 10:17:10,016 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2021-06-28 10:17:10,137 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2021-06-28 10:17:10,226 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2021-06-28 10:17:10,328 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: No pipeline exists in current db
recon_1      | 2021-06-28 10:17:10,492 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2021-06-28 10:17:10,492 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2021-06-28 10:17:10,569 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2021-06-28 10:17:10,583 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2021-06-28 10:17:10,583 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2021-06-28 10:17:10,960 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2021-06-28 10:17:10,975 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
recon_1      | 2021-06-28 10:17:11,095 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2021-06-28 10:17:11,095 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2021-06-28 10:17:11,098 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2021-06-28 10:17:11,121 [Listener at 0.0.0.0/9891] INFO server.session: node0 Stopped scavenging
recon_1      | Problem starting http server
recon_1      | 2021-06-28 10:17:11,210 [shutdown-hook-0] INFO recon.ReconServer: SHUTDOWN_MSG: 
recon_1      | /************************************************************
recon_1      | SHUTDOWN_MSG: Shutting down ReconServer at recon/172.25.0.115
recon_1      | ************************************************************/
datanode1_1  | 2021-06-28 10:32:58,806 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:01,878 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:04,950 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:08,022 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:11,094 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:14,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:17,238 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:20,310 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:23,383 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:26,454 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:29,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:32,603 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:35,670 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:38,742 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:41,814 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:47,958 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:51,030 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:54,105 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:33:57,174 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:00,246 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:03,318 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:06,390 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:09,462 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:12,534 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:15,606 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:18,678 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:21,750 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:24,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode1_1  | 2021-06-28 10:34:27,894 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-28 10:19:25,204 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2021-06-28 10:19:25,251 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om3
om3_1        | 2021-06-28 10:19:25,362 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2021-06-28 10:19:25,369 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2021-06-28 10:19:25,379 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2021-06-28 10:19:25,414 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2021-06-28 10:19:25,415 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-28 10:19:25,443 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om3@group-562213E44849
om3_1        | 2021-06-28 10:19:25,544 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-06-28 10:19:25,574 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2021-06-28 10:19:25,575 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2021-06-28 10:19:25,622 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2021-06-28 10:19:25,623 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-06-28 10:19:25,623 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2021-06-28 10:19:25,624 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2021-06-28 10:19:25,625 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2021-06-28 10:19:25,629 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2021-06-28 10:19:25,635 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2021-06-28 10:19:25,639 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2021-06-28 10:19:25,640 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2021-06-28 10:19:25,682 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2021-06-28 10:19:25,684 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2021-06-28 10:19:25,715 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2021-06-28 10:24:36,986 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:40,054 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:43,130 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:46,198 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:52,342 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:55,417 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:24:58,486 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:01,558 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:04,630 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:07,702 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:10,774 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-28 10:23:02,173 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:06,757 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35376
om1_1        | 2021-06-28 10:23:06,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:10,964 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35400
om1_1        | 2021-06-28 10:23:10,979 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:15,500 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35418
om1_1        | 2021-06-28 10:23:15,509 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:19,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35440
om1_1        | 2021-06-28 10:23:19,420 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:23,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35466
om1_1        | 2021-06-28 10:23:23,625 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:27,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35486
om1_1        | 2021-06-28 10:23:27,966 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:31,816 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35508
om1_1        | 2021-06-28 10:23:31,830 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:35,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35550
om1_1        | 2021-06-28 10:23:35,957 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:40,158 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35568
om1_1        | 2021-06-28 10:23:40,170 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:43,977 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35590
om1_1        | 2021-06-28 10:23:43,996 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:44,672 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:08688-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-28 10:23:47,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35612
om1_1        | 2021-06-28 10:23:47,846 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:51,790 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35628
om1_1        | 2021-06-28 10:23:51,799 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:23:52,393 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:08688-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-28 10:23:55,812 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35654
datanode2_1  | 2021-06-28 10:25:13,847 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:16,918 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:19,994 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:23,062 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:26,134 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:29,206 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:32,278 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:35,350 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:41,498 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:44,567 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:47,638 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:50,714 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:53,782 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:56,854 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:25:59,926 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:02,999 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:06,071 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:09,142 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:12,219 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:15,287 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:18,362 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:21,430 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:24,502 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:30,646 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:33,718 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:36,790 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:39,862 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:42,934 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:01,046 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:04,118 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:07,190 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:10,262 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:13,334 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:16,406 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:22,554 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:23,372 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=541,entriesCount=1,lastEntry=(t:2, i:5)
datanode3_1  | 2021-06-28 10:22:23,372 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=542,entriesCount=1,lastEntry=(t:2, i:6)
datanode3_1  | 2021-06-28 10:22:23,387 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=546,entriesCount=1,lastEntry=(t:2, i:7)
datanode3_1  | 2021-06-28 10:22:23,416 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=550,entriesCount=1,lastEntry=(t:2, i:8)
datanode3_1  | 2021-06-28 10:22:25,622 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:28,694 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:31,766 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:34,838 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:37,910 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:40,982 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:44,056 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:47,126 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:50,198 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:53,274 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:56,342 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:22:59,414 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:02,486 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:05,558 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:11,702 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:14,775 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:17,846 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:20,918 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:23,990 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:27,066 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:30,134 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:33,206 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:36,278 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:39,350 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:42,422 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:45,494 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:48,566 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:51,638 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:23:54,710 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:00,854 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:03,926 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:07,002 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:10,074 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:13,142 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:16,214 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:19,286 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:22,360 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:25,430 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:28,502 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:31,574 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:34,646 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:37,718 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:40,795 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-28 10:23:55,820 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:00,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35678
om1_1        | 2021-06-28 10:24:00,352 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:04,732 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35724
om1_1        | 2021-06-28 10:24:04,747 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:08,881 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35746
om1_1        | 2021-06-28 10:24:08,903 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:12,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35770
om1_1        | 2021-06-28 10:24:13,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:16,915 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35788
om1_1        | 2021-06-28 10:24:16,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:20,850 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35810
om1_1        | 2021-06-28 10:24:20,870 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:24,869 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35836
om1_1        | 2021-06-28 10:24:24,890 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:29,153 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35854
om1_1        | 2021-06-28 10:24:29,171 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:33,387 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35894
om1_1        | 2021-06-28 10:24:33,402 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:42,690 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35940
om1_1        | 2021-06-28 10:24:42,705 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:49,278 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35974
om1_1        | 2021-06-28 10:24:49,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:53,286 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35988
om1_1        | 2021-06-28 10:24:53,301 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:24:57,503 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36014
om1_1        | 2021-06-28 10:24:57,523 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:18,914 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36250
om1_1        | 2021-06-28 10:25:18,936 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:22,943 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:22,947 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40960
om1_1        | 2021-06-28 10:25:22,965 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:27,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36294
om1_1        | 2021-06-28 10:25:27,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:30,248 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:30,250 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41010
om1_1        | 2021-06-28 10:25:30,261 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:30,848 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:30,849 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41020
om2_1        | 2021-06-28 10:19:40,056 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om3
om2_1        | 2021-06-28 10:19:40,056 [grpc-default-executor-0] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2021-06-28 10:19:40,060 [grpc-default-executor-0] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2021-06-28 10:19:40,060 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted: {}
om2_1        | java.lang.InterruptedException: sleep interrupted
om2_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:339)
om2_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om2_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om2_1        | 2021-06-28 10:19:40,082 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:OK-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om3, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2021-06-28 10:19:40,447 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om3 at term 2 for appendEntries, leader elected after 14222ms
om2_1        | 2021-06-28 10:19:40,580 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-06-28 10:19:40,590 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2021-06-28 10:19:40,833 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2021-06-28 10:19:48,875 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38014
datanode3_1  | 2021-06-28 10:24:43,863 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:50,006 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:53,078 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:56,150 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:24:59,222 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:02,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:05,370 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:08,438 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:11,510 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:14,582 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:17,654 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:20,726 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:23,798 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:26,870 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:29,942 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:33,018 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:36,242 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=873,entriesCount=1,lastEntry=(t:2, i:9)
datanode3_1  | 2021-06-28 10:25:36,252 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=874,entriesCount=1,lastEntry=(t:2, i:10)
datanode3_1  | 2021-06-28 10:25:36,264 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=875,entriesCount=1,lastEntry=(t:2, i:11)
datanode3_1  | 2021-06-28 10:25:36,284 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=876,entriesCount=1,lastEntry=(t:2, i:12)
datanode3_1  | 2021-06-28 10:25:39,158 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:42,230 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:45,302 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:48,376 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:51,446 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:54,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:25:57,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-28 10:19:25,726 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2021-06-28 10:19:25,762 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2021-06-28 10:19:25,767 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2021-06-28 10:19:25,767 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2021-06-28 10:19:25,776 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2021-06-28 10:19:25,782 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2021-06-28 10:19:25,786 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2021-06-28 10:19:25,781 [Listener at om3/9862] INFO om.OzoneManager: Configured ozone.om.metadata.layout=SIMPLE and disabled optimized OM FS operations
om3_1        | 2021-06-28 10:19:25,966 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om3@group-562213E44849
om3_1        | 2021-06-28 10:19:26,039 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om3@group-562213E44849
om3_1        | 2021-06-28 10:19:26,420 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2021-06-28 10:19:26,538 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2021-06-28 10:19:26,539 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2021-06-28 10:19:26,881 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2021-06-28 10:19:26,886 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2021-06-28 10:19:26,914 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-28 10:19:26,918 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2021-06-28 10:19:26,927 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-06-28 10:19:26,950 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2021-06-28 10:19:26,955 [Listener at om3/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om3@group-562213E44849
om3_1        | 2021-06-28 10:19:26,977 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2021-06-28 10:19:27,228 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2021-06-28 10:19:27,245 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2021-06-28 10:19:27,246 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$387/0x000000084058fc40@5ceeab0c] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2021-06-28 10:19:27,251 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-06-28 10:19:27,253 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2021-06-28 10:19:27,253 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2021-06-28 10:19:27,267 [Thread[Thread-15,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2021-06-28 10:19:27,333 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2021-06-28 10:19:27,333 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2021-06-28 10:19:27,333 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2021-06-28 10:19:27,441 [Listener at om3/9862] INFO util.log: Logging initialized @43981ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2021-06-28 10:19:27,792 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2021-06-28 10:19:27,814 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2021-06-28 10:19:27,815 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2021-06-28 10:19:27,820 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2021-06-28 10:19:27,820 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2021-06-28 10:19:27,828 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2021-06-28 10:19:27,967 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2021-06-28 10:19:27,968 [Listener at om3/9862] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om3_1        | 2021-06-28 10:19:28,122 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2021-06-28 10:19:28,127 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2021-06-28 10:19:28,139 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
om3_1        | 2021-06-28 10:19:28,251 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-06-28 10:19:28,256 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4f2ab774{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2021-06-28 10:19:28,263 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5479abd8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2021-06-28 10:19:28,678 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2021-06-28 10:19:28,731 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1f9e42d2{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_2_0-SNAPSHOT_jar-_-any-5750831182231789289/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.2.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2021-06-28 10:19:28,780 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@446d7669{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2021-06-28 10:19:28,780 [Listener at om3/9862] INFO server.Server: Started @45320ms
om2_1        | 2021-06-28 10:19:48,883 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:04,246 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38090
om2_1        | 2021-06-28 10:20:04,256 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:05,909 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-06-28 10:20:19,011 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38172
om2_1        | 2021-06-28 10:20:19,024 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:19,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38178
om2_1        | 2021-06-28 10:20:19,489 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:24,293 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38208
om2_1        | 2021-06-28 10:20:24,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:25,017 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38214
om2_1        | 2021-06-28 10:20:25,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:29,565 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38242
om2_1        | 2021-06-28 10:20:29,574 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:37,785 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38296
om2_1        | 2021-06-28 10:20:37,788 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:43,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38322
om2_1        | 2021-06-28 10:20:43,172 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:43,755 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38328
om2_1        | 2021-06-28 10:20:43,763 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:48,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38354
om2_1        | 2021-06-28 10:20:48,397 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:20:53,096 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38378
om2_1        | 2021-06-28 10:20:53,106 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:08,217 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38464
om2_1        | 2021-06-28 10:21:08,234 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:08,934 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:08688-source for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-06-28 10:21:12,464 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38490
om2_1        | 2021-06-28 10:21:12,474 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:13,115 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:08688-target for user:testuser/scm@EXAMPLE.COM
om2_1        | 2021-06-28 10:21:16,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38512
om2_1        | 2021-06-28 10:21:16,558 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:20,671 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38528
om2_1        | 2021-06-28 10:21:20,681 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:29,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38578
om2_1        | 2021-06-28 10:21:29,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:34,392 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38620
om2_1        | 2021-06-28 10:21:34,412 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode2_1  | 2021-06-28 10:26:46,006 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:49,082 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:52,151 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:55,222 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:26:58,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:01,366 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:04,438 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:07,514 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:10,582 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:13,654 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:19,798 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:22,877 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:25,942 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:29,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:32,086 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:35,162 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:38,235 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:41,302 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:44,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:47,450 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:50,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:53,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:56,662 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:27:59,734 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:02,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:08,950 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:12,022 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-28 10:19:28,799 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2021-06-28 10:19:28,802 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2021-06-28 10:19:28,804 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2021-06-28 10:19:28,847 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2021-06-28 10:19:28,806 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2021-06-28 10:19:29,024 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2021-06-28 10:19:29,033 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@595713f3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2021-06-28 10:19:32,019 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5092482871ns, electionTimeout:5083ms
om3_1        | 2021-06-28 10:19:32,020 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-06-28 10:19:32,021 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2021-06-28 10:19:32,024 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2021-06-28 10:19:32,024 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2021-06-28 10:19:32,043 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-28 10:19:34,876 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2021-06-28 10:19:34,877 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2021-06-28 10:19:34,877 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2021-06-28 10:19:34,877 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2021-06-28 10:19:34,891 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2021-06-28 10:19:34,891 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2021-06-28 10:19:34,892 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2021-06-28 10:19:35,482 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om3
om3_1        | 2021-06-28 10:19:35,491 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-06-28 10:19:35,495 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2021-06-28 10:19:35,501 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-28 10:19:35,659 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2021-06-28 10:19:35,659 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2021-06-28 10:19:35,660 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-28 10:19:40,029 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5136680327ns, electionTimeout:5127ms
om3_1        | 2021-06-28 10:19:40,030 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2021-06-28 10:19:40,030 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om3_1        | 2021-06-28 10:19:40,030 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2021-06-28 10:19:40,030 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection2
om3_1        | 2021-06-28 10:19:40,034 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2021-06-28 10:19:40,087 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om3_1        | 2021-06-28 10:19:40,087 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om3<-om1#0:OK-t2
om3_1        | 2021-06-28 10:19:40,088 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om3_1        | 2021-06-28 10:19:40,088 [om3@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection2
om3_1        | 2021-06-28 10:19:40,088 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om3_1        | 2021-06-28 10:19:40,088 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om3 at term 2 for becomeLeader, leader elected after 14719ms
om3_1        | 2021-06-28 10:19:40,108 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om3_1        | 2021-06-28 10:19:40,115 [om3@group-562213E44849-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.om3@group-562213E44849
om3_1        | 2021-06-28 10:19:40,126 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om3_1        | 2021-06-28 10:19:40,128 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om3_1        | 2021-06-28 10:19:40,158 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om2_1        | 2021-06-28 10:21:38,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38634
om2_1        | 2021-06-28 10:21:38,666 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:42,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38658
om2_1        | 2021-06-28 10:21:42,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:46,799 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38684
om2_1        | 2021-06-28 10:21:46,803 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:50,765 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38698
om2_1        | 2021-06-28 10:21:50,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:54,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38722
om2_1        | 2021-06-28 10:21:54,451 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:21:58,583 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38748
om2_1        | 2021-06-28 10:21:58,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:02,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38762
om2_1        | 2021-06-28 10:22:02,423 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:06,964 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38814
om2_1        | 2021-06-28 10:22:06,974 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:11,158 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38842
om2_1        | 2021-06-28 10:22:11,160 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:14,919 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38856
om2_1        | 2021-06-28 10:22:14,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:19,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38882
om2_1        | 2021-06-28 10:22:19,050 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:23,100 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38908
om2_1        | 2021-06-28 10:22:23,104 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:29,835 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38940
om2_1        | 2021-06-28 10:22:29,840 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:36,178 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38990
om2_1        | 2021-06-28 10:22:36,189 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:42,790 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39022
om2_1        | 2021-06-28 10:22:42,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:49,401 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39054
om2_1        | 2021-06-28 10:22:49,418 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:53,624 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39080
om2_1        | 2021-06-28 10:22:53,629 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:22:57,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39096
om2_1        | 2021-06-28 10:22:57,881 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:02,211 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39120
datanode2_1  | 2021-06-28 10:28:15,095 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:18,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:21,238 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:24,310 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:27,382 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:30,454 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:33,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:36,598 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:39,670 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:42,742 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:45,814 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:48,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:51,958 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:28:58,103 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:01,178 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:04,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:07,318 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:10,390 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:13,462 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:16,534 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:19,606 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:22,678 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:25,750 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:28,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:31,894 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:34,970 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:38,038 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:41,114 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:47,254 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:50,326 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:53,398 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:56,470 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:29:59,542 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:02,614 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:05,690 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:08,758 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:09,202 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 110.
datanode2_1  | 2021-06-28 10:30:09,202 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 110.
datanode2_1  | 2021-06-28 10:30:09,238 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 110.
datanode2_1  | 2021-06-28 10:30:11,834 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:14,902 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:17,974 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:21,046 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:24,118 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:27,190 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:30,262 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:36,406 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:39,478 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:42,550 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:45,622 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:48,694 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:51,767 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:54,838 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:30:57,910 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:00,982 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:04,054 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:07,126 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:10,198 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:13,270 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:16,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:19,414 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:25,558 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:28,630 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:31,702 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:34,774 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:37,846 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:40,918 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:43,990 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:47,062 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:50,135 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:53,210 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:56,278 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:31:59,354 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:02,422 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:05,494 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:08,566 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:14,710 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2021-06-28 10:16:55,453 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2021-06-28 10:16:55,458 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2021-06-28 10:16:55,462 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2021-06-28 10:16:55,616 [main] INFO util.log: Logging initialized @5222ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2021-06-28 10:16:56,141 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2021-06-28 10:16:56,156 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2021-06-28 10:16:56,159 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2021-06-28 10:16:56,162 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2021-06-28 10:16:56,162 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2021-06-28 10:16:56,174 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2021-06-28 10:16:56,507 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/javassist-3.25.0-GA.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
s3g_1        | STARTUP_MSG:   java = 11.0.10
s3g_1        | ************************************************************/
s3g_1        | 2021-06-28 10:16:56,513 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2021-06-28 10:16:56,744 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2021-06-28 10:16:56,764 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2021-06-28 10:16:56,787 [main] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
s3g_1        | 2021-06-28 10:16:56,946 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2021-06-28 10:16:56,946 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2021-06-28 10:16:56,948 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1        | 2021-06-28 10:16:57,065 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2021-06-28 10:16:57,200 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@488eb7f2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2021-06-28 10:16:57,204 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@abf688e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2021-06-28 10:17:03,768 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Jun 28, 2021 10:17:07 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2021-06-28 10:17:07,086 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@794c5f5e{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_2_0-SNAPSHOT_jar-_-any-16268392060636530537/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.2.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2021-06-28 10:17:07,122 [main] INFO server.AbstractConnector: Started ServerConnector@51cd7ffc{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2021-06-28 10:17:07,122 [main] INFO server.Server: Started @16729ms
s3g_1        | 2021-06-28 10:17:07,126 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2021-06-28 10:25:23,036 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 2021-06-28 10:19:40,164 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om3_1        | 2021-06-28 10:19:40,171 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om3_1        | 2021-06-28 10:19:40,218 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om3_1        | 2021-06-28 10:19:40,219 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-28 10:19:40,219 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2021-06-28 10:19:40,225 [om3@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2021-06-28 10:19:40,234 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-06-28 10:19:40,240 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-06-28 10:19:40,242 [om3@group-562213E44849-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.om3@group-562213E44849
om3_1        | 2021-06-28 10:19:40,245 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om3_1        | 2021-06-28 10:19:40,249 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-28 10:19:40,249 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2021-06-28 10:19:40,249 [om3@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2021-06-28 10:19:40,249 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2021-06-28 10:19:40,249 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2021-06-28 10:19:40,255 [om3@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderStateImpl
om3_1        | 2021-06-28 10:19:40,285 [om3@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2021-06-28 10:19:40,340 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-06-28 10:19:40,700 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2021-06-28 10:19:49,472 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48980
om3_1        | 2021-06-28 10:19:49,475 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:04,295 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49054
om3_1        | 2021-06-28 10:20:04,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:05,070 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-06-28 10:20:19,047 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49136
om3_1        | 2021-06-28 10:20:19,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:19,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49142
om3_1        | 2021-06-28 10:20:19,523 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:24,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49172
om3_1        | 2021-06-28 10:20:24,346 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:25,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49178
om3_1        | 2021-06-28 10:20:25,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:29,599 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49206
om3_1        | 2021-06-28 10:20:29,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:37,802 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49260
om3_1        | 2021-06-28 10:20:37,806 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:43,202 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49286
om3_1        | 2021-06-28 10:20:43,204 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:43,789 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49292
om3_1        | 2021-06-28 10:20:43,797 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:48,422 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49318
datanode3_1  | 2021-06-28 10:26:00,666 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:03,736 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:06,810 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:09,878 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:12,950 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:16,022 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:19,098 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:22,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:28,310 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:31,382 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:34,133 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1148,entriesCount=1,lastEntry=(t:2, i:13)
datanode3_1  | 2021-06-28 10:26:34,134 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1149,entriesCount=1,lastEntry=(t:2, i:14)
datanode3_1  | 2021-06-28 10:26:34,142 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1150,entriesCount=1,lastEntry=(t:2, i:15)
datanode3_1  | 2021-06-28 10:26:34,146 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1152,entriesCount=1,lastEntry=(t:2, i:16)
datanode3_1  | 2021-06-28 10:26:34,454 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:37,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:40,598 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:43,671 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:45,570 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1404,entriesCount=1,lastEntry=(t:2, i:17)
datanode3_1  | 2021-06-28 10:26:45,581 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1405,entriesCount=1,lastEntry=(t:2, i:18)
datanode3_1  | 2021-06-28 10:26:45,582 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1406,entriesCount=1,lastEntry=(t:2, i:19)
datanode3_1  | 2021-06-28 10:26:45,596 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1409,entriesCount=1,lastEntry=(t:2, i:20)
datanode3_1  | 2021-06-28 10:26:46,742 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:48,357 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1659,entriesCount=1,lastEntry=(t:2, i:21)
datanode3_1  | 2021-06-28 10:26:48,358 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1660,entriesCount=1,lastEntry=(t:2, i:22)
datanode3_1  | 2021-06-28 10:26:48,365 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1661,entriesCount=1,lastEntry=(t:2, i:23)
datanode3_1  | 2021-06-28 10:26:48,374 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1662,entriesCount=1,lastEntry=(t:2, i:24)
datanode3_1  | 2021-06-28 10:26:49,814 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:51,857 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1911,entriesCount=1,lastEntry=(t:2, i:25)
datanode3_1  | 2021-06-28 10:26:51,858 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1912,entriesCount=1,lastEntry=(t:2, i:26)
datanode3_1  | 2021-06-28 10:26:51,977 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1913,entriesCount=1,lastEntry=(t:2, i:27)
datanode3_1  | 2021-06-28 10:26:52,014 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1916,entriesCount=1,lastEntry=(t:2, i:28)
datanode3_1  | 2021-06-28 10:26:52,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:55,813 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2154,entriesCount=1,lastEntry=(t:2, i:29)
datanode3_1  | 2021-06-28 10:26:55,958 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:56,028 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2155,entriesCount=1,lastEntry=(t:2, i:30)
datanode3_1  | 2021-06-28 10:26:56,028 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2156,entriesCount=1,lastEntry=(t:2, i:31)
datanode3_1  | 2021-06-28 10:26:56,142 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2157,entriesCount=1,lastEntry=(t:2, i:32)
datanode3_1  | 2021-06-28 10:26:56,206 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2163,entriesCount=1,lastEntry=(t:2, i:33)
datanode3_1  | 2021-06-28 10:26:56,236 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2167,entriesCount=1,lastEntry=(t:2, i:34)
datanode3_1  | 2021-06-28 10:26:59,030 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:26:59,395 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2419,entriesCount=1,lastEntry=(t:2, i:35)
datanode3_1  | 2021-06-28 10:26:59,402 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2420,entriesCount=1,lastEntry=(t:2, i:36)
datanode3_1  | 2021-06-28 10:26:59,415 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2421,entriesCount=1,lastEntry=(t:2, i:37)
datanode3_1  | 2021-06-28 10:27:02,102 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:05,174 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:08,248 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:11,318 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:17,462 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:20,538 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:23,606 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:26,684 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:29,750 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:32,826 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:35,894 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:38,966 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:42,038 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:45,110 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:46,501 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$323/0x0000000840576840@4385dbbc] WARN util.JvmPauseMonitor: JvmPauseMonitor-264e17c6-d8b4-4795-92be-7db9d85d28e1: Detected pause in JVM or host machine (eg GC): pause of approximately 142778054ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=71ms
datanode3_1  | 2021-06-28 10:27:48,182 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:51,257 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:53,345 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2685,entriesCount=1,lastEntry=(t:2, i:38)
datanode3_1  | 2021-06-28 10:27:53,501 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2686,entriesCount=1,lastEntry=(t:2, i:39)
datanode2_1  | 2021-06-28 10:32:17,782 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:20,858 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:23,926 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:26,998 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:30,070 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:33,142 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:36,214 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:39,286 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:40,312 [pool-37-thread-2] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 138.
datanode2_1  | 2021-06-28 10:32:40,315 [pool-37-thread-2] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 138.
datanode2_1  | 2021-06-28 10:32:40,350 [pool-37-thread-2] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 138.
datanode2_1  | 2021-06-28 10:32:42,358 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:45,434 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:48,502 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:51,574 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:54,646 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:32:57,718 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:03,862 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:06,934 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:10,006 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:13,078 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:16,150 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:19,222 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:22,295 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:25,366 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:28,442 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:31,510 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:34,582 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:37,654 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:40,726 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:43,798 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:46,870 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:53,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:56,086 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:33:59,162 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:02,230 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:05,302 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:08,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:11,448 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:14,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:17,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:20,662 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:23,734 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode2_1  | 2021-06-28 10:34:26,806 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-28 10:20:48,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:20:53,136 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49342
om3_1        | 2021-06-28 10:20:53,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:08,267 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49428
om3_1        | 2021-06-28 10:21:08,278 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:08,911 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:08688-source for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-06-28 10:21:12,492 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49454
om3_1        | 2021-06-28 10:21:12,509 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:13,105 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:08688-target for user:testuser/scm@EXAMPLE.COM
om3_1        | 2021-06-28 10:21:16,583 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49476
om3_1        | 2021-06-28 10:21:16,589 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:20,707 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49492
om3_1        | 2021-06-28 10:21:20,721 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:29,947 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49542
om3_1        | 2021-06-28 10:21:29,971 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:34,441 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49584
om3_1        | 2021-06-28 10:21:34,447 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:38,703 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49598
om3_1        | 2021-06-28 10:21:38,722 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:42,639 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49624
om3_1        | 2021-06-28 10:21:42,645 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:46,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49648
om3_1        | 2021-06-28 10:21:46,840 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:50,793 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49662
om3_1        | 2021-06-28 10:21:50,804 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:54,476 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49686
om3_1        | 2021-06-28 10:21:54,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:21:58,604 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49712
om3_1        | 2021-06-28 10:21:58,614 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:02,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49726
om3_1        | 2021-06-28 10:22:02,449 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:07,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49778
om3_1        | 2021-06-28 10:22:07,014 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:11,175 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49806
om3_1        | 2021-06-28 10:22:11,194 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:14,954 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49820
om3_1        | 2021-06-28 10:22:14,964 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:02,216 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:06,809 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39174
om2_1        | 2021-06-28 10:23:06,818 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:11,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39198
om2_1        | 2021-06-28 10:23:11,013 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:15,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39216
om2_1        | 2021-06-28 10:23:15,561 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:19,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39238
om2_1        | 2021-06-28 10:23:19,463 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:23,663 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39264
om2_1        | 2021-06-28 10:23:23,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:27,994 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39284
om2_1        | 2021-06-28 10:23:27,998 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:31,849 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39306
om2_1        | 2021-06-28 10:23:31,853 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:36,000 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39348
om2_1        | 2021-06-28 10:23:36,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:40,197 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39366
om2_1        | 2021-06-28 10:23:40,210 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:44,035 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39388
om2_1        | 2021-06-28 10:23:44,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:44,674 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:08688-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-28 10:23:47,880 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39412
om2_1        | 2021-06-28 10:23:47,882 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:51,839 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39428
om2_1        | 2021-06-28 10:23:51,846 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:23:52,376 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:08688-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-28 10:23:55,854 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39452
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:23,693 [qtp382627885-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-47001, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:25:23,748 [qtp382627885-22] INFO endpoint.BucketEndpoint: Location is /bucket-47001
s3g_1        | 2021-06-28 10:25:30,286 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:30,316 [qtp382627885-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-85818, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:25:30,334 [qtp382627885-17] INFO endpoint.BucketEndpoint: Location is /bucket-85818
s3g_1        | 2021-06-28 10:25:30,877 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:31,795 [qtp382627885-24] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2021-06-28 10:25:31,808 [qtp382627885-24] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2021-06-28 10:25:31,808 [qtp382627885-24] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1        | 2021-06-28 10:25:31,816 [qtp382627885-24] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2021-06-28 10:25:31,816 [qtp382627885-24] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2021-06-28 10:25:32,133 [qtp382627885-24] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2021-06-28 10:25:32,133 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-8F882D4B1CE9->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:25:32,134 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:34,004 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om2_1        | 2021-06-28 10:23:55,861 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:00,387 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39476
om2_1        | 2021-06-28 10:24:00,391 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:04,783 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39522
om2_1        | 2021-06-28 10:24:04,788 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:08,943 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39544
om2_1        | 2021-06-28 10:24:08,946 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:13,043 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39568
om2_1        | 2021-06-28 10:24:13,054 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:16,966 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39586
om2_1        | 2021-06-28 10:24:16,971 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:20,911 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39608
om2_1        | 2021-06-28 10:24:20,916 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:24,933 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39634
om2_1        | 2021-06-28 10:24:24,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:29,233 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39660
om2_1        | 2021-06-28 10:24:29,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:33,435 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39692
om2_1        | 2021-06-28 10:24:33,442 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:42,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39738
om2_1        | 2021-06-28 10:24:42,774 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:49,327 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39772
om2_1        | 2021-06-28 10:24:49,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:53,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39796
om2_1        | 2021-06-28 10:24:53,350 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:24:57,562 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39812
om2_1        | 2021-06-28 10:24:57,568 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:18,972 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40048
om2_1        | 2021-06-28 10:25:18,986 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:23,019 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:23,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39280
om2_1        | 2021-06-28 10:25:23,032 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:27,555 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40092
om2_1        | 2021-06-28 10:25:27,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:30,269 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:30,270 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39330
om2_1        | 2021-06-28 10:25:30,282 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:30,869 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:30,869 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39340
om2_1        | 2021-06-28 10:25:30,875 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:33,997 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:33,998 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39376
om2_1        | 2021-06-28 10:25:34,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:37,159 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:37,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39400
om2_1        | 2021-06-28 10:25:37,168 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:37,794 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:37,794 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39410
om2_1        | 2021-06-28 10:25:37,801 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:38,354 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:38,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39418
om2_1        | 2021-06-28 10:25:38,362 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:41,880 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40222
om2_1        | 2021-06-28 10:25:41,886 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:44,367 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:44,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39452
om2_1        | 2021-06-28 10:25:44,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:45,041 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:45,042 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39462
om2_1        | 2021-06-28 10:25:45,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:45,136 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:45,137 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39468
om2_1        | 2021-06-28 10:25:45,143 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:45,460 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:45,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39482
om2_1        | 2021-06-28 10:25:45,464 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:48,210 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:48,211 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39502
om2_1        | 2021-06-28 10:25:48,220 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:50,958 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:50,959 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39516
om2_1        | 2021-06-28 10:25:50,962 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:51,237 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:51,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39522
om2_1        | 2021-06-28 10:25:51,244 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:51,460 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:51,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39530
om2_1        | 2021-06-28 10:25:51,479 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:19,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49846
om3_1        | 2021-06-28 10:22:19,084 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:23,117 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49872
om3_1        | 2021-06-28 10:22:23,123 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:29,852 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49904
om3_1        | 2021-06-28 10:22:29,855 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:36,214 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49954
om3_1        | 2021-06-28 10:22:36,224 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:42,813 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49986
om3_1        | 2021-06-28 10:22:42,821 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:49,446 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50018
om3_1        | 2021-06-28 10:22:49,452 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:53,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50046
om3_1        | 2021-06-28 10:22:53,663 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:22:57,917 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50060
om3_1        | 2021-06-28 10:22:57,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:02,233 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50084
om3_1        | 2021-06-28 10:23:02,235 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:06,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50138
om3_1        | 2021-06-28 10:23:06,854 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:11,047 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50162
om3_1        | 2021-06-28 10:23:11,049 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:15,582 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50180
om3_1        | 2021-06-28 10:23:15,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:19,489 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50202
om3_1        | 2021-06-28 10:23:19,495 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:23,687 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50228
om3_1        | 2021-06-28 10:23:23,692 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:28,014 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50248
om3_1        | 2021-06-28 10:23:28,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:31,876 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50270
om3_1        | 2021-06-28 10:23:31,881 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:36,026 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50312
om3_1        | 2021-06-28 10:23:36,031 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:40,249 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50330
om3_1        | 2021-06-28 10:23:40,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:44,067 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50352
om3_1        | 2021-06-28 10:23:44,070 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:44,655 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:08688-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-28 10:23:47,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50376
om3_1        | 2021-06-28 10:23:47,920 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:51,870 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50392
om3_1        | 2021-06-28 10:23:51,877 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:23:52,373 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:08688-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 2021-06-28 10:25:54,616 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:34,074 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-8A062D22326B->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:25:34,076 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:37,171 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:37,804 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:38,367 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:44,372 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:44,390 [qtp382627885-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-06734, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:25:44,420 [qtp382627885-24] INFO endpoint.BucketEndpoint: Location is /bucket-06734
s3g_1        | 2021-06-28 10:25:45,057 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:45,072 [qtp382627885-19] INFO rpc.RpcClient: Creating Bucket: s3v/boto-bucket999, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:25:45,086 [qtp382627885-19] INFO endpoint.BucketEndpoint: Location is /boto-bucket999
s3g_1        | 2021-06-28 10:25:45,146 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:45,249 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-90B35BCF2E26->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-28 10:23:55,883 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50416
om3_1        | 2021-06-28 10:23:55,889 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:00,411 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50440
om3_1        | 2021-06-28 10:24:00,413 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:00,935 [IPC Server handler 21 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket /08688-target/unreadable-link/null
om3_1        | 2021-06-28 10:24:04,806 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50486
om3_1        | 2021-06-28 10:24:04,815 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:08,962 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50508
om3_1        | 2021-06-28 10:24:08,968 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:09,505 [IPC Server handler 37 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket /08688-source/unreadable-bucket/
om3_1        | 2021-06-28 10:24:13,075 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50532
om3_1        | 2021-06-28 10:24:13,078 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:16,996 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50558
om3_1        | 2021-06-28 10:24:17,006 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:20,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50572
om3_1        | 2021-06-28 10:24:20,944 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:24,976 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50598
om3_1        | 2021-06-28 10:24:24,982 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:29,260 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50624
om3_1        | 2021-06-28 10:24:29,266 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:33,455 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50656
om3_1        | 2021-06-28 10:24:33,457 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-06-28 10:16:53,741 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
scm1.org_1   | 2021-06-28 10:16:53,840 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-06-28 10:16:54,642 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-06-28 10:16:54,896 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-06-28 10:16:54,910 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-06-28 10:16:55,415 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2021-06-28 10:16:55,415 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-06-28 10:16:55,482 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2021-06-28 10:16:59,979 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2021-06-28 10:16:59,998 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2021-06-28 10:17:00,000 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2021-06-28 10:17:05,405 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2021-06-28 10:17:07,343 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-06-28 10:17:07,343 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-06-28 10:17:07,729 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2021-06-28 10:17:07,729 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2021-06-28 10:17:07,742 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:00b677bc-7bb5-4c8c-9cb8-b10bc61671d0,clusterId:CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5,subject:scm-sub@scm1.org
scm1.org_1   | 2021-06-28 10:17:07,947 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2021-06-28 10:17:08,309 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2021-06-28 10:17:08,430 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-06-28 10:17:08,431 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-28 10:17:08,432 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2021-06-28 10:17:08,432 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-28 10:17:08,432 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-28 10:17:08,433 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-06-28 10:17:08,439 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-06-28 10:17:08,440 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-06-28 10:17:08,440 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-06-28 10:17:08,838 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-06-28 10:17:08,847 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-06-28 10:17:08,847 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-06-28 10:17:08,868 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-06-28 10:17:08,895 [main] INFO server.RaftServer: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: addNew group-5EB5CA0024F5:[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|priority:0] returns group-5EB5CA0024F5:java.util.concurrent.CompletableFuture@268cbb86[Not completed]
scm1.org_1   | 2021-06-28 10:17:08,936 [pool-2-thread-1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: new RaftServerImpl for group-5EB5CA0024F5:[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-06-28 10:17:08,939 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-06-28 10:17:08,940 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2021-06-28 10:17:08,940 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1        | 2021-06-28 10:25:45,249 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:45,469 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:45,532 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-58D1221012ED->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:25:45,533 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:48,225 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:48,312 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-9D9C46970865->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:25:48,313 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:50,964 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:51,251 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:17:08,940 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-06-28 10:17:08,940 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-06-28 10:17:08,940 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2021-06-28 10:17:08,941 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-06-28 10:17:08,946 [pool-2-thread-1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: ConfigurationManager, init=-1: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-06-28 10:17:08,946 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-06-28 10:17:08,957 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-06-28 10:17:08,958 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5 does not exist. Creating ...
scm1.org_1   | 2021-06-28 10:17:08,979 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/in_use.lock acquired by nodename 22@scm1.org
scm1.org_1   | 2021-06-28 10:17:09,001 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5 has been successfully formatted.
scm1.org_1   | 2021-06-28 10:17:09,005 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-06-28 10:17:09,008 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-06-28 10:17:09,025 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-06-28 10:17:09,030 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-06-28 10:17:09,046 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2021-06-28 10:17:09,052 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:09,056 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:09,058 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-06-28 10:17:09,068 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-06-28 10:17:09,071 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-06-28 10:17:09,080 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5
scm1.org_1   | 2021-06-28 10:17:09,081 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-06-28 10:17:09,081 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-06-28 10:17:09,082 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-06-28 10:17:09,082 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm1.org_1   | 2021-06-28 10:17:09,083 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2021-06-28 10:17:09,094 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2021-06-28 10:17:09,094 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2021-06-28 10:17:09,095 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2021-06-28 10:17:09,110 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2021-06-28 10:17:09,110 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2021-06-28 10:17:09,121 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-06-28 10:17:09,128 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-06-28 10:17:09,136 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2021-06-28 10:17:09,147 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-06-28 10:17:09,147 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-06-28 10:17:09,148 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2021-06-28 10:17:09,150 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2021-06-28 10:17:09,150 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-06-28 10:17:09,189 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:09,190 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:09,202 [pool-2-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:09,202 [pool-2-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:09,208 [main] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: start as a follower, conf=-1: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2021-06-28 10:17:09,210 [main] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2021-06-28 10:17:09,211 [main] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: start 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState
scm1.org_1   | 2021-06-28 10:17:09,439 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5EB5CA0024F5,id=00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
scm1.org_1   | 2021-06-28 10:17:09,444 [main] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:09,444 [main] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:09,446 [main] INFO server.RaftServer: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: start RPC server
scm1.org_1   | 2021-06-28 10:17:09,717 [main] INFO server.GrpcService: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: GrpcService started, listening on 9894
scm1.org_1   | 2021-06-28 10:17:09,735 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$329/0x00000008402fcc40@2121d1f9] INFO util.JvmPauseMonitor: JvmPauseMonitor-00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: Started
scm1.org_1   | 2021-06-28 10:17:14,412 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO impl.FollowerState: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5200943149ns, electionTimeout:5165ms
scm1.org_1   | 2021-06-28 10:17:14,413 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: shutdown 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState
scm1.org_1   | 2021-06-28 10:17:14,413 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2021-06-28 10:17:14,417 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2021-06-28 10:17:14,417 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: start 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1
om3_1        | 2021-06-28 10:24:42,799 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50702
om3_1        | 2021-06-28 10:24:42,805 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:49,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50736
om3_1        | 2021-06-28 10:24:49,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:53,374 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50760
om3_1        | 2021-06-28 10:24:53,384 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:24:57,590 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50776
om3_1        | 2021-06-28 10:24:57,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:19,020 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51012
om3_1        | 2021-06-28 10:25:19,031 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:23,059 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:23,062 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48346
om3_1        | 2021-06-28 10:25:23,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:27,577 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51056
om3_1        | 2021-06-28 10:25:27,583 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:30,293 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:30,294 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48396
om3_1        | 2021-06-28 10:25:30,301 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:30,881 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:30,881 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48406
om3_1        | 2021-06-28 10:25:30,894 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:34,010 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:34,011 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48442
om3_1        | 2021-06-28 10:25:34,018 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:37,176 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:37,176 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48466
om3_1        | 2021-06-28 10:25:37,185 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:37,807 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:37,808 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48476
om3_1        | 2021-06-28 10:25:37,814 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:38,371 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:38,371 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48484
om3_1        | 2021-06-28 10:25:38,377 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:41,911 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51186
om3_1        | 2021-06-28 10:25:41,917 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:44,378 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:44,379 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48518
om3_1        | 2021-06-28 10:25:44,384 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:45,061 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:54,617 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39556
om2_1        | 2021-06-28 10:25:54,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:54,901 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:54,902 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39564
om2_1        | 2021-06-28 10:25:54,904 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:55,058 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:55,059 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39570
om2_1        | 2021-06-28 10:25:55,062 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:55,243 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:55,243 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39578
om2_1        | 2021-06-28 10:25:55,245 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:58,868 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:58,871 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39594
om2_1        | 2021-06-28 10:25:58,878 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:58,984 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:58,985 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39602
om2_1        | 2021-06-28 10:25:58,985 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:59,049 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:59,049 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39608
om2_1        | 2021-06-28 10:25:59,054 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:59,137 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:59,137 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39614
om2_1        | 2021-06-28 10:25:59,138 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:59,179 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:59,180 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39620
om2_1        | 2021-06-28 10:25:59,182 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:25:59,279 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:25:59,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39626
om2_1        | 2021-06-28 10:25:59,286 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:02,016 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:02,017 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39650
om2_1        | 2021-06-28 10:26:02,019 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:02,177 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:02,178 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39658
om2_1        | 2021-06-28 10:26:02,181 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:02,241 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:02,242 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39664
om2_1        | 2021-06-28 10:26:02,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:02,637 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:02,638 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39690
om2_1        | 2021-06-28 10:26:02,653 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:45,061 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48528
om3_1        | 2021-06-28 10:25:45,066 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:45,150 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:45,151 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48534
om3_1        | 2021-06-28 10:25:45,158 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:45,473 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:45,474 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48548
om3_1        | 2021-06-28 10:25:45,479 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:48,230 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:48,230 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48568
om3_1        | 2021-06-28 10:25:48,236 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:50,968 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:50,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48582
om3_1        | 2021-06-28 10:25:50,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:51,257 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:51,257 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48588
om3_1        | 2021-06-28 10:25:51,260 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:51,501 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:51,501 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48598
om3_1        | 2021-06-28 10:25:51,513 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:54,633 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:54,633 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48622
om3_1        | 2021-06-28 10:25:54,640 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:54,930 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:54,930 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48630
om3_1        | 2021-06-28 10:25:54,936 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:55,070 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:55,071 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48636
om3_1        | 2021-06-28 10:25:55,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:55,271 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:55,272 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48646
om3_1        | 2021-06-28 10:25:55,281 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:58,902 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:58,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48660
om3_1        | 2021-06-28 10:25:58,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:58,991 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:58,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48668
om3_1        | 2021-06-28 10:25:58,993 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:59,062 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:59,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48674
om3_1        | 2021-06-28 10:25:59,064 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:59,145 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:59,146 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48680
om3_1        | 2021-06-28 10:25:59,147 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:59,187 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:59,187 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48686
om3_1        | 2021-06-28 10:25:59,192 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:25:59,291 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:25:59,292 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48692
om3_1        | 2021-06-28 10:25:59,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:02,028 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:02,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48716
om3_1        | 2021-06-28 10:26:02,030 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:02,186 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:02,187 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48724
om3_1        | 2021-06-28 10:26:02,188 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:02,253 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:02,253 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48730
om3_1        | 2021-06-28 10:26:02,254 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:02,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:02,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48756
om3_1        | 2021-06-28 10:26:02,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:02,796 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:02,797 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48762
om3_1        | 2021-06-28 10:26:02,798 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:02,843 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:14,424 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO impl.LeaderElection: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2021-06-28 10:17:14,425 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO impl.LeaderElection: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2021-06-28 10:17:14,425 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: shutdown 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1
scm1.org_1   | 2021-06-28 10:17:14,425 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2021-06-28 10:17:14,425 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: change Leader from null to 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0 at term 1 for becomeLeader, leader elected after 5420ms
scm1.org_1   | 2021-06-28 10:17:14,431 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2021-06-28 10:17:14,433 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:14,433 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:14,435 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2021-06-28 10:17:14,435 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-06-28 10:17:14,440 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2021-06-28 10:17:14,440 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2021-06-28 10:17:14,441 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2021-06-28 10:17:14,449 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: start 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl
scm1.org_1   | 2021-06-28 10:17:14,467 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2021-06-28 10:17:14,487 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: set configuration 0: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-06-28 10:17:14,527 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_0
scm1.org_1   | 2021-06-28 10:17:15,737 [main] INFO server.RaftServer: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: close
scm1.org_1   | 2021-06-28 10:17:15,738 [main] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: shutdown
scm1.org_1   | 2021-06-28 10:17:15,738 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5EB5CA0024F5,id=00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
scm1.org_1   | 2021-06-28 10:17:15,738 [main] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: shutdown 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl
scm1.org_1   | 2021-06-28 10:17:15,744 [main] INFO impl.PendingRequests: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2021-06-28 10:17:15,745 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:15,746 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:15,746 [main] INFO impl.StateMachineUpdater: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2021-06-28 10:17:15,747 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO impl.StateMachineUpdater: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2021-06-28 10:17:15,747 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO impl.StateMachineUpdater: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2021-06-28 10:17:15,752 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:15,753 [main] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: closes. applyIndex: 0
scm1.org_1   | 2021-06-28 10:17:15,754 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2021-06-28 10:17:15,755 [main] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker close()
scm1.org_1   | 2021-06-28 10:17:15,756 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:15,756 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:15,756 [main] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:15,757 [main] INFO server.GrpcService: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: shutdown server with port 9894 now
scm1.org_1   | 2021-06-28 10:17:15,764 [main] INFO server.GrpcService: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: shutdown server with port 9894 successfully
scm1.org_1   | 2021-06-28 10:17:15,764 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$329/0x00000008402fcc40@2121d1f9] INFO util.JvmPauseMonitor: JvmPauseMonitor-00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: Stopped
om2_1        | 2021-06-28 10:26:02,784 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:02,784 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39696
om2_1        | 2021-06-28 10:26:02,790 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:02,838 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:02,838 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39702
om2_1        | 2021-06-28 10:26:02,839 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:02,916 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:02,916 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39708
om2_1        | 2021-06-28 10:26:02,927 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:04,442 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:04,443 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39736
om2_1        | 2021-06-28 10:26:04,469 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:09,436 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:09,437 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39766
om2_1        | 2021-06-28 10:26:09,440 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:13,259 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40572
om2_1        | 2021-06-28 10:26:13,263 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:15,780 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:15,780 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39802
om2_1        | 2021-06-28 10:26:15,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:16,319 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:16,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39812
om2_1        | 2021-06-28 10:26:16,322 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:16,899 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:16,900 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39822
om2_1        | 2021-06-28 10:26:16,902 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:16,937 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-72545 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-28 10:26:17,483 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:17,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39830
om2_1        | 2021-06-28 10:26:17,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:21,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40634
om2_1        | 2021-06-28 10:26:21,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:23,983 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:23,983 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39876
om2_1        | 2021-06-28 10:26:23,984 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2021-06-28 10:27:53,502 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2687,entriesCount=1,lastEntry=(t:2, i:40)
datanode3_1  | 2021-06-28 10:27:53,522 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2690,entriesCount=1,lastEntry=(t:2, i:41)
datanode3_1  | 2021-06-28 10:27:53,525 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2692,entriesCount=1,lastEntry=(t:2, i:42)
datanode3_1  | 2021-06-28 10:27:53,563 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2698,entriesCount=1,lastEntry=(t:2, i:43)
datanode3_1  | 2021-06-28 10:27:54,326 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:57,398 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:27:59,900 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2948,entriesCount=1,lastEntry=(t:2, i:44)
datanode3_1  | 2021-06-28 10:27:59,912 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2949,entriesCount=1,lastEntry=(t:2, i:45)
datanode3_1  | 2021-06-28 10:27:59,916 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2950,entriesCount=1,lastEntry=(t:2, i:46)
datanode3_1  | 2021-06-28 10:27:59,925 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2952,entriesCount=1,lastEntry=(t:2, i:47)
datanode3_1  | 2021-06-28 10:28:00,471 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:03,308 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3200,entriesCount=1,lastEntry=(t:2, i:48)
datanode3_1  | 2021-06-28 10:28:03,315 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3201,entriesCount=1,lastEntry=(t:2, i:49)
datanode3_1  | 2021-06-28 10:28:03,327 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3203,entriesCount=1,lastEntry=(t:2, i:50)
datanode3_1  | 2021-06-28 10:28:03,331 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3206,entriesCount=1,lastEntry=(t:2, i:51)
datanode3_1  | 2021-06-28 10:28:06,614 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:09,089 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3455,entriesCount=1,lastEntry=(t:2, i:52)
datanode3_1  | 2021-06-28 10:28:09,209 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3456,entriesCount=1,lastEntry=(t:2, i:53)
datanode3_1  | 2021-06-28 10:28:09,238 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3457,entriesCount=1,lastEntry=(t:2, i:54)
datanode3_1  | 2021-06-28 10:28:09,241 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3458,entriesCount=1,lastEntry=(t:2, i:55)
datanode3_1  | 2021-06-28 10:28:09,262 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3461,entriesCount=1,lastEntry=(t:2, i:56)
datanode3_1  | 2021-06-28 10:28:09,275 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3463,entriesCount=1,lastEntry=(t:2, i:57)
datanode3_1  | 2021-06-28 10:28:09,686 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:12,702 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3713,entriesCount=1,lastEntry=(t:2, i:58)
datanode3_1  | 2021-06-28 10:28:12,711 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3714,entriesCount=1,lastEntry=(t:2, i:59)
datanode3_1  | 2021-06-28 10:28:12,762 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:12,785 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3715,entriesCount=1,lastEntry=(t:2, i:60)
datanode3_1  | 2021-06-28 10:28:12,914 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3716,entriesCount=1,lastEntry=(t:2, i:61)
datanode3_1  | 2021-06-28 10:28:12,915 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3717,entriesCount=1,lastEntry=(t:2, i:62)
datanode3_1  | 2021-06-28 10:28:12,933 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3719,entriesCount=1,lastEntry=(t:2, i:63)
datanode3_1  | 2021-06-28 10:28:15,830 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:16,262 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3960,entriesCount=1,lastEntry=(t:2, i:64)
datanode3_1  | 2021-06-28 10:28:16,262 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3961,entriesCount=1,lastEntry=(t:2, i:65)
datanode3_1  | 2021-06-28 10:28:16,278 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3962,entriesCount=1,lastEntry=(t:2, i:66)
datanode3_1  | 2021-06-28 10:28:16,280 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3963,entriesCount=1,lastEntry=(t:2, i:67)
datanode3_1  | 2021-06-28 10:28:18,902 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:21,979 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:25,046 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:25,568 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4217,entriesCount=1,lastEntry=(t:2, i:68)
datanode3_1  | 2021-06-28 10:28:25,632 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4218,entriesCount=1,lastEntry=(t:2, i:69)
datanode3_1  | 2021-06-28 10:28:25,666 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4219,entriesCount=1,lastEntry=(t:2, i:70)
datanode3_1  | 2021-06-28 10:28:25,698 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4220,entriesCount=1,lastEntry=(t:2, i:71)
datanode3_1  | 2021-06-28 10:28:25,700 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4221,entriesCount=1,lastEntry=(t:2, i:72)
datanode3_1  | 2021-06-28 10:28:25,719 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4224,entriesCount=1,lastEntry=(t:2, i:73)
datanode3_1  | 2021-06-28 10:28:28,118 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1        | 2021-06-28 10:25:30,863 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:33,971 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:33,971 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41056
om1_1        | 2021-06-28 10:25:33,987 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:37,144 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:37,145 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41080
om1_1        | 2021-06-28 10:25:37,151 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:37,771 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:37,771 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41090
om1_1        | 2021-06-28 10:25:37,786 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:38,334 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:38,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41098
om1_1        | 2021-06-28 10:25:38,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:41,826 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36424
om1_1        | 2021-06-28 10:25:41,838 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:44,355 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:44,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41132
om1_1        | 2021-06-28 10:25:44,359 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:45,028 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:45,030 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41142
om1_1        | 2021-06-28 10:25:45,035 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:45,120 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:45,120 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41148
om1_1        | 2021-06-28 10:25:45,129 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:45,450 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:45,451 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41162
om1_1        | 2021-06-28 10:25:45,453 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:48,181 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:48,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41182
om1_1        | 2021-06-28 10:25:48,201 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:50,950 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:50,950 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41196
om1_1        | 2021-06-28 10:25:50,953 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:51,212 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:51,213 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41202
om1_1        | 2021-06-28 10:25:51,229 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:51,421 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:51,422 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41210
om1_1        | 2021-06-28 10:25:51,428 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:54,603 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:54,604 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41236
om1_1        | 2021-06-28 10:25:54,607 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:54,865 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:54,866 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41242
om1_1        | 2021-06-28 10:25:54,878 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:55,035 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:55,037 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41250
om1_1        | 2021-06-28 10:25:55,044 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:55,175 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:55,178 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41258
om1_1        | 2021-06-28 10:25:55,217 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:58,852 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:58,853 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41274
om1_1        | 2021-06-28 10:25:58,860 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:58,968 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:58,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41282
om1_1        | 2021-06-28 10:25:58,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:59,034 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:59,035 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41288
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:51,489 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:51,566 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-EEB6A5F88561->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:25:51,588 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:51,767 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-2EF293365A9D->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:25:51,768 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:54,626 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:54,915 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode3_1  | 2021-06-28 10:28:31,190 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:33,438 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4480,entriesCount=1,lastEntry=(t:2, i:74)
datanode3_1  | 2021-06-28 10:28:33,510 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4481,entriesCount=1,lastEntry=(t:2, i:75)
datanode3_1  | 2021-06-28 10:28:33,511 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4482,entriesCount=1,lastEntry=(t:2, i:76)
datanode3_1  | 2021-06-28 10:28:33,511 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4483,entriesCount=1,lastEntry=(t:2, i:77)
datanode3_1  | 2021-06-28 10:28:33,543 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4485,entriesCount=1,lastEntry=(t:2, i:78)
datanode3_1  | 2021-06-28 10:28:33,723 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4494,entriesCount=1,lastEntry=(t:2, i:79)
datanode3_1  | 2021-06-28 10:28:33,887 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4498,entriesCount=1,lastEntry=(t:2, i:80)
datanode3_1  | 2021-06-28 10:28:33,887 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4499,entriesCount=1,lastEntry=(t:2, i:81)
datanode3_1  | 2021-06-28 10:28:34,033 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4512,entriesCount=1,lastEntry=(t:2, i:82)
datanode3_1  | 2021-06-28 10:28:34,158 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4524,entriesCount=1,lastEntry=(t:2, i:83)
datanode3_1  | 2021-06-28 10:28:34,158 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4525,entriesCount=1,lastEntry=(t:2, i:84)
datanode3_1  | 2021-06-28 10:28:34,262 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:37,334 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:40,407 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:43,482 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:46,550 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:49,622 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:50,033 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4781,entriesCount=1,lastEntry=(t:2, i:85)
datanode3_1  | 2021-06-28 10:28:50,126 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4782,entriesCount=1,lastEntry=(t:2, i:86)
datanode3_1  | 2021-06-28 10:28:50,168 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4783,entriesCount=1,lastEntry=(t:2, i:87)
datanode3_1  | 2021-06-28 10:28:50,168 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4784,entriesCount=1,lastEntry=(t:2, i:88)
datanode3_1  | 2021-06-28 10:28:50,176 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4785,entriesCount=1,lastEntry=(t:2, i:89)
datanode3_1  | 2021-06-28 10:28:50,233 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4789,entriesCount=1,lastEntry=(t:2, i:90)
datanode3_1  | 2021-06-28 10:28:50,246 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4792,entriesCount=1,lastEntry=(t:2, i:91)
datanode3_1  | 2021-06-28 10:28:50,259 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4795,entriesCount=1,lastEntry=(t:2, i:92)
datanode3_1  | 2021-06-28 10:28:55,376 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5049,entriesCount=1,lastEntry=(t:2, i:93)
datanode3_1  | 2021-06-28 10:28:55,498 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5050,entriesCount=1,lastEntry=(t:2, i:94)
datanode3_1  | 2021-06-28 10:28:55,584 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5051,entriesCount=1,lastEntry=(t:2, i:95)
datanode3_1  | 2021-06-28 10:28:55,715 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5052,entriesCount=1,lastEntry=(t:2, i:96)
datanode3_1  | 2021-06-28 10:28:55,736 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5053,entriesCount=1,lastEntry=(t:2, i:97)
datanode3_1  | 2021-06-28 10:28:55,766 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:28:55,988 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5077,entriesCount=1,lastEntry=(t:2, i:98)
datanode3_1  | 2021-06-28 10:28:55,988 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5078,entriesCount=1,lastEntry=(t:2, i:99)
datanode3_1  | 2021-06-28 10:28:55,988 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5079,entriesCount=1,lastEntry=(t:2, i:100)
datanode3_1  | 2021-06-28 10:28:58,842 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:01,910 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:04,982 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:08,054 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:11,126 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:13,349 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5332,entriesCount=1,lastEntry=(t:2, i:101)
datanode3_1  | 2021-06-28 10:29:13,350 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5333,entriesCount=1,lastEntry=(t:2, i:102)
datanode3_1  | 2021-06-28 10:29:13,361 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5334,entriesCount=1,lastEntry=(t:2, i:103)
datanode3_1  | 2021-06-28 10:29:13,365 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5335,entriesCount=1,lastEntry=(t:2, i:104)
datanode3_1  | 2021-06-28 10:29:14,200 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:17,270 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:20,346 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:23,414 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:26,486 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:29,558 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:31,794 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5589,entriesCount=1,lastEntry=(t:2, i:105)
datanode3_1  | 2021-06-28 10:29:31,808 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5590,entriesCount=1,lastEntry=(t:2, i:106)
datanode3_1  | 2021-06-28 10:29:31,815 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5593,entriesCount=1,lastEntry=(t:2, i:107)
datanode3_1  | 2021-06-28 10:29:31,822 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5595,entriesCount=1,lastEntry=(t:2, i:108)
datanode3_1  | 2021-06-28 10:29:32,631 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:35,702 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:37,072 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5842,entriesCount=1,lastEntry=(t:2, i:109)
datanode3_1  | 2021-06-28 10:29:37,079 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5843,entriesCount=1,lastEntry=(t:2, i:110)
datanode3_1  | 2021-06-28 10:29:37,085 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5844,entriesCount=1,lastEntry=(t:2, i:111)
datanode3_1  | 2021-06-28 10:29:37,085 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5845,entriesCount=1,lastEntry=(t:2, i:112)
datanode3_1  | 2021-06-28 10:29:38,774 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:44,918 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:47,990 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:51,062 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:29:54,134 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | 2021-06-28 10:26:02,843 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48768
om3_1        | 2021-06-28 10:26:02,850 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:02,932 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:02,932 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48774
om3_1        | 2021-06-28 10:26:02,934 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:04,478 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:04,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48802
om3_1        | 2021-06-28 10:26:04,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:09,450 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:09,451 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48832
om3_1        | 2021-06-28 10:26:09,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:13,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51536
om3_1        | 2021-06-28 10:26:13,282 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:15,789 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:15,790 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48868
om3_1        | 2021-06-28 10:26:15,791 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:16,327 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:16,327 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48878
om3_1        | 2021-06-28 10:26:16,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:16,909 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:16,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48888
om3_1        | 2021-06-28 10:26:16,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:16,928 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-72545 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-28 10:26:17,491 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:17,492 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48896
om3_1        | 2021-06-28 10:26:17,493 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:21,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51598
om3_1        | 2021-06-28 10:26:21,391 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:23,988 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:23,989 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48942
om3_1        | 2021-06-28 10:26:23,995 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:24,565 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:24,565 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48954
om3_1        | 2021-06-28 10:26:24,567 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:25,105 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:25,105 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48962
om3_1        | 2021-06-28 10:26:25,108 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:25,647 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:25,647 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:48972
om3_1        | 2021-06-28 10:26:25,648 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:25,666 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-28 10:26:29,163 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51668
om3_1        | 2021-06-28 10:26:29,169 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:31,775 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:31,776 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49010
om3_1        | 2021-06-28 10:26:31,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:59,036 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:59,127 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:59,129 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41294
om1_1        | 2021-06-28 10:25:59,130 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:59,172 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:59,173 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41300
om1_1        | 2021-06-28 10:25:59,174 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:25:59,264 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:25:59,264 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41306
om1_1        | 2021-06-28 10:25:59,273 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:01,998 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:01,999 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41330
om1_1        | 2021-06-28 10:26:02,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:02,164 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:02,166 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41338
om1_1        | 2021-06-28 10:26:02,171 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:02,232 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:02,234 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41344
om1_1        | 2021-06-28 10:26:02,236 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:02,564 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:02,564 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41364
om1_1        | 2021-06-28 10:26:02,584 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:02,769 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:02,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41376
om1_1        | 2021-06-28 10:26:02,775 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:02,832 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:02,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41382
om1_1        | 2021-06-28 10:26:02,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:02,909 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:02,909 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41388
om1_1        | 2021-06-28 10:26:02,911 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:04,419 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:04,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41416
om1_1        | 2021-06-28 10:26:04,423 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:09,427 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:09,427 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41446
om1_1        | 2021-06-28 10:26:09,431 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:13,227 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36774
om1_1        | 2021-06-28 10:26:13,238 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:15,771 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:15,772 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41482
om1_1        | 2021-06-28 10:26:15,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:16,314 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:16,314 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41492
om1_1        | 2021-06-28 10:26:16,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:16,887 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:16,887 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41502
om1_1        | 2021-06-28 10:26:16,895 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:16,952 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-72545 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-28 10:26:17,475 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:17,475 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41510
om1_1        | 2021-06-28 10:26:17,477 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:21,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36836
om1_1        | 2021-06-28 10:26:21,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:23,975 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:23,976 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41556
om1_1        | 2021-06-28 10:26:23,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:24,559 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:24,560 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39888
om2_1        | 2021-06-28 10:26:24,560 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:25,092 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:25,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39896
om2_1        | 2021-06-28 10:26:25,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:25,637 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:25,638 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39906
om2_1        | 2021-06-28 10:26:25,642 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:25,674 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-28 10:26:29,137 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40704
om2_1        | 2021-06-28 10:26:29,141 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:31,766 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:31,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39944
om2_1        | 2021-06-28 10:26:31,769 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:32,330 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:32,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39952
om2_1        | 2021-06-28 10:26:32,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:32,988 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:32,988 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:39978
om2_1        | 2021-06-28 10:26:32,997 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:36,501 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40782
om2_1        | 2021-06-28 10:26:36,512 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:39,175 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:39,175 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40014
om2_1        | 2021-06-28 10:26:39,180 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:39,675 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:39,676 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40022
om2_1        | 2021-06-28 10:26:39,682 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:43,314 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40828
om2_1        | 2021-06-28 10:26:43,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:45,834 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:45,835 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40058
om2_1        | 2021-06-28 10:26:45,836 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:46,367 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:46,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40068
om1_1        | 2021-06-28 10:26:24,552 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:24,553 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41568
om1_1        | 2021-06-28 10:26:24,554 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:25,077 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:25,083 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41576
om1_1        | 2021-06-28 10:26:25,085 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:25,628 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:25,629 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41586
om1_1        | 2021-06-28 10:26:25,633 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:25,673 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not exists
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-28 10:26:29,072 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36906
om1_1        | 2021-06-28 10:26:29,091 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:31,760 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:31,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41624
om1_1        | 2021-06-28 10:26:31,762 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:32,323 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:32,324 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41632
om1_1        | 2021-06-28 10:26:32,325 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:32,975 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:32,976 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41658
om1_1        | 2021-06-28 10:26:32,983 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:36,459 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36984
om1_1        | 2021-06-28 10:26:36,478 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:39,165 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:39,166 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41694
om1_1        | 2021-06-28 10:26:39,171 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:39,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:39,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41702
om1_1        | 2021-06-28 10:26:39,672 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:43,236 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37030
om1_1        | 2021-06-28 10:26:43,256 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:45,829 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:45,829 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41738
om1_1        | 2021-06-28 10:26:45,830 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:46,357 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:46,357 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41748
scm1.org_1   | 2021-06-28 10:17:15,765 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-06-28 10:17:15,767 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5; layoutVersion=0; scmId=00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
scm1.org_1   | 2021-06-28 10:17:15,783 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-06-28 10:17:17,343 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.10
scm1.org_1   | ************************************************************/
scm1.org_1   | 2021-06-28 10:17:17,354 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2021-06-28 10:17:17,432 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2021-06-28 10:17:17,432 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2021-06-28 10:17:17,469 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2021-06-28 10:17:17,470 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2021-06-28 10:17:17,507 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-06-28 10:17:18,021 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2021-06-28 10:17:18,119 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2021-06-28 10:17:18,122 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2423078939712.crt.
scm1.org_1   | 2021-06-28 10:17:18,126 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2021-06-28 10:17:18,284 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm1.org_1   | 2021-06-28 10:17:18,285 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2021-06-28 10:17:18,332 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-06-28 10:17:18,484 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2021-06-28 10:17:18,652 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2021-06-28 10:17:18,652 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2021-06-28 10:17:18,717 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
scm1.org_1   | 2021-06-28 10:17:18,836 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2021-06-28 10:17:18,907 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2021-06-28 10:17:18,908 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-28 10:17:18,909 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2021-06-28 10:17:18,909 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-28 10:17:18,910 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2021-06-28 10:17:18,911 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2021-06-28 10:17:18,917 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-06-28 10:17:18,917 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2021-06-28 10:17:18,918 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-06-28 10:17:19,549 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2021-06-28 10:17:19,550 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-06-28 10:17:19,551 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-06-28 10:17:19,560 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-06-28 10:17:19,562 [main] INFO server.RaftServer: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: found a subdirectory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5
scm1.org_1   | 2021-06-28 10:17:19,570 [main] INFO server.RaftServer: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: addNew group-5EB5CA0024F5:[] returns group-5EB5CA0024F5:java.util.concurrent.CompletableFuture@648c5fb3[Not completed]
scm1.org_1   | 2021-06-28 10:17:19,609 [pool-13-thread-1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: new RaftServerImpl for group-5EB5CA0024F5:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2021-06-28 10:17:19,612 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2021-06-28 10:17:19,612 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2021-06-28 10:17:19,612 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2021-06-28 10:17:19,613 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2021-06-28 10:17:19,613 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-06-28 10:17:19,613 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2021-06-28 10:17:19,614 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-06-28 10:17:19,617 [pool-13-thread-1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2021-06-28 10:17:19,618 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2021-06-28 10:17:19,620 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2021-06-28 10:17:19,634 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/in_use.lock acquired by nodename 8@scm1.org
scm1.org_1   | 2021-06-28 10:17:19,639 [pool-13-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=00b677bc-7bb5-4c8c-9cb8-b10bc61671d0} from /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/raft-meta
scm1.org_1   | 2021-06-28 10:17:19,670 [pool-13-thread-1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: set configuration 0: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-06-28 10:17:19,671 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2021-06-28 10:17:19,672 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2021-06-28 10:17:19,681 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2021-06-28 10:17:19,681 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2021-06-28 10:17:19,698 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2021-06-28 10:17:19,701 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:19,702 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:19,705 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-06-28 10:17:19,710 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2021-06-28 10:17:19,711 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2021-06-28 10:17:19,717 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5
scm1.org_1   | 2021-06-28 10:17:19,718 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2021-06-28 10:17:19,718 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2021-06-28 10:17:19,719 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
scm1.org_1   | 2021-06-28 10:17:19,720 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om3_1        | 2021-06-28 10:26:32,337 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:32,338 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49018
om3_1        | 2021-06-28 10:26:32,339 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:33,007 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:33,007 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49044
om3_1        | 2021-06-28 10:26:33,010 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:36,533 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51746
om3_1        | 2021-06-28 10:26:36,547 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:39,184 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:39,185 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49080
om3_1        | 2021-06-28 10:26:39,186 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:39,689 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:39,690 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49088
om3_1        | 2021-06-28 10:26:39,691 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:43,343 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51792
om3_1        | 2021-06-28 10:26:43,357 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:45,842 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:45,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49124
om3_1        | 2021-06-28 10:26:45,843 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:46,376 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:46,377 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49134
om3_1        | 2021-06-28 10:26:46,387 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:47,003 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:47,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49144
om3_1        | 2021-06-28 10:26:47,006 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:47,641 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:47,641 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49154
om3_1        | 2021-06-28 10:26:47,644 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:51,300 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:51,301 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49180
om3_1        | 2021-06-28 10:26:51,302 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:52,414 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:52,414 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49192
om3_1        | 2021-06-28 10:26:52,415 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:53,076 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:53,077 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49202
om3_1        | 2021-06-28 10:26:53,078 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:56,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:56,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49228
om3_1        | 2021-06-28 10:26:56,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:57,488 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:57,489 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49238
om3_1        | 2021-06-28 10:26:57,490 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:58,094 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:58,094 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49246
om3_1        | 2021-06-28 10:26:58,095 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:59,073 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:59,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49264
om3_1        | 2021-06-28 10:26:59,075 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:26:59,786 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:26:59,786 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49274
om3_1        | 2021-06-28 10:26:59,787 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:03,217 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:03,217 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49326
om3_1        | 2021-06-28 10:27:03,220 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:06,469 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:06,470 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49350
om3_1        | 2021-06-28 10:27:06,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:06,491 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-99943/37288/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2021-06-28 10:27:06,499 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 37288/multipartKey2 in Volume/Bucket s3v/bucket-99943
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 37288/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:464)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-28 10:27:07,004 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:07,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49358
om3_1        | 2021-06-28 10:27:07,006 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:07,586 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:07,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49370
om3_1        | 2021-06-28 10:27:07,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:07,618 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-99943/63229/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:55,066 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:55,235 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-78C8DD69A382->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:25:55,235 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:55,265 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:55,474 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-EEA94CDDE8A2->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:25:55,474 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:25:58,891 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode3_1  | 2021-06-28 10:29:57,206 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:00,278 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:03,350 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:06,426 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:09,066 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 110.
datanode3_1  | 2021-06-28 10:30:09,067 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 110.
datanode3_1  | 2021-06-28 10:30:09,084 [pool-36-thread-8] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 110.
datanode3_1  | 2021-06-28 10:30:09,495 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:12,566 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:15,642 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:18,710 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:21,782 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:24,854 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:27,930 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:34,070 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:37,146 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:40,214 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:43,286 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:46,358 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:49,430 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:52,502 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:55,574 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:30:58,646 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:01,718 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:04,790 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:07,862 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:09,037 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6130,entriesCount=1,lastEntry=(t:2, i:113)
datanode3_1  | 2021-06-28 10:31:09,053 [java.util.concurrent.ThreadPoolExecutor$Worker@3311e10f[State = -1, empty queue]] WARN server.GrpcLogAppender: 264e17c6-d8b4-4795-92be-7db9d85d28e1@group-6D6802BBD247->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6131,entriesCount=1,lastEntry=(t:2, i:114)
datanode3_1  | 2021-06-28 10:31:10,934 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:14,006 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:17,078 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:23,222 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:26,294 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:29,366 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:32,438 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:35,510 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:38,582 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:41,658 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:44,730 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:47,798 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:50,870 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:53,946 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:31:57,014 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:00,086 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:03,158 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:06,230 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:12,374 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:15,446 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:18,518 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:21,590 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:24,662 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:27,734 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:30,806 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:33,878 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:36,950 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:40,022 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:40,330 [pool-37-thread-4] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 138.
datanode3_1  | 2021-06-28 10:32:40,331 [pool-37-thread-4] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 138.
datanode3_1  | 2021-06-28 10:32:40,372 [pool-37-thread-4] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 138.
datanode3_1  | 2021-06-28 10:32:40,374 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 30 seconds.
datanode3_1  | 2021-06-28 10:32:43,096 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:46,166 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:49,242 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:52,314 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:32:55,382 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:01,526 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:04,598 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:07,670 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:10,747 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:13,814 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:16,886 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:19,962 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:23,031 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:26,102 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:29,174 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om2_1        | 2021-06-28 10:26:46,369 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:46,991 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:46,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40078
om2_1        | 2021-06-28 10:26:46,993 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:47,633 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:47,633 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40088
om2_1        | 2021-06-28 10:26:47,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:51,288 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:51,289 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40114
om2_1        | 2021-06-28 10:26:51,294 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:52,407 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:52,407 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40126
om2_1        | 2021-06-28 10:26:52,410 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:53,071 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:53,071 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40136
om2_1        | 2021-06-28 10:26:53,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:56,661 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:56,661 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40162
om2_1        | 2021-06-28 10:26:56,662 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:57,482 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:57,482 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40172
om2_1        | 2021-06-28 10:26:57,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:58,086 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:58,087 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40180
om2_1        | 2021-06-28 10:26:58,087 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:59,062 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:59,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40198
om2_1        | 2021-06-28 10:26:59,064 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:26:59,780 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:26:59,781 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40208
om2_1        | 2021-06-28 10:26:59,782 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:03,209 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:03,210 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40260
om2_1        | 2021-06-28 10:27:03,212 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:06,460 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:06,460 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40284
om2_1        | 2021-06-28 10:27:06,465 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:06,495 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-99943/37288/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2021-06-28 10:27:06,503 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 37288/multipartKey2 in Volume/Bucket s3v/bucket-99943
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 37288/multipartKey2. Entity too small.
datanode3_1  | 2021-06-28 10:33:32,250 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:35,322 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:38,390 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:41,465 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:44,534 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:50,678 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:53,750 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:56,822 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode3_1  | 2021-06-28 10:33:59,894 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:58,987 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:59,002 [qtp382627885-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-lepmkbmzpg, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:25:59,019 [qtp382627885-22] INFO endpoint.BucketEndpoint: Location is /bucket-lepmkbmzpg
s3g_1        | 2021-06-28 10:25:59,059 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:25:59,141 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
datanode3_1  | 2021-06-28 10:34:02,966 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2021-06-28 10:27:07,620 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3
om1_1        | 2021-06-28 10:26:46,364 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:46,982 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:46,983 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41758
om1_1        | 2021-06-28 10:26:46,986 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:47,622 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:47,623 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41768
om1_1        | 2021-06-28 10:26:47,624 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:51,279 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:51,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41794
om1_1        | 2021-06-28 10:26:51,284 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:52,399 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:52,400 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41806
om1_1        | 2021-06-28 10:26:52,402 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:53,060 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:53,061 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41816
om1_1        | 2021-06-28 10:26:53,066 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:56,654 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:56,655 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41842
om1_1        | 2021-06-28 10:26:56,656 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:26:57,474 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:57,474 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41852
scm1.org_1   | 2021-06-28 10:17:19,720 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 2021-06-28 10:26:57,476 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | Sleeping for 5 seconds
datanode3_1  | 2021-06-28 10:34:06,038 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | Sleeping for 5 seconds
scm1.org_1   | 2021-06-28 10:17:19,726 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:464)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om1_1        | 2021-06-28 10:26:58,078 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | Waiting for the service scm1.org:9894
datanode3_1  | 2021-06-28 10:34:09,110 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | Waiting for the service scm2.org:9894
scm1.org_1   | 2021-06-28 10:17:19,727 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 2021-06-28 10:26:58,079 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41860
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | 2021-06-28 10:25:59,183 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
datanode3_1  | 2021-06-28 10:34:12,182 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | 2021-06-28 10:17:19,728 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2021-06-28 10:26:58,081 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
datanode3_1  | 2021-06-28 10:34:15,258 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2021-06-28 10:17:19,736 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2021-06-28 10:26:59,056 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:26:59,057 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41878
scm2.org_1   | 2021-06-28 10:17:12,441 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
datanode3_1  | 2021-06-28 10:34:18,326 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | 2021-06-28 10:17:47,645 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | 2021-06-28 10:17:19,737 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 2021-06-28 10:26:59,058 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | /************************************************************
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode3_1  | 2021-06-28 10:34:21,398 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | /************************************************************
scm1.org_1   | 2021-06-28 10:17:19,759 [pool-13-thread-1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: set configuration 0: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 2021-06-28 10:26:59,771 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:08,179 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode3_1  | 2021-06-28 10:34:24,470 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | 2021-06-28 10:17:19,760 [pool-13-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_0
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2021-06-28 10:26:59,772 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41888
om3_1        | 2021-06-28 10:27:08,180 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49378
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode3_1  | 2021-06-28 10:34:27,543 [EndpointStateMachine task thread for recon/172.25.0.115:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.25.0.115:9891. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm1.org_1   | 2021-06-28 10:17:19,764 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2021-06-28 10:26:59,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:08,183 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-28 10:27:03,203 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:08,205 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-99943/63229/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
scm1.org_1   | 2021-06-28 10:17:19,764 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2021-06-28 10:27:03,203 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41940
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om2_1        | 2021-06-28 10:27:06,999 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:19,844 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
om3_1        | partName: "etag2"
om1_1        | 2021-06-28 10:27:03,205 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om2_1        | 2021-06-28 10:27:06,999 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40292
scm1.org_1   | 2021-06-28 10:17:19,845 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
om3_1        | ]
om1_1        | 2021-06-28 10:27:06,441 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om2_1        | 2021-06-28 10:27:07,000 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:19,845 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om3_1        | 2021-06-28 10:27:08,206 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om1_1        | 2021-06-28 10:27:06,441 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41964
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om2_1        | 2021-06-28 10:27:07,581 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:19,846 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | ************************************************************/
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3
om1_1        | 2021-06-28 10:27:06,456 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om2_1        | 2021-06-28 10:27:07,581 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40304
scm1.org_1   | 2021-06-28 10:17:19,847 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2021-06-28 10:17:47,696 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | ************************************************************/
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om1_1        | 2021-06-28 10:27:06,496 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-99943/37288/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om2_1        | 2021-06-28 10:27:07,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:19,848 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2021-06-28 10:17:48,094 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2021-06-28 10:17:12,449 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 2021-06-28 10:27:06,498 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 37288/multipartKey2 in Volume/Bucket s3v/bucket-99943
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2021-06-28 10:27:07,615 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-99943/63229/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
scm1.org_1   | 2021-06-28 10:17:19,867 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm3.org_1   | 2021-06-28 10:17:48,094 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2021-06-28 10:17:12,583 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 37288/multipartKey2. Entity too small.
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:17:19,867 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-06-28 10:17:48,218 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm2.org_1   | 2021-06-28 10:17:12,583 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | partName: "etag1"
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:464)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:17:19,872 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm3.org_1   | 2021-06-28 10:17:48,219 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm2.org_1   | 2021-06-28 10:17:12,674 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | , partNumber: 2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:17:19,873 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-06-28 10:17:48,250 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2021-06-28 10:17:12,675 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | partName: "etag2"
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
s3g_1        | 2021-06-28 10:25:59,288 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:17:19,879 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2021-06-28 10:17:48,877 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm2.org_1   | 2021-06-28 10:17:12,690 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | ]
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm1.org_1   | 2021-06-28 10:17:19,880 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2021-06-28 10:17:48,877 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2021-06-28 10:17:12,901 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-28 10:27:07,616 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:17:19,881 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2021-06-28 10:17:50,052 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2021-06-28 10:17:12,902 [main] INFO server.StorageContainerManager: SCM login successful.
om3_1        | 2021-06-28 10:27:08,802 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:17:20,146 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm3.org_1   | 2021-06-28 10:17:51,154 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2021-06-28 10:17:15,147 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2021-06-28 10:27:08,802 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49390
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:17:20,146 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2021-06-28 10:17:51,154 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2021-06-28 10:17:17,150 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2021-06-28 10:17:19,151 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:17:20,150 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2021-06-28 10:17:51,156 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2021-06-28 10:17:21,153 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2021-06-28 10:27:08,803 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 2021-06-28 10:27:06,991 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:17:20,152 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2021-06-28 10:17:52,279 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2021-06-28 10:17:23,156 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2021-06-28 10:27:12,458 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 2021-06-28 10:27:06,992 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41972
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:17:20,217 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2021-06-28 10:17:52,341 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm2.org_1   | 2021-06-28 10:17:25,339 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:00b677bc-7bb5-4c8c-9cb8-b10bc61671d0 is not the leader. Could not determine the leader node.
om3_1        | 2021-06-28 10:27:12,459 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49414
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 2021-06-28 10:27:06,995 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:17:20,333 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2021-06-28 10:17:52,342 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om3_1        | 2021-06-28 10:27:12,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2021-06-28 10:27:07,576 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:17:20,346 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
scm3.org_1   | 2021-06-28 10:17:52,359 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef,clusterId:CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5,subject:scm-sub@scm3.org
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:196)
om3_1        | 2021-06-28 10:27:16,161 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2021-06-28 10:27:07,576 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41982
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-28 10:17:53,145 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:108)
om3_1        | 2021-06-28 10:27:16,162 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49432
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-28 10:27:07,577 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:20,384 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-28 10:17:53,168 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5, SCMID 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13937)
om3_1        | 2021-06-28 10:27:16,163 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:08,166 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:07,620 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-99943/63229/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:17:20,401 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2021-06-28 10:17:53,168 [main] INFO server.StorageContainerManager: Primary SCM Node ID 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-28 10:27:19,375 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:08,167 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40312
om1_1        | partName: "etag1"
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:17:20,401 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2021-06-28 10:17:53,202 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-28 10:27:19,376 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49454
om2_1        | 2021-06-28 10:27:08,175 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | , partNumber: 2
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:17:20,457 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | /************************************************************
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 2021-06-28 10:27:19,386 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:08,224 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-99943/63229/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag2"
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:17:20,473 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-28 10:27:19,411 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om2_1        | partName: "etag1"
om1_1        | ]
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:17:20,482 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2021-06-28 10:17:20,485 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-99943/63229/multipartKey3106487875424092193
om2_1        | , partNumber: 1
om1_1        | 2021-06-28 10:27:07,621 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:17:20,492 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
scm3.org_1   | ************************************************************/
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
om2_1        | partName: "etag2"
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3
s3g_1        | 2021-06-28 10:25:59,361 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0ADEE27A3B62->264e17c6-d8b4-4795-92be-7db9d85d28e1
scm1.org_1   | 2021-06-28 10:17:20,496 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1        | ]
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
s3g_1        | 2021-06-28 10:25:59,363 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:20,499 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 2021-06-28 10:27:08,237 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
s3g_1        | 2021-06-28 10:26:02,023 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:17:20,501 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2021-06-28 10:17:54,793 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:17:20,527 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | /************************************************************
scm2.org_1   | 2021-06-28 10:17:27,341 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:17:20,533 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | 2021-06-28 10:17:29,343 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:17:20,534 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 2423078939712 on primary SCM
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm2.org_1   | 2021-06-28 10:17:31,484 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:17:20,538 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm3.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | 2021-06-28 10:17:32,145 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:17:20,565 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
scm2.org_1   | 2021-06-28 10:17:32,145 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:17:20,585 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
scm2.org_1   | 2021-06-28 10:17:32,146 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2021-06-28 10:27:19,930 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2021-06-28 10:27:08,157 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:17:21,363 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om3_1        | 2021-06-28 10:27:19,930 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49464
scm2.org_1   | 2021-06-28 10:17:32,678 [main] INFO ha.HASecurityUtils: Init response: GETCERT
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:17:21,364 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | STARTUP_MSG:   java = 11.0.10
om3_1        | 2021-06-28 10:27:19,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:32,712 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
om2_1        | 2021-06-28 10:27:08,796 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:08,158 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41992
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:17:21,382 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | ************************************************************/
om3_1        | 2021-06-28 10:27:19,946 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-99943/63229/multipartKey3106487875663822882
om2_1        | 2021-06-28 10:27:08,796 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40324
om1_1        | 2021-06-28 10:27:08,162 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:17:21,383 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2021-06-28 10:17:54,817 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
scm2.org_1   | 2021-06-28 10:17:32,713 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2021-06-28 10:27:08,797 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:08,204 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-99943/63229/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:17:21,401 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-06-28 10:17:54,946 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
scm2.org_1   | 2021-06-28 10:17:32,717 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:c72270bf-80b5-4b5a-a86a-6233c9fb41e8,clusterId:CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5,subject:scm-sub@scm2.org
om2_1        | 2021-06-28 10:27:12,450 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | partName: "etag1"
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:17:21,402 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2021-06-28 10:17:54,946 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm2.org_1   | 2021-06-28 10:17:34,154 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
om2_1        | 2021-06-28 10:27:12,450 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40348
om1_1        | , partNumber: 1
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:17:21,489 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | 2021-06-28 10:17:55,031 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm2.org_1   | 2021-06-28 10:17:34,178 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-eafdf580-9071-48e6-87f9-5eb5ca0024f5, SCMID c72270bf-80b5-4b5a-a86a-6233c9fb41e8
scm2.org_1   | 2021-06-28 10:17:34,178 [main] INFO server.StorageContainerManager: Primary SCM Node ID 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
om1_1        | partName: "etag2"
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | Container Balancer status:
scm3.org_1   | 2021-06-28 10:17:55,034 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm2.org_1   | 2021-06-28 10:17:34,218 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
om2_1        | 2021-06-28 10:27:12,453 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | ]
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | Key                            Value
scm3.org_1   | 2021-06-28 10:17:55,105 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | /************************************************************
om2_1        | 2021-06-28 10:27:16,156 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 2021-06-28 10:27:08,206 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | Running                        true
scm3.org_1   | 2021-06-28 10:17:55,622 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
om2_1        | 2021-06-28 10:27:16,156 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40366
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3
s3g_1        | 2021-06-28 10:26:02,182 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | Container Balancer Configuration values:
scm3.org_1   | 2021-06-28 10:17:55,733 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | ************************************************************/
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 2021-06-28 10:27:16,157 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | 2021-06-28 10:17:55,735 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2467937441448.crt.
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1        | 2021-06-28 10:27:19,366 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | Key                            Value
scm3.org_1   | 2021-06-28 10:17:55,740 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2021-06-28 10:27:20,452 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:19,366 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40388
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | Threshold                      0.1
scm1.org_1   | Max Datanodes to Balance       5
scm2.org_1   | 2021-06-28 10:17:36,459 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om3_1        | 2021-06-28 10:27:20,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49472
om2_1        | 2021-06-28 10:27:19,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm1.org_1   | Max Size to Move               10737418240B
scm3.org_1   | 2021-06-28 10:17:55,989 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | /************************************************************
om3_1        | 2021-06-28 10:27:20,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:19,416 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 
scm3.org_1   | 2021-06-28 10:17:55,990 [main] INFO server.StorageContainerManager: SCM login successful.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
om3_1        | 2021-06-28 10:27:20,480 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-99943/63229/multipartKey3
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-99943/63229/multipartKey3106487875424092193
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-28 10:17:21,489 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2021-06-28 10:17:56,054 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
om3_1        | 2021-06-28 10:27:20,481 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-06-28 10:17:21,489 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2021-06-28 10:17:56,423 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.2.0-SNAPSHOT
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-28 10:17:21,492 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2021-06-28 10:17:56,743 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0-a398b19-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.1.0-ff8aa66-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar
om1_1        | 2021-06-28 10:27:08,787 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:21,493 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2021-06-28 10:17:56,746 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:412)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/b7ecf8bcc04e2289873596c9dd0d991780c70a77 ; compiled by 'runner' on 2021-06-28T09:29Z
om1_1        | 2021-06-28 10:27:08,788 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42004
scm1.org_1   | 2021-06-28 10:17:21,493 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: start as a follower, conf=0: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2021-06-28 10:17:56,935 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef
scm3.org_1   | 2021-06-28 10:17:57,144 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm2.org_1   | STARTUP_MSG:   java = 11.0.10
om1_1        | 2021-06-28 10:27:08,791 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:21,510 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: changes role from      null to FOLLOWER at term 1 for startAsFollower
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-28 10:17:57,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | ************************************************************/
om1_1        | 2021-06-28 10:27:12,443 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:21,511 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: start 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-28 10:17:57,268 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2021-06-28 10:17:36,475 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2021-06-28 10:27:12,444 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42028
om1_1        | 2021-06-28 10:27:12,446 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:16,150 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:16,151 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42046
om1_1        | 2021-06-28 10:27:16,152 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:21,513 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5EB5CA0024F5,id=00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
scm2.org_1   | 2021-06-28 10:17:36,636 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2021-06-28 10:17:57,269 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm1.org_1   | 2021-06-28 10:17:21,514 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
scm2.org_1   | 2021-06-28 10:17:36,642 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
om2_1        | 2021-06-28 10:27:19,925 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:19,925 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40398
scm3.org_1   | 2021-06-28 10:17:57,276 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2021-06-28 10:17:21,514 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-28 10:17:36,749 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
om2_1        | 2021-06-28 10:27:19,926 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:19,359 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:17:57,276 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-28 10:17:21,516 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: start RPC server
scm2.org_1   | 2021-06-28 10:17:36,750 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
om2_1        | 2021-06-28 10:27:19,949 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
om1_1        | 2021-06-28 10:27:19,360 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42068
scm3.org_1   | 2021-06-28 10:17:57,278 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2021-06-28 10:17:57,280 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-06-28 10:17:21,594 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: GrpcService started, listening on 9894
scm2.org_1   | 2021-06-28 10:17:36,846 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-99943/63229/multipartKey3106487875663822882
om1_1        | 2021-06-28 10:27:19,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:17:57,280 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-28 10:17:21,600 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-06-28 10:17:37,856 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
om1_1        | 2021-06-28 10:27:19,419 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
scm3.org_1   | 2021-06-28 10:17:57,281 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
s3g_1        | 2021-06-28 10:26:02,249 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 2021-06-28 10:27:20,969 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:21,600 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2021-06-28 10:17:38,015 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-99943/63229/multipartKey3106487875424092193
scm3.org_1   | 2021-06-28 10:17:58,342 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 2021-06-28 10:27:20,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49484
scm1.org_1   | 2021-06-28 10:17:21,601 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$409/0x00000008404ef040@367fbb28] INFO util.JvmPauseMonitor: JvmPauseMonitor-00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: Started
scm2.org_1   | 2021-06-28 10:17:38,018 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/2448319313062.crt.
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
scm3.org_1   | 2021-06-28 10:17:58,345 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 2021-06-28 10:27:20,971 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:21,606 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2021-06-28 10:17:38,027 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
scm3.org_1   | 2021-06-28 10:17:58,350 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 2021-06-28 10:27:21,523 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:21,607 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2021-06-28 10:17:38,489 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm3.org_1   | 2021-06-28 10:17:58,373 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 2021-06-28 10:27:21,523 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49492
scm1.org_1   | 2021-06-28 10:17:21,702 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2021-06-28 10:17:38,489 [main] INFO server.StorageContainerManager: SCM login successful.
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm3.org_1   | 2021-06-28 10:17:58,390 [main] INFO server.RaftServer: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef: addNew group-5EB5CA0024F5:[] returns group-5EB5CA0024F5:java.util.concurrent.CompletableFuture@322e49ee[Not completed]
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2021-06-28 10:27:21,526 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:21,714 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2021-06-28 10:17:38,595 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm3.org_1   | 2021-06-28 10:17:58,435 [pool-13-thread-1] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef: new RaftServerImpl for group-5EB5CA0024F5:[] with SCMStateMachine:uninitialized
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 2021-06-28 10:27:22,457 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:21,714 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2021-06-28 10:17:38,946 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2021-06-28 10:17:58,440 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-28 10:27:22,458 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49506
scm1.org_1   | 2021-06-28 10:17:21,969 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2021-06-28 10:17:39,334 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.0-SNAPSHOT.jar!/network-topology-default.xml]
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 2021-06-28 10:17:58,440 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-28 10:27:22,459 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:21,969 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2021-06-28 10:17:39,334 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
om2_1        | 2021-06-28 10:27:20,447 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-06-28 10:17:58,441 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-28 10:27:23,040 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:21,985 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2021-06-28 10:17:39,533 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:c72270bf-80b5-4b5a-a86a-6233c9fb41e8
om2_1        | 2021-06-28 10:27:20,448 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40406
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 2021-06-28 10:17:58,442 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 2021-06-28 10:27:23,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49516
scm1.org_1   | 2021-06-28 10:17:22,007 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2021-06-28 10:17:39,751 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2021-06-28 10:17:39,915 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2021-06-28 10:27:19,914 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:17:58,442 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-28 10:27:23,041 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:39,916 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om2_1        | 2021-06-28 10:27:20,448 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:22,011 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
om1_1        | 2021-06-28 10:27:19,915 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42078
scm3.org_1   | 2021-06-28 10:17:58,442 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 2021-06-28 10:27:23,593 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:39,917 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2021-06-28 10:27:20,488 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-99943/63229/multipartKey3
scm1.org_1   | 2021-06-28 10:17:22,013 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2021-06-28 10:27:19,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:17:58,443 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-28 10:27:23,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49524
scm2.org_1   | 2021-06-28 10:17:39,917 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om2_1        | 2021-06-28 10:27:20,500 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
scm1.org_1   | 2021-06-28 10:17:22,022 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
om1_1        | 2021-06-28 10:27:19,953 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
scm3.org_1   | 2021-06-28 10:17:58,455 [pool-13-thread-1] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om3_1        | 2021-06-28 10:27:23,595 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:39,917 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3 because parts are in Invalid order.
scm1.org_1   | 2021-06-28 10:17:22,066 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-99943/63229/multipartKey3106487875663822882
scm3.org_1   | 2021-06-28 10:17:58,459 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 2021-06-28 10:27:23,615 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 56615/multipartKey5 in VolumeName/Bucket s3v/bucket-99943
scm2.org_1   | 2021-06-28 10:17:39,918 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:412)
scm1.org_1   | 2021-06-28 10:17:22,066 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:446)
scm3.org_1   | 2021-06-28 10:17:58,469 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-99943key: 56615/multipartKey5
scm2.org_1   | 2021-06-28 10:17:39,920 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
scm1.org_1   | 2021-06-28 10:17:22,068 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
scm3.org_1   | 2021-06-28 10:17:58,471 [pool-13-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5 does not exist. Creating ...
s3g_1        | 2021-06-28 10:26:02,655 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
scm2.org_1   | 2021-06-28 10:17:39,920 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm1.org_1   | 2021-06-28 10:17:22,069 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm3.org_1   | 2021-06-28 10:17:58,494 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/in_use.lock acquired by nodename 7@scm3.org
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm2.org_1   | 2021-06-28 10:17:39,921 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm1.org_1   | 2021-06-28 10:17:22,070 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm3.org_1   | 2021-06-28 10:17:58,566 [pool-13-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5 has been successfully formatted.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm2.org_1   | 2021-06-28 10:17:41,096 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm1.org_1   | 2021-06-28 10:17:22,153 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a9f8c2f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm3.org_1   | 2021-06-28 10:17:58,581 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm2.org_1   | 2021-06-28 10:17:41,099 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2021-06-28 10:17:22,182 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2021-06-28 10:17:58,583 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 2021-06-28 10:17:41,099 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-28 10:17:22,182 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 2021-06-28 10:17:58,617 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2021-06-28 10:17:41,108 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-06-28 10:17:22,183 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-06-28 10:17:58,617 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2021-06-28 10:17:41,127 [main] INFO server.RaftServer: c72270bf-80b5-4b5a-a86a-6233c9fb41e8: addNew group-5EB5CA0024F5:[] returns group-5EB5CA0024F5:java.util.concurrent.CompletableFuture@322e49ee[Not completed]
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-28 10:17:22,207 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @5925ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 2021-06-28 10:17:58,638 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-28 10:17:41,169 [pool-13-thread-1] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8: new RaftServerImpl for group-5EB5CA0024F5:[] with SCMStateMachine:uninitialized
om2_1        | 2021-06-28 10:27:20,963 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:22,301 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
om1_1        | 2021-06-28 10:27:20,433 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:17:58,639 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-28 10:27:24,150 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,172 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
om2_1        | 2021-06-28 10:27:20,964 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40418
scm1.org_1   | 2021-06-28 10:17:22,307 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2021-06-28 10:27:20,433 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42086
scm3.org_1   | 2021-06-28 10:17:58,640 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-28 10:27:24,150 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49546
scm2.org_1   | 2021-06-28 10:17:41,172 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2021-06-28 10:27:20,965 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:22,308 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
om1_1        | 2021-06-28 10:27:20,443 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:17:58,650 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om3_1        | 2021-06-28 10:27:24,151 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,172 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2021-06-28 10:27:21,517 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:22,308 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2021-06-28 10:27:20,487 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-99943/63229/multipartKey3
scm3.org_1   | 2021-06-28 10:17:58,660 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om3_1        | 2021-06-28 10:27:24,169 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-99943, Key75736/multipartKey. Exception:{}
scm2.org_1   | 2021-06-28 10:17:41,173 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2021-06-28 10:17:41,173 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2021-06-28 10:17:22,308 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2021-06-28 10:27:20,490 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 63229/multipartKey3 in Volume/Bucket s3v/bucket-99943
scm3.org_1   | 2021-06-28 10:17:58,661 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-06-28 10:17:41,173 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2021-06-28 10:27:21,518 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40426
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
scm1.org_1   | 2021-06-28 10:17:22,311 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3 because parts are in Invalid order.
scm3.org_1   | 2021-06-28 10:17:58,674 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 2021-06-28 10:17:41,174 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2021-06-28 10:27:21,519 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
scm1.org_1   | 2021-06-28 10:17:22,344 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:412)
scm3.org_1   | 2021-06-28 10:17:58,675 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm2.org_1   | 2021-06-28 10:17:41,178 [pool-13-thread-1] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
om2_1        | 2021-06-28 10:27:22,443 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:22,345 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:180)
scm3.org_1   | 2021-06-28 10:17:58,676 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
scm2.org_1   | 2021-06-28 10:17:41,178 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om2_1        | 2021-06-28 10:27:22,444 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40440
scm1.org_1   | 2021-06-28 10:17:22,386 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm3.org_1   | 2021-06-28 10:17:58,678 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
scm2.org_1   | 2021-06-28 10:17:41,183 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2021-06-28 10:27:22,451 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:22,387 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm3.org_1   | 2021-06-28 10:17:58,685 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
s3g_1        | 2021-06-28 10:26:02,791 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm2.org_1   | 2021-06-28 10:17:41,184 [pool-13-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5 does not exist. Creating ...
om2_1        | 2021-06-28 10:27:23,027 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:22,388 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm3.org_1   | 2021-06-28 10:17:58,688 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm2.org_1   | 2021-06-28 10:17:41,200 [pool-13-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/in_use.lock acquired by nodename 7@scm2.org
om2_1        | 2021-06-28 10:27:23,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40450
scm1.org_1   | 2021-06-28 10:17:22,402 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2021-06-28 10:17:58,697 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm2.org_1   | 2021-06-28 10:17:41,213 [pool-13-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5 has been successfully formatted.
om2_1        | 2021-06-28 10:27:23,036 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:22,410 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@37a0c3c6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 2021-06-28 10:17:58,701 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 2021-06-28 10:17:41,216 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
om2_1        | 2021-06-28 10:27:23,586 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:22,412 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@69542112{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-06-28 10:17:58,702 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2021-06-28 10:17:41,235 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2021-06-28 10:27:23,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40458
scm1.org_1   | 2021-06-28 10:17:22,518 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 2021-06-28 10:17:58,716 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2021-06-28 10:17:41,246 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2021-06-28 10:27:23,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:22,530 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@12ae75f1{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-12479980689952155542/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
om1_1        | 2021-06-28 10:27:20,954 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:17:58,719 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-28 10:17:41,247 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2021-06-28 10:27:23,620 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 56615/multipartKey5 in VolumeName/Bucket s3v/bucket-99943
scm1.org_1   | 2021-06-28 10:17:22,540 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@1b4ade78{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
om1_1        | 2021-06-28 10:27:20,954 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42098
scm3.org_1   | 2021-06-28 10:17:58,734 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-28 10:27:24,683 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,255 [pool-13-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-99943key: 56615/multipartKey5
scm1.org_1   | 2021-06-28 10:17:22,540 [Listener at 0.0.0.0/9860] INFO server.Server: Started @6258ms
om1_1        | 2021-06-28 10:27:20,958 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:17:58,735 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-28 10:27:24,684 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49554
scm2.org_1   | 2021-06-28 10:17:41,257 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
scm1.org_1   | 2021-06-28 10:17:22,543 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-06-28 10:27:21,503 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:17:58,757 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-28 10:27:24,688 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,258 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm1.org_1   | 2021-06-28 10:17:22,543 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-06-28 10:27:21,504 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42106
scm3.org_1   | 2021-06-28 10:17:58,763 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm2.org_1   | 2021-06-28 10:17:41,260 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm1.org_1   | 2021-06-28 10:17:22,544 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2021-06-28 10:17:24,537 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60620
scm3.org_1   | 2021-06-28 10:17:58,764 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2021-06-28 10:27:25,344 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-06-28 10:17:41,266 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm1.org_1   | 2021-06-28 10:17:24,553 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2021-06-28 10:27:21,513 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:22,437 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:25,344 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49562
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 2021-06-28 10:17:41,267 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2021-06-28 10:17:25,288 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:51406
om1_1        | 2021-06-28 10:27:22,438 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42120
scm3.org_1   | 2021-06-28 10:17:58,765 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2021-06-28 10:17:41,274 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: new c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5
scm2.org_1   | 2021-06-28 10:17:41,274 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2021-06-28 10:27:22,439 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:25,346 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-28 10:17:25,304 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-28 10:17:41,275 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2021-06-28 10:17:41,276 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 16384 (custom)
om1_1        | 2021-06-28 10:27:23,009 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:28,852 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2021-06-28 10:17:26,583 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO impl.FollowerState: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5072341073ns, electionTimeout:5068ms
scm2.org_1   | 2021-06-28 10:17:41,278 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm3.org_1   | 2021-06-28 10:17:58,767 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
om1_1        | 2021-06-28 10:27:23,014 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42130
om3_1        | 2021-06-28 10:27:28,853 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49578
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-28 10:17:41,283 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2021-06-28 10:17:58,769 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2021-06-28 10:27:23,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:28,854 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:26,585 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: shutdown 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState
om2_1        | 2021-06-28 10:27:24,139 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,289 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
s3g_1        | 2021-06-28 10:26:02,840 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm3.org_1   | 2021-06-28 10:17:58,817 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5
om1_1        | 2021-06-28 10:27:23,580 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:29,667 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:26,585 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om2_1        | 2021-06-28 10:27:24,139 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40480
scm2.org_1   | 2021-06-28 10:17:41,289 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm3.org_1   | 2021-06-28 10:17:58,820 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om1_1        | 2021-06-28 10:27:23,581 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42138
om3_1        | 2021-06-28 10:27:29,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49590
scm1.org_1   | 2021-06-28 10:17:26,588 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2021-06-28 10:27:24,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,290 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | 2021-06-28 10:17:58,845 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5
om1_1        | 2021-06-28 10:27:23,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:29,669 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:26,588 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-FollowerState] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: start 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1
om2_1        | 2021-06-28 10:27:24,173 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-99943, Key75736/multipartKey. Exception:{}
scm2.org_1   | 2021-06-28 10:17:41,303 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm3.org_1   | 2021-06-28 10:17:58,845 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om1_1        | 2021-06-28 10:27:23,617 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 56615/multipartKey5 in VolumeName/Bucket s3v/bucket-99943
om3_1        | 2021-06-28 10:27:30,396 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:26,604 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO impl.LeaderElection: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
scm2.org_1   | 2021-06-28 10:17:41,304 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 2021-06-28 10:17:58,864 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-99943key: 56615/multipartKey5
om3_1        | 2021-06-28 10:27:30,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49610
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
scm2.org_1   | 2021-06-28 10:17:41,311 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-06-28 10:17:26,605 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO impl.LeaderElection: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1 ELECTION round 0: result PASSED (term=2)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-06-28 10:17:58,865 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:148)
om3_1        | 2021-06-28 10:27:30,398 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
scm2.org_1   | 2021-06-28 10:17:41,312 [pool-13-thread-1] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2021-06-28 10:17:26,606 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: shutdown 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 2021-06-28 10:17:58,865 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 2021-06-28 10:27:30,997 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
scm2.org_1   | 2021-06-28 10:17:41,317 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2021-06-28 10:17:26,606 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-28 10:17:59,248 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 2021-06-28 10:27:30,998 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49618
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
scm2.org_1   | 2021-06-28 10:17:41,319 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2021-06-28 10:17:26,607 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-28 10:17:59,252 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 2021-06-28 10:27:31,004 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm2.org_1   | 2021-06-28 10:17:41,319 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2021-06-28 10:17:26,607 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-28 10:17:59,268 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 2021-06-28 10:27:31,547 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
scm2.org_1   | 2021-06-28 10:17:41,320 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2021-06-28 10:17:26,609 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: change Leader from null to 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0 at term 2 for becomeLeader, leader elected after 6936ms
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-28 10:17:59,272 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 2021-06-28 10:27:31,547 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49626
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm2.org_1   | 2021-06-28 10:17:41,322 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2021-06-28 10:17:26,616 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-28 10:17:59,467 [main] INFO node.SCMNodeManager: Entering startup safe mode.
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 2021-06-28 10:27:31,550 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 2021-06-28 10:17:41,323 [pool-13-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2021-06-28 10:17:26,618 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-28 10:17:59,663 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-28 10:27:32,367 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2021-06-28 10:17:41,347 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:26,618 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-28 10:17:59,696 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
om1_1        | 2021-06-28 10:27:24,130 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:32,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49636
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2021-06-28 10:17:41,347 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:26,621 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-28 10:17:59,815 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
om1_1        | 2021-06-28 10:27:24,130 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42160
om3_1        | 2021-06-28 10:27:32,414 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-28 10:17:41,350 [pool-13-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5
scm1.org_1   | 2021-06-28 10:17:26,621 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-28 10:17:59,846 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
om1_1        | 2021-06-28 10:27:24,135 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:32,737 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:24,675 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,351 [pool-13-thread-1] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:17:26,627 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-06-28 10:17:59,846 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
om1_1        | 2021-06-28 10:27:24,167 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-99943, Key75736/multipartKey. Exception:{}
om3_1        | 2021-06-28 10:27:32,739 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49660
om2_1        | 2021-06-28 10:27:24,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40488
scm2.org_1   | 2021-06-28 10:17:41,358 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2021-06-28 10:17:26,627 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1        | 2021-06-28 10:26:02,929 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm3.org_1   | 2021-06-28 10:17:59,899 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 2021-06-28 10:27:32,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:24,677 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,359 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2021-06-28 10:17:26,628 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm3.org_1   | 2021-06-28 10:17:59,943 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:708)
om3_1        | 2021-06-28 10:27:32,858 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:25,338 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,360 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2021-06-28 10:17:26,635 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO impl.RoleInfo: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: start 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | 2021-06-28 10:18:00,005 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:600)
om3_1        | 2021-06-28 10:27:32,862 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49674
om2_1        | 2021-06-28 10:27:25,339 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40496
scm2.org_1   | 2021-06-28 10:17:41,627 [main] INFO ha.SequenceIdGenerator: upgrade localId to 107544261427200000
scm1.org_1   | 2021-06-28 10:17:26,650 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm3.org_1   | 2021-06-28 10:18:00,020 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:577)
om3_1        | 2021-06-28 10:27:32,873 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:25,340 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,627 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2021-06-28 10:17:26,655 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_0 to /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_0-0
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 2021-06-28 10:18:00,039 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 5 milliseconds for processing 0 containers.
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:278)
om3_1        | 2021-06-28 10:27:32,914 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:28,846 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,632 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2021-06-28 10:17:26,672 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderElection1] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: set configuration 1: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-06-28 10:18:00,070 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 2021-06-28 10:27:32,914 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49678
om2_1        | 2021-06-28 10:27:28,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40512
scm2.org_1   | 2021-06-28 10:17:41,634 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2021-06-28 10:17:26,673 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 2021-06-28 10:18:00,088 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 2021-06-28 10:27:32,919 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:28,848 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,706 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2021-06-28 10:17:26,702 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-28 10:18:00,099 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 2021-06-28 10:27:36,764 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:29,660 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:29,660 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40524
om2_1        | 2021-06-28 10:27:29,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,799 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2021-06-28 10:18:00,164 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:17:26,703 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm2.org_1   | 2021-06-28 10:17:41,812 [main] INFO pipeline.PipelineStateManager: No pipeline exists in current db
om3_1        | 2021-06-28 10:27:36,764 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49706
scm3.org_1   | 2021-06-28 10:18:00,192 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
om2_1        | 2021-06-28 10:27:30,386 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:26,708 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-28 10:17:41,847 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
om3_1        | 2021-06-28 10:27:36,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:00,227 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
om2_1        | 2021-06-28 10:27:30,386 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40544
scm1.org_1   | 2021-06-28 10:17:26,709 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2021-06-28 10:17:41,856 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
om3_1        | 2021-06-28 10:27:37,336 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:01,875 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:17:26,709 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om2_1        | 2021-06-28 10:27:30,389 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,856 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
om3_1        | 2021-06-28 10:27:37,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49714
scm3.org_1   | 2021-06-28 10:18:01,876 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2021-06-28 10:18:01,959 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2021-06-28 10:18:01,970 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2021-06-28 10:17:26,710 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2021-06-28 10:17:26,718 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
om3_1        | 2021-06-28 10:27:37,342 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-28 10:18:02,038 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2021-06-28 10:27:24,670 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:26,752 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-28 10:27:30,990 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,904 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
om3_1        | 2021-06-28 10:27:37,479 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-28 10:18:02,051 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
om1_1        | 2021-06-28 10:27:24,670 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42168
scm1.org_1   | 2021-06-28 10:17:33,001 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:34458
om2_1        | 2021-06-28 10:27:30,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40552
scm2.org_1   | 2021-06-28 10:17:41,934 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
om3_1        | 2021-06-28 10:27:37,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49734
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-28 10:18:02,266 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
om1_1        | 2021-06-28 10:27:24,671 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:33,012 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om2_1        | 2021-06-28 10:27:30,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,970 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
om3_1        | 2021-06-28 10:27:37,488 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | Container Balancer status:
om1_1        | 2021-06-28 10:27:25,331 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:33,094 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: c72270bf-80b5-4b5a-a86a-6233c9fb41e8
om2_1        | 2021-06-28 10:27:31,528 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,977 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
om3_1        | 2021-06-28 10:27:37,488 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49738
s3g_1        | 2021-06-28 10:26:03,258 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-31340D966914->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
scm3.org_1   | Key                            Value
om1_1        | 2021-06-28 10:27:25,332 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42176
scm1.org_1   | 2021-06-28 10:17:33,255 [IPC Server handler 0 on default port 9961] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E8B72B2B9441->00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
om2_1        | 2021-06-28 10:27:31,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40560
scm2.org_1   | 2021-06-28 10:17:41,988 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 0 containers.
om3_1        | 2021-06-28 10:27:37,489 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-06-28 10:26:03,258 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | Running                        true
om1_1        | 2021-06-28 10:27:25,335 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:33,255 [IPC Server handler 0 on default port 9961] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 2021-06-28 10:27:31,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:41,991 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
om3_1        | 2021-06-28 10:27:37,491 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-06-28 10:26:04,471 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm3.org_1   | Container Balancer Configuration values:
om1_1        | 2021-06-28 10:27:28,839 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:33,854 [grpc-default-executor-2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
om2_1        | 2021-06-28 10:27:32,361 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:41,997 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:27:37,500 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:37,501 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49740
scm3.org_1   | Key                            Value
om1_1        | 2021-06-28 10:27:28,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42192
scm1.org_1   | 2021-06-28 10:17:33,855 [grpc-default-executor-2] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 2021-06-28 10:27:32,361 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40570
scm2.org_1   | 2021-06-28 10:17:42,000 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om3_1        | 2021-06-28 10:27:37,505 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm3.org_1   | Threshold                      0.1
om1_1        | 2021-06-28 10:27:28,842 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:34,008 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:27:32,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:42,033 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om3_1        | 2021-06-28 10:27:39,045 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | Max Datanodes to Balance       5
om1_1        | 2021-06-28 10:27:29,653 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:34,009 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om2_1        | 2021-06-28 10:27:32,663 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:32,663 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40594
om3_1        | 2021-06-28 10:27:39,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49758
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm3.org_1   | Max Size to Move               10737418240B
om1_1        | 2021-06-28 10:27:29,654 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42204
om2_1        | 2021-06-28 10:27:32,672 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:42,065 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-06-28 10:17:34,009 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om3_1        | 2021-06-28 10:27:39,047 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 
om1_1        | 2021-06-28 10:27:29,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:32,847 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:42,085 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2021-06-28 10:17:34,022 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 834160.316us
om3_1        | 2021-06-28 10:27:39,850 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-06-28 10:18:02,270 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om1_1        | 2021-06-28 10:27:30,366 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:32,849 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40608
scm2.org_1   | 2021-06-28 10:17:42,958 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-06-28 10:17:40,619 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60880
om3_1        | 2021-06-28 10:27:39,851 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49768
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 2021-06-28 10:18:02,270 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
om1_1        | 2021-06-28 10:27:30,366 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42224
om2_1        | 2021-06-28 10:27:32,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:42,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2021-06-28 10:17:40,651 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om3_1        | 2021-06-28 10:27:39,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-28 10:18:02,275 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
om2_1        | 2021-06-28 10:27:32,869 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:30,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:42,995 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-06-28 10:17:44,080 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:51710
om3_1        | 2021-06-28 10:27:40,764 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-28 10:18:02,277 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
om2_1        | 2021-06-28 10:27:32,869 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40612
om1_1        | 2021-06-28 10:27:30,985 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:43,002 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2021-06-28 10:17:44,113 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-28 10:27:40,764 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49778
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-28 10:18:02,282 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: start with initializing state, conf=-1: [], old=null
om2_1        | 2021-06-28 10:27:32,885 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:30,986 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42232
scm2.org_1   | 2021-06-28 10:17:43,051 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2021-06-28 10:17:44,116 [IPC Server handler 18 on default port 9863] INFO ha.SCMRatisServerImpl: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: Submitting SetConfiguration request to Ratis server with new SCM peers list: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0]
om3_1        | 2021-06-28 10:27:40,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-28 10:18:02,284 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: changes role from      null to FOLLOWER at term 0 for startInitializing
om2_1        | 2021-06-28 10:27:36,757 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:30,987 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:43,052 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2021-06-28 10:17:44,118 [IPC Server handler 18 on default port 9863] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: receive setConfiguration SetConfigurationRequest:client-38F4DAE72914->00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5, cid=0, seq=0, RW, null, peers:[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0]
om3_1        | 2021-06-28 10:27:41,363 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-28 10:18:02,286 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5EB5CA0024F5,id=11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef
om2_1        | 2021-06-28 10:27:36,758 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40640
om1_1        | 2021-06-28 10:27:31,521 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:43,310 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | 2021-06-28 10:17:44,118 [IPC Server handler 18 on default port 9863] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-38F4DAE72914->00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5, cid=0, seq=0, RW, null, peers:[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0]
om3_1        | 2021-06-28 10:27:41,364 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49788
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-28 10:18:02,292 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5
om2_1        | 2021-06-28 10:27:36,759 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:31,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42240
scm2.org_1   | Container Balancer status:
scm1.org_1   | 2021-06-28 10:17:44,135 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om3_1        | 2021-06-28 10:27:41,367 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-28 10:18:02,293 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 2021-06-28 10:27:37,331 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:37,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40648
scm2.org_1   | Key                            Value
scm1.org_1   | 2021-06-28 10:17:44,141 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2021-06-28 10:27:42,525 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om2_1        | 2021-06-28 10:27:37,333 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:31,524 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:02,305 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef: start RPC server
scm2.org_1   | Running                        true
scm1.org_1   | 2021-06-28 10:17:44,141 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 33554432 (custom)
om3_1        | 2021-06-28 10:27:42,526 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49812
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om2_1        | 2021-06-28 10:27:37,463 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:32,354 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:02,379 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef: GrpcService started, listening on 9894
scm2.org_1   | Container Balancer Configuration values:
scm1.org_1   | 2021-06-28 10:17:44,854 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$409/0x00000008404ef040@367fbb28] WARN util.JvmPauseMonitor: JvmPauseMonitor-00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: Detected pause in JVM or host machine (eg GC): pause of approximately 708019110ns.
om3_1        | 2021-06-28 10:27:42,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om2_1        | 2021-06-28 10:27:37,464 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40666
om1_1        | 2021-06-28 10:27:32,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42250
scm3.org_1   | 2021-06-28 10:18:02,389 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$391/0x00000008404d7040@57abe94d] INFO util.JvmPauseMonitor: JvmPauseMonitor-11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef: Started
scm2.org_1   | Key                            Value
scm1.org_1   | GC pool 'ParNew' had collection(s): count=1 time=116ms
om3_1        | 2021-06-28 10:27:43,072 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 2021-06-28 10:26:04,908 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1A26219660CB->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
om2_1        | 2021-06-28 10:27:37,467 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:32,357 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:02,404 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | Threshold                      0.1
scm1.org_1   | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=589ms
om3_1        | 2021-06-28 10:27:43,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49820
s3g_1        | 2021-06-28 10:26:04,908 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om2_1        | 2021-06-28 10:27:37,476 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:32,639 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:02,404 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | Max Datanodes to Balance       5
scm1.org_1   | 2021-06-28 10:17:45,119 [IPC Server handler 18 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2021-06-28 10:27:43,078 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 2021-06-28 10:26:09,441 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om2_1        | 2021-06-28 10:27:37,476 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40668
om1_1        | 2021-06-28 10:27:32,640 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42274
scm3.org_1   | 2021-06-28 10:18:02,405 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | Max Size to Move               10737418240B
scm1.org_1   | 2021-06-28 10:17:45,120 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2021-06-28 10:17:45,120 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2021-06-28 10:17:45,121 [IPC Server handler 18 on default port 9863] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5
om2_1        | 2021-06-28 10:27:37,480 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:32,658 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:10,802 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef
scm2.org_1   | 
om3_1        | 2021-06-28 10:27:43,990 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:45,127 [IPC Server handler 18 on default port 9863] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om2_1        | 2021-06-28 10:27:37,481 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:32,786 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:10,803 [grpc-default-executor-0] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-28 10:17:43,310 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om3_1        | 2021-06-28 10:27:43,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49830
scm1.org_1   | 2021-06-28 10:17:47,005 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: set configuration 5: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0], old=[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2021-06-28 10:17:47,463 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: set configuration 7: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0], old=null
om2_1        | 2021-06-28 10:27:37,481 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40672
om1_1        | 2021-06-28 10:27:32,787 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42284
scm3.org_1   | 2021-06-28 10:18:11,060 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2021-06-28 10:17:43,310 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
om3_1        | 2021-06-28 10:27:43,994 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:47,541 [IPC Server handler 18 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: c72270bf-80b5-4b5a-a86a-6233c9fb41e8.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
om2_1        | 2021-06-28 10:27:37,489 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:39,039 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:11,066 [grpc-default-executor-0] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: change Leader from null to 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0 at term 2 for appendEntries, leader elected after 12491ms
scm3.org_1   | 2021-06-28 10:18:11,074 [grpc-default-executor-0] INFO impl.RoleInfo: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef: start 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-FollowerState
om3_1        | 2021-06-28 10:27:45,157 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:49,364 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:34706
om2_1        | 2021-06-28 10:27:39,040 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40692
om1_1        | 2021-06-28 10:27:32,818 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm3.org_1   | 2021-06-28 10:18:11,521 [grpc-default-executor-0] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: set configuration 0: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-28 10:17:43,317 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
om3_1        | 2021-06-28 10:27:45,157 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49844
scm1.org_1   | 2021-06-28 10:17:49,440 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om2_1        | 2021-06-28 10:27:39,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:32,818 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42286
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 2021-06-28 10:18:11,530 [grpc-default-executor-0] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: set configuration 1: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-28 10:17:43,320 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
om3_1        | 2021-06-28 10:27:45,166 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:17:49,860 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:47332
om2_1        | 2021-06-28 10:27:39,844 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:32,823 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-06-28 10:18:11,531 [grpc-default-executor-0] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: set configuration 5: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2021-06-28 10:17:43,321 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: start with initializing state, conf=-1: [], old=null
om3_1        | 2021-06-28 10:27:45,762 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:17:49,906 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om2_1        | 2021-06-28 10:27:39,845 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40702
om1_1        | 2021-06-28 10:27:32,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 2021-06-28 10:18:11,543 [grpc-default-executor-0] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: set configuration 7: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2021-06-28 10:17:43,327 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: changes role from      null to FOLLOWER at term 0 for startInitializing
om3_1        | 2021-06-28 10:27:45,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49854
scm1.org_1   | 2021-06-28 10:17:52,691 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:49734
om2_1        | 2021-06-28 10:27:39,846 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:36,752 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-28 10:18:11,568 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2021-06-28 10:17:43,342 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5EB5CA0024F5,id=c72270bf-80b5-4b5a-a86a-6233c9fb41e8
scm2.org_1   | 2021-06-28 10:17:43,343 [Listener at 0.0.0.0/9860] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5
om2_1        | 2021-06-28 10:27:40,751 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:27:45,764 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:47,294 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-28 10:18:11,615 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2021-06-28 10:17:52,721 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2021-06-28 10:17:43,343 [Listener at 0.0.0.0/9860] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm2.org_1   | 2021-06-28 10:17:43,362 [Listener at 0.0.0.0/9860] INFO server.RaftServer: c72270bf-80b5-4b5a-a86a-6233c9fb41e8: start RPC server
om1_1        | 2021-06-28 10:27:36,753 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42320
om2_1        | 2021-06-28 10:27:40,752 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40712
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:17:52,731 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef
om3_1        | 2021-06-28 10:27:47,295 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49866
om1_1        | 2021-06-28 10:27:36,754 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:40,754 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm2.org_1   | 2021-06-28 10:17:43,443 [Listener at 0.0.0.0/9860] INFO server.GrpcService: c72270bf-80b5-4b5a-a86a-6233c9fb41e8: GrpcService started, listening on 9894
scm1.org_1   | 2021-06-28 10:17:52,816 [IPC Server handler 0 on default port 9961] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A092405AAC00->00b677bc-7bb5-4c8c-9cb8-b10bc61671d0
scm3.org_1   | 2021-06-28 10:18:11,917 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_0
om3_1        | 2021-06-28 10:27:47,297 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:37,320 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:41,355 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm2.org_1   | 2021-06-28 10:17:43,458 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$390/0x00000008404d7c40@2c9aeec6] INFO util.JvmPauseMonitor: JvmPauseMonitor-c72270bf-80b5-4b5a-a86a-6233c9fb41e8: Started
scm1.org_1   | 2021-06-28 10:17:52,819 [IPC Server handler 0 on default port 9961] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm3.org_1   | 2021-06-28 10:18:11,930 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_0 to /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_0-0
om3_1        | 2021-06-28 10:27:48,136 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:37,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42328
om2_1        | 2021-06-28 10:27:41,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40722
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-06-28 10:17:43,460 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm1.org_1   | 2021-06-28 10:17:53,028 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-28 10:18:11,980 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_1
om3_1        | 2021-06-28 10:27:48,136 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49880
om1_1        | 2021-06-28 10:27:37,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:41,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 2021-06-28 10:17:43,462 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm1.org_1   | 2021-06-28 10:17:53,057 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 243490.898us
scm3.org_1   | 2021-06-28 10:18:12,044 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:27:48,140 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:37,450 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:42,514 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm2.org_1   | 2021-06-28 10:17:43,462 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm1.org_1   | 2021-06-28 10:17:53,337 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:32842
scm3.org_1   | 2021-06-28 10:18:12,047 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
om3_1        | 2021-06-28 10:27:48,654 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:37,450 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42342
om2_1        | 2021-06-28 10:27:42,514 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40746
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm2.org_1   | 2021-06-28 10:17:46,316 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.c72270bf-80b5-4b5a-a86a-6233c9fb41e8
scm1.org_1   | 2021-06-28 10:17:53,362 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-28 10:18:12,056 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om3_1        | 2021-06-28 10:27:48,655 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49900
om1_1        | 2021-06-28 10:27:37,452 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:42,521 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-06-28 10:17:46,317 [grpc-default-executor-0] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm1.org_1   | 2021-06-28 10:18:05,003 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:47542
scm3.org_1   | 2021-06-28 10:18:12,080 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
om3_1        | 2021-06-28 10:27:48,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:37,452 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:43,066 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 2021-06-28 10:26:15,786 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm2.org_1   | 2021-06-28 10:17:46,411 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm1.org_1   | 2021-06-28 10:18:05,189 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2021-06-28 10:18:12,115 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
om3_1        | 2021-06-28 10:27:49,772 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:37,457 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42344
om2_1        | 2021-06-28 10:27:43,067 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40754
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm2.org_1   | 2021-06-28 10:17:46,412 [grpc-default-executor-0] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: change Leader from null to 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0 at term 2 for appendEntries, leader elected after 5196ms
scm1.org_1   | 2021-06-28 10:18:05,194 [IPC Server handler 18 on default port 9863] INFO ha.SCMRatisServerImpl: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: Submitting SetConfiguration request to Ratis server with new SCM peers list: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|priority:0]
scm3.org_1   | 2021-06-28 10:18:12,324 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2021-06-28 10:27:49,773 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49912
om1_1        | 2021-06-28 10:27:37,462 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:43,068 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm2.org_1   | 2021-06-28 10:17:46,416 [grpc-default-executor-0] INFO impl.RoleInfo: c72270bf-80b5-4b5a-a86a-6233c9fb41e8: start c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-FollowerState
scm1.org_1   | 2021-06-28 10:18:05,198 [IPC Server handler 18 on default port 9863] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: receive setConfiguration SetConfigurationRequest:client-38F4DAE72914->00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5, cid=1, seq=0, RW, null, peers:[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|priority:0]
scm3.org_1   | 2021-06-28 10:18:12,653 [grpc-default-executor-0] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: set configuration 11: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
om3_1        | 2021-06-28 10:27:49,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:37,463 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42346
om2_1        | 2021-06-28 10:27:43,986 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm2.org_1   | 2021-06-28 10:17:46,558 [grpc-default-executor-0] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: set configuration 0: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-06-28 10:18:05,202 [IPC Server handler 18 on default port 9863] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-38F4DAE72914->00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5, cid=1, seq=0, RW, null, peers:[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|priority:0]
scm3.org_1   | 2021-06-28 10:18:12,746 [grpc-default-executor-0] INFO server.RaftServer$Division: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5: set configuration 13: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2021-06-28 10:27:53,286 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:37,466 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:43,986 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40764
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 2021-06-28 10:17:46,558 [grpc-default-executor-0] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: set configuration 1: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2021-06-28 10:18:05,205 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm3.org_1   | 2021-06-28 10:18:13,172 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-5EB5CA0024F5:[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0]
om3_1        | 2021-06-28 10:27:53,286 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49928
om1_1        | 2021-06-28 10:27:37,478 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:27:43,987 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:18:05,205 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2021-06-28 10:17:46,608 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2021-06-28 10:18:13,189 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
om3_1        | 2021-06-28 10:27:53,287 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:27:53,878 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:45,150 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:18:05,205 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 33554432 (custom)
scm2.org_1   | 2021-06-28 10:17:46,684 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
om3_1        | 2021-06-28 10:27:53,878 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49938
om1_1        | 2021-06-28 10:27:39,034 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:39,035 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42372
om2_1        | 2021-06-28 10:27:45,151 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40778
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:18:06,330 [IPC Server handler 18 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm2.org_1   | 2021-06-28 10:17:46,880 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_0
om3_1        | 2021-06-28 10:27:53,881 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:39,036 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:39,833 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:27:45,152 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:18:06,338 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2021-06-28 10:17:46,887 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_0 to /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_0-0
om3_1        | 2021-06-28 10:27:54,477 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:39,833 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42382
scm3.org_1   | 2021-06-28 10:18:13,234 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:27:45,748 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:18:06,338 [IPC Server handler 18 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2021-06-28 10:17:46,906 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_1
om3_1        | 2021-06-28 10:27:54,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49956
om1_1        | 2021-06-28 10:27:39,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:13,242 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om2_1        | 2021-06-28 10:27:45,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40788
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:18:06,519 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$409/0x00000008404ef040@367fbb28] WARN util.JvmPauseMonitor: JvmPauseMonitor-00b677bc-7bb5-4c8c-9cb8-b10bc61671d0: Detected pause in JVM or host machine (eg GC): pause of approximately 578762093ns. No GCs detected.
scm2.org_1   | 2021-06-28 10:17:46,919 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:27:54,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:40,744 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:13,247 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om2_1        | 2021-06-28 10:27:45,756 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:18:08,981 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33008
scm2.org_1   | 2021-06-28 10:17:46,933 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
om3_1        | 2021-06-28 10:27:55,021 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:13,247 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
om2_1        | 2021-06-28 10:27:47,287 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:40,745 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42392
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:18:09,241 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-06-28 10:17:46,934 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om3_1        | 2021-06-28 10:27:55,021 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49966
scm3.org_1   | 2021-06-28 10:18:13,252 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2021-06-28 10:27:47,287 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40800
om1_1        | 2021-06-28 10:27:40,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:18:12,571 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: set configuration 11: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|priority:0], old=[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0]
scm2.org_1   | 2021-06-28 10:17:46,939 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
om3_1        | 2021-06-28 10:27:55,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:13,660 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:27:47,290 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:41,347 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:18:12,657 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-LeaderStateImpl] INFO server.RaftServer$Division: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5: set configuration 13: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|priority:0], old=null
scm2.org_1   | 2021-06-28 10:17:46,985 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2021-06-28 10:27:59,359 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:14,229 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2021-06-28 10:27:48,123 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:41,347 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42402
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:18:12,700 [IPC Server handler 18 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef.
scm2.org_1   | 2021-06-28 10:17:46,988 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
om3_1        | 2021-06-28 10:27:59,360 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:49984
scm3.org_1   | 2021-06-28 10:18:14,393 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2021-06-28 10:27:48,123 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40814
om1_1        | 2021-06-28 10:27:41,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:18:19,321 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:49932
scm2.org_1   | 2021-06-28 10:17:47,003 [grpc-default-executor-0] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: set configuration 5: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
om3_1        | 2021-06-28 10:27:59,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:14,393 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
om2_1        | 2021-06-28 10:27:48,131 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:27:42,502 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 2021-06-28 10:26:15,797 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-72545, with Versioning false and Storage Type set to DISK and Encryption set to false 
om2_1        | 2021-06-28 10:27:48,645 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 2021-06-28 10:26:15,809 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-72545
scm1.org_1   | 2021-06-28 10:18:19,362 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om3_1        | 2021-06-28 10:28:00,183 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:47,496 [grpc-default-executor-0] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: set configuration 7: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2021-06-28 10:27:42,503 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42426
scm3.org_1   | 2021-06-28 10:18:16,270 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$391/0x00000008404d7040@57abe94d] WARN util.JvmPauseMonitor: JvmPauseMonitor-11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef: Detected pause in JVM or host machine (eg GC): pause of approximately 171735288ns.
om2_1        | 2021-06-28 10:27:48,645 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40834
s3g_1        | 2021-06-28 10:26:16,323 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:18:22,445 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:28:00,184 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50000
scm2.org_1   | 2021-06-28 10:17:47,568 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:27:42,510 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=221ms
om2_1        | 2021-06-28 10:27:48,649 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:18:22,454 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 274417.742us
om3_1        | 2021-06-28 10:28:00,191 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:47,570 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om1_1        | 2021-06-28 10:27:43,051 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:16,815 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
om2_1        | 2021-06-28 10:27:49,766 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:18:29,528 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:38576
om3_1        | 2021-06-28 10:28:00,766 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:47,570 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om1_1        | 2021-06-28 10:27:43,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42434
scm3.org_1   | 2021-06-28 10:18:16,822 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-28 10:27:49,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40846
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:18:29,633 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-28 10:28:00,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50018
scm2.org_1   | 2021-06-28 10:17:47,743 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-5EB5CA0024F5:[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
om1_1        | 2021-06-28 10:27:43,062 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:16,998 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
om2_1        | 2021-06-28 10:27:49,767 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:18:29,735 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:47006
om3_1        | 2021-06-28 10:28:00,769 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:47,744 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
om1_1        | 2021-06-28 10:27:43,980 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:17,457 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
om2_1        | 2021-06-28 10:27:53,279 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:18:29,800 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-28 10:28:01,761 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:01,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50030
om1_1        | 2021-06-28 10:27:43,980 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42444
scm3.org_1   | 2021-06-28 10:18:17,464 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
om2_1        | 2021-06-28 10:27:53,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40862
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:18:30,652 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:34016
om3_1        | 2021-06-28 10:28:01,763 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:02,346 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:27:43,981 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:17,471 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-28 10:27:53,279 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 2021-06-28 10:28:02,347 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50038
scm2.org_1   | 2021-06-28 10:17:47,746 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2021-06-28 10:18:30,758 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2021-06-28 10:27:45,135 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:17,472 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
om2_1        | 2021-06-28 10:27:53,863 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1        | 2021-06-28 10:28:02,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:47,754 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2021-06-28 10:18:31,203 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43978
om1_1        | 2021-06-28 10:27:45,135 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42458
scm3.org_1   | 2021-06-28 10:18:17,909 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
om2_1        | 2021-06-28 10:27:53,863 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40872
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
om3_1        | 2021-06-28 10:28:03,091 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:47,998 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2021-06-28 10:18:31,238 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-06-28 10:27:45,141 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:17,918 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
om2_1        | 2021-06-28 10:27:53,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm2.org_1   | 2021-06-28 10:17:48,052 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2021-06-28 10:28:03,092 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50068
scm1.org_1   | 2021-06-28 10:18:31,242 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 1c475e88bcbd, UUID: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
om1_1        | 2021-06-28 10:27:45,731 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:17,919 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-28 10:27:54,471 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm2.org_1   | 2021-06-28 10:17:48,052 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
om3_1        | 2021-06-28 10:28:03,092 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:18:31,479 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:27:45,731 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42468
scm3.org_1   | 2021-06-28 10:18:17,934 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
om2_1        | 2021-06-28 10:27:54,471 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40890
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 2021-06-28 10:28:07,049 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52782
scm1.org_1   | 2021-06-28 10:18:31,572 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 183346.222us
om1_1        | 2021-06-28 10:27:45,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:17,951 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm2.org_1   | 2021-06-28 10:17:48,670 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
om2_1        | 2021-06-28 10:27:54,474 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:07,050 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:18:31,967 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49130
om1_1        | 2021-06-28 10:27:47,257 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:18,508 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm2.org_1   | 2021-06-28 10:17:48,761 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-28 10:27:55,010 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:09,594 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:18:32,108 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-06-28 10:27:47,257 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42480
scm3.org_1   | 2021-06-28 10:18:18,512 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm2.org_1   | 2021-06-28 10:17:48,762 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
om2_1        | 2021-06-28 10:27:55,011 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40900
om3_1        | 2021-06-28 10:28:09,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50112
scm1.org_1   | 2021-06-28 10:18:32,159 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn e668f0a27607, UUID: 264e17c6-d8b4-4795-92be-7db9d85d28e1
om1_1        | 2021-06-28 10:27:47,271 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:18,516 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
s3g_1        | 2021-06-28 10:26:16,339 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-02302, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm2.org_1   | 2021-06-28 10:17:48,814 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
om2_1        | 2021-06-28 10:27:55,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:09,596 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:18:32,441 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:27:48,116 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:19,780 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef
s3g_1        | 2021-06-28 10:26:16,353 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-02302
scm2.org_1   | 2021-06-28 10:17:48,818 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
om2_1        | 2021-06-28 10:27:59,335 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:10,147 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:18:32,562 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 187770.731us
om1_1        | 2021-06-28 10:27:48,116 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42494
scm3.org_1   | 2021-06-28 10:18:19,818 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 2423078939712 on Scm Bootstrap Node 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef
s3g_1        | 2021-06-28 10:26:16,906 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm2.org_1   | 2021-06-28 10:17:48,819 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-28 10:27:59,336 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40918
om3_1        | 2021-06-28 10:28:10,147 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50124
scm1.org_1   | 2021-06-28 10:18:36,436 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32978
om1_1        | 2021-06-28 10:27:48,117 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:19,948 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1da53092] INFO util.JvmPauseMonitor: Starting JVM pause monitor
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm2.org_1   | 2021-06-28 10:17:48,819 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
om2_1        | 2021-06-28 10:27:59,350 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:10,149 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:18:36,550 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-06-28 10:27:48,637 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:20,194 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm2.org_1   | 2021-06-28 10:17:48,937 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
om2_1        | 2021-06-28 10:28:00,174 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:10,677 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:18:36,552 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 0a2e2cce409d, UUID: 89aa20a7-dff6-484e-91c9-5fa0b70dff48
om1_1        | 2021-06-28 10:27:48,637 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42514
scm3.org_1   | 2021-06-28 10:18:20,195 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm2.org_1   | 2021-06-28 10:17:48,942 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
om2_1        | 2021-06-28 10:28:00,174 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40934
om3_1        | 2021-06-28 10:28:10,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50132
scm1.org_1   | 2021-06-28 10:18:37,062 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:27:48,642 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:20,196 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 2021-06-28 10:17:48,946 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2021-06-28 10:28:00,178 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:10,678 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:18:37,082 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 111820.756us
om1_1        | 2021-06-28 10:27:49,760 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:20,475 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @26942ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2021-06-28 10:17:48,947 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
om2_1        | 2021-06-28 10:28:00,758 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:11,404 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:18:40,998 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43432
om1_1        | 2021-06-28 10:27:49,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42526
scm3.org_1   | 2021-06-28 10:18:21,626 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm2.org_1   | 2021-06-28 10:17:48,947 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
om2_1        | 2021-06-28 10:28:00,758 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40952
om3_1        | 2021-06-28 10:28:11,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50144
scm1.org_1   | 2021-06-28 10:18:41,030 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-06-28 10:27:49,762 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:21,660 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om2_1        | 2021-06-28 10:28:00,759 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:11,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:18:41,092 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: cba5ac43-5979-4cf5-9dc7-4b165edb83b5
om1_1        | 2021-06-28 10:27:53,270 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:21,683 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm2.org_1   | 2021-06-28 10:17:49,089 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
om2_1        | 2021-06-28 10:28:01,755 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:11,963 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:18:41,547 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:27:53,270 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42542
scm3.org_1   | 2021-06-28 10:18:21,690 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm2.org_1   | 2021-06-28 10:17:49,089 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
om2_1        | 2021-06-28 10:28:01,755 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40964
om3_1        | 2021-06-28 10:28:11,963 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50152
scm1.org_1   | 2021-06-28 10:18:41,567 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 135785.008us
om1_1        | 2021-06-28 10:27:53,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:21,690 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm2.org_1   | 2021-06-28 10:17:49,097 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
om2_1        | 2021-06-28 10:28:01,758 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:11,966 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:18:41,592 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44002
om1_1        | 2021-06-28 10:27:53,849 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:21,717 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-06-28 10:17:49,565 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node c72270bf-80b5-4b5a-a86a-6233c9fb41e8
om2_1        | 2021-06-28 10:28:02,339 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:12,680 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:18:41,621 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-06-28 10:27:53,849 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42552
scm3.org_1   | 2021-06-28 10:18:21,996 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 2021-06-28 10:17:49,571 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 2423078939712 on Scm Bootstrap Node c72270bf-80b5-4b5a-a86a-6233c9fb41e8
om2_1        | 2021-06-28 10:28:02,339 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:40972
om2_1        | 2021-06-28 10:28:02,342 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:18:42,836 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36480
om1_1        | 2021-06-28 10:27:53,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:18:21,999 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
om2_1        | 2021-06-28 10:28:03,086 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:12,681 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50176
scm2.org_1   | 2021-06-28 10:17:49,691 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@402fcf14] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2021-06-28 10:18:42,866 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-06-28 10:27:54,466 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:18:22,177 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
om2_1        | 2021-06-28 10:28:03,087 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41002
om3_1        | 2021-06-28 10:28:12,681 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:49,822 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2021-06-28 10:18:42,867 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: f4bc9fda-abee-423f-be09-e243246978d4
om1_1        | 2021-06-28 10:27:54,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42570
scm3.org_1   | 2021-06-28 10:18:22,192 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2021-06-28 10:18:22,195 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
om2_1        | 2021-06-28 10:28:03,087 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:13,225 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:49,828 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2021-06-28 10:18:43,116 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-28 10:18:22,343 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om1_1        | 2021-06-28 10:27:54,467 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:07,026 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41818
om3_1        | 2021-06-28 10:28:13,225 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50188
scm2.org_1   | 2021-06-28 10:17:49,836 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2021-06-28 10:18:43,196 [IPC Server handler 1 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 171010.586us
scm3.org_1   | 2021-06-28 10:18:22,363 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1d2b49b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2021-06-28 10:26:16,920 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-72545, with Versioning false and Storage Type set to DISK and Encryption set to false 
om1_1        | 2021-06-28 10:27:54,996 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:07,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:13,226 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:49,904 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @15417ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2021-06-28 10:18:43,487 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51686
scm3.org_1   | 2021-06-28 10:18:22,366 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5a5cd0af{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | 2021-06-28 10:26:16,955 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-72545
om1_1        | 2021-06-28 10:27:54,997 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42580
om2_1        | 2021-06-28 10:28:09,583 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:16,443 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:50,234 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2021-06-28 10:18:43,521 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   | 2021-06-28 10:18:22,854 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 2021-06-28 10:26:17,486 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
om1_1        | 2021-06-28 10:27:55,006 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:09,583 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41046
om2_1        | 2021-06-28 10:28:09,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:50,258 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2021-06-28 10:18:43,526 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 47fbf1d7-c427-428f-a484-793022c98c39
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm3.org_1   | 2021-06-28 10:18:23,454 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
om1_1        | 2021-06-28 10:27:59,328 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:10,142 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:16,443 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50210
scm2.org_1   | 2021-06-28 10:17:50,260 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2021-06-28 10:18:43,858 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | 2021-06-28 10:18:23,512 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@33ccc8cd{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-14964019368473742256/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
om1_1        | 2021-06-28 10:27:59,329 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42598
om2_1        | 2021-06-28 10:28:10,143 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41058
om3_1        | 2021-06-28 10:28:16,444 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:50,260 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:18:43,911 [IPC Server handler 0 on default port 9961] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.security.x509.certificate.authority.CertificateStore.storeValidCertificate(java.math.BigInteger,java.security.cert.X509Certificate,org.apache.hadoop.hdds.protocol.proto.HddsProtos$NodeType) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 251695.469us
scm3.org_1   | 2021-06-28 10:18:23,674 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@1435feb6{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
om1_1        | 2021-06-28 10:27:59,330 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:10,143 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:17,000 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:50,260 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:18:44,019 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49158
scm3.org_1   | 2021-06-28 10:18:23,686 [Listener at 0.0.0.0/9860] INFO server.Server: Started @30154ms
om1_1        | 2021-06-28 10:28:00,167 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:10,671 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:17,000 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50218
scm2.org_1   | 2021-06-28 10:17:50,267 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:18:44,033 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   | 2021-06-28 10:18:23,748 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2021-06-28 10:28:00,167 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42614
om2_1        | 2021-06-28 10:28:10,671 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41066
om3_1        | 2021-06-28 10:28:17,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:50,330 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:18:46,558 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33010
scm3.org_1   | 2021-06-28 10:18:23,749 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2021-06-28 10:28:00,169 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:10,672 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:17,543 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:50,333 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:18:46,582 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   | 2021-06-28 10:18:23,751 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
om1_1        | 2021-06-28 10:28:00,741 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:11,398 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:17,543 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50226
scm2.org_1   | 2021-06-28 10:17:50,404 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:18:46,919 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33098
scm3.org_1   | 2021-06-28 10:18:31,493 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:00,741 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42632
om2_1        | 2021-06-28 10:28:11,398 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41078
om3_1        | 2021-06-28 10:28:17,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:50,404 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:18:47,081 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-28 10:18:32,467 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:00,743 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:11,400 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:18,070 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:50,415 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:18:59,527 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50034
scm3.org_1   | 2021-06-28 10:18:37,069 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:01,750 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:11,951 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:18,070 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50234
scm2.org_1   | 2021-06-28 10:17:50,463 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:18:59,570 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:18:41,538 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:01,750 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42644
om2_1        | 2021-06-28 10:28:11,952 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41086
om3_1        | 2021-06-28 10:28:18,073 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:50,471 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@105e9fef{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:19:02,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39260
scm3.org_1   | 2021-06-28 10:18:43,147 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:01,751 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:11,958 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:18,596 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:50,474 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6bc45472{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:19:02,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:18:43,895 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:02,332 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:12,675 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:18,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50252
scm2.org_1   | 2021-06-28 10:17:50,760 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:19:03,799 [IPC Server handler 64 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
scm3.org_1   | 2021-06-28 10:18:59,545 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40116
om1_1        | 2021-06-28 10:28:02,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42652
om2_1        | 2021-06-28 10:28:12,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41110
om3_1        | 2021-06-28 10:28:18,597 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:22,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52950
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:19:03,811 [IPC Server handler 64 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2506470198331, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-06-28 10:18:59,602 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:28:02,336 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:50,799 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7b491b89{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_0-SNAPSHOT_jar-_-any-3629273464494909522/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.0-SNAPSHOT.jar!/webapps/scm}
om2_1        | 2021-06-28 10:28:12,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
om3_1        | 2021-06-28 10:28:22,378 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:03,844 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm3.org_1   | 2021-06-28 10:19:02,014 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40040
om1_1        | 2021-06-28 10:28:03,080 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:50,827 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@5a349644{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
om2_1        | 2021-06-28 10:28:13,213 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 2021-06-28 10:26:17,500 [qtp382627885-20] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
om3_1        | 2021-06-28 10:28:24,931 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:03,904 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=585bdc5b-ad84-49e1-9117-a9418c9e01b7 to datanode:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
scm3.org_1   | 2021-06-28 10:19:02,042 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:28:03,081 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42682
scm2.org_1   | 2021-06-28 10:17:50,834 [Listener at 0.0.0.0/9860] INFO server.Server: Started @16347ms
om2_1        | 2021-06-28 10:28:13,214 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41122
s3g_1        | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
om3_1        | 2021-06-28 10:28:24,935 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50290
scm1.org_1   | 2021-06-28 10:19:03,917 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2021-06-28 10:19:03,482 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
om1_1        | 2021-06-28 10:28:03,082 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:50,844 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2021-06-28 10:28:13,217 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:519)
om3_1        | 2021-06-28 10:28:24,938 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:04,110 [IPC Server handler 70 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/264e17c6-d8b4-4795-92be-7db9d85d28e1
scm3.org_1   | 2021-06-28 10:19:03,503 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2506470198331, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om1_1        | 2021-06-28 10:28:06,990 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38018
scm2.org_1   | 2021-06-28 10:17:50,844 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2021-06-28 10:28:16,436 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:463)
om3_1        | 2021-06-28 10:28:25,494 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:04,374 [IPC Server handler 70 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2507416097209, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-06-28 10:19:03,618 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
om1_1        | 2021-06-28 10:28:07,002 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:17:50,846 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
om2_1        | 2021-06-28 10:28:16,436 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41144
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:454)
om3_1        | 2021-06-28 10:28:25,495 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50302
scm1.org_1   | 2021-06-28 10:19:04,377 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm3.org_1   | 2021-06-28 10:19:03,663 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
om1_1        | 2021-06-28 10:28:09,574 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:17:53,035 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-28 10:18:12,600 [grpc-default-executor-0] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: set configuration 11: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:385)
om3_1        | 2021-06-28 10:28:25,497 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:04,417 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56972
scm3.org_1   | 2021-06-28 10:19:04,014 [IPC Server handler 91 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/264e17c6-d8b4-4795-92be-7db9d85d28e1
om1_1        | 2021-06-28 10:28:09,574 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42726
scm2.org_1   | 2021-06-28 10:18:12,672 [grpc-default-executor-0] INFO server.RaftServer$Division: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5: set configuration 13: [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c72270bf-80b5-4b5a-a86a-6233c9fb41e8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2021-06-28 10:28:16,437 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
om3_1        | 2021-06-28 10:28:28,674 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:04,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:19:04,019 [IPC Server handler 91 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2507416097209, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om1_1        | 2021-06-28 10:28:09,579 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:18:22,480 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:16,995 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:94)
om3_1        | 2021-06-28 10:28:28,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50320
scm1.org_1   | 2021-06-28 10:19:04,486 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2021-06-28 10:19:04,029 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
om1_1        | 2021-06-28 10:28:10,129 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:18:31,499 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:16,996 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41152
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:239)
om3_1        | 2021-06-28 10:28:28,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:04,736 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 585bdc5b-ad84-49e1-9117-a9418c9e01b7, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:03.888Z].
scm3.org_1   | 2021-06-28 10:19:04,048 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
om1_1        | 2021-06-28 10:28:10,130 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42738
scm2.org_1   | 2021-06-28 10:18:32,496 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:16,996 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om3_1        | 2021-06-28 10:28:29,175 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:04,797 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-28 10:19:04,385 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38878
om1_1        | 2021-06-28 10:28:10,138 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:18:37,088 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:17,538 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om3_1        | 2021-06-28 10:28:29,176 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50328
scm1.org_1   | 2021-06-28 10:19:04,814 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 373203.314us
scm3.org_1   | 2021-06-28 10:19:04,416 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:28:10,662 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:18:41,520 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:17,538 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41160
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om3_1        | 2021-06-28 10:28:29,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:04,874 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6316ee16-cb24-4652-ad4f-ad5185786b12 to datanode:264e17c6-d8b4-4795-92be-7db9d85d28e1
scm3.org_1   | 2021-06-28 10:19:05,011 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 585bdc5b-ad84-49e1-9117-a9418c9e01b7, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:03.888Z].
om1_1        | 2021-06-28 10:28:10,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42746
scm2.org_1   | 2021-06-28 10:18:43,138 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:17,539 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om3_1        | 2021-06-28 10:28:29,711 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:04,909 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6316ee16-cb24-4652-ad4f-ad5185786b12, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:04.874Z].
scm3.org_1   | 2021-06-28 10:19:05,020 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:10,666 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:18:43,869 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:18,056 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
om3_1        | 2021-06-28 10:28:29,711 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50338
scm1.org_1   | 2021-06-28 10:19:04,918 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-28 10:19:05,023 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6316ee16-cb24-4652-ad4f-ad5185786b12, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:04.874Z].
om1_1        | 2021-06-28 10:28:11,386 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:18:59,437 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35590
om2_1        | 2021-06-28 10:28:18,056 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41168
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
om3_1        | 2021-06-28 10:28:29,712 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:04,918 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 43899.096us
scm3.org_1   | 2021-06-28 10:19:05,042 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:11,387 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42758
scm2.org_1   | 2021-06-28 10:18:59,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:18,064 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:18,586 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:30,229 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:06,675 [IPC Server handler 77 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/89aa20a7-dff6-484e-91c9-5fa0b70dff48
scm3.org_1   | 2021-06-28 10:19:06,684 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/89aa20a7-dff6-484e-91c9-5fa0b70dff48
scm3.org_1   | 2021-06-28 10:19:06,685 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2511752401050, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2021-06-28 10:19:06,686 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2021-06-28 10:19:06,687 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2021-06-28 10:19:06,689 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2021-06-28 10:19:06,689 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2021-06-28 10:19:02,011 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59066
om3_1        | 2021-06-28 10:28:30,229 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50346
om3_1        | 2021-06-28 10:28:30,231 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
om1_1        | 2021-06-28 10:28:11,390 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:18,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41186
scm1.org_1   | 2021-06-28 10:19:06,687 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
om3_1        | 2021-06-28 10:28:30,743 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:19:06,689 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2021-06-28 10:19:02,038 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
om1_1        | 2021-06-28 10:28:11,939 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:18,590 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:06,693 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=682582ca-26c3-4aee-8c4e-18130cb94390 to datanode:89aa20a7-dff6-484e-91c9-5fa0b70dff48
om3_1        | 2021-06-28 10:28:30,744 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50364
scm3.org_1   | 2021-06-28 10:19:06,690 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2021-06-28 10:19:03,478 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
om1_1        | 2021-06-28 10:28:11,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42766
om2_1        | 2021-06-28 10:28:22,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41984
scm1.org_1   | 2021-06-28 10:19:06,687 [IPC Server handler 77 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2511752401050, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om3_1        | 2021-06-28 10:28:30,744 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:19:06,698 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-06-28 10:19:03,506 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2506470198331, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om1_1        | 2021-06-28 10:28:11,946 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:22,337 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:06,784 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
om3_1        | 2021-06-28 10:28:31,199 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:19:06,803 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 682582ca-26c3-4aee-8c4e-18130cb94390, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:06.693Z].
scm2.org_1   | 2021-06-28 10:19:03,569 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
om1_1        | 2021-06-28 10:28:12,660 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:24,917 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:06,784 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
om3_1        | 2021-06-28 10:28:31,200 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50374
scm3.org_1   | 2021-06-28 10:19:06,807 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-28 10:19:03,694 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om1_1        | 2021-06-28 10:28:12,660 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42790
om2_1        | 2021-06-28 10:28:24,917 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41224
scm1.org_1   | 2021-06-28 10:19:06,789 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
om3_1        | 2021-06-28 10:28:31,205 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:19:07,041 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: cb80ed17-10cc-4c00-b001-6d6802bbd247, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:06.868Z].
scm2.org_1   | 2021-06-28 10:19:04,006 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om2_1        | 2021-06-28 10:28:24,920 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:12,670 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:06,796 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om3_1        | 2021-06-28 10:28:31,708 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:19:07,042 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-28 10:19:04,042 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2507416097209, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om2_1        | 2021-06-28 10:28:25,489 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:13,207 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:06,796 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
om3_1        | 2021-06-28 10:28:31,708 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50384
scm3.org_1   | 2021-06-28 10:19:07,246 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolling segment log-1_36 to index:36
scm2.org_1   | 2021-06-28 10:19:04,045 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om2_1        | 2021-06-28 10:28:25,490 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41236
om1_1        | 2021-06-28 10:28:13,208 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42802
scm1.org_1   | 2021-06-28 10:19:06,796 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
om3_1        | 2021-06-28 10:28:31,709 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:19:07,248 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_1 to /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_1-36
scm2.org_1   | 2021-06-28 10:19:04,061 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om2_1        | 2021-06-28 10:28:25,491 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:13,209 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:06,792 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 682582ca-26c3-4aee-8c4e-18130cb94390, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:06.693Z].
om3_1        | 2021-06-28 10:28:34,876 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:19:07,249 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_37
scm2.org_1   | 2021-06-28 10:19:04,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48368
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om2_1        | 2021-06-28 10:28:28,669 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:16,430 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:06,806 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:28:34,876 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50418
scm3.org_1   | 2021-06-28 10:19:07,292 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 181b9da4-4150-4912-9b2a-4435dcc970fa, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:07.170Z].
scm2.org_1   | 2021-06-28 10:19:04,518 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om2_1        | 2021-06-28 10:28:28,669 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41254
om1_1        | 2021-06-28 10:28:16,431 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42824
scm1.org_1   | 2021-06-28 10:19:06,824 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 122236.666us
om3_1        | 2021-06-28 10:28:34,877 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:19:07,303 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-28 10:19:05,049 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 585bdc5b-ad84-49e1-9117-a9418c9e01b7, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:03.888Z].
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om2_1        | 2021-06-28 10:28:28,670 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:16,432 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:06,868 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247 to datanode:89aa20a7-dff6-484e-91c9-5fa0b70dff48
om3_1        | 2021-06-28 10:28:35,467 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:19:07,449 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 6316ee16-cb24-4652-ad4f-ad5185786b12, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:264e17c6-d8b4-4795-92be-7db9d85d28e1, CreationTimestamp2021-06-28T10:19:04.874Z] moved to OPEN state
scm2.org_1   | 2021-06-28 10:19:05,080 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om2_1        | 2021-06-28 10:28:29,171 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:16,989 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:06,884 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247 to datanode:264e17c6-d8b4-4795-92be-7db9d85d28e1
scm1.org_1   | 2021-06-28 10:19:06,884 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247 to datanode:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
scm3.org_1   | 2021-06-28 10:19:07,689 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-28 10:19:05,088 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6316ee16-cb24-4652-ad4f-ad5185786b12, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:04.874Z].
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om2_1        | 2021-06-28 10:28:29,171 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41262
om1_1        | 2021-06-28 10:28:16,989 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42832
scm1.org_1   | 2021-06-28 10:19:07,033 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: cb80ed17-10cc-4c00-b001-6d6802bbd247, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:06.868Z].
om3_1        | 2021-06-28 10:28:35,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50426
scm3.org_1   | 2021-06-28 10:19:07,763 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@ca25638, cost 303703.259us
scm2.org_1   | 2021-06-28 10:19:05,102 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
om2_1        | 2021-06-28 10:28:29,172 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:16,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:07,049 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:28:35,468 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:19:08,870 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2021-06-28 10:19:06,665 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/89aa20a7-dff6-484e-91c9-5fa0b70dff48
scm2.org_1   | 2021-06-28 10:19:06,666 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 2511752401050, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2021-06-28 10:19:06,667 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2021-06-28 10:19:06,668 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
om1_1        | 2021-06-28 10:28:17,530 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:35,945 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:29,707 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm2.org_1   | 2021-06-28 10:19:06,673 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
om1_1        | 2021-06-28 10:28:17,531 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42840
scm3.org_1   | 2021-06-28 10:19:09,968 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 682582ca-26c3-4aee-8c4e-18130cb94390, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:89aa20a7-dff6-484e-91c9-5fa0b70dff48, CreationTimestamp2021-06-28T10:19:06.693Z] moved to OPEN state
scm1.org_1   | 2021-06-28 10:19:07,141 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 257024.559us
om3_1        | 2021-06-28 10:28:35,946 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50434
om2_1        | 2021-06-28 10:28:29,707 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41272
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm2.org_1   | 2021-06-28 10:19:06,673 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
om1_1        | 2021-06-28 10:28:17,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:19:09,969 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@ca25638, cost 960.302us
scm1.org_1   | 2021-06-28 10:19:07,170 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa to datanode:89aa20a7-dff6-484e-91c9-5fa0b70dff48
om3_1        | 2021-06-28 10:28:35,946 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:29,707 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm2.org_1   | 2021-06-28 10:19:06,673 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om1_1        | 2021-06-28 10:28:18,040 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:19:10,113 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-28 10:19:07,171 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa to datanode:264e17c6-d8b4-4795-92be-7db9d85d28e1
om3_1        | 2021-06-28 10:28:36,453 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:28:30,224 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm2.org_1   | 2021-06-28 10:19:06,684 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
om1_1        | 2021-06-28 10:28:18,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42848
scm3.org_1   | 2021-06-28 10:19:11,322 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-06-28 10:19:07,172 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa to datanode:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
om3_1        | 2021-06-28 10:28:36,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50450
om2_1        | 2021-06-28 10:28:30,224 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41280
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
scm2.org_1   | 2021-06-28 10:19:06,684 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
om1_1        | 2021-06-28 10:28:18,047 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:19:13,688 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-06-28 10:19:07,188 [RatisPipelineUtilsThread - 0] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolling segment log-1_36 to index:36
om3_1        | 2021-06-28 10:28:36,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:30,225 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
scm2.org_1   | 2021-06-28 10:19:06,797 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 682582ca-26c3-4aee-8c4e-18130cb94390, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:06.693Z].
om1_1        | 2021-06-28 10:28:18,577 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:19:15,943 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-06-28 10:19:07,201 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_1 to /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_1-36
om2_1        | 2021-06-28 10:28:30,737 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:36,999 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm2.org_1   | 2021-06-28 10:19:06,798 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:18,577 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42866
scm3.org_1   | 2021-06-28 10:19:22,230 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-28 10:19:07,206 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_37
om2_1        | 2021-06-28 10:28:30,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41298
om3_1        | 2021-06-28 10:28:36,999 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50460
om3_1        | 2021-06-28 10:28:37,002 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:18,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:07,022 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: cb80ed17-10cc-4c00-b001-6d6802bbd247, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:06.868Z].
scm3.org_1   | 2021-06-28 10:19:35,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40304
scm1.org_1   | 2021-06-28 10:19:07,267 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 181b9da4-4150-4912-9b2a-4435dcc970fa, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:07.170Z].
om3_1        | 2021-06-28 10:28:40,123 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om2_1        | 2021-06-28 10:28:30,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:22,226 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38184
scm2.org_1   | 2021-06-28 10:19:07,023 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-28 10:19:35,178 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:07,295 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:28:40,123 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50476
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om2_1        | 2021-06-28 10:28:31,195 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:22,266 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:07,230 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolling segment log-1_36 to index:36
scm3.org_1   | 2021-06-28 10:19:35,867 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40238
scm1.org_1   | 2021-06-28 10:19:07,304 [RatisPipelineUtilsThread - 0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 119327.659us
om3_1        | 2021-06-28 10:28:40,123 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om2_1        | 2021-06-28 10:28:31,195 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41308
om1_1        | 2021-06-28 10:28:24,906 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:07,232 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_1 to /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_1-36
scm3.org_1   | 2021-06-28 10:19:35,870 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:07,326 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerV2Impl: Pipeline: PipelineID=181b9da4-4150-4912-9b2a-4435dcc970fa contains same datanodes as previous pipelines: PipelineID=cb80ed17-10cc-4c00-b001-6d6802bbd247 nodeIds: 89aa20a7-dff6-484e-91c9-5fa0b70dff48, 264e17c6-d8b4-4795-92be-7db9d85d28e1, 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
om3_1        | 2021-06-28 10:28:40,656 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om2_1        | 2021-06-28 10:28:31,196 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:24,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42904
scm2.org_1   | 2021-06-28 10:19:07,234 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/eafdf580-9071-48e6-87f9-5eb5ca0024f5/current/log_inprogress_37
scm3.org_1   | 2021-06-28 10:19:35,871 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-06-28 10:19:07,482 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 6316ee16-cb24-4652-ad4f-ad5185786b12, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:264e17c6-d8b4-4795-92be-7db9d85d28e1, CreationTimestamp2021-06-28T10:19:04.874Z] moved to OPEN state
om3_1        | 2021-06-28 10:28:40,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50486
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om2_1        | 2021-06-28 10:28:31,703 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:24,909 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:07,318 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 181b9da4-4150-4912-9b2a-4435dcc970fa, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2021-06-28T10:19:07.170Z].
scm3.org_1   | 2021-06-28 10:19:36,176 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 585bdc5b-ad84-49e1-9117-a9418c9e01b7, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21, CreationTimestamp2021-06-28T10:19:03.888Z] moved to OPEN state
scm1.org_1   | 2021-06-28 10:19:07,588 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:28:40,656 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om2_1        | 2021-06-28 10:28:31,703 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41318
om1_1        | 2021-06-28 10:28:25,475 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:07,322 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-28 10:19:36,177 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@ca25638, cost 906.701us
scm1.org_1   | 2021-06-28 10:19:07,604 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 103937.025us
om3_1        | 2021-06-28 10:28:41,113 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
om2_1        | 2021-06-28 10:28:31,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:07,426 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 6316ee16-cb24-4652-ad4f-ad5185786b12, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:264e17c6-d8b4-4795-92be-7db9d85d28e1, CreationTimestamp2021-06-28T10:19:04.874Z] moved to OPEN state
scm3.org_1   | 2021-06-28 10:19:36,192 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-28 10:19:07,790 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om3_1        | 2021-06-28 10:28:41,114 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50496
om1_1        | 2021-06-28 10:28:25,477 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42916
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om2_1        | 2021-06-28 10:28:34,860 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:07,756 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-28 10:19:36,327 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: cb80ed17-10cc-4c00-b001-6d6802bbd247, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:264e17c6-d8b4-4795-92be-7db9d85d28e1, CreationTimestamp2021-06-28T10:19:06.868Z] moved to OPEN state
scm1.org_1   | 2021-06-28 10:19:08,865 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om3_1        | 2021-06-28 10:28:41,118 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:25,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om2_1        | 2021-06-28 10:28:34,861 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41352
scm2.org_1   | 2021-06-28 10:19:07,815 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1c93eb57, cost 364643.392us
scm3.org_1   | 2021-06-28 10:19:36,327 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-06-28 10:19:09,146 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:38700
om3_1        | 2021-06-28 10:28:41,584 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:28,660 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om2_1        | 2021-06-28 10:28:34,870 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:08,906 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-06-28 10:19:36,340 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@ca25638, cost 12608.327us
scm1.org_1   | 2021-06-28 10:19:09,277 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-28 10:28:41,585 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50504
om1_1        | 2021-06-28 10:28:28,660 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42934
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om2_1        | 2021-06-28 10:28:35,426 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:09,952 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 682582ca-26c3-4aee-8c4e-18130cb94390, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:89aa20a7-dff6-484e-91c9-5fa0b70dff48, CreationTimestamp2021-06-28T10:19:06.693Z] moved to OPEN state
scm3.org_1   | 2021-06-28 10:19:36,378 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-28 10:19:10,007 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 682582ca-26c3-4aee-8c4e-18130cb94390, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:89aa20a7-dff6-484e-91c9-5fa0b70dff48, CreationTimestamp2021-06-28T10:19:06.693Z] moved to OPEN state
om3_1        | 2021-06-28 10:28:41,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:28,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om2_1        | 2021-06-28 10:28:35,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41360
scm2.org_1   | 2021-06-28 10:19:09,954 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1c93eb57, cost 949.702us
scm3.org_1   | 2021-06-28 10:19:36,954 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
scm1.org_1   | 2021-06-28 10:19:10,048 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 2021-06-28 10:28:42,119 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:29,166 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
om2_1        | 2021-06-28 10:28:35,426 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:10,112 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2021-06-28 10:19:36,964 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2021-06-28 10:19:10,054 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 46070.299us
om3_1        | 2021-06-28 10:28:42,120 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50512
om1_1        | 2021-06-28 10:28:29,167 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42942
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om2_1        | 2021-06-28 10:28:35,939 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:11,341 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-06-28 10:19:36,964 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2021-06-28 10:19:10,077 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om3_1        | 2021-06-28 10:28:42,120 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:29,167 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
om2_1        | 2021-06-28 10:28:35,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41368
scm2.org_1   | 2021-06-28 10:19:13,704 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-06-28 10:19:36,964 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2021-06-28 10:19:11,079 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:47142
om3_1        | 2021-06-28 10:28:45,701 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53214
om1_1        | 2021-06-28 10:28:29,702 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om2_1        | 2021-06-28 10:28:35,940 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:15,979 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2021-06-28 10:19:36,964 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2021-06-28 10:19:11,139 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-28 10:28:45,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:29,703 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42952
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om2_1        | 2021-06-28 10:28:36,442 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:22,228 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2021-06-28 10:19:35,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35784
om2_1        | 2021-06-28 10:28:36,443 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41384
scm1.org_1   | 2021-06-28 10:19:11,326 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om1_1        | 2021-06-28 10:28:29,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:35,177 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:19:36,964 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
om3_1        | 2021-06-28 10:28:48,130 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:48,131 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50548
om2_1        | 2021-06-28 10:28:36,449 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:11,861 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:34152
om1_1        | 2021-06-28 10:28:30,217 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:35,917 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59270
om3_1        | 2021-06-28 10:28:48,131 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om2_1        | 2021-06-28 10:28:36,995 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:11,978 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2021-06-28 10:28:30,217 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42960
scm2.org_1   | 2021-06-28 10:19:35,923 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:48,672 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
scm3.org_1   | 2021-06-28 10:19:36,964 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
om2_1        | 2021-06-28 10:28:36,996 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41394
scm1.org_1   | 2021-06-28 10:19:13,674 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om1_1        | 2021-06-28 10:28:30,221 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:35,929 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om3_1        | 2021-06-28 10:28:48,672 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50564
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm3.org_1   | 2021-06-28 10:19:38,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39066
om2_1        | 2021-06-28 10:28:36,996 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:15,924 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om1_1        | 2021-06-28 10:28:30,731 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:48,673 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:36,156 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 585bdc5b-ad84-49e1-9117-a9418c9e01b7, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21, CreationTimestamp2021-06-28T10:19:03.888Z] moved to OPEN state
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
scm3.org_1   | 2021-06-28 10:19:38,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:19:50,741 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40320
scm1.org_1   | 2021-06-28 10:19:19,787 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43594
om1_1        | 2021-06-28 10:28:30,732 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42978
om3_1        | 2021-06-28 10:28:49,291 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:36,158 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1c93eb57, cost 1058.103us
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
om2_1        | 2021-06-28 10:28:40,118 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:19:50,745 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:19,833 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2021-06-28 10:28:30,733 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:49,292 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50580
scm2.org_1   | 2021-06-28 10:19:36,205 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om2_1        | 2021-06-28 10:28:40,119 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41410
scm3.org_1   | 2021-06-28 10:20:05,185 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40480
scm1.org_1   | 2021-06-28 10:19:22,216 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2021-06-28 10:28:31,188 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:31,189 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42986
scm2.org_1   | 2021-06-28 10:19:36,352 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
om2_1        | 2021-06-28 10:28:40,119 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:20:05,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:20:06,271 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
om1_1        | 2021-06-28 10:28:31,191 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:22,239 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 83452.176us
scm2.org_1   | 2021-06-28 10:19:36,357 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: cb80ed17-10cc-4c00-b001-6d6802bbd247, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:264e17c6-d8b4-4795-92be-7db9d85d28e1, CreationTimestamp2021-06-28T10:19:06.868Z] moved to OPEN state
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
om2_1        | 2021-06-28 10:28:40,646 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:31,697 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:31,697 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:42998
om3_1        | 2021-06-28 10:28:49,292 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:20:10,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40426
scm1.org_1   | 2021-06-28 10:19:22,266 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36664
scm2.org_1   | 2021-06-28 10:19:36,358 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1c93eb57, cost 1241.802us
scm2.org_1   | 2021-06-28 10:19:36,361 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:40,647 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41420
om1_1        | 2021-06-28 10:28:31,699 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:49,917 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:20:10,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:22,292 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-06-28 10:19:22,457 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33260
scm2.org_1   | 2021-06-28 10:19:36,953 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:40,648 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:28:41,109 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:49,917 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50592
om3_1        | 2021-06-28 10:28:49,918 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:50,561 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:28:50,561 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50602
om3_1        | 2021-06-28 10:28:50,562 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:51,073 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:20:11,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39250
om1_1        | 2021-06-28 10:28:34,853 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:36,967 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2021-06-28 10:19:36,968 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2021-06-28 10:19:36,968 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
om3_1        | 2021-06-28 10:28:51,074 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50610
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm3.org_1   | 2021-06-28 10:20:11,426 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:28:34,855 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43032
scm2.org_1   | 2021-06-28 10:19:36,968 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2021-06-28 10:19:22,480 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51870
om2_1        | 2021-06-28 10:28:41,109 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41430
om3_1        | 2021-06-28 10:28:51,074 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
scm3.org_1   | 2021-06-28 10:20:32,495 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40638
om1_1        | 2021-06-28 10:28:34,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:36,968 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2021-06-28 10:19:22,501 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om2_1        | 2021-06-28 10:28:41,110 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:51,110 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-82453, Key:92395/multidelete/f4.
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm3.org_1   | 2021-06-28 10:20:32,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:28:35,390 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:36,968 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2021-06-28 10:19:22,550 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2021-06-28 10:28:41,576 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm3.org_1   | 2021-06-28 10:20:32,666 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39368
om1_1        | 2021-06-28 10:28:35,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43040
scm2.org_1   | 2021-06-28 10:19:38,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48564
scm1.org_1   | 2021-06-28 10:19:34,217 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33312
om2_1        | 2021-06-28 10:28:41,577 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41438
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:133)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm3.org_1   | 2021-06-28 10:20:32,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40566
om1_1        | 2021-06-28 10:28:35,421 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:19:38,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:34,243 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2021-06-28 10:28:41,580 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
om1_1        | 2021-06-28 10:28:35,928 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:19:50,719 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59352
scm1.org_1   | 2021-06-28 10:19:35,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50228
om2_1        | 2021-06-28 10:28:42,115 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
scm3.org_1   | 2021-06-28 10:20:32,723 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om1_1        | 2021-06-28 10:28:35,928 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43048
scm2.org_1   | 2021-06-28 10:19:50,736 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:20:05,263 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35958
om2_1        | 2021-06-28 10:28:42,115 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41446
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
scm3.org_1   | 2021-06-28 10:20:32,743 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om1_1        | 2021-06-28 10:28:35,935 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:20:05,274 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:35,178 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:42,116 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
scm3.org_1   | 2021-06-28 10:21:02,660 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40796
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 2021-06-28 10:28:36,427 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:20:06,260 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
scm1.org_1   | 2021-06-28 10:19:35,850 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39454
om2_1        | 2021-06-28 10:28:45,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42250
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
scm3.org_1   | 2021-06-28 10:21:02,737 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2021-06-28 10:28:36,428 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43060
scm2.org_1   | 2021-06-28 10:20:10,103 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59454
scm1.org_1   | 2021-06-28 10:19:35,853 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:45,675 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2021-06-28 10:28:36,438 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:20:10,121 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:35,855 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om2_1        | 2021-06-28 10:28:48,124 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 2021-06-28 10:26:17,780 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
scm3.org_1   | 2021-06-28 10:21:02,761 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39526
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1        | 2021-06-28 10:28:36,991 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:20:11,419 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48744
scm1.org_1   | 2021-06-28 10:19:36,164 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 585bdc5b-ad84-49e1-9117-a9418c9e01b7, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:87b0b3c6-67c6-498c-a3d3-879b3c6d2c21, CreationTimestamp2021-06-28T10:19:03.888Z] moved to OPEN state
s3g_1        | <Error>
om2_1        | 2021-06-28 10:28:48,125 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41482
scm3.org_1   | 2021-06-28 10:21:02,786 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40726
om3_1        | 2021-06-28 10:28:51,645 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:36,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43074
scm2.org_1   | 2021-06-28 10:20:11,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:36,178 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        |   <Code>InvalidBucketName</Code>
om2_1        | 2021-06-28 10:28:48,126 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:21:02,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:51,645 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50618
om1_1        | 2021-06-28 10:28:36,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:20:32,508 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48866
scm1.org_1   | 2021-06-28 10:19:36,179 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 14472.93us
s3g_1        |   <Message>The specified bucket is not valid.</Message>
om2_1        | 2021-06-28 10:28:48,668 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:21:02,996 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:51,649 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:40,113 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:20:32,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59598
scm1.org_1   | 2021-06-28 10:19:36,201 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
s3g_1        |   <Resource>bucket_1</Resource>
om2_1        | 2021-06-28 10:28:48,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41498
scm3.org_1   | 2021-06-28 10:21:32,505 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40968
om3_1        | 2021-06-28 10:28:55,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53322
om1_1        | 2021-06-28 10:28:40,114 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43090
scm2.org_1   | 2021-06-28 10:20:32,604 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:19:36,324 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: cb80ed17-10cc-4c00-b001-6d6802bbd247, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:264e17c6-d8b4-4795-92be-7db9d85d28e1, CreationTimestamp2021-06-28T10:19:06.868Z] moved to OPEN state
s3g_1        |   <RequestId/>
om2_1        | 2021-06-28 10:28:48,669 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:21:32,546 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:55,019 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:40,114 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:20:32,648 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36128
scm1.org_1   | 2021-06-28 10:19:36,325 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2021-06-28 10:19:36,338 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
om2_1        | 2021-06-28 10:28:49,277 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:21:32,605 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40898
om3_1        | 2021-06-28 10:28:57,399 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:40,626 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:36,341 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 15948.233us
s3g_1        | </Error>
scm2.org_1   | 2021-06-28 10:20:32,675 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:49,277 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41514
scm3.org_1   | 2021-06-28 10:21:32,614 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:57,399 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50654
om1_1        | 2021-06-28 10:28:40,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43100
scm1.org_1   | 2021-06-28 10:19:36,341 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
s3g_1        | 
scm2.org_1   | 2021-06-28 10:20:32,697 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:49,288 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:21:32,659 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39704
om3_1        | 2021-06-28 10:28:57,400 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:40,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:36,341 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm2.org_1   | 2021-06-28 10:21:02,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49024
om2_1        | 2021-06-28 10:28:49,912 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:21:32,671 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:57,982 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:41,104 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:36,341 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:88)
scm2.org_1   | 2021-06-28 10:21:02,807 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36270
om2_1        | 2021-06-28 10:28:49,912 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41526
scm3.org_1   | 2021-06-28 10:22:02,510 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39878
om3_1        | 2021-06-28 10:28:57,983 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50662
om3_1        | 2021-06-28 10:28:57,983 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:36,341 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
scm2.org_1   | 2021-06-28 10:21:02,819 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59754
om2_1        | 2021-06-28 10:28:49,913 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:22:02,524 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:58,611 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:41,105 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43110
scm1.org_1   | 2021-06-28 10:19:36,342 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm2.org_1   | 2021-06-28 10:21:02,826 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:50,557 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:22:02,633 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41080
om3_1        | 2021-06-28 10:28:58,611 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50674
om1_1        | 2021-06-28 10:28:41,106 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:19:36,343 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm2.org_1   | 2021-06-28 10:21:02,850 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:50,557 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41536
scm3.org_1   | 2021-06-28 10:22:02,644 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41148
om3_1        | 2021-06-28 10:28:58,612 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:41,571 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:19:36,343 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om2_1        | 2021-06-28 10:28:50,558 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:22:02,651 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:59,112 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:41,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43118
scm2.org_1   | 2021-06-28 10:21:02,932 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2021-06-28 10:19:36,928 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 181b9da4-4150-4912-9b2a-4435dcc970fa, Nodes: 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:264e17c6-d8b4-4795-92be-7db9d85d28e1, CreationTimestamp2021-06-28T10:19:07.170Z] moved to OPEN state
om2_1        | 2021-06-28 10:28:51,065 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:22:02,680 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:28:59,113 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50684
om1_1        | 2021-06-28 10:28:41,572 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:21:32,569 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36446
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm1.org_1   | 2021-06-28 10:19:36,947 [EventQueue-PipelineReportForPipelineReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 17172.736us
om2_1        | 2021-06-28 10:28:51,066 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41544
scm3.org_1   | 2021-06-28 10:22:32,570 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41334
om3_1        | 2021-06-28 10:28:59,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:42,109 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:21:32,576 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49198
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2021-06-28 10:19:38,356 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57160
scm1.org_1   | 2021-06-28 10:19:38,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:51,068 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:28:59,672 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:42,109 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43126
scm2.org_1   | 2021-06-28 10:21:32,595 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm1.org_1   | 2021-06-28 10:19:42,920 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33380
scm3.org_1   | 2021-06-28 10:22:32,588 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40070
om2_1        | 2021-06-28 10:28:51,113 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-82453, Key:92395/multidelete/f4.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 2021-06-28 10:28:42,110 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:21:32,635 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm1.org_1   | 2021-06-28 10:19:42,933 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:133)
om3_1        | 2021-06-28 10:28:59,672 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50694
scm3.org_1   | 2021-06-28 10:22:32,597 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:28:45,609 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38452
scm2.org_1   | 2021-06-28 10:21:32,646 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59932
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2021-06-28 10:19:50,693 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39536
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
om3_1        | 2021-06-28 10:28:59,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:22:32,610 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:28:45,622 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:21:32,660 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm1.org_1   | 2021-06-28 10:19:50,703 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om3_1        | 2021-06-28 10:29:00,195 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:22:32,625 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41266
om1_1        | 2021-06-28 10:28:48,116 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:22:02,504 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49378
scm2.org_1   | 2021-06-28 10:22:02,511 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36626
scm1.org_1   | 2021-06-28 10:20:05,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50400
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
om3_1        | 2021-06-28 10:29:00,195 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50702
scm3.org_1   | 2021-06-28 10:22:32,630 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:22:02,528 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60108
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
om1_1        | 2021-06-28 10:28:48,116 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43162
scm1.org_1   | 2021-06-28 10:20:05,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 2021-06-28 10:29:00,197 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:23:00,054 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm2.org_1   | 2021-06-28 10:22:02,542 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
om1_1        | 2021-06-28 10:28:48,120 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:48,663 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 2021-06-28 10:29:00,873 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:23:02,546 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40236
scm2.org_1   | 2021-06-28 10:22:02,572 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
om1_1        | 2021-06-28 10:28:48,664 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43178
scm1.org_1   | 2021-06-28 10:20:05,969 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39024
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 2021-06-28 10:29:00,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50722
scm3.org_1   | 2021-06-28 10:23:02,587 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41506
scm2.org_1   | 2021-06-28 10:22:02,573 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
om1_1        | 2021-06-28 10:28:48,664 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:20:05,984 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1        | 2021-06-28 10:29:00,874 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:23:02,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41436
scm2.org_1   | 2021-06-28 10:22:32,492 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36814
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om1_1        | 2021-06-28 10:28:49,273 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:20:06,055 [IPC Server handler 60 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 46092.091us
om2_1        | 2021-06-28 10:28:51,640 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:29:01,430 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:23:02,618 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:22:32,500 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49562
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
om1_1        | 2021-06-28 10:28:49,273 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43194
scm1.org_1   | 2021-06-28 10:20:06,058 [IPC Server handler 60 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
om2_1        | 2021-06-28 10:28:51,641 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41552
om3_1        | 2021-06-28 10:29:01,430 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50734
scm3.org_1   | 2021-06-28 10:23:02,626 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:22:32,507 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om1_1        | 2021-06-28 10:28:49,274 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:20:06,198 [IPC Server handler 60 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 128532.854us
om2_1        | 2021-06-28 10:28:51,641 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:29:01,432 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:23:02,651 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:22:32,549 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
om1_1        | 2021-06-28 10:28:49,899 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:20:06,246 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 107544261427200000.
om2_1        | 2021-06-28 10:28:54,972 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42358
om3_1        | 2021-06-28 10:29:02,043 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:23:32,495 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41692
scm2.org_1   | 2021-06-28 10:22:32,554 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60298
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om1_1        | 2021-06-28 10:28:49,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43206
scm1.org_1   | 2021-06-28 10:20:06,249 [IPC Server handler 60 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 37651.774us
om2_1        | 2021-06-28 10:28:54,977 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:29:02,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50746
scm3.org_1   | 2021-06-28 10:23:32,512 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40424
scm2.org_1   | 2021-06-28 10:22:32,586 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
om1_1        | 2021-06-28 10:28:49,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:20:06,280 [IPC Server handler 60 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 27065.253us
om2_1        | 2021-06-28 10:28:57,385 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:29:02,055 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:23:32,518 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:22:41,990 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
om1_1        | 2021-06-28 10:28:50,551 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:20:06,281 [IPC Server handler 60 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 107544261427200000 to 107544261427201000.
om2_1        | 2021-06-28 10:28:57,385 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41588
om3_1        | 2021-06-28 10:29:03,050 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:23:32,567 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:23:02,556 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36984
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
om1_1        | 2021-06-28 10:28:50,552 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43216
scm1.org_1   | 2021-06-28 10:20:09,877 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49590
om2_1        | 2021-06-28 10:28:57,389 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:29:03,050 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50774
scm3.org_1   | 2021-06-28 10:23:32,571 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41626
scm2.org_1   | 2021-06-28 10:23:02,575 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60468
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
om1_1        | 2021-06-28 10:28:50,553 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:20:09,878 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om2_1        | 2021-06-28 10:28:57,976 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om3_1        | 2021-06-28 10:29:03,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:23:32,580 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:23:02,590 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49732
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om1_1        | 2021-06-28 10:28:51,059 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:20:10,102 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39646
om2_1        | 2021-06-28 10:28:57,978 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41596
om3_1        | 2021-06-28 10:29:03,615 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:24:02,511 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41868
scm2.org_1   | 2021-06-28 10:23:02,610 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om1_1        | 2021-06-28 10:28:51,059 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43224
scm1.org_1   | 2021-06-28 10:20:10,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:28:57,979 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:29:03,616 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50792
scm3.org_1   | 2021-06-28 10:24:02,530 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:23:02,626 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
om1_1        | 2021-06-28 10:28:51,060 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:20:10,965 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33440
om2_1        | 2021-06-28 10:28:58,606 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:24:02,532 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40600
scm2.org_1   | 2021-06-28 10:23:02,662 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:03,618 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
om1_1        | 2021-06-28 10:28:51,114 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-82453, Key:92395/multidelete/f4.
scm1.org_1   | 2021-06-28 10:20:10,973 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om2_1        | 2021-06-28 10:28:58,606 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41608
scm3.org_1   | 2021-06-28 10:24:02,571 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41800
scm2.org_1   | 2021-06-28 10:23:32,499 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37170
om3_1        | 2021-06-28 10:29:04,220 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm1.org_1   | 2021-06-28 10:20:10,999 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44454
om2_1        | 2021-06-28 10:28:58,607 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:24:02,577 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:23:32,513 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49922
om3_1        | 2021-06-28 10:29:04,221 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50802
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:133)
scm1.org_1   | 2021-06-28 10:20:11,013 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om2_1        | 2021-06-28 10:28:59,101 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:24:02,586 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:23:32,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:04,221 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:228)
scm1.org_1   | 2021-06-28 10:20:11,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57342
om2_1        | 2021-06-28 10:28:59,101 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41618
om2_1        | 2021-06-28 10:28:59,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:23:32,563 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:04,797 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:417)
om2_1        | 2021-06-28 10:28:59,666 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:24:32,494 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42052
scm3.org_1   | 2021-06-28 10:24:32,533 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40788
scm1.org_1   | 2021-06-28 10:20:11,445 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:04,797 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50814
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:242)
scm3.org_1   | 2021-06-28 10:24:32,559 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:23:32,565 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60654
om2_1        | 2021-06-28 10:28:59,666 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41628
om2_1        | 2021-06-28 10:28:59,667 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2021-06-28 10:29:04,805 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2021-06-28 10:24:32,585 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41986
om2_1        | 2021-06-28 10:29:00,189 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:20:19,543 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39102
scm2.org_1   | 2021-06-28 10:23:32,598 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:24:02,581 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37342
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 2021-06-28 10:24:32,586 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:29:00,190 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41636
scm1.org_1   | 2021-06-28 10:20:19,547 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-28 10:24:02,643 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60828
om3_1        | 2021-06-28 10:29:05,364 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 2021-06-28 10:24:32,601 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:29:00,191 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:20:19,568 [IPC Server handler 50 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 19789.538us
scm2.org_1   | 2021-06-28 10:24:02,651 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50094
om3_1        | 2021-06-28 10:29:05,364 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50828
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 2021-06-28 10:25:02,518 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40948
om2_1        | 2021-06-28 10:29:00,866 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:20:22,178 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 21605.842us
scm2.org_1   | 2021-06-28 10:24:02,655 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:05,366 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 2021-06-28 10:28:51,636 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:51,636 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43232
om1_1        | 2021-06-28 10:28:51,637 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:54,903 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38560
om1_1        | 2021-06-28 10:28:54,919 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:57,380 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:57,380 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43268
om1_1        | 2021-06-28 10:28:57,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:57,971 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:57,971 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43276
om1_1        | 2021-06-28 10:28:57,972 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:58,600 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:58,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43288
om1_1        | 2021-06-28 10:28:58,602 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:59,094 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:59,095 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43298
om1_1        | 2021-06-28 10:28:59,096 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:28:59,661 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:28:59,661 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43308
om1_1        | 2021-06-28 10:28:59,662 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:29:00,183 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:29:00,184 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43316
scm2.org_1   | 2021-06-28 10:24:02,669 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:00,185 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:00,867 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41656
scm3.org_1   | 2021-06-28 10:25:02,623 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:20:30,252 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39166
om3_1        | 2021-06-28 10:29:05,917 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm2.org_1   | 2021-06-28 10:24:02,673 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:00,860 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:00,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:25:02,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42218
scm1.org_1   | 2021-06-28 10:20:30,258 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om3_1        | 2021-06-28 10:29:05,917 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50838
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm2.org_1   | 2021-06-28 10:24:32,498 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37528
om1_1        | 2021-06-28 10:29:00,861 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43336
om2_1        | 2021-06-28 10:29:01,426 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:25:02,657 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:20:32,501 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50558
om3_1        | 2021-06-28 10:29:05,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm2.org_1   | 2021-06-28 10:24:32,539 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50282
om1_1        | 2021-06-28 10:29:00,861 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:01,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41668
scm3.org_1   | 2021-06-28 10:25:02,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42148
scm1.org_1   | 2021-06-28 10:20:32,555 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:06,429 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm2.org_1   | 2021-06-28 10:24:32,548 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32782
om1_1        | 2021-06-28 10:29:01,420 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:01,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:25:02,700 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:20:32,600 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39782
om3_1        | 2021-06-28 10:29:06,430 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50848
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm2.org_1   | 2021-06-28 10:24:32,572 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:01,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43348
om2_1        | 2021-06-28 10:29:02,020 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:25:32,503 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42516
scm1.org_1   | 2021-06-28 10:20:32,670 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57462
om3_1        | 2021-06-28 10:29:06,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm2.org_1   | 2021-06-28 10:24:32,586 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:01,421 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:02,021 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41680
scm3.org_1   | 2021-06-28 10:25:32,508 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41248
scm1.org_1   | 2021-06-28 10:20:32,685 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:07,022 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm2.org_1   | 2021-06-28 10:24:32,587 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:02,002 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:02,036 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:25:32,514 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:20:32,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:07,023 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50866
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm2.org_1   | 2021-06-28 10:25:02,506 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37692
om1_1        | 2021-06-28 10:29:02,002 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43360
om2_1        | 2021-06-28 10:29:03,043 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:20:53,760 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:42382
scm3.org_1   | 2021-06-28 10:25:32,575 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42442
om3_1        | 2021-06-28 10:29:07,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm2.org_1   | 2021-06-28 10:25:02,527 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50446
om1_1        | 2021-06-28 10:29:02,014 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:03,044 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41708
scm1.org_1   | 2021-06-28 10:20:53,764 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-28 10:25:32,581 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:07,629 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm2.org_1   | 2021-06-28 10:25:02,540 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:03,038 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:03,046 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:21:02,587 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50714
scm3.org_1   | 2021-06-28 10:25:32,610 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:07,630 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50878
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om1_1        | 2021-06-28 10:29:03,038 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43388
om2_1        | 2021-06-28 10:29:03,606 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:21:02,598 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:26:02,570 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41562
om3_1        | 2021-06-28 10:29:07,633 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
scm2.org_1   | 2021-06-28 10:25:02,576 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32944
om1_1        | 2021-06-28 10:29:03,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:03,606 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41726
scm1.org_1   | 2021-06-28 10:21:02,681 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57620
scm3.org_1   | 2021-06-28 10:26:02,613 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42764
om3_1        | 2021-06-28 10:29:08,209 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm2.org_1   | 2021-06-28 10:25:02,583 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:03,598 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:03,612 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:21:02,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39940
scm3.org_1   | 2021-06-28 10:26:02,637 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:08,209 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50890
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm2.org_1   | 2021-06-28 10:25:02,610 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:03,598 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43406
om2_1        | 2021-06-28 10:29:04,211 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:21:02,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:26:02,644 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:08,214 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
scm2.org_1   | 2021-06-28 10:25:32,520 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50740
om1_1        | 2021-06-28 10:29:03,602 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:04,211 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41736
scm1.org_1   | 2021-06-28 10:21:02,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:26:02,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42842
om3_1        | 2021-06-28 10:29:08,732 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm2.org_1   | 2021-06-28 10:25:32,553 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:04,204 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:04,217 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:21:21,298 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39454
scm3.org_1   | 2021-06-28 10:26:02,713 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:08,732 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50900
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm2.org_1   | 2021-06-28 10:25:32,586 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37990
om1_1        | 2021-06-28 10:29:04,205 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43416
om2_1        | 2021-06-28 10:29:04,792 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:21:21,307 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2021-06-28 10:26:32,506 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43120
om3_1        | 2021-06-28 10:29:08,733 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm2.org_1   | 2021-06-28 10:25:32,596 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33242
om1_1        | 2021-06-28 10:29:04,206 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:04,792 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41748
scm1.org_1   | 2021-06-28 10:21:22,182 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 26124.146us
scm3.org_1   | 2021-06-28 10:26:32,551 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:09,210 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm2.org_1   | 2021-06-28 10:25:32,600 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:04,788 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:04,793 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:21:27,400 [IPC Server handler 82 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract java.lang.Boolean org.apache.hadoop.hdds.scm.ha.SequenceIdGenerator$StateManager.allocateBatch(java.lang.String,java.lang.Long,java.lang.Long) on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 25917.445us
scm3.org_1   | 2021-06-28 10:26:32,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43050
om3_1        | 2021-06-28 10:29:09,210 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50908
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
scm2.org_1   | 2021-06-28 10:25:32,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:04,788 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43428
om2_1        | 2021-06-28 10:29:05,355 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:21:27,403 [IPC Server handler 82 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm3.org_1   | 2021-06-28 10:26:32,571 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:09,211 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm2.org_1   | 2021-06-28 10:26:02,543 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51056
om1_1        | 2021-06-28 10:29:04,789 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:05,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41762
scm1.org_1   | 2021-06-28 10:21:27,433 [IPC Server handler 82 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 16158.628us
scm3.org_1   | 2021-06-28 10:26:32,572 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41852
om3_1        | 2021-06-28 10:29:12,715 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53610
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm2.org_1   | 2021-06-28 10:26:02,604 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:05,350 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:05,356 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:21:32,560 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40116
scm3.org_1   | 2021-06-28 10:26:32,577 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:12,718 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
scm2.org_1   | 2021-06-28 10:26:02,627 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33566
om1_1        | 2021-06-28 10:29:05,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43442
om2_1        | 2021-06-28 10:29:05,908 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm1.org_1   | 2021-06-28 10:21:32,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50894
scm3.org_1   | 2021-06-28 10:27:02,541 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43392
om3_1        | 2021-06-28 10:29:15,244 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm2.org_1   | 2021-06-28 10:26:02,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:05,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:05,909 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41772
scm1.org_1   | 2021-06-28 10:21:32,599 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:27:02,580 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:15,244 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:50944
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm2.org_1   | 2021-06-28 10:26:02,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38316
om1_1        | 2021-06-28 10:29:05,901 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:05,913 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2021-06-28 10:21:32,613 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:21:32,625 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57796
om3_1        | 2021-06-28 10:29:15,245 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm2.org_1   | 2021-06-28 10:26:02,718 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:05,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43452
om2_1        | 2021-06-28 10:29:06,425 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:27:02,593 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43320
scm1.org_1   | 2021-06-28 10:21:32,651 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2021-06-28 10:29:28,198 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53682
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
scm2.org_1   | 2021-06-28 10:26:32,501 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38598
om1_1        | 2021-06-28 10:29:05,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2021-06-28 10:29:06,425 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41782
scm3.org_1   | 2021-06-28 10:27:02,622 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42122
scm1.org_1   | 2021-06-28 10:22:02,702 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57974
om3_1        | 2021-06-28 10:29:28,206 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
scm2.org_1   | 2021-06-28 10:26:32,511 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:06,420 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:06,426 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:27:02,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:22:02,708 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40294
om3_1        | 2021-06-28 10:32:03,496 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:35414
om3_1        | 2021-06-28 10:32:03,512 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:29:06,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43462
om1_1        | 2021-06-28 10:29:06,422 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:29:07,009 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:29:07,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43480
om1_1        | 2021-06-28 10:29:07,012 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:29:07,602 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:27:02,666 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:29:07,015 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
om1_1        | 2021-06-28 10:29:07,602 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43492
scm2.org_1   | 2021-06-28 10:26:32,531 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51350
scm2.org_1   | 2021-06-28 10:26:32,552 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33850
scm3.org_1   | 2021-06-28 10:27:32,589 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43738
om2_1        | 2021-06-28 10:29:07,016 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41800
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
scm1.org_1   | 2021-06-28 10:22:02,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:26:32,565 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:07,609 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:27:32,592 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43666
om2_1        | 2021-06-28 10:29:07,017 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
scm1.org_1   | 2021-06-28 10:22:02,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51068
scm2.org_1   | 2021-06-28 10:26:32,569 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:08,198 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om2_1        | 2021-06-28 10:29:07,616 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
scm1.org_1   | 2021-06-28 10:22:02,738 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:27:32,593 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42472
scm3.org_1   | 2021-06-28 10:27:32,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:27:02,586 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38870
om2_1        | 2021-06-28 10:29:07,617 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41812
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm3.org_1   | 2021-06-28 10:27:32,631 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:08,199 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43504
scm2.org_1   | 2021-06-28 10:27:02,604 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-28 10:26:23,985 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:22:02,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:29:07,622 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:27:32,693 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:08,200 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:27:02,619 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51620
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:22:20,494 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
om2_1        | 2021-06-28 10:29:08,204 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:28:00,055 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
om1_1        | 2021-06-28 10:29:08,723 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:27:02,627 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:22:22,183 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 26129.542us
om2_1        | 2021-06-28 10:29:08,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41824
scm3.org_1   | 2021-06-28 10:28:02,498 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44140
om1_1        | 2021-06-28 10:29:08,724 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43514
scm2.org_1   | 2021-06-28 10:27:02,652 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34122
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:22:23,705 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39832
om2_1        | 2021-06-28 10:29:08,205 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:28:02,517 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42872
om1_1        | 2021-06-28 10:29:08,724 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:27:02,674 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:22:23,708 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om2_1        | 2021-06-28 10:29:08,728 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:28:02,548 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:09,199 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:27:32,577 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39216
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:22:30,423 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:42942
om2_1        | 2021-06-28 10:29:08,728 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41834
scm3.org_1   | 2021-06-28 10:28:02,575 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:09,200 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43522
scm2.org_1   | 2021-06-28 10:27:32,588 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34468
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:22:30,431 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2021-06-28 10:29:08,729 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:28:02,578 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44070
om1_1        | 2021-06-28 10:29:09,201 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:27:32,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51964
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:22:32,491 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51258
om2_1        | 2021-06-28 10:29:09,205 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm3.org_1   | 2021-06-28 10:28:02,606 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:12,623 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38840
scm2.org_1   | 2021-06-28 10:27:32,613 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:22:32,540 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58164
om2_1        | 2021-06-28 10:29:09,205 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41842
scm3.org_1   | 2021-06-28 10:28:32,516 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43220
om1_1        | 2021-06-28 10:29:12,643 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:27:32,638 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:22:32,560 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:29:09,206 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:28:32,521 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44486
om1_1        | 2021-06-28 10:29:15,219 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
scm2.org_1   | 2021-06-28 10:27:32,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:22:32,569 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:29:12,689 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42642
scm3.org_1   | 2021-06-28 10:28:32,555 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44420
om1_1        | 2021-06-28 10:29:15,220 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:43558
scm2.org_1   | 2021-06-28 10:27:41,991 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:22:32,589 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40482
om2_1        | 2021-06-28 10:29:12,691 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2021-06-28 10:28:32,571 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2021-06-28 10:29:15,226 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:29:28,109 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38920
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:22:32,598 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2021-06-28 10:29:15,236 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 05d2d909c058a645c70a4ddb683f216f5ef6e5c3b5aac93b7115ded0879ce649
om1_1        | 2021-06-28 10:29:28,132 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:28:02,634 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39614
scm3.org_1   | 2021-06-28 10:28:32,588 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:22:36,875 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:39914
om2_1        | 2021-06-28 10:29:15,236 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) from 172.25.0.114:41878
om1_1        | 2021-06-28 10:32:03,419 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:45496
scm2.org_1   | 2021-06-28 10:28:02,665 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52370
scm3.org_1   | 2021-06-28 10:28:32,591 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:22:36,877 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om2_1        | 2021-06-28 10:29:15,239 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2021-06-28 10:32:03,433 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:28:02,665 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:29:02,502 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44850
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:22:43,338 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43026
om2_1        | 2021-06-28 10:29:28,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:42718
scm2.org_1   | 2021-06-28 10:28:02,682 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:29:02,591 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:22:43,341 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2021-06-28 10:29:28,174 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:28:02,688 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34870
scm3.org_1   | 2021-06-28 10:29:02,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43582
s3g_1        | 2021-06-28 10:26:24,001 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-19907, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm1.org_1   | 2021-06-28 10:23:02,520 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51426
om2_1        | 2021-06-28 10:32:03,467 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59726
scm2.org_1   | 2021-06-28 10:28:02,702 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:29:02,621 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44780
s3g_1        | 2021-06-28 10:26:24,018 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-19907
scm1.org_1   | 2021-06-28 10:23:02,521 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58336
om2_1        | 2021-06-28 10:32:03,470 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2021-06-28 10:28:32,521 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52718
scm3.org_1   | 2021-06-28 10:29:02,625 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-28 10:26:24,561 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:23:02,575 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:28:32,522 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39966
scm3.org_1   | 2021-06-28 10:29:02,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:23:02,612 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:29:32,489 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45122
scm1.org_1   | 2021-06-28 10:23:02,640 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40658
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm2.org_1   | 2021-06-28 10:28:32,574 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:29:32,514 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43856
scm1.org_1   | 2021-06-28 10:23:02,658 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm2.org_1   | 2021-06-28 10:28:32,588 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:29:32,533 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:23:22,172 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 15805.423us
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm2.org_1   | 2021-06-28 10:28:32,596 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35216
scm3.org_1   | 2021-06-28 10:29:32,545 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:23:27,446 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40198
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm2.org_1   | 2021-06-28 10:28:32,612 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:29:32,564 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45054
scm1.org_1   | 2021-06-28 10:23:27,460 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm2.org_1   | 2021-06-28 10:29:02,516 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53080
scm3.org_1   | 2021-06-28 10:29:32,572 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:23:27,486 [IPC Server handler 82 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 20190.929us
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm2.org_1   | 2021-06-28 10:29:02,520 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40328
scm3.org_1   | 2021-06-28 10:29:35,942 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6768cfe1-cb46-47ec-893f-707b88b3d3f7, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:29:35.922Z].
scm1.org_1   | 2021-06-28 10:23:32,579 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51612
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm2.org_1   | 2021-06-28 10:29:02,550 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35580
scm3.org_1   | 2021-06-28 10:30:02,506 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45270
scm1.org_1   | 2021-06-28 10:23:32,591 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58518
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm2.org_1   | 2021-06-28 10:29:02,555 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:30:02,512 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44002
scm1.org_1   | 2021-06-28 10:23:32,596 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm2.org_1   | 2021-06-28 10:29:02,557 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:30:02,536 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:23:32,607 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm2.org_1   | 2021-06-28 10:29:02,608 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:30:02,544 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:23:32,614 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40840
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2021-06-28 10:29:32,485 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40600
scm3.org_1   | 2021-06-28 10:30:08,013 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45240
scm1.org_1   | 2021-06-28 10:23:32,617 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 2021-06-28 10:29:32,503 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53350
scm3.org_1   | 2021-06-28 10:30:08,041 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:30:09,121 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm1.org_1   | 2021-06-28 10:24:02,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58698
scm2.org_1   | 2021-06-28 10:29:32,505 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:30:09,154 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@ca25638, cost 1239.901us
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:24:02,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41014
scm2.org_1   | 2021-06-28 10:29:32,533 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:30:09,190 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:24:02,691 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:29:32,578 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35850
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5 is not the leader 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:24:02,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51792
scm1.org_1   | 2021-06-28 10:24:02,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
scm1.org_1   | 2021-06-28 10:24:02,727 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:29:32,587 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-28 10:26:24,574 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-93555, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
scm1.org_1   | 2021-06-28 10:24:22,172 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 12028.316us
scm2.org_1   | 2021-06-28 10:29:35,956 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6768cfe1-cb46-47ec-893f-707b88b3d3f7, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:29:35.922Z].
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
scm1.org_1   | 2021-06-28 10:24:32,546 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41200
s3g_1        | 2021-06-28 10:26:24,584 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-93555
scm2.org_1   | 2021-06-28 10:30:02,504 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40750
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
scm1.org_1   | 2021-06-28 10:24:32,548 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51978
s3g_1        | 2021-06-28 10:26:25,100 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm2.org_1   | 2021-06-28 10:30:02,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53502
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-28 10:24:32,559 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm2.org_1   | 2021-06-28 10:30:02,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:24:32,591 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:24:32,594 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58880
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm1.org_1   | 2021-06-28 10:24:32,608 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:30:02,546 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-28 10:24:34,088 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:40618
scm2.org_1   | 2021-06-28 10:30:08,020 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36040
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
scm1.org_1   | 2021-06-28 10:24:34,105 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-28 10:30:08,046 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
scm1.org_1   | 2021-06-28 10:24:43,400 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43744
scm2.org_1   | 2021-06-28 10:30:39,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36182
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
scm1.org_1   | 2021-06-28 10:24:43,403 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-06-28 10:30:39,186 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
scm1.org_1   | 2021-06-28 10:25:02,521 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59042
scm2.org_1   | 2021-06-28 10:30:39,268 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53698
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
scm1.org_1   | 2021-06-28 10:25:02,555 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52136
scm2.org_1   | 2021-06-28 10:30:39,298 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40954
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
scm1.org_1   | 2021-06-28 10:25:02,599 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:30:39,298 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
scm1.org_1   | 2021-06-28 10:25:02,619 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:30:39,355 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
scm1.org_1   | 2021-06-28 10:25:02,622 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41362
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:25:02,670 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
scm2.org_1   | 2021-06-28 10:30:40,015 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: eedce3c4-3971-48ee-b9b4-61c9fa7978e0, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:30:39.995Z].
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:25:22,172 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 11875.115us
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
scm2.org_1   | 2021-06-28 10:31:09,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36346
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:25:31,006 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41046
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
scm2.org_1   | 2021-06-28 10:31:09,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:25:31,012 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
scm2.org_1   | 2021-06-28 10:31:09,281 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53856
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:25:32,496 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59342
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
scm2.org_1   | 2021-06-28 10:31:09,301 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-28 10:26:25,644 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:25:32,534 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52434
scm3.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
scm2.org_1   | 2021-06-28 10:31:09,318 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41118
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:25:32,552 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2021-06-28 10:31:09,341 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:25:32,555 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2021-06-28 10:31:20,698 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34780
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:25:32,597 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41664
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-28 10:31:20,720 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:25:32,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:30:39,133 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45382
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:25:45,199 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41174
scm3.org_1   | 2021-06-28 10:30:39,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:31:21,051 [IPC Server handler 4 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:25:45,204 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2021-06-28 10:30:39,274 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44200
scm2.org_1   | 2021-06-28 10:31:28,236 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34816
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:26:02,108 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44434
scm3.org_1   | 2021-06-28 10:30:39,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45470
scm2.org_1   | 2021-06-28 10:31:28,244 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:26:02,111 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-28 10:30:39,294 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:31:28,252 [IPC Server handler 8 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:26:02,520 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52760
scm2.org_1   | 2021-06-28 10:31:28,254 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 3 containers.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-28 10:30:39,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:31:39,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36506
scm1.org_1   | 2021-06-28 10:26:02,562 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59654
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-28 10:30:40,009 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: eedce3c4-3971-48ee-b9b4-61c9fa7978e0, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:30:39.995Z].
scm2.org_1   | 2021-06-28 10:31:39,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:26:02,566 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2021-06-28 10:31:09,118 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45546
scm2.org_1   | 2021-06-28 10:31:39,272 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54020
scm1.org_1   | 2021-06-28 10:26:02,569 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41984
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-28 10:31:09,120 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:31:39,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41268
scm1.org_1   | 2021-06-28 10:26:02,625 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-28 10:31:09,308 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44366
scm2.org_1   | 2021-06-28 10:31:39,306 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:26:02,634 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-28 10:31:09,311 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45638
scm2.org_1   | 2021-06-28 10:31:39,342 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:26:22,191 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 30304.534us
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-06-28 10:31:09,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:32:09,142 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36666
scm1.org_1   | 2021-06-28 10:26:27,411 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41616
s3g_1        | 2021-06-28 10:26:25,671 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
scm3.org_1   | 2021-06-28 10:31:09,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:32:09,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:32:09,327 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41432
s3g_1        | <Error>
scm1.org_1   | 2021-06-28 10:26:27,415 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        |   <Code>NoSuchBucket</Code>
scm3.org_1   | 2021-06-28 10:31:21,305 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44040
scm1.org_1   | 2021-06-28 10:26:27,431 [IPC Server handler 82 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 15318.217us
scm2.org_1   | 2021-06-28 10:32:09,334 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54182
s3g_1        |   <Message>The specified bucket does not exist</Message>
scm3.org_1   | 2021-06-28 10:31:21,319 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:26:32,514 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53040
scm2.org_1   | 2021-06-28 10:32:09,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        |   <Resource>nosuchbucket</Resource>
scm3.org_1   | 2021-06-28 10:31:21,762 [IPC Server handler 45 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2021-06-28 10:26:32,575 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59946
scm2.org_1   | 2021-06-28 10:32:09,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        |   <RequestId/>
scm3.org_1   | 2021-06-28 10:31:28,469 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44074
scm1.org_1   | 2021-06-28 10:26:32,577 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:32:39,318 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41582
s3g_1        | </Error>
scm3.org_1   | 2021-06-28 10:31:28,475 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:26:32,607 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42266
scm2.org_1   | 2021-06-28 10:32:39,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 
scm3.org_1   | 2021-06-28 10:31:28,479 [IPC Server handler 51 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-06-28 10:26:32,608 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:32:39,333 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54322
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm3.org_1   | 2021-06-28 10:31:28,483 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 3 containers.
scm1.org_1   | 2021-06-28 10:26:32,618 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:32:39,342 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
scm3.org_1   | 2021-06-28 10:31:39,137 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45706
scm1.org_1   | 2021-06-28 10:26:47,691 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41794
scm2.org_1   | 2021-06-28 10:32:40,378 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
scm3.org_1   | 2021-06-28 10:31:39,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:26:47,697 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-28 10:32:40,417 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@1c93eb57, cost 5249.404us
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm3.org_1   | 2021-06-28 10:31:39,270 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44526
scm1.org_1   | 2021-06-28 10:26:58,206 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44964
scm2.org_1   | 2021-06-28 10:32:40,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36832
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm3.org_1   | 2021-06-28 10:31:39,291 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45792
scm1.org_1   | 2021-06-28 10:26:58,211 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-06-28 10:32:40,445 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm3.org_1   | 2021-06-28 10:31:39,306 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:27:02,526 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53312
scm2.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5 is not the leader 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm3.org_1   | 2021-06-28 10:31:39,332 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:27:02,577 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm3.org_1   | 2021-06-28 10:32:09,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45866
scm1.org_1   | 2021-06-28 10:27:02,580 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42540
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm3.org_1   | 2021-06-28 10:32:09,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:27:02,632 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60222
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm3.org_1   | 2021-06-28 10:32:09,263 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45952
scm1.org_1   | 2021-06-28 10:27:02,648 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm3.org_1   | 2021-06-28 10:32:09,274 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44684
scm1.org_1   | 2021-06-28 10:27:02,678 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm3.org_1   | 2021-06-28 10:32:09,294 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2021-06-28 10:27:20,497 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 2 containers.
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
scm3.org_1   | 2021-06-28 10:32:09,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm1.org_1   | 2021-06-28 10:27:21,622 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:45210
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
scm3.org_1   | 2021-06-28 10:32:39,263 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44828
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm1.org_1   | 2021-06-28 10:27:21,626 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
scm3.org_1   | 2021-06-28 10:32:39,291 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46108
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm1.org_1   | 2021-06-28 10:27:22,181 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 20244.921us
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm1.org_1   | 2021-06-28 10:27:27,341 [IPC Server handler 60 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 12678.413us
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
scm3.org_1   | 2021-06-28 10:32:39,298 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm1.org_1   | 2021-06-28 10:27:32,615 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42884
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
scm3.org_1   | 2021-06-28 10:32:39,323 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm1.org_1   | 2021-06-28 10:27:32,619 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53658
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
scm3.org_1   | 2021-06-28 10:32:40,338 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm1.org_1   | 2021-06-28 10:27:32,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
scm3.org_1   | 2021-06-28 10:32:40,339 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@ca25638, cost 874.601us
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm1.org_1   | 2021-06-28 10:27:32,656 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60566
scm1.org_1   | 2021-06-28 10:27:32,658 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:32:40,339 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
scm2.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5 is not the leader 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm1.org_1   | 2021-06-28 10:27:32,712 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
scm1.org_1   | 2021-06-28 10:27:37,409 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:45432
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
scm1.org_1   | 2021-06-28 10:27:37,413 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
scm1.org_1   | 2021-06-28 10:28:02,565 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60966
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
scm1.org_1   | 2021-06-28 10:28:02,587 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-28 10:28:02,610 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43286
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm2.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2021-06-28 10:28:02,611 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54064
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm1.org_1   | 2021-06-28 10:28:02,630 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-28 10:32:40,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-28 10:28:02,639 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2021-06-28 10:33:10,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41744
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
scm1.org_1   | 2021-06-28 10:28:10,696 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:42772
scm2.org_1   | 2021-06-28 10:33:10,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
scm1.org_1   | 2021-06-28 10:28:10,703 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm2.org_1   | 2021-06-28 10:33:10,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36996
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
scm1.org_1   | 2021-06-28 10:28:11,984 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:45870
scm2.org_1   | 2021-06-28 10:33:10,460 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54498
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
scm1.org_1   | 2021-06-28 10:28:11,986 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2021-06-28 10:33:10,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
scm1.org_1   | 2021-06-28 10:28:13,492 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54322
scm2.org_1   | 2021-06-28 10:33:10,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm1.org_1   | 2021-06-28 10:28:13,494 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:45068
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
scm2.org_1   | 2021-06-28 10:33:13,147 [c72270bf-80b5-4b5a-a86a-6233c9fb41e8@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3fe59e30-f5c2-4654-b355-5f8be71ef349, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:33:13.127Z].
scm1.org_1   | 2021-06-28 10:28:13,496 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
scm2.org_1   | 2021-06-28 10:33:40,420 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41896
scm1.org_1   | 2021-06-28 10:28:13,503 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
scm3.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
scm1.org_1   | 2021-06-28 10:28:22,199 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 36618.336us
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
scm2.org_1   | 2021-06-28 10:33:40,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:28:25,526 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:42942
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
scm2.org_1   | 2021-06-28 10:33:40,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54644
scm1.org_1   | 2021-06-28 10:28:25,528 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
scm2.org_1   | 2021-06-28 10:33:40,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:28:27,339 [IPC Server handler 5 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 9609.009us
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
scm2.org_1   | 2021-06-28 10:33:40,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37148
scm1.org_1   | 2021-06-28 10:28:29,206 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:46046
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
scm2.org_1   | 2021-06-28 10:33:40,493 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:28:29,210 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm3.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
scm2.org_1   | 2021-06-28 10:33:53,289 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38260
scm1.org_1   | 2021-06-28 10:28:32,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54408
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm2.org_1   | 2021-06-28 10:33:53,308 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:28:32,517 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33082
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2021-06-28 10:33:53,310 [IPC Server handler 6 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2021-06-28 10:28:32,577 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2021-06-28 10:34:00,593 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38296
scm1.org_1   | 2021-06-28 10:28:32,593 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm2.org_1   | 2021-06-28 10:34:00,611 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:28:32,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43634
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm3.org_1   | 2021-06-28 10:32:40,369 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode 89aa20a7-dff6-484e-91c9-5fa0b70dff48{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm2.org_1   | 2021-06-28 10:34:00,615 [IPC Server handler 7 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-06-28 10:28:32,614 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
scm3.org_1   | 2021-06-28 10:32:40,370 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@ca25638, cost 962.2us
scm2.org_1   | 2021-06-28 10:34:00,623 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 4 milliseconds for processing 4 containers.
scm1.org_1   | 2021-06-28 10:28:48,691 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43204
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm3.org_1   | 2021-06-28 10:32:40,370 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
scm2.org_1   | 2021-06-28 10:34:10,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54814
scm1.org_1   | 2021-06-28 10:28:48,692 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5 is not the leader 00b677bc-7bb5-4c8c-9cb8-b10bc61671d0|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm2.org_1   | 2021-06-28 10:34:10,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:29:00,309 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:46420
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:661)
scm2.org_1   | 2021-06-28 10:34:10,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42066
scm1.org_1   | 2021-06-28 10:29:00,314 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:626)
scm2.org_1   | 2021-06-28 10:34:10,468 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37314
scm1.org_1   | 2021-06-28 10:29:02,551 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54772
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:754)
scm2.org_1   | 2021-06-28 10:34:10,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:29:02,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43996
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm2.org_1   | 2021-06-28 10:34:10,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:29:02,663 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$9(RaftServerProxy.java:417)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$7(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-28 10:29:02,667 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33444
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm1.org_1   | 2021-06-28 10:29:02,670 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$8(RaftServerProxy.java:412)
scm1.org_1   | 2021-06-28 10:29:02,672 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
scm1.org_1   | 2021-06-28 10:29:22,179 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 16159.714us
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
scm1.org_1   | 2021-06-28 10:29:27,424 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:43634
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:411)
scm1.org_1   | 2021-06-28 10:29:27,428 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:417)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.submitRequest(SCMRatisServerImpl.java:212)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:110)
scm1.org_1   | 2021-06-28 10:29:27,450 [IPC Server handler 22 on default port 9863] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.addTransactionsToDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 20728.519us
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:67)
scm1.org_1   | 2021-06-28 10:29:32,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33716
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
scm3.org_1   | 	at com.sun.proxy.$Proxy16.updateContainerState(Unknown Source)
scm1.org_1   | 2021-06-28 10:29:32,523 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55042
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.ContainerManagerImpl.updateContainerState(ContainerManagerImpl.java:242)
scm1.org_1   | 2021-06-28 10:29:32,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.updateContainerState(AbstractContainerReportHandler.java:227)
scm1.org_1   | 2021-06-28 10:29:32,544 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.AbstractContainerReportHandler.processContainerReplica(AbstractContainerReportHandler.java:96)
scm1.org_1   | 2021-06-28 10:29:32,592 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44268
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:88)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
scm3.org_1   | 	at org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler.onMessage(IncrementalContainerReportHandler.java:40)
scm1.org_1   | 2021-06-28 10:29:32,601 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
scm1.org_1   | 2021-06-28 10:29:35,581 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52508
scm3.org_1   | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-28 10:29:35,596 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 2021-06-28 10:26:31,771 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:29:35,915 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38164
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:29:35,916 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:29:35,935 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6768cfe1-cb46-47ec-893f-707b88b3d3f7, Nodes: 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:29:35.922Z].
scm3.org_1   | 2021-06-28 10:32:40,403 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46036
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:29:35,936 [IPC Server handler 69 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 13606.312us
scm3.org_1   | 2021-06-28 10:32:40,409 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:29:35,957 [IPC Server handler 69 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 20962.919us
scm3.org_1   | 2021-06-28 10:33:10,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46200
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:29:41,770 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38190
scm3.org_1   | 2021-06-28 10:33:10,442 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45000
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:29:41,787 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2021-06-28 10:33:10,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46270
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-28 10:33:10,450 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:29:45,151 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38208
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-28 10:33:10,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:29:45,159 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-28 10:33:10,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:29:48,692 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38220
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-28 10:33:13,145 [11a03b12-2660-4fe0-9a3b-9bd3fc9cb1ef@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3fe59e30-f5c2-4654-b355-5f8be71ef349, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:33:13.127Z].
scm1.org_1   | 2021-06-28 10:29:48,707 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-28 10:33:40,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46418
scm1.org_1   | 2021-06-28 10:29:52,295 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38238
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:29:52,313 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2021-06-28 10:33:40,388 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:29:55,814 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38256
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm3.org_1   | 2021-06-28 10:33:40,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45148
scm1.org_1   | 2021-06-28 10:29:55,829 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm3.org_1   | 2021-06-28 10:33:40,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46346
scm1.org_1   | 2021-06-28 10:29:59,379 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38266
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm3.org_1   | 2021-06-28 10:33:40,435 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:29:59,391 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 2021-06-28 10:26:31,781 [qtp382627885-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-95776, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm3.org_1   | 2021-06-28 10:33:40,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-28 10:26:31,795 [qtp382627885-20] INFO endpoint.BucketEndpoint: Location is /bucket-95776
scm1.org_1   | 2021-06-28 10:30:02,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55194
scm3.org_1   | 2021-06-28 10:33:53,526 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:49280
s3g_1        | 2021-06-28 10:26:32,333 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:30:02,552 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:33:53,533 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:30:02,562 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33868
scm3.org_1   | 2021-06-28 10:33:53,536 [IPC Server handler 48 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:30:02,568 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2021-06-28 10:34:00,839 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:49316
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:30:03,166 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38298
scm1.org_1   | 2021-06-28 10:30:03,189 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:30:03,384 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm1.org_1   | 2021-06-28 10:30:03,404 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 20289.618us
scm1.org_1   | 2021-06-28 10:30:06,680 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38320
scm1.org_1   | 2021-06-28 10:30:06,694 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:30:08,054 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44456
scm1.org_1   | 2021-06-28 10:30:08,064 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:30:09,090 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 264e17c6-d8b4-4795-92be-7db9d85d28e1{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm3.org_1   | 2021-06-28 10:34:00,848 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:30:09,120 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 29023.025us
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm3.org_1   | 2021-06-28 10:34:00,850 [IPC Server handler 3 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-06-28 10:30:10,553 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38346
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2021-06-28 10:34:00,854 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 4 containers.
scm1.org_1   | 2021-06-28 10:30:10,574 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm3.org_1   | 2021-06-28 10:34:10,374 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46588
scm1.org_1   | 2021-06-28 10:30:16,427 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38372
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm3.org_1   | 2021-06-28 10:34:10,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45322
scm1.org_1   | 2021-06-28 10:30:16,439 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm3.org_1   | 2021-06-28 10:34:10,409 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:30:16,440 [IPC Server handler 65 on default port 9860] INFO ipc.Server: IPC Server handler 65 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:38372
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm3.org_1   | 2021-06-28 10:34:10,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46516
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm3.org_1   | 2021-06-28 10:34:10,429 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm3.org_1   | 2021-06-28 10:34:10,431 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:212)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:403)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:183)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:30:19,861 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52738
scm1.org_1   | 2021-06-28 10:30:19,876 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2021-06-28 10:30:20,171 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38392
scm1.org_1   | 2021-06-28 10:30:20,178 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:30:20,180 [IPC Server handler 1 on default port 9860] INFO ipc.Server: IPC Server handler 1 on default port 9860, call Call#1 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:38392
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
s3g_1        | 2021-06-28 10:26:32,999 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.allocateContainer(SCMClientProtocolServer.java:196)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.allocateContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:392)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:175)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:30:22,173 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 9956.809us
scm1.org_1   | 2021-06-28 10:30:23,562 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38402
scm1.org_1   | 2021-06-28 10:30:23,577 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:30:23,577 [IPC Server handler 90 on default port 9860] INFO ipc.Server: IPC Server handler 90 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:38402
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:212)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:403)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:183)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:30:26,896 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38422
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:30:26,905 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:30:30,639 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38436
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:30:30,652 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:30:34,075 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38452
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:30:34,090 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:30:39,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44598
s3g_1        | 2021-06-28 10:26:33,016 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
scm1.org_1   | 2021-06-28 10:30:39,169 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | <Error>
scm1.org_1   | 2021-06-28 10:30:39,302 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34062
s3g_1        |   <Code>NoSuchBucket</Code>
scm1.org_1   | 2021-06-28 10:30:39,311 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        |   <Message>The specified bucket does not exist</Message>
scm1.org_1   | 2021-06-28 10:30:39,345 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55390
s3g_1        |   <Resource>ozonenosuchbucketqqweqwe</Resource>
scm1.org_1   | 2021-06-28 10:30:39,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        |   <RequestId/>
scm1.org_1   | 2021-06-28 10:30:39,983 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38496
s3g_1        | </Error>
scm1.org_1   | 2021-06-28 10:30:39,994 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 
scm1.org_1   | 2021-06-28 10:30:40,004 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: eedce3c4-3971-48ee-b9b4-61c9fa7978e0, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:30:39.995Z].
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm1.org_1   | 2021-06-28 10:30:40,005 [IPC Server handler 69 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 9550.208us
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
scm1.org_1   | 2021-06-28 10:30:43,536 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38516
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
scm1.org_1   | 2021-06-28 10:30:43,549 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm1.org_1   | 2021-06-28 10:30:47,093 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38528
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm1.org_1   | 2021-06-28 10:30:47,105 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm1.org_1   | 2021-06-28 10:30:50,503 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38546
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm1.org_1   | 2021-06-28 10:30:50,513 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2021-06-28 10:30:50,529 [IPC Server handler 90 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 14657.912us
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm1.org_1   | 2021-06-28 10:30:53,956 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38556
scm1.org_1   | 2021-06-28 10:30:53,972 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:30:57,267 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38574
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2021-06-28 10:30:57,277 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm1.org_1   | 2021-06-28 10:30:57,301 [IPC Server handler 18 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 22881.019us
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
scm1.org_1   | 2021-06-28 10:31:00,841 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38584
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2021-06-28 10:31:00,849 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm1.org_1   | 2021-06-28 10:31:04,230 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38612
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm1.org_1   | 2021-06-28 10:31:04,239 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:31:04,253 [IPC Server handler 27 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 13778.712us
scm1.org_1   | 2021-06-28 10:31:04,254 [IPC Server handler 27 on default port 9860] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: eedce3c4-3971-48ee-b9b4-61c9fa7978e0, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:30:39.995Z] moved to CLOSED state
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm1.org_1   | 2021-06-28 10:31:07,932 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38632
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm1.org_1   | 2021-06-28 10:31:07,945 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm1.org_1   | 2021-06-28 10:31:09,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44762
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm1.org_1   | 2021-06-28 10:31:09,164 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm1.org_1   | 2021-06-28 10:31:09,312 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34222
scm1.org_1   | 2021-06-28 10:31:09,316 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55558
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm1.org_1   | 2021-06-28 10:31:09,333 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:31:09,342 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
scm1.org_1   | 2021-06-28 10:31:13,641 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38676
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
scm1.org_1   | 2021-06-28 10:31:13,656 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm1.org_1   | 2021-06-28 10:31:17,101 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38688
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm1.org_1   | 2021-06-28 10:31:17,115 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2021-06-28 10:31:21,285 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38710
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-28 10:31:21,287 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm1.org_1   | 2021-06-28 10:31:21,287 [IPC Server handler 27 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm1.org_1   | 2021-06-28 10:31:22,173 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 9670.908us
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-28 10:31:24,998 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38722
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
scm1.org_1   | 2021-06-28 10:31:25,012 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2021-06-28 10:31:28,429 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38744
scm1.org_1   | 2021-06-28 10:31:28,431 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:31:28,435 [IPC Server handler 53 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2021-06-28 10:31:28,457 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 6 milliseconds for processing 3 containers.
scm1.org_1   | 2021-06-28 10:31:31,852 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38766
scm1.org_1   | 2021-06-28 10:31:31,868 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:31:37,741 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38786
scm1.org_1   | 2021-06-28 10:31:37,756 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:31:39,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44922
scm1.org_1   | 2021-06-28 10:31:39,165 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:31:39,301 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55718
scm1.org_1   | 2021-06-28 10:31:39,313 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34392
scm1.org_1   | 2021-06-28 10:31:39,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:31:39,332 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2021-06-28 10:31:41,458 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38820
scm1.org_1   | 2021-06-28 10:31:41,474 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:31:44,825 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38838
scm1.org_1   | 2021-06-28 10:31:44,841 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:31:50,566 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38864
scm1.org_1   | 2021-06-28 10:31:50,586 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:32:03,934 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:44456
scm1.org_1   | 2021-06-28 10:32:03,942 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2021-06-28 10:32:03,962 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:47536
scm1.org_1   | 2021-06-28 10:32:03,975 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55950
scm1.org_1   | 2021-06-28 10:32:03,976 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-28 10:32:03,982 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm1.org_1   | 2021-06-28 10:32:03,995 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:46696
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-28 10:32:04,004 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm1.org_1   | 2021-06-28 10:32:09,109 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45084
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm1.org_1   | 2021-06-28 10:32:09,123 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm1.org_1   | 2021-06-28 10:32:09,251 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55874
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 2021-06-28 10:32:09,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm1.org_1   | 2021-06-28 10:32:09,299 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34552
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
scm1.org_1   | 2021-06-28 10:32:09,312 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm1.org_1   | 2021-06-28 10:32:09,721 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:40902
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm1.org_1   | 2021-06-28 10:32:09,740 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
scm1.org_1   | 2021-06-28 10:32:10,074 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36072
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm1.org_1   | 2021-06-28 10:32:10,081 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm1.org_1   | 2021-06-28 10:32:10,090 [IPC Server handler 99 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.addContainer(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerInfoProto) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 7576.106us
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm1.org_1   | 2021-06-28 10:32:15,669 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36094
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
scm1.org_1   | 2021-06-28 10:32:15,687 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
scm1.org_1   | 2021-06-28 10:32:19,182 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36108
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
scm1.org_1   | 2021-06-28 10:32:19,190 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
scm1.org_1   | 2021-06-28 10:32:22,175 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 10914.608us
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
scm1.org_1   | 2021-06-28 10:32:22,623 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36126
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
scm1.org_1   | 2021-06-28 10:32:22,639 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
scm1.org_1   | 2021-06-28 10:32:26,303 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36146
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-28 10:32:26,314 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 2021-06-28 10:26:33,016 [qtp382627885-20] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
scm1.org_1   | 2021-06-28 10:32:29,676 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36156
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm1.org_1   | 2021-06-28 10:32:29,698 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:131)
scm1.org_1   | 2021-06-28 10:32:33,089 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36174
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:68)
scm1.org_1   | 2021-06-28 10:32:33,109 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:295)
scm1.org_1   | 2021-06-28 10:32:36,751 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36186
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm1.org_1   | 2021-06-28 10:32:36,762 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm1.org_1   | 2021-06-28 10:32:36,918 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm1.org_1   | 2021-06-28 10:32:36,931 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 12239.609us
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2021-06-28 10:32:39,268 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56026
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm1.org_1   | 2021-06-28 10:32:39,286 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34688
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2021-06-28 10:32:39,299 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
scm1.org_1   | 2021-06-28 10:32:39,320 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2021-06-28 10:32:40,358 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
scm1.org_1   | 2021-06-28 10:32:40,387 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.container.ContainerStateManagerV2.updateContainerState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$ContainerID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$LifeCycleEvent) throws java.io.IOException,org.apache.hadoop.ozone.common.statemachine.InvalidStateTransitionException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 21677.816us
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm1.org_1   | 2021-06-28 10:32:40,420 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45256
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
scm1.org_1   | 2021-06-28 10:32:40,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm1.org_1   | 2021-06-28 10:32:40,544 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36218
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm1.org_1   | 2021-06-28 10:32:40,561 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
scm1.org_1   | 2021-06-28 10:32:43,953 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36236
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm1.org_1   | 2021-06-28 10:32:43,960 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
scm1.org_1   | 2021-06-28 10:32:49,433 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36260
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
scm1.org_1   | 2021-06-28 10:32:49,446 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
scm1.org_1   | 2021-06-28 10:32:49,447 [IPC Server handler 84 on default port 9860] INFO ipc.Server: IPC Server handler 84 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.117:36260
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:212)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:403)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:183)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2021-06-28 10:32:52,828 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:41114
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-28 10:32:52,845 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm1.org_1   | 2021-06-28 10:32:53,254 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36282
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2021-06-28 10:32:53,259 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2021-06-28 10:32:53,260 [IPC Server handler 94 on default port 9860] INFO ipc.Server: IPC Server handler 94 on default port 9860, call Call#1 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.117:36282
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.allocateContainer(SCMClientProtocolServer.java:196)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.allocateContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:392)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:175)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm1.org_1   | 2021-06-28 10:32:56,594 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36300
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 2021-06-28 10:32:56,604 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
scm1.org_1   | 2021-06-28 10:32:56,605 [IPC Server handler 95 on default port 9860] INFO ipc.Server: IPC Server handler 95 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.117:36300
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1551)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:212)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:403)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:183)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:162)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:52594)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm1.org_1   | 2021-06-28 10:32:59,979 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36312
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
scm1.org_1   | 2021-06-28 10:32:59,989 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm1.org_1   | 2021-06-28 10:33:03,327 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36328
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
scm1.org_1   | 2021-06-28 10:33:03,344 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
scm1.org_1   | 2021-06-28 10:33:06,877 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36348
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
scm1.org_1   | 2021-06-28 10:33:06,891 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
scm1.org_1   | 2021-06-28 10:33:10,400 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34862
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
scm1.org_1   | 2021-06-28 10:33:10,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56188
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
scm1.org_1   | 2021-06-28 10:33:10,410 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45414
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm1.org_1   | 2021-06-28 10:33:10,418 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2021-06-28 10:26:39,181 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:33:10,434 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:33:10,438 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:33:13,115 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36392
scm1.org_1   | 2021-06-28 10:33:13,126 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:33:13,138 [00b677bc-7bb5-4c8c-9cb8-b10bc61671d0@group-5EB5CA0024F5-StateMachineUpdater] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3fe59e30-f5c2-4654-b355-5f8be71ef349, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:33:13.127Z].
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:33:13,138 [IPC Server handler 48 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.addPipeline(org.apache.hadoop.hdds.protocol.proto.HddsProtos$Pipeline) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 11055.908us
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:33:16,689 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36412
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:33:16,702 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:33:20,060 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36422
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:33:20,075 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:33:22,171 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 6239.604us
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:33:23,400 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36442
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:33:23,421 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:33:23,430 [IPC Server handler 89 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 7312.205us
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:33:26,850 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36464
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:33:26,861 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:33:30,233 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36474
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:33:30,242 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 2021-06-28 10:26:39,190 [qtp382627885-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-97130, with Versioning false and Storage Type set to DISK and Encryption set to false 
scm1.org_1   | 2021-06-28 10:33:30,253 [IPC Server handler 94 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 10072.007us
s3g_1        | 2021-06-28 10:26:39,204 [qtp382627885-20] INFO endpoint.BucketEndpoint: Location is /bucket-97130
scm1.org_1   | 2021-06-28 10:33:33,667 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36492
s3g_1        | 2021-06-28 10:26:39,683 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:33:33,684 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:33:37,334 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36502
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:33:37,341 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:33:37,355 [IPC Server handler 18 on default port 9860] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.pipeline.StateManager.updatePipelineState(org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineID,org.apache.hadoop.hdds.protocol.proto.HddsProtos$PipelineState) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 13269.91us
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:33:37,356 [IPC Server handler 18 on default port 9860] INFO pipeline.PipelineManagerV2Impl: Pipeline Pipeline[ Id: 3fe59e30-f5c2-4654-b355-5f8be71ef349, Nodes: 87b0b3c6-67c6-498c-a3d3-879b3c6d2c21{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2021-06-28T10:33:13.127Z] moved to CLOSED state
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:33:40,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56338
scm1.org_1   | 2021-06-28 10:33:40,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45566
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:33:40,410 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35016
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:33:40,411 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:33:40,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:33:40,465 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:33:40,821 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36538
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:33:40,831 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:33:46,616 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36564
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:33:46,637 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:33:49,924 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36576
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:45,837 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:33:49,947 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:33:53,469 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36596
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:33:53,482 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:33:53,489 [IPC Server handler 34 on default port 9860] INFO container.ReplicationManager: Stopping Replication Monitor Thread.
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:33:56,936 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36616
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
scm1.org_1   | 2021-06-28 10:33:56,951 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:45,848 [qtp382627885-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-99943, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:26:45,860 [qtp382627885-21] INFO endpoint.BucketEndpoint: Location is /bucket-99943
s3g_1        | 2021-06-28 10:26:46,370 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:34:00,806 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36632
s3g_1        | 2021-06-28 10:26:46,998 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:34:00,816 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:34:00,819 [IPC Server handler 64 on default port 9860] INFO container.ReplicationManager: Starting Replication Monitor Thread.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:34:00,827 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 4 milliseconds for processing 4 containers.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:34:04,167 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36662
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 2021-06-28 10:34:04,182 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
scm1.org_1   | 2021-06-28 10:34:09,836 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36688
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2021-06-28 10:34:09,849 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm1.org_1   | 2021-06-28 10:34:10,395 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45738
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
scm1.org_1   | 2021-06-28 10:34:10,402 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56508
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
scm1.org_1   | 2021-06-28 10:34:10,417 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2021-06-28 10:34:10,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35182
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 2021-06-28 10:34:10,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
scm1.org_1   | 2021-06-28 10:34:10,448 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
scm1.org_1   | 2021-06-28 10:34:13,370 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36716
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
scm1.org_1   | 2021-06-28 10:34:13,384 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 2021-06-28 10:26:47,638 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
scm1.org_1   | 2021-06-28 10:34:16,820 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36734
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
scm1.org_1   | 2021-06-28 10:34:16,842 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
scm1.org_1   | 2021-06-28 10:34:22,179 [SCMBlockDeletingService#0] INFO ha.SCMHAInvocationHandler: Invoking method public abstract void org.apache.hadoop.hdds.scm.block.DeletedBlockLogStateManager.removeTransactionsFromDB(java.util.ArrayList) throws java.io.IOException on target org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl@30be7763, cost 14543.709us
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
scm1.org_1   | 2021-06-28 10:34:22,579 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:36760
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
scm1.org_1   | 2021-06-28 10:34:22,609 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:47,752 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A0B53BAD18C5->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:26:47,752 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:26:51,297 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:51,387 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F69298E20191->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:26:51,387 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:26:52,411 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:53,073 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:53,171 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-530DFA06BF07->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:26:53,171 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:26:56,663 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:56,766 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-400E2783AFC9->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:26:56,766 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:26:57,486 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:58,088 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:59,065 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:59,783 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:26:59,861 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-609C62797DE4->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:26:59,862 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:03,214 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:03,283 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-CE6014C6F0C6->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:03,283 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:06,466 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:06,501 [qtp382627885-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99943, , key: 37288/multipartKey2
s3g_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 37288/multipartKey2. Entity too small.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:06,504 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>EntityTooSmall</Code>
s3g_1        |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
s3g_1        |   <Resource>37288/multipartKey2</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:102)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:07,001 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:07,583 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:07,629 [qtp382627885-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99943, , key: 63229/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:07,630 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>63229/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:08,176 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:08,209 [qtp382627885-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99943, , key: 63229/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:08,210 [qtp382627885-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>63229/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:08,799 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:08,895 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BD3BCC25AA17->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:08,895 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:12,455 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:12,543 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6C810E7282D9->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:12,543 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:16,158 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:16,237 [qtp382627885-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-29EAB40DFD72->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:16,237 [qtp382627885-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:19,371 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:19,415 [qtp382627885-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99943, , key: 63229/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-99943/63229/multipartKey3106487875424092193
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:19,421 [qtp382627885-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>63229/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:19,927 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:19,954 [qtp382627885-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99943, , key: 63229/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-99943/63229/multipartKey3106487875663822882
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:19,959 [qtp382627885-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPart</Code>
s3g_1        |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1        |   <Resource>63229/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:92)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:20,449 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:20,492 [qtp382627885-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99943, , key: 63229/multipartKey3
s3g_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-99943 key: 63229/multipartKey3 because parts are in Invalid order.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:605)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:977)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1075)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:691)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:531)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:20,497 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidPartOrder</Code>
s3g_1        |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
s3g_1        |   <Resource>63229/multipartKey3</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:97)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:20,966 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:21,520 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:22,452 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:23,037 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:23,589 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:23,621 [qtp382627885-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:24,148 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:24,177 [qtp382627885-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchUpload</Code>
s3g_1        |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1        |   <Resource>random</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:83)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:24,679 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:25,341 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:25,422 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-935942198917->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:25,422 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:28,849 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:28,915 [qtp382627885-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-3FC31E128B8B->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:27:28,915 [qtp382627885-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:29,662 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:30,392 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:30,993 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:31,542 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:32,364 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:32,673 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:32,854 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:32,876 [qtp382627885-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6E555E0CDC36->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:32,877 [qtp382627885-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:32,887 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:33,100 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F67A0180E82F->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:33,107 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:33,139 [qtp382627885-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-710628F538BC->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:27:33,151 [qtp382627885-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:36,761 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:37,334 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:37,474 [qtp382627885-21] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:37,481 [qtp382627885-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:37,492 [qtp382627885-24] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:39,042 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:39,847 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:39,924 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B29CD08CC376->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:27:39,924 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:40,756 [qtp382627885-17] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:41,360 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:41,549 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-9CCA14A3995D->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:27:41,550 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:42,522 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:43,070 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:43,988 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:44,056 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-D7C062E62BD6->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:27:44,056 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:45,153 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:45,758 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:45,980 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B8CFAB69EEC9->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:27:45,980 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:47,291 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:47,454 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C7F286DC9A0A->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:27:47,454 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:48,133 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:48,650 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:49,769 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:49,846 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-FDC92CEF951E->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:49,847 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:53,281 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:53,870 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:53,925 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-99943/94427/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:54,475 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:54,521 [qtp382627885-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>PreconditionFailed</Code>
s3g_1        |   <Message>At least one of the pre-conditions you specified did not hold</Message>
s3g_1        |   <Resource>bucket-99943/94427/copyrange/source</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:115)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:27:55,017 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:55,209 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0A34574CBCB6->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:27:55,210 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:27:59,352 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:27:59,477 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4819B8A2B3EF->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:27:59,479 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:00,179 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:00,760 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:01,759 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:02,343 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:03,089 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:09,592 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:09,601 [qtp382627885-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-29667, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:28:09,611 [qtp382627885-19] INFO endpoint.BucketEndpoint: Location is /bucket-29667
s3g_1        | 2021-06-28 10:28:10,145 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:10,154 [qtp382627885-20] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-16838, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:28:10,170 [qtp382627885-20] INFO endpoint.BucketEndpoint: Location is /destbucket-16838
s3g_1        | 2021-06-28 10:28:10,674 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:10,737 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-D5118BAF9E6F->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:28:10,737 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:11,402 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:11,960 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:12,060 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-DF9ED98CD114->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:28:12,061 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:12,677 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:13,221 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:13,307 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-95A46826BE81->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:28:13,308 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:16,439 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:16,997 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:17,006 [qtp382627885-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:28:17,540 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:17,550 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:28:18,066 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:18,593 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:18,606 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchKey</Code>
s3g_1        |   <Message>The specified key does not exist</Message>
s3g_1        |   <Resource>nonnonexistentkey</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:28:24,921 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:24,949 [qtp382627885-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-05135, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:28:24,957 [qtp382627885-20] INFO endpoint.BucketEndpoint: Location is /bucket-05135
s3g_1        | 2021-06-28 10:28:25,492 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:25,575 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E9D80CD72633->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:28:25,575 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:28,672 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:29,173 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:29,708 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:30,226 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:30,741 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:31,197 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:31,706 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:31,757 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F21D65FF7F03->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:28:31,759 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:34,872 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:35,464 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:35,941 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:36,450 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:36,997 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:37,033 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E929D6A2924B->264e17c6-d8b4-4795-92be-7db9d85d28e1
s3g_1        | 2021-06-28 10:28:37,034 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:40,120 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:40,649 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:41,111 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:41,581 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:42,117 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:42,142 [qtp382627885-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>NoSuchBucket</Code>
s3g_1        |   <Message>The specified bucket does not exist</Message>
s3g_1        |   <Resource>bucket-05135-nosuchbucket</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:51)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:28:48,127 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:48,137 [qtp382627885-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-82453, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:28:48,145 [qtp382627885-20] INFO endpoint.BucketEndpoint: Location is /bucket-82453
s3g_1        | 2021-06-28 10:28:48,670 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:48,720 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B568C754C5C4->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:28:48,720 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:49,289 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:49,322 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0684632B1FFA->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:28:49,324 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:49,914 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:49,954 [qtp382627885-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BB7A5E61CA75->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:28:49,954 [qtp382627885-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:50,559 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:51,070 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:51,643 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:57,391 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:57,405 [qtp382627885-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-72724, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:28:57,422 [qtp382627885-20] INFO endpoint.BucketEndpoint: Location is /bucket-72724
s3g_1        | 2021-06-28 10:28:57,980 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:58,017 [qtp382627885-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F8025C12D9BF->87b0b3c6-67c6-498c-a3d3-879b3c6d2c21
s3g_1        | 2021-06-28 10:28:58,018 [qtp382627885-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1        | 2021-06-28 10:28:58,609 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:59,103 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:28:59,670 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:00,192 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:00,871 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:01,428 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:02,038 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:03,048 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:03,068 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=10000-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:29:03,613 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:04,218 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:04,794 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:05,361 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:05,914 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:06,427 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:07,018 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:07,626 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:08,206 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:08,223 [qtp382627885-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-0</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:29:08,730 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:08,739 [qtp382627885-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-1</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:29:09,207 [qtp382627885-19] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:09,219 [qtp382627885-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1        | <Error>
s3g_1        |   <Code>InvalidRange</Code>
s3g_1        |   <Message>The requested range is not satisfiable</Message>
s3g_1        |   <Resource>bytes=0-10000</Resource>
s3g_1        |   <RequestId/>
s3g_1        | </Error>
s3g_1        | 
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.<clinit>(S3ErrorTable.java:79)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:247)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1        | 2021-06-28 10:29:15,240 [qtp382627885-20] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:199)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1029)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:957)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2957)
s3g_1        | , while invoking $Proxy110.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2021-06-28 10:29:15,252 [qtp382627885-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-07422, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2021-06-28 10:29:15,275 [qtp382627885-20] INFO endpoint.BucketEndpoint: Location is /bucket-07422
